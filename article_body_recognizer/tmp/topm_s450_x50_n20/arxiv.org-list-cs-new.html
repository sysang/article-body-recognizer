<!DOCTYPE html>
<html>
<head>

      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

        <script> var url = encodeURIComponent('https://arxiv.org/list/cs/new');</script>

        <script> var body_html = '<body > <div > <div > <a >We gratefully acknowledge support from the Simons Foundation and member institutions.</a> </div> </div> <div > <h1><a >arXiv.org</a> &gt; <a >cs</a></h1> </div> <div > <div > <h1>Computer Science </h1> <h2>New submissions</h2> <div >Submissions received from Wed 8 Dec 21 to Thu 9 Dec 21, announced Fri, 10 Dec 21</div> <ul> <li><a >New submissions</a></li> <li><a >Cross-lists</a></li> <li><a >Replacements</a></li> </ul> <small>[ total of 409 entries: <b>1-409</b> ]</small> <small>[ showing up to 2000 entries per page: <a >fewer</a> | <font >more</font> ]</small> <h3>New submissions for Fri, 10 Dec 21</h3> <dl> <dt><a >[1]</a> arXiv:2112.04492 [pdf, other]</dt> <dd> <div > <div > Title: Daily peak electrical load forecasting with a multi-resolution approach </div> <div > Authors: Yvenn Amara-Ouali, <a >Matteo Fasiolo</a>, <a >Yannig Goude</a>, <a >Hui Yan</a> </div> <div > Subjects: Machine Learning (cs.LG); Methodology (stat.ME) </div> <p >In the context of smart grids and load balancing, daily peak load forecasting has become a critical activity for stakeholders of the energy industry. An understanding of peak magnitude and timing is paramount for the implementation of smart grid strategies such as peak shaving. The modelling approach proposed in this paper leverages high-resolution and low-resolution information to forecast daily peak demand size and timing. The resulting multi-resolution modelling framework can be adapted to different model classes. The key contributions of this paper are a) a general and formal introduction to the multi-resolution modelling approach, b) a discussion on modelling approaches at different resolutions implemented via Generalised Additive Models and Neural Networks and c) experimental results on real data from the UK electricity market. The results confirm that the predictive performance of the proposed modelling approach is competitive with that of low- and high-resolution alternatives. </p> </div> </dd> <dt>[2] arXiv:2112.04494 [pdf, other]</dt> <dd> <div > <div > Title: Deep Q-Learning Market Makers in a Multi-Agent Simulated Stock Market </div> <div > Authors: Oscar Fernández Vicente, <a >Fernando Fernández Rebollo</a>, <a >Francisco Javier García Polo</a> </div> <div > Comments: Presented at 2nd ACM International Conference on AI in Finance </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >Market makers play a key role in financial markets by providing liquidity. They usually fill order books with buy and sell limit orders in order to provide traders alternative price levels to operate. This paper focuses precisely on the study of these markets makers strategies from an agent-based perspective. In particular, we propose the application of Reinforcement Learning (RL) for the creation of intelligent market markers in simulated stock markets. This research analyzes how RL market maker agents behaves in non-competitive (only one RL market maker learning at the same time) and competitive scenarios (multiple RL market markers learning at the same time), and how they adapt their strategies in a Sim2Real scope with interesting results. Furthermore, it covers the application of policy transfer between different experiments, describing the impact of competing environments on RL agents performance. RL and deep RL techniques are proven as profitable market maker approaches, leading to a better understanding of their behavior in stock markets. </p> </div> </dd> <dt>[3] arXiv:2112.04497 [pdf, other]</dt> <dd> <div > <div > Title: SIRfyN: Single Image Relighting from your Neighbors </div> <div > Authors: D.A. Forsyth, <a >Anand Bhattad</a>, <a >Pranav Asthana</a>, <a >Yuanyi Zhong</a>, <a >Yuxiong Wang</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We show how to relight a scene, depicted in a single image, such that (a) the overall shading has changed and (b) the resulting image looks like a natural image of that scene. Applications for such a procedure include generating training data and building authoring environments. Naive methods for doing this fail. One reason is that shading and albedo are quite strongly related; for example, sharp boundaries in shading tend to appear at depth discontinuities, which usually apparent in albedo. The same scene can be lit in different ways, and established theory shows the different lightings form a cone (the illumination cone). Novel theory shows that one can use similar scenes to estimate the different lightings that apply to a given scene, with bounded expected error. Our method exploits this theory to estimate a representation of the available lighting fields in the form of imputed generators of the illumination cone. Our procedure does not require expensive "inverse graphics" datasets, and sees no ground truth data of any kind. Qualitative evaluation suggests the method can erase and restore soft indoor shadows, and can "steer" light around a scene. We offer a summary quantitative evaluation of the method with a novel application of the FID. An extension of the FID allows per-generated-image evaluation. Furthermore, we offer qualitative evaluation with a user study, and show that our method produces images that can successfully be used for data augmentation. </p> </div> </dd> <dt>[4] arXiv:2112.04532 [pdf, other]</dt> <dd> <div > <div > Title: Segment and Complete: Defending Object Detectors against Adversarial Patch Attacks with Robust Patch Detection </div> <div > Authors: Jiang Liu, <a >Alexander Levine</a>, <a >Chun Pong Lau</a>, <a >Rama Chellappa</a>, <a >Soheil Feizi</a> </div> <div > Comments: Under submission </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p >Object detection plays a key role in many security-critical systems. Adversarial patch attacks, which are easy to implement in the physical world, pose a serious threat to state-of-the-art object detectors. Developing reliable defenses for object detectors against patch attacks is critical but severely understudied. In this paper, we propose Segment and Complete defense (SAC), a general framework for defending object detectors against patch attacks through detecting and removing adversarial patches. We first train a patch segmenter that outputs patch masks that provide pixel-level localization of adversarial patches. We then propose a self adversarial training algorithm to robustify the patch segmenter. In addition, we design a robust shape completion algorithm, which is guaranteed to remove the entire patch from the images given the outputs of the patch segmenter are within a certain Hamming distance of the ground-truth patch masks. Our experiments on COCO and xView datasets demonstrate that SAC achieves superior robustness even under strong adaptive attacks with no performance drop on clean images, and generalizes well to unseen patch shapes, attack budgets, and unseen attack methods. Furthermore, we present the APRICOT-Mask dataset, which augments the APRICOT dataset with pixel-level annotations of adversarial patches. We show SAC can significantly reduce the targeted attack success rate of physical patch attacks. </p> </div> </dd> <dt>[5] arXiv:2112.04536 [pdf, other]</dt> <dd> <div > <div > Title: Adaptive CLF-MPC With Application To Quadrupedal Robots </div> <div > Authors: Maria Vittoria Minniti, <a >Ruben Grandia</a>, <a >Farbod Farshidian</a>, <a >Marco Hutter</a> </div> <div > Journal-ref: IEEE Robotics and Automation Letters (Volume: 7, Issue: 1, Jan. 2022) </div> <div > Subjects: Robotics (cs.RO); Systems and Control (eess.SY) </div> <p >Modern robotic systems are endowed with superior mobility and mechanical skills that make them suited to be employed in real-world scenarios, where interactions with heavy objects and precise manipulation capabilities are required. For instance, legged robots with high payload capacity can be used in disaster scenarios to remove dangerous material or carry injured people. It is thus essential to develop planning algorithms that can enable complex robots to perform motion and manipulation tasks accurately. In addition, online adaptation mechanisms with respect to new, unknown environments are needed. In this work, we impose that the optimal state-input trajectories generated by Model Predictive Control (MPC) satisfy the Lyapunov function criterion derived in adaptive control for robotic systems. As a result, we combine the stability guarantees provided by Control Lyapunov Functions (CLFs) and the optimality offered by MPC in a unified adaptive framework, yielding an improved performance during the robot's interaction with unknown objects. We validate the proposed approach in simulation and hardware tests on a quadrupedal robot carrying un-modeled payloads and pulling heavy boxes. </p> </div> </dd> <dt>[6] arXiv:2112.04539 [pdf, other]</dt> <dd> <div > <div > Title: Prompt-based Zero-shot Relation Classification with Semantic Knowledge Augmentation </div> <div > Authors: Jiaying Gong, <a >Hoda Eldardiry</a> </div> <div > Comments: 11 pages, 7 figures </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >Recognizing unseen relations with no training instances is a challenging task in the real world. In this paper, we propose a prompt-based model with semantic knowledge augmentation (ZS-SKA) to recognize unseen relations under the zero-shot setting. We generate augmented instances with unseen relations from instances with seen relations following a new word-level sentence translation rule. We design prompts based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. Instead of using the actual label sets in the prompt template, we construct weighted virtual label words. By generating the representations of both seen and unseen relations with augmented instances and prompts through prototypical networks, distance is calculated to predict unseen relations. Extensive experiments conducted on three public datasets show that ZS-SKA outperforms state-of-the-art methods under the zero-shot scenarios. Our experimental results also demonstrate the effectiveness and robustness of ZS-SKA. </p> </div> </dd> <dt>[7] arXiv:2112.04540 [pdf, ps, other]</dt> <dd> <div > <div > Title: Two-grid $hp$-version discontinuous Galerkin finite element methods for quasilinear elliptic PDEs on agglomerated coarse meshes </div> <div > Authors: Scott Congreve, <a >Paul Houston</a> </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >This article considers the extension of two-grid $hp$-version discontinuous Galerkin finite element methods for the numerical approximation of second-order quasilinear elliptic boundary value problems of monotone type to the case when agglomerated polygonal/polyhedral meshes are employed for the coarse mesh approximation. We recall that within the two-grid setting, while it is necessary to solve a nonlinear problem on the coarse approximation space, only a linear problem must be computed on the original fine finite element space. In this article, the coarse space will be constructed by agglomerating elements from the original fine mesh. Here, we extend the existing a priori and a posteriori error analysis for the two-grid $hp$-version discontinuous Galerkin finite element method from 10.1007/s10915-012-9644-1 for coarse meshes consisting of standard element shapes to include arbitrarily agglomerated coarse grids. Moreover, we develop an $hp$-adaptive two-grid algorithm to adaptively design the fine and coarse finite element spaces; we stress that this is undertaken in a fully automatic manner, and hence can be viewed as blackbox solver. Numerical experiments are presented for two- and three-dimensional problems to demonstrate the computational performance of the proposed $hp$-adaptive two-grid method. </p> </div> </dd> <dt>[8] arXiv:2112.04548 [pdf]</dt> <dd> <div > <div > Title: Relaxation of condition for convergence of dynamic regressor extension and mixing procedure </div> <div > Authors: Anton Glushchenko, <a >Konstantin Lastochkin</a> </div> <div > Comments: 17 pages. In Russian </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >A generalization of the dynamic regressor extension and mixing procedure is proposed. First of all, it relaxes the requirement of the regressor finite excitation, which is known to be the condition for the mentioned procedure convergence. Secondly, if the weaker requirement of the regressor semi-finite-excitation is met, it guarantees the uniform ultimate boundedness of the parameter error and elementwise monotonicity for transients of some parameters to be identified. </p> </div> </dd> <dt>[9] arXiv:2112.04549 [pdf, other]</dt> <dd> <div > <div > Title: A Simple Algorithm for Graph Reconstruction </div> <div > Authors: Claire Mathieu, <a >Hang Zhou</a> </div> <div > Subjects: Data Structures and Algorithms (cs.DS) </div> <p >How efficiently can we find an unknown graph using distance queries between its vertices? We assume that the unknown graph is connected, unweighted, and has bounded degree. The goal is to find every edge in the graph. This problem admits a reconstruction algorithm based on multi-phase Voronoi-cell decomposition and using $ilde O(n^{3/2})$ distance queries. In our work, we analyze a simple reconstruction algorithm. We show that, on random $\Delta$-regular graphs, our algorithm uses $ilde O(n)$ distance queries. As by-products, we can reconstruct those graphs using $O(\log^2 n)$ queries to an all-distances oracle or $ilde O(n)$ queries to a betweenness oracle, and we bound the metric dimension of those graphs by $\log^2 n$. Our reconstruction algorithm has a very simple structure, and is highly parallelizable. On general graphs of bounded degree, our reconstruction algorithm has subquadratic query complexity. </p> </div> </dd> <dt>[10] arXiv:2112.04550 [pdf, other]</dt> <dd> <div > <div > Title: NOMA Empowered Integrated Sensing and Communication </div> <div > Authors: Zhaolin Wang, <a >Yuanwei Liu</a>, <a >Xidong Mu</a>, <a >Zhiguo Ding</a>, <a >Octavia A. Dobre</a> </div> <div > Comments: 11 pages, 2 figures </div> <div > Subjects: Information Theory (cs.IT) </div> <p >A non-orthogonal multiple access (NOMA) empowered integrated sensing and communication (ISAC) framework is investigated. A dual-functional base station serves multiple communication users employing NOMA, while the superimposed NOMA communication signal is simultaneously exploited for target sensing. A beamforming design problem is formulated to maximize the weighted sum of the communication throughput and the effective sensing power. To solve this problem, an efficient double-layer penalty-based algorithm is proposed by invoking successive convex approximation (SCA). Numerical results show that the proposed NOMA-ISAC approaches the ideal ISAC system and outperforms the conventional ISAC in the underloaded regime experiencing high-correlated channels and in the overloaded regime. </p> </div> </dd> <dt>[11] arXiv:2112.04552 [pdf, other]</dt> <dd> <div > <div > Title: PATO: Producibility-Aware Topology Optimization using Deep Learning for Metal Additive Manufacturing </div> <div > Authors: Naresh S. Iyer, <a >Amir M. Mirzendehdel</a>, <a >Sathyanarayanan Raghavan</a>, <a >Yang Jiao</a>, <a >Erva Ulu</a>, <a >Morad Behandish</a>, <a >Saigopal Nelaturi</a>, <a >Dean M. Robinson</a> </div> <div > Subjects: Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >In this paper, we propose PATO-a producibility-aware topology optimization (TO) framework to help efficiently explore the design space of components fabricated using metal additive manufacturing (AM), while ensuring manufacturability with respect to cracking. Specifically, parts fabricated through Laser Powder Bed Fusion are prone to defects such as warpage or cracking due to high residual stress values generated from the steep thermal gradients produced during the build process. Maturing the design for such parts and planning their fabrication can span months to years, often involving multiple handoffs between design and manufacturing engineers. PATO is based on the a priori discovery of crack-free designs, so that the optimized part can be built defect-free at the outset. To ensure that the design is crack free during optimization, producibility is explicitly encoded within the standard formulation of TO, using a crack index. Multiple crack indices are explored and using experimental validation, maximum shear strain index (MSSI) is shown to be an accurate crack index. Simulating the build process is a coupled, multi-physics computation and incorporating it in the TO loop can be computationally prohibitive. We leverage the current advances in deep convolutional neural networks and present a high-fidelity surrogate model based on an Attention-based U-Net architecture to predict the MSSI values as a spatially varying field over the part's domain. Further, we employ automatic differentiation to directly compute the gradient of maximum MSSI with respect to the input design variables and augment it with the performance-based sensitivity field to optimize the design while considering the trade-off between weight, manufacturability, and functionality. We demonstrate the effectiveness of the proposed method through benchmark studies in 3D as well as experimental validation. </p> </div> </dd> <dt>[12] arXiv:2112.04554 [pdf, ps, other]</dt> <dd> <div > <div > Title: Whose Ground Truth? Accounting for Individual and Collective Identities Underlying Dataset Annotation </div> <div > Authors: Emily Denton, <a >Mark Díaz</a>, <a >Ian Kivlichan</a>, <a >Vinodkumar Prabhakaran</a>, <a >Rachel Rosen</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Human annotations play a crucial role in machine learning (ML) research and development. However, the ethical considerations around the processes and decisions that go into building ML datasets has not received nearly enough attention. In this paper, we survey an array of literature that provides insights into ethical considerations around crowdsourced dataset annotation. We synthesize these insights, and lay out the challenges in this space along two layers: (1) who the annotator is, and how the annotators' lived experiences can impact their annotations, and (2) the relationship between the annotators and the crowdsourcing platforms and what that relationship affords them. Finally, we put forth a concrete set of recommendations and considerations for dataset developers at various stages of the ML data pipeline: task formulation, selection of annotators, platform and infrastructure choices, dataset analysis and evaluation, and dataset documentation and release. </p> </div> </dd> <dt>[13] arXiv:2112.04558 [pdf, ps, other]</dt> <dd> <div > <div > Title: SoK: Anti-Facial Recognition Technology </div> <div > Authors: Emily Wenger, <a >Shawn Shan</a>, <a >Haitao Zheng</a>, <a >Ben Y. Zhao</a> </div> <div > Comments: 13 pages </div> <div > Subjects: Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >The rapid adoption of facial recognition (FR) technology by both government and commercial entities in recent years has raised concerns about civil liberties and privacy. In response, a broad suite of so-called "anti-facial recognition" (AFR) tools has been developed to help users avoid unwanted facial recognition. The set of AFR tools proposed in the last few years is wide-ranging and rapidly evolving, necessitating a step back to consider the broader design space of AFR systems and long-term challenges. This paper aims to fill that gap and provides the first comprehensive analysis of the AFR research landscape. Using the operational stages of FR systems as a starting point, we create a systematic framework for analyzing the benefits and tradeoffs of different AFR approaches. We then consider both technical and social challenges facing AFR tools and propose directions for future research in this field. </p> </div> </dd> <dt>[14] arXiv:2112.04559 [pdf, other]</dt> <dd> <div > <div > Title: Achieving Reliable Coordination of Residential Plug-in Electric Vehicle Charging: A Pilot Study </div> <div > Authors: Polina Alexeenko, <a >Eilyan Bitar</a> </div> <div > Comments: 19 pages, 12 figures </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >Wide-scale electrification of the transportation sector will require careful planning and coordination with the power grid. Left unmanaged, uncoordinated charging of electric vehicles (EVs) at increased levels of penetration will amplify existing peak loads, potentially outstripping the grid's capacity to reliably meet demand. In this paper, we report findings from the OptimizEV Project - a real-world pilot study in Upstate New York exploring a novel approach to coordinated residential EV charging. The proposed coordination mechanism seeks to harness the latent flexibility in EV charging by offering EV owners monetary incentives to delay the time required to charge their EVs. Each time an EV owner initiates a charging session, they specify how long they intend to leave their vehicle plugged in by selecting from a menu of deadlines that offers lower electricity prices the longer they're willing to delay the time required to charge their EV. Given a collection of active charging requests, a smart charging system dynamically optimizes the power being drawn by each EV in real time to minimize strain on the grid, while ensuring that each customer's car is fully charged by its deadline. Under the proposed incentive mechanism, we find that customers are frequently willing to engage in optimized charging sessions, allowing the system to delay the completion of their charging requests by more than eight hours on average. Using the flexibility provided by customers, the smart charging system was shown to be highly effective in shifting the majority of EV charging loads off-peak to fill the night-time valley of the aggregate load curve. Customer opt-in rates remained stable over the span of the study, providing empirical evidence in support of the proposed coordination mechanism as a potentially viable "non-wires alternative" to meet the increased demand for electricity driven growing EV adoption. </p> </div> </dd> <dt>[15] arXiv:2112.04563 [pdf, other]</dt> <dd> <div > <div > Title: Homogenization of higher-order continua </div> <div > Authors: Felix Schmid, <a >Melanie Krüger</a>, <a >Marc-Andre Keip</a>, <a >Christian Hesch</a> </div> <div > Subjects: Computational Engineering, Finance, and Science (cs.CE) </div> <p >We introduce a novel computational framework for the multiscale simulation of higher-order continua that allows for the consideration of first-, second- and third- order effects at both micro- and macro-level. In line with classical two-scale approaches, we describe the microstructure via representative volume elements (RVE) that are attached at each integration point of the macroscopic problem. To take account of the extended continuity requirements of independent fields at micro- and macro-level, we discretize both scales via isogeometric analysis (IGA). As a result, we obtain an IGA2-method that is conceptually similar to the well-known FE2-method. We demonstrate the functionality and accuracy of this novel multiscale method by means of a series of multiscale simulations involving different kinds of higher-order continua. </p> </div> </dd> <dt>[16] arXiv:2112.04564 [pdf, other]</dt> <dd> <div > <div > Title: CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning </div> <div > Authors: Yue Fan, <a >Dengxin Dai</a>, <a >Bernt Schiele</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >In this paper, we propose a novel co-learning framework (CoSSL) with decoupled representation learning and classifier learning for imbalanced SSL. To handle the data imbalance, we devise Tail-class Feature Enhancement (TFE) for classifier learning. Furthermore, the current evaluation protocol for imbalanced SSL focuses only on balanced test sets, which has limited practicality in real-world scenarios. Therefore, we further conduct a comprehensive evaluation under various shifted test distributions. In experiments, we show that our approach outperforms other methods over a large range of shifted distributions, achieving state-of-the-art performance on benchmark datasets ranging from CIFAR-10, CIFAR-100, ImageNet, to Food-101. Our code will be made publicly available. </p> </div> </dd> <dt>[17] arXiv:2112.04567 [pdf, other]</dt> <dd> <div > <div > Title: A simulation driven optimization algorithm for scheduling sorting center operations </div> <div > Authors: Supratim Ghosh, <a >Aritra Pal</a>, <a >Prashant Kumar</a>, <a >Ankush Ojha</a>, <a >Aditya Paranjape</a>, <a >Souvik Barat</a>, <a >Harshad Khadilkar</a> </div> <div > Comments: 12 pages, Winter Simulation Conference 2021 </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >Parcel sorting operations in logistics enterprises aim to achieve a high throughput of parcels through sorting centers. These sorting centers are composed of large circular conveyor belts on which incoming parcels are placed, with multiple arms known as chutes for sorting the parcels by destination, followed by packing into roller cages and loading onto outbound trucks. Modern sorting systems need to complement their hardware innovations with sophisticated algorithms and software to map destinations and workforce to specific chutes. While state of the art systems operate with fixed mappings, we propose an optimization approach that runs before every shift, and uses real-time forecast of destination demand and labor availability in order to maximize throughput. We use simulation to improve the performance and robustness of the optimization solution to stochasticity in the environment, through closed-loop tuning of the optimization parameters. </p> </div> </dd> <dt>[18] arXiv:2112.04570 [pdf, other]</dt> <dd> <div > <div > Title: Formalising Lie algebras </div> <div > Authors: Oliver Nash </div> <div > Comments: 12 pages, 1 figure, to appear in CPP 2022 </div> <div > Subjects: Logic in Computer Science (cs.LO); Representation Theory (math.RT) </div> <p >Lie algebras are an important class of algebras which arise throughout mathematics and physics. We report on the formalisation of Lie algebras in Lean's Mathlib library. Although basic knowledge of Lie theory will benefit the reader, none is assumed; the intention is that the overall themes will be accessible even to readers unfamiliar with Lie theory. Particular attention is paid to the construction of the classical and exceptional Lie algebras. Thanks to these constructions, it is possible to state the classification theorem for finite-dimensional semisimple Lie algebras over an algebraically closed field of characteristic zero. In addition to the focus on Lie theory, we also aim to highlight the unity of Mathlib. To this end, we include examples of achievements made possible only by leaning on several branches of the library simultaneously. </p> </div> </dd> <dt>[19] arXiv:2112.04571 [pdf, other]</dt> <dd> <div > <div > Title: Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach </div> <div > Authors: Soroush Saghafian </div> <div > Subjects: Machine Learning (cs.LG); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML) </div> <p >A main research goal in various studies is to use an observational data set and provide a new set of counterfactual guidelines that can yield causal improvements. Dynamic Treatment Regimes (DTRs) are widely studied to formalize this process. However, available methods in finding optimal DTRs often rely on assumptions that are violated in real-world applications (e.g., medical decision-making or public policy), especially when (a) the existence of unobserved confounders cannot be ignored, and (b) the unobserved confounders are time-varying (e.g., affected by previous actions). When such assumptions are violated, one often faces ambiguity regarding the underlying causal model that is needed to be assumed to obtain an optimal DTR. This ambiguity is inevitable, since the dynamics of unobserved confounders and their causal impact on the observed part of the data cannot be understood from the observed data. Motivated by a case study of finding superior treatment regimes for patients who underwent transplantation in our partner hospital and faced a medical condition known as New Onset Diabetes After Transplantation (NODAT), we extend DTRs to a new class termed Ambiguous Dynamic Treatment Regimes (ADTRs), in which the casual impact of treatment regimes is evaluated based on a "cloud" of potential causal models. We then connect ADTRs to Ambiguous Partially Observable Mark Decision Processes (APOMDPs) proposed by Saghafian (2018), and develop two Reinforcement Learning methods termed Direct Augmented V-Learning (DAV-Learning) and Safe Augmented V-Learning (SAV-Learning), which enable using the observed data to efficiently learn an optimal treatment regime. We establish theoretical results for these learning methods, including (weak) consistency and asymptotic normality. We further evaluate the performance of these learning methods both in our case study and in simulation experiments. </p> </div> </dd> <dt>[20] arXiv:2112.04572 [pdf, other]</dt> <dd> <div > <div > Title: Merging Subject Matter Expertise and Deep Convolutional Neural Network for State-Based Online Machine-Part Interaction Classification </div> <div > Authors: Hao Wang, Yassine Qamsane, <a >James Moyne</a>, <a >Kira Barton</a> </div> <div > Comments: Published at ASME Manufacturing Science and Engineering Conference (MSEC) </div> <div > Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY) </div> <p >Machine-part interaction classification is a key capability required by Cyber-Physical Systems (CPS), a pivotal enabler of Smart Manufacturing (SM). While previous relevant studies on the subject have primarily focused on time series classification, change point detection is equally important because it provides temporal information on changes in behavior of the machine. In this work, we address point detection and time series classification for machine-part interactions with a deep Convolutional Neural Network (CNN) based framework. The CNN in this framework utilizes a two-stage encoder-classifier structure for efficient feature representation and convenient deployment customization for CPS. Though data-driven, the design and optimization of the framework are Subject Matter Expertise (SME) guided. An SME defined Finite State Machine (FSM) is incorporated into the framework to prohibit intermittent misclassifications. In the case study, we implement the framework to perform machine-part interaction classification on a milling machine, and the performance is evaluated using a testing dataset and deployment simulations. The implementation achieved an average F1-Score of 0.946 across classes on the testing dataset and an average delay of 0.24 seconds on the deployment simulations. </p> </div> </dd> <dt>[21] arXiv:2112.04573 [pdf]</dt> <dd> <div > <div > Title: Application of Artificial Intelligence and Machine Learning in Libraries: A Systematic Review </div> <div > Authors: Rajesh Kumar Das, <a >Mohammad Sharif Ul Islam</a> </div> <div > Subjects: Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >As the concept and implementation of cutting-edge technologies like artificial intelligence and machine learning has become relevant, academics, researchers and information professionals involve research in this area. The objective of this systematic literature review is to provide a synthesis of empirical studies exploring application of artificial intelligence and machine learning in libraries. To achieve the objectives of the study, a systematic literature review was conducted based on the original guidelines proposed by Kitchenham et al. (2009). Data was collected from Web of Science, Scopus, LISA and LISTA databases. Following the rigorous/ established selection process, a total of thirty-two articles were finally selected, reviewed and analyzed to summarize on the application of AI and ML domain and techniques which are most often used in libraries. Findings show that the current state of the AI and ML research that is relevant with the LIS domain mainly focuses on theoretical works. However, some researchers also emphasized on implementation projects or case studies. This study will provide a panoramic view of AI and ML in libraries for researchers, practitioners and educators for furthering the more technology-oriented approaches, and anticipating future innovation pathways. </p> </div> </dd> <dt>[22] arXiv:2112.04575 [pdf, other]</dt> <dd> <div > <div > Title: Adaptive Kernel Graph Neural Network </div> <div > Authors: Mingxuan Ju, <a >Shifu Hou</a>, <a >Yujie Fan</a>, <a >Jianan Zhao</a>, <a >Liang Zhao</a>, <a >Yanfang Ye</a> </div> <div > Comments: To be appear at AAAI2022 </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Graph neural networks (GNNs) have demonstrated great success in representation learning for graph-structured data. The layer-wise graph convolution in GNNs is shown to be powerful at capturing graph topology. During this process, GNNs are usually guided by pre-defined kernels such as Laplacian matrix, adjacency matrix, or their variants. However, the adoptions of pre-defined kernels may restrain the generalities to different graphs: mismatch between graph and kernel would entail sub-optimal performance. For example, GNNs that focus on low-frequency information may not achieve satisfactory performance when high-frequency information is significant for the graphs, and vice versa. To solve this problem, in this paper, we propose a novel framework - i.e., namely Adaptive Kernel Graph Neural Network (AKGNN) - which learns to adapt to the optimal graph kernel in a unified manner at the first attempt. In the proposed AKGNN, we first design a data-driven graph kernel learning mechanism, which adaptively modulates the balance between all-pass and low-pass filters by modifying the maximal eigenvalue of the graph Laplacian. Through this process, AKGNN learns the optimal threshold between high and low frequency signals to relieve the generality problem. Later, we further reduce the number of parameters by a parameterization trick and enhance the expressive power by a global readout function. Extensive experiments are conducted on acknowledged benchmark datasets and promising results demonstrate the outstanding performance of our proposed AKGNN by comparison with state-of-the-art GNNs. The source code is publicly available at: https://github.com/jumxglhf/AKGNN. </p> </div> </dd> <dt>[23] arXiv:2112.04577 [pdf]</dt> <dd> <div > <div > Title: Gaussian Random Number Generator with Reconfigurable Mean and Variance using Stochastic Magnetic Tunnel Junctions </div> <div > Authors: Punyashloka Debashis, <a >Hai Li</a>, <a >Dmitri Nikonov</a>, <a >Ian Young</a> </div> <div > Comments: 14 pages, 5 figures </div> <div > Subjects: Emerging Technologies (cs.ET); Disordered Systems and Neural Networks (cond-mat.dis-nn); Mesoscale and Nanoscale Physics (cond-mat.mes-hall) </div> <p >Generating high-quality random numbers with a Gaussian probability distribution function is an important and resource consuming computational task for many applications in the fields of machine learning and Monte Carlo algorithms. Recently, CMOS-based digital hardware architectures have been explored as specialized Gaussian random number generators (GRNGs). These CMOS-based GRNGs have a large area and require entropy sources at their input which increase the computing cost. Here, we propose a GRNG that works on the principle of the Boltzmann law in a physical system made from an interconnected network of thermally unstable magnetic tunnel junctions. The proposed hardware can produce multi-bit Gaussian random numbers at a gigahertz speed and can be configured to generate distributions with a desired mean and variance. An analytical derivation of the required interconnection and bias strengths is provided followed by numerical simulations to demonstrate the functionalities of the GRNG. </p> </div> </dd> <dt>[24] arXiv:2112.04581 [pdf, other]</dt> <dd> <div > <div > Title: Building Usable Witness Encryption </div> <div > Authors: Gavin Uberti, <a >Kevin Luo</a>, <a >Oliver Cheng</a>, <a >Wittmann Goh</a> </div> <div > Comments: 21 pages, 3 figures </div> <div > Subjects: Cryptography and Security (cs.CR) </div> <p >Witness encryption using multilinear maps was first proposed in 2013, and has continued to evolve since. In this paper, we build on an open-source multilinear map implementation by Carmer and Malozemoff of the graded encoding scheme CLT13 with asymmetric modifications. Using this map, we created the world's first ciphertext encoded with a candidate witness encryption scheme. Finally, using a reduction from Sudoku to Exact Cover, we encrypted the private key to a Bitcoin wallet with 22,700 Satoshi using a Sudoku. </p> </div> </dd> <dt>[25] arXiv:2112.04583 [pdf, other]</dt> <dd> <div > <div > Title: Estimating Divergences in High Dimensions </div> <div > Authors: Loong Kuan Lee, <a >Nico Piatkowski</a>, <a >François Petitjean</a>, <a >Geoffrey I. Webb</a> </div> <div > Comments: 13 pages, 6 Figures. Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >The problem of estimating the divergence between 2 high dimensional distributions with limited samples is an important problem in various fields such as machine learning. Although previous methods perform well with moderate dimensional data, their accuracy starts to degrade in situations with 100s of binary variables. Therefore, we propose the use of decomposable models for estimating divergences in high dimensional data. These allow us to factorize the estimated density of the high-dimensional distribution into a product of lower dimensional functions. We conduct formal and experimental analyses to explore the properties of using decomposable models in the context of divergence estimation. To this end, we show empirically that estimating the Kullback-Leibler divergence using decomposable models from a maximum likelihood estimator outperforms existing methods for divergence estimation in situations where dimensionality is high and useful decomposable models can be learnt from the available data. </p> </div> </dd> <dt>[26] arXiv:2112.04585 [pdf, other]</dt> <dd> <div > <div > Title: STAF: A Spatio-Temporal Attention Fusion Network for Few-shot Video Classification </div> <div > Authors: Rex Liu, <a >Huanle Zhang</a>, <a >Hamed Pirsiavash</a>, <a >Xin Liu</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >We propose STAF, a Spatio-Temporal Attention Fusion network for few-shot video classification. STAF first extracts coarse-grained spatial and temporal features of videos by applying a 3D Convolution Neural Networks embedding network. It then fine-tunes the extracted features using self-attention and cross-attention networks. Last, STAF applies a lightweight fusion network and a nearest neighbor classifier to classify each query video. To evaluate STAF, we conduct extensive experiments on three benchmarks (UCF101, HMDB51, and Something-Something-V2). The experimental results show that STAF improves state-of-the-art accuracy by a large margin, e.g., STAF increases the five-way one-shot accuracy by 5.3% and 7.0% for UCF101 and HMDB51, respectively. </p> </div> </dd> <dt>[27] arXiv:2112.04588 [pdf, ps, other]</dt> <dd> <div > <div > Title: A Critical Comparison on Attitude Estimation: From Gaussian Approximate Filters to Coordinate-free Dual Optimal Control </div> <div > Authors: Nikolaos Koumpis, <a >Panagiotis Panagiotou</a>, <a >Ioannis Arvanitakis</a> </div> <div > Comments: Accept </div> <div > Journal-ref: IET Control Theory Applications, Volume 15,19 February 2021, Issue 10, p. 1297-1313 </div> <div > Subjects: Systems and Control (eess.SY); Dynamical Systems (math.DS) </div> <p >This paper conveys attitude and rate estimation without rate sensors by performing a critical comparison, validated by extensive simulations. The two dominant approaches to facilitate attitude estimation are based on stochastic and set-membership reasoning. The first one mostly utilizes the commonly known Gaussian-approximate filters, namely the EKF and UKF. Although more conservative, the latter seems to be more promising as it considers the inherent geometric characteristics of the underline compact state space and accounts -- from first principles -- for large model errors. We address the set-theoretic approach from a control point of view, and we show that it can overcome reported deficiencies of the Bayesian architectures related to this problem, leading to coordinate-free optimal filters. Lastly, as an example, we derive a modified predictive filter on the tangent bundle of the special orthogonal group $\mathbb{TSO}(3)$. </p> </div> </dd> <dt>[28] arXiv:2112.04590 [pdf, ps, other]</dt> <dd> <div > <div > Title: The perils of being unhinged: On the accuracy of classifiers minimizing a noise-robust convex loss </div> <div > Authors: Philip M. Long, <a >Rocco A. Servedio</a> </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >van Rooyen et al. introduced a notion of convex loss functions being robust to random classification noise, and established that the "unhinged" loss function is robust in this sense. In this note we study the accuracy of binary classifiers obtained by minimizing the unhinged loss, and observe that even for simple linearly separable data distributions, minimizing the unhinged loss may only yield a binary classifier with accuracy no better than random guessing. </p> </div> </dd> <dt>[29] arXiv:2112.04591 [pdf, ps, other]</dt> <dd> <div > <div > Title: Variational Regularization in Inverse Problems and Machine Learning </div> <div > Authors: Martin Burger </div> <div > Subjects: Machine Learning (cs.LG); Numerical Analysis (math.NA); Optimization and Control (math.OC) </div> <p >This paper discusses basic results and recent developments on variational regularization methods, as developed for inverse problems. In a typical setup we review basic properties needed to obtain a convergent regularization scheme and further discuss the derivation of quantitative estimates respectively needed ingredients such as Bregman distances for convex functionals. In addition to the approach developed for inverse problems we will also discuss variational regularization in machine learning and work out some connections to the classical regularization theory. In particular we will discuss a reinterpretation of machine learning problems in the framework of regularization theory and a reinterpretation of variational methods for inverse problems in the framework of risk minimization. Moreover, we establish some previously unknown connections between error estimates in Bregman distances and generalization errors. </p> </div> </dd> <dt>[30] arXiv:2112.04596 [pdf, other]</dt> <dd> <div > <div > Title: Refined Commonsense Knowledge from Large-Scale Web Contents </div> <div > Authors: Tuan-Phong Nguyen, <a >Simon Razniewski</a>, <a >Julien Romero</a>, <a >Gerhard Weikum</a> </div> <div > Comments: This is a substantial extension of the WWW paper (<a >arXiv:2011.00905</a>). arXiv admin note: substantial text overlap with <a >arXiv:2011.00905</a> </div> <div > Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> <p >Commonsense knowledge (CSK) about concepts and their properties is useful for AI applications. Prior works like ConceptNet, COMET and others compiled large CSK collections, but are restricted in their expressiveness to subject-predicate-object (SPO) triples with simple concepts for S and strings for P and O. This paper presents a method, called ASCENT++, to automatically build a large-scale knowledge base (KB) of CSK assertions, with refined expressiveness and both better precision and recall than prior works. ASCENT++ goes beyond SPO triples by capturing composite concepts with subgroups and aspects, and by refining assertions with semantic facets. The latter is important to express the temporal and spatial validity of assertions and further qualifiers. ASCENT++ combines open information extraction with judicious cleaning and ranking by typicality and saliency scores. For high coverage, our method taps into the large-scale crawl C4 with broad web contents. The evaluation with human judgements shows the superior quality of the ASCENT++ KB, and an extrinsic evaluation for QA-support tasks underlines the benefits of ASCENT++. A web interface, data and code can be accessed at https://www.mpi-inf.mpg.de/ascentpp. </p> </div> </dd> <dt>[31] arXiv:2112.04598 [pdf, other]</dt> <dd> <div > <div > Title: InvGAN: Invertable GANs </div> <div > Authors: Partha Ghosh, <a >Dominik Zietlow</a>, <a >Michael J. Black</a>, <a >Larry S. Davis</a>, <a >Xiaochen Hu</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Generation of photo-realistic images, semantic editing and representation learning are a few of many potential applications of high resolution generative models. Recent progress in GANs have established them as an excellent choice for such tasks. However, since they do not provide an inference model, image editing or downstream tasks such as classification can not be done on real images using the GAN latent space. Despite numerous efforts to train an inference model or design an iterative method to invert a pre-trained generator, previous methods are dataset (e.g. human face images) and architecture (e.g. StyleGAN) specific. These methods are nontrivial to extend to novel datasets or architectures. We propose a general framework that is agnostic to architecture and datasets. Our key insight is that, by training the inference and the generative model together, we allow them to adapt to each other and to converge to a better quality model. Our extbf{InvGAN}, short for Invertable GAN, successfully embeds real images to the latent space of a high quality generative model. This allows us to perform image inpainting, merging, interpolation and online data augmentation. We demonstrate this with extensive qualitative and quantitative experiments. </p> </div> </dd> <dt>[32] arXiv:2112.04602 [pdf, other]</dt> <dd> <div > <div > Title: Adaptive packet transmission in response to anomaly detection in software defined smart meter networks </div> <div > Authors: Mihnea Maris, <a >Thomas Halpin</a>, <a >Dubem Ezeh</a>, <a >Karen Miu</a>, <a >Jaudelice de Oliveira</a> </div> <div > Subjects: Networking and Internet Architecture (cs.NI) </div> <p >In this paper, we examine a basic smart meter network topology in mininet and address the issue of congestion over a commodity network, proposing an adaptive algorithm to cope with varying grid data delivery latencies. </p> </div> </dd> <dt>[33] arXiv:2112.04603 [pdf, other]</dt> <dd> <div > <div > Title: A Unified Architecture of Semantic Segmentation and Hierarchical Generative Adversarial Networks for Expression Manipulation </div> <div > Authors: Rumeysa Bodur, <a >Binod Bhattarai</a>, <a >Tae-Kyun Kim</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Editing facial expressions by only changing what we want is a long-standing research problem in Generative Adversarial Networks (GANs) for image manipulation. Most of the existing methods that rely only on a global generator usually suffer from changing unwanted attributes along with the target attributes. Recently, hierarchical networks that consist of both a global network dealing with the whole image and multiple local networks focusing on local parts are showing success. However, these methods extract local regions by bounding boxes centred around the sparse facial key points which are non-differentiable, inaccurate and unrealistic. Hence, the solution becomes sub-optimal, introduces unwanted artefacts degrading the overall quality of the synthetic images. Moreover, a recent study has shown strong correlation between facial attributes and local semantic regions. To exploit this relationship, we designed a unified architecture of semantic segmentation and hierarchical GANs. A unique advantage of our framework is that on forward pass the semantic segmentation network conditions the generative model, and on backward pass gradients from hierarchical GANs are propagated to the semantic segmentation network, which makes our framework an end-to-end differentiable architecture. This allows both architectures to benefit from each other. To demonstrate its advantages, we evaluate our method on two challenging facial expression translation benchmarks, AffectNet and RaFD, and a semantic segmentation benchmark, CelebAMask-HQ across two popular architectures, BiSeNet and UNet. Our extensive quantitative and qualitative evaluations on both face semantic segmentation and face expression manipulation tasks validate the effectiveness of our work over existing state-of-the-art methods. </p> </div> </dd> <dt>[34] arXiv:2112.04604 [pdf, other]</dt> <dd> <div > <div > Title: Regularization methods for the short-term forecasting of the Italian electric load </div> <div > Authors: Alessandro Incremona, <a >Giuseppe De Nicolao</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >The problem of forecasting the whole 24 profile of the Italian electric load is addressed as a multitask learning problem, whose complexity is kept under control via alternative regularization methods. In view of the quarter-hourly samplings, 96 predictors are used, each of which linearly depends on 96 regressors. The 96x96 matrix weights form a 96x96 matrix, that can be seen and displayed as a surface sampled on a square domain. Different regularization and sparsity approaches to reduce the degrees of freedom of the surface were explored, comparing the obtained forecasts with those of the Italian Transmission System Operator Terna. Besides outperforming Terna in terms of quarter-hourly mean absolute percentage error and mean absolute error, the prediction residuals turned out to be weakly correlated with Terna, which suggests that further improvement could ensue from forecasts aggregation. In fact, the aggregated forecasts yielded further relevant drops in terms of quarter-hourly and daily mean absolute percentage error, mean absolute error and root mean square error (up to 30%) over the three test years considered. </p> </div> </dd> <dt>[35] arXiv:2112.04605 [pdf, other]</dt> <dd> <div > <div > Title: Prediction of Adverse Biological Effects of Chemicals Using Knowledge Graph Embeddings </div> <div > Authors: Erik B. Myklebust, Ernesto Jiménez-Ruiz, <a >Jiaoyan Chen</a>, <a >Raoul Wolf</a>, <a >Knut Erik Tollefsen</a> </div> <div > Comments: Accepted for publication in the Semantic Web Journal </div> <div > Subjects: Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >We have created a knowledge graph based on major data sources used in ecotoxicological risk assessment. We have applied this knowledge graph to an important task in risk assessment, namely chemical effect prediction. We have evaluated nine knowledge graph embedding models from a selection of geometric, decomposition, and convolutional models on this prediction task. We show that using knowledge graph embeddings can increase the accuracy of effect prediction with neural networks. Furthermore, we have implemented a fine-tuning architecture which adapts the knowledge graph embeddings to the effect prediction task and leads to a better performance. Finally, we evaluate certain characteristics of the knowledge graph embedding models to shed light on the individual model performance. </p> </div> </dd> <dt>[36] arXiv:2112.04607 [pdf, other]</dt> <dd> <div > <div > Title: Constrained Mean Shift Using Distant Yet Related Neighbors for Representation Learning </div> <div > Authors: Ajinkya Tejankar, <a >Soroush Abbasi Koohpayegani</a>, <a >KL Navaneet</a>, <a >Kossar Pourahmadi</a>, <a >Akshayvarun Subramanya</a>, <a >Hamed Pirsiavash</a> </div> <div > Comments: Code is available at <a >this https URL</a> arXiv admin note: text overlap with <a >arXiv:2110.10309</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We are interested in representation learning in self-supervised, supervised, or semi-supervised settings. The prior work on applying mean-shift idea for self-supervised learning, MSF, generalizes the BYOL idea by pulling a query image to not only be closer to its other augmentation, but also to the nearest neighbors (NNs) of its other augmentation. We believe the learning can benefit from choosing far away neighbors that are still semantically related to the query. Hence, we propose to generalize MSF algorithm by constraining the search space for nearest neighbors. We show that our method outperforms MSF in SSL setting when the constraint utilizes a different augmentation of an image, and outperforms PAWS in semi-supervised setting with less training resources when the constraint ensures the NNs have the same pseudo-label as the query. </p> </div> </dd> <dt>[37] arXiv:2112.04608 [pdf, other]</dt> <dd> <div > <div > Title: Enhancing Food Intake Tracking in Long-Term Care with Automated Food Imaging and Nutrient Intake Tracking (AFINI-T) Technology </div> <div > Authors: Kaylen J. Pfisterer, <a >Robert Amelard</a>, <a >Jennifer Boger</a>, <a >Audrey G. Chung</a>, <a >Heather H. Keller</a>, <a >Alexander Wong</a> </div> <div > Comments: Key words: Automatic segmentation, convolutional neural network, deep learning, food intake tracking, volume estimation, malnutrition prevention, long-term care, hospital </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >Half of long-term care (LTC) residents are malnourished increasing hospitalization, mortality, morbidity, with lower quality of life. Current tracking methods are subjective and time consuming. This paper presents the automated food imaging and nutrient intake tracking (AFINI-T) technology designed for LTC. We propose a novel convolutional autoencoder for food classification, trained on an augmented UNIMIB2016 dataset and tested on our simulated LTC food intake dataset (12 meal scenarios; up to 15 classes each; top-1 classification accuracy: 88.9%; mean intake error: -0.4 mL$\pm$36.7 mL). Nutrient intake estimation by volume was strongly linearly correlated with nutrient estimates from mass ($r^2$ 0.92 to 0.99) with good agreement between methods ($\sigma$= -2.7 to -0.01; zero within each of the limits of agreement). The AFINI-T approach is a deep-learning powered computational nutrient sensing system that may provide a novel means for more accurately and objectively tracking LTC resident food intake to support and prevent malnutrition tracking strategies. </p> </div> </dd> <dt>[38] arXiv:2112.04610 [pdf, other]</dt> <dd> <div > <div > Title: A Simple and efficient deep Scanpath Prediction </div> <div > Authors: Mohamed Amine Kerkouri, <a >Aladine Chetouani</a> </div> <div > Comments: Electronic Imaging Symposium 2022 (EI 2022) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Visual scanpath is the sequence of fixation points that the human gaze travels while observing an image, and its prediction helps in modeling the visual attention of an image. To this end several models were proposed in the literature using complex deep learning architectures and frameworks. Here, we explore the efficiency of using common deep learning architectures, in a simple fully convolutional regressive manner. We experiment how well these models can predict the scanpaths on 2 datasets. We compare with other models using different metrics and show competitive results that sometimes surpass previous complex architectures. We also compare the different leveraged backbone architectures based on their performances on the experiment to deduce which ones are the most suitable for the task. </p> </div> </dd> <dt>[39] arXiv:2112.04612 [pdf, other]</dt> <dd> <div > <div > Title: Gaussian Process Constraint Learning for Scalable Chance-Constrained Motion Planning from Demonstrations </div> <div > Authors: Glen Chou, <a >Hao Wang</a>, <a >Dmitry Berenson</a> </div> <div > Comments: Under review at RA-L + ICRA 2022 </div> <div > Subjects: Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY) </div> <p >We propose a method for learning constraints represented as Gaussian processes (GPs) from locally-optimal demonstrations. Our approach uses the Karush-Kuhn-Tucker (KKT) optimality conditions to determine where on the demonstrations the constraint is tight, and a scaling of the constraint gradient at those states. We then train a GP representation of the constraint which is consistent with and which generalizes this information. We further show that the GP uncertainty can be used within a kinodynamic RRT to plan probabilistically-safe trajectories, and that we can exploit the GP structure within the planner to exactly achieve a specified safety probability. We demonstrate our method can learn complex, nonlinear constraints demonstrated on a 5D nonholonomic car, a 12D quadrotor, and a 3-link planar arm, all while requiring minimal prior information on the constraint. Our results suggest the learned GP constraint is accurate, outperforming previous constraint learning methods that require more a priori knowledge. </p> </div> </dd> <dt>[40] arXiv:2112.04613 [pdf, other]</dt> <dd> <div > <div > Title: NICE-Beam: Neural Integrated Covariance Estimators for Time-Varying Beamformers </div> <div > Authors: Jonah Casebeer, <a >Jacob Donley</a>, <a >Daniel Wong</a>, <a >Buye Xu</a>, <a >Anurag Kumar</a> </div> <div > Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p >Estimating a time-varying spatial covariance matrix for a beamforming algorithm is a challenging task, especially for wearable devices, as the algorithm must compensate for time-varying signal statistics due to rapid pose-changes. In this paper, we propose Neural Integrated Covariance Estimators for Beamformers, NICE-Beam. NICE-Beam is a general technique for learning how to estimate time-varying spatial covariance matrices, which we apply to joint speech enhancement and dereverberation. It is based on training a neural network module to non-linearly track and leverage scene information across time. We integrate our solution into a beamforming pipeline, which enables simple training, faster than real-time inference, and a variety of test-time adaptation options. We evaluate the proposed model against a suite of baselines in scenes with both stationary and moving microphones. Our results show that the proposed method can outperform a hand-tuned estimator, despite the hand-tuned estimator using oracle source separation knowledge. </p> </div> </dd> <dt>[41] arXiv:2112.04619 [pdf]</dt> <dd> <div > <div > Title: Taxonomy of Virtual and Augmented Reality Applications in Education </div> <div > Authors: Jiri Motejlek, <a >Esat Alpay</a> </div> <div > Subjects: Human-Computer Interaction (cs.HC) </div> <p >This paper presents and analyses existing taxonomies of virtual and augmented reality and demonstrates knowledge gaps and mixed terminology which may cause confusion among educators, researchers, and developers. Several such occasions of confusion are presented. A methodology is then presented to construct a taxonomy of virtual reality and augmented reality applications based on a combination of: a faceted analysis approach for the overall design of the taxonomy; an existing taxonomy of educational objectives to derive the educational purpose; an information systems analysis to establish important facets of the taxonomy; and two systematic mapping studies to identify categories within each facet. Based onUsing thisthe methodology a new taxonomy is proposed and the implications of its facets (and their combinations of facets)are demonstrated. The taxonomy focuses on technology used to provide the virtual or augmented reality as well as the content presented to the user, including the type of gamification and how it is operated. It also takes into accountaccommodates a large number of devices and approaches developed throughout the years and for multiple industries, and proposes and developsprovides a way to categorize them in order to clarify communication between researchers, developers and as well as educators. Use of the taxonomy and implications of choices made during their development is then demonstrated ion two case studies:, a virtual reality chemical plant for use in chemical engineering education and an augmented reality dog for veterinary education. </p> </div> </dd> <dt>[42] arXiv:2112.04620 [pdf, other]</dt> <dd> <div > <div > Title: Calibration Improves Bayesian Optimization </div> <div > Authors: Shachi Deshpande, <a >Volodymyr Kuleshov</a> </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Bayesian optimization is a procedure that allows obtaining the global optimum of black-box functions and that is useful in applications such as hyper-parameter optimization. Uncertainty estimates over the shape of the objective function are instrumental in guiding the optimization process. However, these estimates can be inaccurate if the objective function violates assumptions made within the underlying model (e.g., Gaussianity). We propose a simple algorithm to calibrate the uncertainty of posterior distributions over the objective function as part of the Bayesian optimization process. We show that by improving the uncertainty estimates of the posterior distribution with calibration, Bayesian optimization makes better decisions and arrives at the global optimum in fewer steps. We show that this technique improves the performance of Bayesian optimization on standard benchmark functions and hyperparameter optimization tasks. </p> </div> </dd> <dt>[43] arXiv:2112.04622 [pdf, other]</dt> <dd> <div > <div > Title: Greedy Algorithm for Multiway Matching with Bounded Regret </div> <div > Authors: Varun Gupta </div> <div > Subjects: Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC); Probability (math.PR) </div> <p >In this paper we prove the efficacy of a simple greedy algorithm for a finite horizon online resource allocation/matching problem, when the corresponding static planning linear program (SPP) exhibits a non-degeneracy condition called the general position gap (GPG). The key intuition that we formalize is that the solution of the reward maximizing SPP is the same as a feasibility LP restricted to the optimal basic activities, and under GPG this solution can be tracked with bounded regret by a greedy algorithm, i.e., without the commonly used technique of periodically resolving the SPP. The goal of the decision maker is to combine resources (from a finite set of resource types) into configurations (from a finite set of feasible configurations) where each configuration is specified by the number of resources consumed of each type and a reward. The resources are further subdivided into three types - offline (whose quantity is known and available at time 0), online-queueable (which arrive online and can be stored in a buffer), and online-nonqueueable (which arrive online and must be matched on arrival or lost). Under GRG we prove that, (i) our greedy algorithm gets bounded any-time regret for matching reward (independent of $t$) when no configuration contains both an online-queueable and an online-nonqueueable resource, and (ii) $\mathcal{O}(\log t)$ expected any-time regret otherwise (we also prove a matching lower bound). By considering the three types of resources, our matching framework encompasses several well-studied problems such as dynamic multi-sided matching, network revenue management, online stochastic packing, and multiclass queueing systems. </p> </div> </dd> <dt>[44] arXiv:2112.04623 [pdf, other]</dt> <dd> <div > <div > Title: Efficient Checking of Temporal Compliance Rules Over Business Process Event Logs </div> <div > Authors: Adriano Augusto, <a >Ahmed Awad</a>, <a >Marlon Dumas</a> </div> <div > Subjects: Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE) </div> <p >Verifying temporal compliance rules, such as a rule stating that an inquiry must be answered within a time limit, is a recurrent operation in the realm of business process compliance. In this setting, a typical use case is one where a manager seeks to retrieve all cases where a temporal rule is violated, given an event log recording the execution of a process over a time period. Existing approaches for checking temporal rules require a full scan of the log. Such approaches are unsuitable for interactive use when the log is large and the set of compliance rules is evolving. This paper proposes an approach to evaluate temporal compliance rules in sublinear time by pre-computing a data structure that summarizes the temporal relations between activities in a log. The approach caters for a wide range of temporal compliance patterns and supports incremental updates. Our evaluation on twenty real-life logs shows that our data structure allows for real-time checking of a large set of compliance rules. </p> </div> </dd> <dt>[45] arXiv:2112.04628 [pdf, other]</dt> <dd> <div > <div > Title: Learning Auxiliary Monocular Contexts Helps Monocular 3D Object Detection </div> <div > Authors: Xianpeng Liu, <a >Nan Xue</a>, <a >Tianfu Wu</a> </div> <div > Journal-ref: Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-2022) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Monocular 3D object detection aims to localize 3D bounding boxes in an input single 2D image. It is a highly challenging problem and remains open, especially when no extra information (e.g., depth, lidar and/or multi-frames) can be leveraged in training and/or inference. This paper proposes a simple yet effective formulation for monocular 3D object detection without exploiting any extra information. It presents the MonoCon method which learns Monocular Contexts, as auxiliary tasks in training, to help monocular 3D object detection. The key idea is that with the annotated 3D bounding boxes of objects in an image, there is a rich set of well-posed projected 2D supervision signals available in training, such as the projected corner keypoints and their associated offset vectors with respect to the center of 2D bounding box, which should be exploited as auxiliary tasks in training. The proposed MonoCon is motivated by the Cramer-Wold theorem in measure theory at a high level. In implementation, it utilizes a very simple end-to-end design to justify the effectiveness of learning auxiliary monocular contexts, which consists of three components: a Deep Neural Network (DNN) based feature backbone, a number of regression head branches for learning the essential parameters used in the 3D bounding box prediction, and a number of regression head branches for learning auxiliary contexts. After training, the auxiliary context regression branches are discarded for better inference efficiency. In experiments, the proposed MonoCon is tested in the KITTI benchmark (car, pedestrain and cyclist). It outperforms all prior arts in the leaderboard on car category and obtains comparable performance on pedestrian and cyclist in terms of accuracy. Thanks to the simple design, the proposed MonoCon method obtains the fastest inference speed with 38.7 fps in comparisons </p> </div> </dd> <dt>[46] arXiv:2112.04629 [pdf, other]</dt> <dd> <div > <div > Title: Transferability Properties of Graph Neural Networks </div> <div > Authors: Luana Ruiz, <a >Luiz F. O. Chamon</a>, <a >Alejandro Ribeiro</a> </div> <div > Comments: Submitted to IEEE TSP </div> <div > Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP) </div> <p >Graph neural networks (GNNs) are deep convolutional architectures consisting of layers composed by graph convolutions and pointwise nonlinearities. Due to their invariance and stability properties, GNNs are provably successful at learning representations from network data. However, training them requires matrix computations which can be expensive for large graphs. To address this limitation, we investigate the ability of GNNs to be transferred across graphs. We consider graphons, which are both graph limits and generative models for weighted and stochastic graphs, to define limit objects of graph convolutions and GNNs -- graphon convolutions and graphon neural networks (WNNs) -- which we use as generative models for graph convolutions and GNNs. We show that these graphon filters and WNNs can be approximated by graph filters and GNNs sampled from them on weighted and stochastic graphs. Using these results, we then derive error bounds for transferring graph filters and GNNs across such graphs. These bounds show that transferability increases with the graph size, and reveal a tradeoff between transferability and spectral discriminability which in GNNs is alleviated by the pointwise nonlinearities. These findings are further verified empirically in numerical experiments in movie recommendation and decentralized robot control. </p> </div> </dd> <dt>[47] arXiv:2112.04630 [pdf, other]</dt> <dd> <div > <div > Title: Towards Neural Functional Program Evaluation </div> <div > Authors: Torsten Scholak, <a >Jonathan Pilault</a>, <a >Joey Velez-Ginorio</a> </div> <div > Comments: 9 pages. Accepted at the AIPLANS workshop at NeurIPS 2021 </div> <div > Subjects: Computation and Language (cs.CL); Programming Languages (cs.PL) </div> <p >This paper explores the capabilities of current transformer-based language models for program evaluation of simple functional programming languages. We introduce a new program generation mechanism that allows control over syntactic sugar for semantically equivalent programs. T5 experiments reveal that neural functional program evaluation performs surprisingly well, achieving high 90% exact program match scores for most in-distribution and out-of-distribution tests. Using pretrained T5 weights has significant advantages over random initialization. We present and evaluate on three datasets to study generalization abilities that are specific to functional programs based on: type, function composition, and reduction steps. Code and data are publicly available at https://github.com/ElementAI/neural-interpreters. </p> </div> </dd> <dt>[48] arXiv:2112.04632 [pdf, other]</dt> <dd> <div > <div > Title: Recurrent Glimpse-based Decoder for Detection with Transformer </div> <div > Authors: Zhe Chen, <a >Jing Zhang</a>, <a >Dacheng Tao</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Although detection with Transformer (DETR) is increasingly popular, its global attention modeling requires an extremely long training period to optimize and achieve promising detection performance. Alternative to existing studies that mainly develop advanced feature or embedding designs to tackle the training issue, we point out that the Region-of-Interest (RoI) based detection refinement can easily help mitigate the difficulty of training for DETR methods. Based on this, we introduce a novel REcurrent Glimpse-based decOder (REGO) in this paper. In particular, the REGO employs a multi-stage recurrent processing structure to help the attention of DETR gradually focus on foreground objects more accurately. In each processing stage, visual features are extracted as glimpse features from RoIs with enlarged bounding box areas of detection results from the previous stage. Then, a glimpse-based decoder is introduced to provide refined detection results based on both the glimpse features and the attention modeling outputs of the previous stage. In practice, REGO can be easily embedded in representative DETR variants while maintaining their fully end-to-end training and inference pipelines. In particular, REGO helps Deformable DETR achieve 44.8 AP on the MSCOCO dataset with only 36 training epochs, compared with the first DETR and the Deformable DETR that require 500 and 50 epochs to achieve comparable performance, respectively. Experiments also show that REGO consistently boosts the performance of different DETR detectors by up to 7% relative gain at the same setting of 50 training epochs. Code is available via https://github.com/zhechen/Deformable-DETR-REGO. </p> </div> </dd> <dt>[49] arXiv:2112.04634 [pdf, other]</dt> <dd> <div > <div > Title: Process Mining-Driven Analysis of the COVID19 Impact on the Vaccinations of Victorian Patients </div> <div > Authors: Adriano Augusto, <a >Timothy Deitz</a>, <a >Noel Faux</a>, <a >Jo-Anne Manski-Nankervis</a>, <a >Daniel Capurro</a> </div> <div > Subjects: Databases (cs.DB); Computers and Society (cs.CY) </div> <p >Process mining is a discipline sitting between data mining and process science, whose goal is to provide theoretical methods and software tools to analyse process execution data, known as event logs. Although process mining was originally conceived to facilitate business process management activities, research studies have shown the benefit of leveraging process mining tools in different contexts, including healthcare. However, applying process mining tools to analyse healthcare process execution data is not straightforward. In this paper, we report the analysis of an event log recording more than 30 million events capturing the general practice healthcare processes of more than one million patients in Victoria--Australia--over five years. Our analysis allowed us to understand benefits and limitations of the state-of-the-art process mining techniques when dealing with highly variable processes and large data-sets. While we provide solutions to the identified limitations, the overarching goal of this study was to detect differences between the patients` health services utilization pattern observed in 2020--during the COVID-19 pandemic and mandatory lock-downs --and the one observed in the prior four years, 2016 to 2019. By using a combination of process mining techniques and traditional data mining, we were able to demonstrate that vaccinations in Victoria did not drop drastically--as other interactions did. On the contrary, we observed a surge of influenza and pneumococcus vaccinations in 2020, contradicting research findings of similar studies conducted in different geographical areas. </p> </div> </dd> <dt>[50] arXiv:2112.04635 [pdf]</dt> <dd> <div > <div > Title: Decentralized Frequency Regulation of Hybrid MTDC-linked Grids </div> <div > Authors: Young-Jin Kim </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >This paper proposes a new strategy for optimal grid frequency regulation (FR) in an interconnected power system where regional ac grids and an offshore wind farm are linked via a multi-terminal high voltage direct-current (MTDC) network. In the proposed strategy, decentralized H-infinity controllers are developed to coordinate the operations of ac synchronous generators and hybrid MTDC converters, thus achieving optimal power sharing of interconnected ac grids and minimizing frequency deviations in each grid. To develop the controllers, robust optimization problems are formulated and solved using a dynamic model of the hybrid MTDC-linked grids with model parameter uncertainty and decentralized control inputs and outputs. The model orders of the resulting controllers are then reduced using a balanced truncation algorithm to eliminate unobservable and uncontrollable state variables while preserving their dominant response characteristics. Sensitivity and eigenvalue analyses are conducted focusing on the effects of grid measurements, parameter uncertainty levels, and communication time delays. Comparative case studies are also carried out to verify that the proposed strategy improves the effectiveness, stability, and robustness of real-time FR in MTDC-linked grids under various conditions characterized mainly by load demands, communications systems, and weighting functions. </p> </div> </dd> <dt>[51] arXiv:2112.04639 [pdf, other]</dt> <dd> <div > <div > Title: Safe Autonomous Navigation for Systems with Learned SE(3) Hamiltonian Dynamics </div> <div > Authors: Zhichao Li, <a >Thai Duong</a>, <a >Nikolay Atanasov</a> </div> <div > Subjects: Robotics (cs.RO); Systems and Control (eess.SY) </div> <p >Safe autonomous navigation in unknown environments is an important problem for ground, aerial, and underwater robots. This paper proposes techniques to learn the dynamics models of a mobile robot from trajectory data and synthesize a tracking controller with safety and stability guarantees. The state of a mobile robot usually contains its position, orientation, and generalized velocity and satisfies Hamilton's equations of motion. Instead of a hand-derived dynamics model, we use a dataset of state-control trajectories to train a translation-equivariant nonlinear Hamiltonian model represented as a neural ordinary differential equation (ODE) network. The learned Hamiltonian model is used to synthesize an energy-shaping passivity-based controller and derive conditions which guarantee safe regulation to a desired reference pose. Finally, we enable adaptive tracking of a desired path, subject to safety constraints obtained from obstacle distance measurements. The trade-off between the system's energy level and the distance to safety constraint violation is used to adaptively govern the reference pose along the desired path. Our safe adaptive controller is demonstrated on a simulated hexarotor robot navigating in unknown complex environments. </p> </div> </dd> <dt>[52] arXiv:2112.04640 [pdf, other]</dt> <dd> <div > <div > Title: Differentially Private Ensemble Classifiers for Data Streams </div> <div > Authors: Lovedeep Gondara, <a >Ke Wang</a>, <a >Ricardo Silva Carvalho</a> </div> <div > Comments: Accepted at WSDM 2022 </div> <div > Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML) </div> <p >Learning from continuous data streams via classification/regression is prevalent in many domains. Adapting to evolving data characteristics (concept drift) while protecting data owners' private information is an open challenge. We present a differentially private ensemble solution to this problem with two distinguishing features: it allows an extit{unbounded} number of ensemble updates to deal with the potentially never-ending data streams under a fixed privacy budget, and it is extit{model agnostic}, in that it treats any pre-trained differentially private classification/regression model as a black-box. Our method outperforms competitors on real-world and simulated datasets for varying settings of privacy, concept drift, and data distribution. </p> </div> </dd> <dt>[53] arXiv:2112.04641 [pdf, ps, other]</dt> <dd> <div > <div > Title: Multiple Residual Dense Networks for Reconfigurable Intelligent Surfaces Cascaded Channel Estimation </div> <div > Authors: Yu Jin, <a >Jiayi Zhang</a>, <a >Chongwen Huang</a>, <a >Liang Yang</a>, <a >Huahua Xiao</a>, <a >Bo Ai</a>, <a >Zhiqin Wang</a> </div> <div > Comments: to appear in IEEE TVT </div> <div > Subjects: Information Theory (cs.IT); Signal Processing (eess.SP) </div> <p >Reconfigurable intelligent surface (RIS) constitutes an essential and promising paradigm that relies programmable wireless environment and provides capability for space-intensive communications, due to the use of low-cost massive reflecting elements over the entire surfaces of man-made structures. However, accurate channel estimation is a fundamental technical prerequisite to achieve the huge performance gains from RIS. By leveraging the low rank structure of RIS channels, three practical residual neural networks, named convolutional blind denoising network, convolutional denoising generative adversarial networks and multiple residual dense network, are proposed to obtain accurate channel state information, which can reflect the impact of different methods on the estimation performance. Simulation results reveal the evolution direction of these three methods and reveal their superior performance compared with existing benchmark schemes. </p> </div> </dd> <dt>[54] arXiv:2112.04643 [pdf, other]</dt> <dd> <div > <div > Title: Autoregressive Quantile Flows for Predictive Uncertainty Estimation </div> <div > Authors: Phillip Si, <a >Allan Bishop</a>, <a >Volodymyr Kuleshov</a> </div> <div > Comments: 9 pages, 4 figures, 6 tables (main body) additional 4 pages, 2 figures, 4 tables (appendix) </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Numerous applications of machine learning involve predicting flexible probability distributions over model outputs. We propose Autoregressive Quantile Flows, a flexible class of probabilistic models over high-dimensional variables that can be used to accurately capture predictive aleatoric uncertainties. These models are instances of autoregressive flows trained using a novel objective based on proper scoring rules, which simplifies the calculation of computationally expensive determinants of Jacobians during training and supports new types of neural architectures. We demonstrate that these models can be used to parameterize predictive conditional distributions and improve the quality of probabilistic predictions on time series forecasting and object detection. </p> </div> </dd> <dt>[55] arXiv:2112.04645 [pdf, other]</dt> <dd> <div > <div > Title: BACON: Band-limited Coordinate Networks for Multiscale Scene Representation </div> <div > Authors: David B. Lindell, <a >Dave Van Veen</a>, <a >Jeong Joon Park</a>, <a >Gordon Wetzstein</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG) </div> <p >Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, and so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has predictable behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without explicit supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality. </p> </div> </dd> <dt>[56] arXiv:2112.04660 [pdf, other]</dt> <dd> <div > <div > Title: A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse </div> <div > Authors: Junyi Li, <a >Bin Gu</a>, <a >Heng Huang</a> </div> <div > Comments: To appear in AAAI 2022 </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >In this paper, we propose a new Hessian inverse free Fully Single Loop Algorithm (FSLA) for bilevel optimization problems. Classic algorithms for bilevel optimization admit a double loop structure which is computationally expensive. Recently, several single loop algorithms have been proposed with optimizing the inner and outer variable alternatively. However, these algorithms not yet achieve fully single loop. As they overlook the loop needed to evaluate the hyper-gradient for a given inner and outer state. In order to develop a fully single loop algorithm, we first study the structure of the hyper-gradient and identify a general approximation formulation of hyper-gradient computation that encompasses several previous common approaches, e.g. back-propagation through time, conjugate gradient, \emph{etc.} Based on this formulation, we introduce a new state variable to maintain the historical hyper-gradient information. Combining our new formulation with the alternative update of the inner and outer variables, we propose an efficient fully single loop algorithm. We theoretically show that the error generated by the new state can be bounded and our algorithm converges with the rate of $O(\epsilon^{-2})$. Finally, we verify the efficacy our algorithm empirically through multiple bilevel optimization based machine learning tasks. </p> </div> </dd> <dt>[57] arXiv:2112.04662 [pdf, other]</dt> <dd> <div > <div > Title: Dual Cluster Contrastive learning for Person Re-Identification </div> <div > Authors: Hantao Yao, <a >Changsheng Xu</a> </div> <div > Comments: 10 pages, 6 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Recently, cluster contrastive learning has been proven effective for person ReID by computing the contrastive loss between the individual feature and the cluster memory. However, existing methods that use the individual feature to momentum update the cluster memory are not robust to the noisy samples, such as the samples with wrong annotated labels or the pseudo-labels. Unlike the individual-based updating mechanism, the centroid-based updating mechanism that applies the mean feature of each cluster to update the cluster memory is robust against minority noisy samples. Therefore, we formulate the individual-based updating and centroid-based updating mechanisms in a unified cluster contrastive framework, named Dual Cluster Contrastive learning (DCC), which maintains two types of memory banks: individual and centroid cluster memory banks. Significantly, the individual cluster memory is momentum updated based on the individual feature.The centroid cluster memory applies the mean feature of each cluter to update the corresponding cluster memory. Besides the vallina contrastive loss for each memory, a consistency constraint is applied to guarantee the consistency of the output of two memories. Note that DCC can be easily applied for unsupervised or supervised person ReID by using ground-truth labels or pseudo-labels generated with clustering method, respectively. Extensive experiments on two benchmarks under supervised person ReID and unsupervised person ReID demonstrate the superior of the proposed DCC. Code is available at: https://github.com/htyao89/Dual-Cluster-Contrastive/ </p> </div> </dd> <dt>[58] arXiv:2112.04665 [pdf, other]</dt> <dd> <div > <div > Title: Style Mixing and Patchwise Prototypical Matching for One-Shot Unsupervised Domain Adaptive Semantic Segmentation </div> <div > Authors: Xinyi Wu, <a >Zhenyao Wu</a>, <a >Yuhang Lu</a>, <a >Lili Ju</a>, <a >Song Wang</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >In this paper, we tackle the problem of one-shot unsupervised domain adaptation (OSUDA) for semantic segmentation where the segmentors only see one unlabeled target image during training. In this case, traditional unsupervised domain adaptation models usually fail since they cannot adapt to the target domain with over-fitting to one (or few) target samples. To address this problem, existing OSUDA methods usually integrate a style-transfer module to perform domain randomization based on the unlabeled target sample, with which multiple domains around the target sample can be explored during training. However, such a style-transfer module relies on an additional set of images as style reference for pre-training and also increases the memory demand for domain adaptation. Here we propose a new OSUDA method that can effectively relieve such computational burden. Specifically, we integrate several style-mixing layers into the segmentor which play the role of style-transfer module to stylize the source images without introducing any learned parameters. Moreover, we propose a patchwise prototypical matching (PPM) method to weighted consider the importance of source pixels during the supervised training to relieve the negative adaptation. Experimental results show that our method achieves new state-of-the-art performance on two commonly used benchmarks for domain adaptive semantic segmentation under the one-shot setting and is more efficient than all comparison approaches. </p> </div> </dd> <dt>[59] arXiv:2112.04666 [pdf, other]</dt> <dd> <div > <div > Title: Densifying Sparse Representations for Passage Retrieval by Representational Slicing </div> <div > Authors: Sheng-Chieh Lin, <a >Jimmy Lin</a> </div> <div > Subjects: Information Retrieval (cs.IR) </div> <p >Learned sparse and dense representations capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust. Prior work combines dense and sparse retrievers by fusing their model scores. As an alternative, this paper presents a simple approach to densifying sparse representations for text retrieval that does not involve any training. Our densified sparse representations (DSRs) are interpretable and can be easily combined with dense representations for end-to-end retrieval. We demonstrate that our approach can jointly learn sparse and dense representations within a single model and then combine them for dense retrieval. Experimental results suggest that combining our DSRs and dense representations yields a balanced tradeoff between effectiveness and efficiency. </p> </div> </dd> <dt>[60] arXiv:2112.04669 [pdf, ps, other]</dt> <dd> <div > <div > Title: A Survey on Parameterized Inapproximability: $k$-Clique, $k$-SetCover, and More </div> <div > Authors: Xuandi Ren </div> <div > Subjects: Computational Complexity (cs.CC) </div> <p >In the past a few years, many interesting inapproximability results have been obtained from the parameterized perspective. This article surveys some of such results, with a focus on $k$-Clique, $k$-SetCover, and other related problems. </p> </div> </dd> <dt>[61] arXiv:2112.04674 [pdf, other]</dt> <dd> <div > <div > Title: DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition </div> <div > Authors: Yuxuan Liang, <a >Pan Zhou</a>, <a >Roger Zimmermann</a>, <a >Shuicheng Yan</a> </div> <div > Comments: Preprint </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p >While transformers have shown great potential on video recognition tasks with their strong capability of capturing long-range dependencies, they often suffer high computational costs induced by self-attention operation on the huge number of 3D tokens in a video. In this paper, we propose a new transformer architecture, termed DualFormer, which can effectively and efficiently perform space-time attention for video recognition. Specifically, our DualFormer stratifies the full space-time attention into dual cascaded levels, i.e., to first learn fine-grained local space-time interactions among nearby 3D tokens, followed by the capture of coarse-grained global dependencies between the query token and the coarse-grained global pyramid contexts. Different from existing methods that apply space-time factorization or restrict attention computations within local windows for improving efficiency, our local-global stratified strategy can well capture both short- and long-range spatiotemporal dependencies, and meanwhile greatly reduces the number of keys and values in attention computation to boost efficiency. Experimental results show the superiority of DualFormer on five video benchmarks against existing methods. In particular, DualFormer sets new state-of-the-art 82.9%/85.2% top-1 accuracy on Kinetics-400/600 with around 1000G inference FLOPs which is at least 3.2 times fewer than existing methods with similar performances. </p> </div> </dd> <dt>[62] arXiv:2112.04680 [pdf, other]</dt> <dd> <div > <div > Title: SimIPU: Simple 2D Image and 3D Point Cloud Unsupervised Pre-Training for Spatial-Aware Visual Representations </div> <div > Authors: Zhenyu Li, <a >Zehui Chen</a>, <a >Ang Li</a>, <a >Liangji Fang</a>, <a >Qinhong Jiang</a>, <a >Xianming Liu</a>, <a >Junjun Jiang</a>, <a >Bolei Zhou</a>, <a >Hang Zhao</a> </div> <div > Comments: Accepted to 36th AAAI Conference on Artificial Intelligence (AAAI 2022) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Pre-training has become a standard paradigm in many computer vision tasks. However, most of the methods are generally designed on the RGB image domain. Due to the discrepancy between the two-dimensional image plane and the three-dimensional space, such pre-trained models fail to perceive spatial information and serve as sub-optimal solutions for 3D-related tasks. To bridge this gap, we aim to learn a spatial-aware visual representation that can describe the three-dimensional space and is more suitable and effective for these tasks. To leverage point clouds, which are much more superior in providing spatial information compared to images, we propose a simple yet effective 2D Image and 3D Point cloud Unsupervised pre-training strategy, called SimIPU. Specifically, we develop a multi-modal contrastive learning framework that consists of an intra-modal spatial perception module to learn a spatial-aware representation from point clouds and an inter-modal feature interaction module to transfer the capability of perceiving spatial information from the point cloud encoder to the image encoder, respectively. Positive pairs for contrastive losses are established by the matching algorithm and the projection matrix. The whole framework is trained in an unsupervised end-to-end fashion. To the best of our knowledge, this is the first study to explore contrastive learning pre-training strategies for outdoor multi-modal datasets, containing paired camera images and LIDAR point clouds. Codes and models are available at https://github.com/zhyever/SimIPU. </p> </div> </dd> <dt>[63] arXiv:2112.04682 [pdf, other]</dt> <dd> <div > <div > Title: Clairvoyance: Intelligent Route Planning for Electric Buses Based on Urban Big Data </div> <div > Authors: Xiangyong Lu, <a >Kaoru Ota</a>, <a >Mianxiong Dong</a>, <a >Chen Yu</a>, <a >Hai Jin</a> </div> <div > Comments: 13 pages,12 figures </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Nowadays many cities around the world have introduced electric buses to optimize urban traffic and reduce local carbon emissions. In order to cut carbon emissions and maximize the utility of electric buses, it is important to choose suitable routes for them. Traditionally, route selection is on the basis of dedicated surveys, which are costly in time and labor. In this paper, we mainly focus attention on planning electric bus routes intelligently, depending on the unique needs of each region throughout the city. We propose Clairvoyance, a route planning system that leverages a deep neural network and a multilayer perceptron to predict the future people's trips and the future transportation carbon emission in the whole city, respectively. Given the future information of people's trips and transportation carbon emission, we utilize a greedy mechanism to recommend bus routes for electric buses that will depart in an ideal state. Furthermore, representative features of the two neural networks are extracted from the heterogeneous urban datasets. We evaluate our approach through extensive experiments on real-world data sources in Zhuhai, China. The results show that our designed neural network-based algorithms are consistently superior to the typical baselines. Additionally, the recommended routes for electric buses are helpful in reducing the peak value of carbon emissions and making full use of electric buses in the city. </p> </div> </dd> <dt>[64] arXiv:2112.04683 [pdf]</dt> <dd> <div > <div > Title: Dynamic Interaction of Transportation and Power Distribution Networks With Electric Vehicles </div> <div > Authors: Li Jiaqi, <a >Xu Xiaoyuan</a>, <a >Yan Zheng</a>, <a >Wang Han</a>, <a >Chen Yue</a> </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >The increasing global spread of electric vehicles has introduced significant interdependence between transportation and power networks. Most of the previous studies on the coupled networks are based on static models, and the spatial and temporal variations of traffic and power flows are neglected, which is not suitable for short-term operation. This paper constructs a dynamic interaction model of coupled networks. First, the dynamic traffic assignment (DTA) model is established considering departure time and route choices simultaneously, and a nested diagonalization method is exploited to solve it. Then, based on DTA and multi-period optimal power flow, the equilibrium state of coupled networks is designed as the solution of a fixed-point problem. Moreover, the solution existence is proved based on mild assumptions. Third, the linearization and convex relaxation techniques are used to improve computational efficiency. A Monte Carlo simulation technique is developed to evaluate the influence of uncertain travel demands on coupled networks. Numerical simulations of the interaction analyses of coupled networks in both deterministic and uncertain conditions are presented. </p> </div> </dd> <dt>[65] arXiv:2112.04684 [pdf, other]</dt> <dd> <div > <div > Title: Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain </div> <div > Authors: Stefan Wapnick, <a >Travis Manderson</a>, <a >David Meger</a>, <a >Gregory Dudek</a> </div> <div > Comments: Published in International Conference on Intelligent Robots and Systems (IROS) 2021 proceedings. Project website: <a >this https URL</a> </div> <div > Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >We present a reward-predictive, model-based deep learning method featuring trajectory-constrained visual attention for use in mapless, local visual navigation tasks. Our method learns to place visual attention at locations in latent image space which follow trajectories caused by vehicle control actions to enhance predictive accuracy during planning. The attention model is jointly optimized by the task-specific loss and an additional trajectory-constraint loss, allowing adaptability yet encouraging a regularized structure for improved generalization and reliability. Importantly, visual attention is applied in latent feature map space instead of raw image space to promote efficient planning. We validated our model in visual navigation tasks of planning low turbulence, collision-free trajectories in off-road settings and hill climbing with locking differentials in the presence of slippery terrain. Experiments involved randomized procedural generated simulation and real-world environments. We found our method improved generalization and learning efficiency when compared to no-attention and self-attention alternatives. </p> </div> </dd> <dt>[66] arXiv:2112.04685 [pdf, other]</dt> <dd> <div > <div > Title: CWS-PResUNet: Music Source Separation with Channel-wise Subband Phase-aware ResUNet </div> <div > Authors: Haohe Liu, <a >Qiuqiang Kong</a>, <a >Jiafeng Liu</a> </div> <div > Comments: Published at MDX Workshop @ ISMIR 2021 </div> <div > Subjects: Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS) </div> <p >Music source separation (MSS) shows active progress with deep learning models in recent years. Many MSS models perform separations on spectrograms by estimating bounded ratio masks and reusing the phases of the mixture. When using convolutional neural networks (CNN), weights are usually shared within a spectrogram during convolution regardless of the different patterns between frequency bands. In this study, we propose a new MSS model, channel-wise subband phase-aware ResUNet (CWS-PResUNet), to decompose signals into subbands and estimate an unbound complex ideal ratio mask (cIRM) for each source. CWS-PResUNet utilizes a channel-wise subband (CWS) feature to limit unnecessary global weights sharing on the spectrogram and reduce computational resource consumptions. The saved computational cost and memory can in turn allow for a larger architecture. On the MUSDB18HQ test set, we propose a 276-layer CWS-PResUNet and achieve state-of-the-art (SoTA) performance on vocals with an 8.92 signal-to-distortion ratio (SDR) score. By combining CWS-PResUNet and Demucs, our ByteMSS system ranks the 2nd on vocals score and 5th on average score in the 2021 ISMIR Music Demixing (MDX) Challenge limited training data track (leaderboard A). Our code and pre-trained models are publicly available at: https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet </p> </div> </dd> <dt>[67] arXiv:2112.04688 [pdf, other]</dt> <dd> <div > <div > Title: Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single Lane Representations of Traffic-compressed </div> <div > Authors: Abdul Rahman Kreidieh, <a >Yibo Zhao</a>, <a >Samyak Parajuli</a>, <a >Alexandre Bayen</a> </div> <div > Subjects: Multiagent Systems (cs.MA); Systems and Control (eess.SY) </div> <p >Reinforcement learning techniques can provide substantial insights into the desired behaviors of future autonomous driving systems. By optimizing for societal metrics of traffic such as increased throughput and reduced energy consumption, such methods can derive maneuvers that, if adopted by even a small portion of vehicles, may significantly improve the state of traffic for all vehicles involved. These methods, however, are hindered in practice by the difficulty of designing efficient and accurate models of traffic, as well as the challenges associated with optimizing for the behaviors of dozens of interacting agents. In response to these challenges, this paper tackles the problem of learning generalizable traffic control strategies in simple representations of vehicle driving dynamics. In particular, we look to mixed-autonomy ring roads as depictions of instabilities that result in the formation of congestion. Within this problem, we design a curriculum learning paradigm that exploits the natural extendability of the network to effectively learn behaviors that reduce congestion over long horizons. Next, we study the implications of modeling lane changing on the transferability of policies. Our findings suggest that introducing lane change behaviors that even approximately match trends in more complex systems can significantly improve the generalizability of subsequent learned models to more accurate multi-lane models of traffic. </p> </div> </dd> <dt>[68] arXiv:2112.04693 [pdf, other]</dt> <dd> <div > <div > Title: A Monotone, Second Order Accurate Scheme for Curvature Motion </div> <div > Authors: Selim Esedoglu, <a >Jiajia Guo</a> </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >We present a second order accurate in time numerical scheme for curve shortening flow in the plane that is unconditionally monotone. It is a variant of threshold dynamics, a class of algorithms in the spirit of the level set method that represent interfaces implicitly. The novelty is monotonicity: it is possible to preserve the comparison principle of the exact evolution while achieving second order in time consistency. As a consequence of monotonicity, convergence to the viscosity solution of curve shortening is ensured by existing theory. </p> </div> </dd> <dt>[69] arXiv:2112.04698 [pdf, other]</dt> <dd> <div > <div > Title: Explainable AI for B5G/6G: Technical Aspects, Use Cases, and Research Challenges </div> <div > Authors: Shen Wang, <a >M.Atif Qureshi</a>, <a >Luis Miralles-Pechuaán</a>, <a >Thien Huynh-The</a>, <a >Thippa Reddy Gadekallu</a>, <a >Madhusanka Liyanage</a> </div> <div > Subjects: Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI) </div> <p >When 5G began its commercialisation journey around 2020, the discussion on the vision of 6G also surfaced. Researchers expect 6G to have higher bandwidth, coverage, reliability, energy efficiency, lower latency, and, more importantly, an integrated "human-centric" network system powered by artificial intelligence (AI). Such a 6G network will lead to an excessive number of automated decisions made every second. These decisions can range widely, from network resource allocation to collision avoidance for self-driving cars. However, the risk of losing control over decision-making may increase due to high-speed data-intensive AI decision-making beyond designers and users' comprehension. The promising explainable AI (XAI) methods can mitigate such risks by enhancing the transparency of the black box AI decision-making process. This survey paper highlights the need for XAI towards the upcoming 6G age in every aspect, including 6G technologies (e.g., intelligent radio, zero-touch network management) and 6G use cases (e.g., industry 5.0). Moreover, we summarised the lessons learned from the recent attempts and outlined important research challenges in applying XAI for building 6G systems. This research aligns with goals 9, 11, 16, and 17 of the United Nations Sustainable Development Goals (UN-SDG), promoting innovation and building infrastructure, sustainable and inclusive human settlement, advancing justice and strong institutions, and fostering partnership at the global level. </p> </div> </dd> <dt>[70] arXiv:2112.04699 [pdf, other]</dt> <dd> <div > <div > Title: Contraction Analysis and Control Synthesis for Discrete-time Nonlinear Processes </div> <div > Authors: Lai Wei, <a >Ryan McCloy</a>, <a >Jie Bao</a> </div> <div > Comments: Submitted to Elsevier for possible publication. arXiv admin note: text overlap with <a >arXiv:2105.05432</a>, <a >arXiv:2104.10352</a> </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >Shifting away from the traditional mass production approach, the process industry is moving towards more agile, cost-effective and dynamic process operation (next-generation smart plants). This warrants the development of control systems for nonlinear chemical processes to be capable of tracking time-varying setpoints to produce products with different specifications as per market demand and deal with variations in the raw materials and utility (e.g., energy). This article presents a systematic approach to the implementation of contraction-based control for discrete-time nonlinear processes. Through the differential dynamic system framework, the contraction conditions to ensure the exponential convergence to feasible time-varying references are derived. The discrete-time differential dissipativity condition is further developed, which can be used for control designs for disturbance rejection. Computationally tractable equivalent conditions are then derived and additionally transformed into an SOS programming problem, such that a discrete-time control contraction metric and stabilising feedback controller can be jointly obtained. Synthesis and implementation details are provided and demonstrated through a numerical case study. </p> </div> </dd> <dt>[71] arXiv:2112.04701 [pdf, other]</dt> <dd> <div > <div > Title: Unsupervised Complementary-aware Multi-process Fusion for Visual Place Recognition </div> <div > Authors: Stephen Hausler, <a >Tobias Fischer</a>, <a >Michael Milford</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >A recent approach to the Visual Place Recognition (VPR) problem has been to fuse the place recognition estimates of multiple complementary VPR techniques simultaneously. However, selecting the optimal set of techniques to use in a specific deployment environment a-priori is a difficult and unresolved challenge. Further, to the best of our knowledge, no method exists which can select a set of techniques on a frame-by-frame basis in response to image-to-image variations. In this work, we propose an unsupervised algorithm that finds the most robust set of VPR techniques to use in the current deployment environment, on a frame-by-frame basis. The selection of techniques is determined by an analysis of the similarity scores between the current query image and the collection of database images and does not require ground-truth information. We demonstrate our approach on a wide variety of datasets and VPR techniques and show that the proposed dynamic multi-process fusion (Dyn-MPF) has superior VPR performance compared to a variety of challenging competitive methods, some of which are given an unfair advantage through access to the ground-truth information. </p> </div> </dd> <dt>[72] arXiv:2112.04702 [pdf, other]</dt> <dd> <div > <div > Title: Fast Point Transformer </div> <div > Authors: Chunghyun Park, <a >Yoonwoo Jeong</a>, <a >Minsu Cho</a>, <a >Jaesik Park</a> </div> <div > Comments: 16 pages, 8 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >The recent success of neural networks enables a better interpretation of 3D point clouds, but processing a large-scale 3D scene remains a challenging problem. Most current approaches divide a large-scale scene into small regions and combine the local predictions together. However, this scheme inevitably involves additional stages for pre- and post-processing and may also degrade the final output due to predictions in a local perspective. This paper introduces Fast Point Transformer that consists of a new lightweight self-attention layer. Our approach encodes continuous 3D coordinates, and the voxel hashing-based architecture boosts computational efficiency. The proposed method is demonstrated with 3D semantic segmentation and 3D detection. The accuracy of our approach is competitive to the best voxel-based method, and our network achieves 136 times faster inference time than the state-of-the-art, Point Transformer, with a reasonable accuracy trade-off. </p> </div> </dd> <dt>[73] arXiv:2112.04703 [pdf, ps, other]</dt> <dd> <div > <div > Title: Modelling and Optimization of OAM-MIMO Communication Systems with Unaligned Antennas </div> <div > Authors: Xusheng Xiong, <a >Hanqiong Lou</a>, <a >Xiaohu Ge</a> </div> <div > Subjects: Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP) </div> <p >The orbital angular momentum (OAM) wireless communication technique is emerging as one of potential techniques for the Sixth generation (6G) wireless communication system. The most advantage of OAM wireless communication technique is the natural orthogonality among different OAM states. However, one of the most disadvantages is the crosstalk among different OAM states which is widely caused by the atmospheric turbulence and misalignment between transmitting and receiving antennas. Considering the OAM-based multiple-input multiple-output (OAM-MIMO) transmission system with unaligned antennas, a new channel model is proposed for performance analysis. Moreover, a purity model of the OAM-MIMO transmission system with unaligned antennas is derived for the non-Kolmogorov turbulence. Furthermore, error probability and capacity models are derived for OAM-MIMO transmission systems with unaligned antennas. To overcome the disadvantage caused by unaligned antennas and non-Kolmogorov turbulence, a new optimization algorithm of OAM state interval is proposed to improve the capacity of OAM-MIMO transmission system. Numerical results indicate that the capacity of OAM-MIMO transmission system is improved by the optimization algorithm. Specifically, the capacity increment of OAM-MIMO transmission system adopting the optimization algorithm is up to 28.7% and 320.3% when the angle of deflection between transmitting and receiving antennas is -24 dB and -5 dB, respectively. </p> </div> </dd> <dt>[74] arXiv:2112.04704 [pdf, other]</dt> <dd> <div > <div > Title: Ymir: A Supervised Ensemble Framework for Multivariate Time Series Anomaly Detection </div> <div > Authors: Zhanxiang Zhao </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >We proposed a multivariate time series anomaly detection frame-work Ymir, which leverages ensemble learning and supervisedlearning technology to efficiently learn and adapt to anomaliesin real-world system applications. Ymir integrates several currentlywidely used unsupervised anomaly detection models through anensemble learning method, and thus can provide robust frontalanomaly detection results in unsupervised scenarios. In a super-vised setting, domain experts and system users discuss and providelabels (anomalous or not) for the training data, which reflects theiranomaly detection criteria for the specific system. Ymir leveragesthe aforementioned unsupervised methods to extract rich and usefulfeature representations from the raw multivariate time series data,then combines the features and labels with a supervised classifier todo anomaly detection. We evaluated Ymir on internal multivariatetime series datasets from large monitoring systems and achievedgood anomaly detection performance. </p> </div> </dd> <dt>[75] arXiv:2112.04706 [pdf, other]</dt> <dd> <div > <div > Title: Kinematic Modeling of Handed Shearing Auxetics via Piecewise Constant Curvature </div> <div > Authors: Aman Garg, <a >Ian Good</a>, <a >Daniel Revier</a>, <a >Kevin Airis</a>, <a >Jeffrey Lipton</a> </div> <div > Comments: 7 pages, 10 figures, This paper has been submitted to International Conference on Soft Robotics 2022 </div> <div > Subjects: Robotics (cs.RO) </div> <p >Handed Shearing Auxetics (HSA) are a promising technique for making motor-driven, soft, continuum robots. Many potential applications from inspection tasks to solar tracking require accurate kinematic models to predict the position and orientation of these structures. Currently there are no models for HSA based continuum platforms. To address this gap we propose to adapt Piecewise Constant Curvature (PCC) Models using a length change coupling matrix. This models the interaction of HSA structures in a 2x2 array. The coupling matrix maps the change in motor angles to length changes and defines the configuration space in our modified PCC Model. We evaluate our model on a composite movement encompassing bending, extension and compression behavior. Our model achieves a positional accuracy with mean error of 5.5mm or 4.5% body length and standard deviation of 1.72mm. Further, we achieve an angular accuracy with mean error of -2.8$^\circ$ and standard deviation of 1.9$^\circ$. </p> </div> </dd> <dt>[76] arXiv:2112.04709 [pdf, other]</dt> <dd> <div > <div > Title: Implicit Feature Refinement for Instance Segmentation </div> <div > Authors: Lufan Ma, <a >Tiancai Wang</a>, <a >Bin Dong</a>, <a >Jiangpeng Yan</a>, <a >Xiu Li</a>, <a >Xiangyu Zhang</a> </div> <div > Comments: Published at ACM MM 2021. Code is available at <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We propose a novel implicit feature refinement module for high-quality instance segmentation. Existing image/video instance segmentation methods rely on explicitly stacked convolutions to refine instance features before the final prediction. In this paper, we first give an empirical comparison of different refinement strategies,which reveals that the widely-used four consecutive convolutions are not necessary. As an alternative, weight-sharing convolution blocks provides competitive performance. When such block is iterated for infinite times, the block output will eventually convergeto an equilibrium state. Based on this observation, the implicit feature refinement (IFR) is developed by constructing an implicit function. The equilibrium state of instance features can be obtained by fixed-point iteration via a simulated infinite-depth network. Our IFR enjoys several advantages: 1) simulates an infinite-depth refinement network while only requiring parameters of single residual block; 2) produces high-level equilibrium instance features of global receptive field; 3) serves as a plug-and-play general module easily extended to most object recognition frameworks. Experiments on the COCO and YouTube-VIS benchmarks show that our IFR achieves improved performance on state-of-the-art image/video instance segmentation frameworks, while reducing the parameter burden (e.g.1% AP improvement on Mask R-CNN with only 30.0% parameters in mask head). Code is made available at https://github.com/lufanma/IFR.git </p> </div> </dd> <dt>[77] arXiv:2112.04710 [pdf, other]</dt> <dd> <div > <div > Title: Auto-X3D: Ultra-Efficient Video Understanding via Finer-Grained Neural Architecture Search </div> <div > Authors: Yifan Jiang, <a >Xinyu Gong</a>, <a >Junru Wu</a>, <a >Humphrey Shi</a>, <a >Zhicheng Yan</a>, <a >Zhangyang Wang</a> </div> <div > Comments: Accepted by WACV'2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Efficient video architecture is the key to deploying video recognition systems on devices with limited computing resources. Unfortunately, existing video architectures are often computationally intensive and not suitable for such applications. The recent X3D work presents a new family of efficient video models by expanding a hand-crafted image architecture along multiple axes, such as space, time, width, and depth. Although operating in a conceptually large space, X3D searches one axis at a time, and merely explored a small set of 30 architectures in total, which does not sufficiently explore the space. This paper bypasses existing 2D architectures, and directly searched for 3D architectures in a fine-grained space, where block type, filter number, expansion ratio and attention block are jointly searched. A probabilistic neural architecture search method is adopted to efficiently search in such a large space. Evaluations on Kinetics and Something-Something-V2 benchmarks confirm our AutoX3D models outperform existing ones in accuracy up to 1.3% under similar FLOPs, and reduce the computational cost up to x1.74 when reaching similar performance. </p> </div> </dd> <dt>[78] arXiv:2112.04711 [pdf, other]</dt> <dd> <div > <div > Title: Feature Modulation to Improve Struggle Detection in Web Search: A Psychological Approach </div> <div > Authors: Jiyun Luo, <a >Yan Yang</a>, <a >Valerie Nayak</a>, <a >Grace Hui Yang</a> </div> <div > Subjects: Information Retrieval (cs.IR) </div> <p >Searcher struggle is important feedback to Web search engines. Existing Web search struggle detection methods rely on effort-based features to identify the struggling moments. Their underlying assumption is that the more effort a user spends, the more struggling the user may be. However, recent studies have suggested this simple association might be incorrect. This paper proposes a new feature modulation method for struggle detection and refers to the reversal theory in psychology. The reversal theory (RT) points out that instead of having a static personality trait, people constantly switch between opposite psychological states, complicating the relationship between the efforts they spend and the level of frustration they feel. Supported by the theory, our method modulates the effort-based features based on RT's bi-modal arousal model. Evaluations on week-long Web search logs confirm that the proposed method can statistically significantly improve state-of-the-art struggle detection methods. </p> </div> </dd> <dt>[79] arXiv:2112.04713 [pdf, other]</dt> <dd> <div > <div > Title: Adaptive List Decoder with Flip Operations for Polar Codes </div> <div > Authors: Yansong Lv, <a >Hang Yin</a>, <a >Zhanxin Yang</a>, <a >Yuhuan Wang</a>, <a >Jingxin Dai</a>, <a >Jing Huan</a> </div> <div > Subjects: Information Theory (cs.IT) </div> <p >Successive cancellation list decoders with flip operations (SCL-Flip) can utilize re-decoding attempts to significantly improve the error-correction performance of polar codes. However, these re-decoding attempts result in extra computation complexity, which thus leads to increased energy consumption and decoding latency to the communication system adopting SCL-Flip decoders. To significantly reduce the computation complexity of current SCL-Flip decoders, we design a new adaptive SCL-Flip (AD-SCLF) decoder, which can be easily implemented based on existing SCL-Flip techniques. Simulation results showed that the AD-SCLF can reduce up to 80.85\% of the computational complexity of a current SCL-Flip decoder at a matched $FER=10^{-3}$. The result implies our decoder can significantly reduce the energy consumption caused by redundant re-decoding attempts from the SCL-Flip decoder. </p> </div> </dd> <dt>[80] arXiv:2112.04715 [pdf, other]</dt> <dd> <div > <div > Title: Scheduling Algorithms for Hierarchical Fog Networks </div> <div > Authors: Amanjot Kaur, <a >Nitin Auluck</a> </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> <p >Fog computing brings the functionality of the cloud near the edge of the network with the help of fog devices/micro data centers ($mdcs$). Job scheduling in such systems is a complex problem due to the hierarchical and geo-distributed nature of fog devices. We propose two fog scheduling algorithms, named $FiFSA$ (Hierarchical $Fi$rst $F$og $S$cheduling $A$lgorithm) and $EFSA$ ( Hierarchical $E$lected $F$og $S$cheduling $A$lgorithm). We consider a hierarchical model of fog devices, where the computation power of fog devices present in higher tiers is greater than those present in lower tiers. However, the higher tier fog devices are located at greater physical distance from data generation sources as compared to lower tier fog devices. Jobs with varying granularity and cpu requirements have been considered. In general, jobs with modest cpu requirements are scheduled on lower tier fog devices, and jobs with larger cpu requirements are scheduled on higher tier fog devices or the cloud data center $(cdc)$. The performance of $FiFSA$ and $EFSA$ has been evaluated using a real life workload trace on various simulated fog hierarchies as well as on a prototype testbed. Employing $FiFSA$ offers an average improvement of 27% and 57.9% in total completion time and an improvement of 32% and 61% in cost as compared to Longest Time First ($LTF$) and cloud-only ($cdc-only$) scheduling algorithms, respectively. Employing $EFSA$ offers an average improvement of 48% and 70% in total completion time and an improvement of 52% and 72% in cost as compared to $LTF$ and $cdc-only$ respectively. </p> </div> </dd> <dt>[81] arXiv:2112.04716 [pdf, other]</dt> <dd> <div > <div > Title: DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization </div> <div > Authors: Aviral Kumar, <a >Rishabh Agarwal</a>, <a >Tengyu Ma</a>, <a >Aaron Courville</a>, <a >George Tucker</a>, <a >Sergey Levine</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Despite overparameterization, deep networks trained via supervised learning are easy to optimize and exhibit excellent generalization. One hypothesis to explain this is that overparameterized deep networks enjoy the benefits of implicit regularization induced by stochastic gradient descent, which favors parsimonious solutions that generalize well on test inputs. It is reasonable to surmise that deep reinforcement learning (RL) methods could also benefit from this effect. In this paper, we discuss how the implicit regularization effect of SGD seen in supervised learning could in fact be harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. Our theoretical analysis shows that when existing models of implicit regularization are applied to temporal difference learning, the resulting derived regularizer favors degenerate solutions with excessive "aliasing", in stark contrast to the supervised learning case. We back up these findings empirically, showing that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, we derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. When combined with existing offline RL methods, DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images. </p> </div> </dd> <dt>[82] arXiv:2112.04719 [pdf, other]</dt> <dd> <div > <div > Title: Learning with Nested Scene Modeling and Cooperative Architecture Search for Low-Light Vision </div> <div > Authors: Risheng Liu, <a >Long Ma</a>, <a >Tengyu Ma</a>, <a >Xin Fan</a>, <a >Zhongxuan Luo</a> </div> <div > Comments: Submitted to IEEE TPAMI. Code is available at <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Images captured from low-light scenes often suffer from severe degradations, including low visibility, color cast and intensive noises, etc. These factors not only affect image qualities, but also degrade the performance of downstream Low-Light Vision (LLV) applications. A variety of deep learning methods have been proposed to enhance the visual quality of low-light images. However, these approaches mostly rely on significant architecture engineering to obtain proper low-light models and often suffer from high computational burden. Furthermore, it is still challenging to extend these enhancement techniques to handle other LLVs. To partially address above issues, we establish Retinex-inspired Unrolling with Architecture Search (RUAS), a general learning framework, which not only can address low-light enhancement task, but also has the flexibility to handle other more challenging downstream vision applications. Specifically, we first establish a nested optimization formulation, together with an unrolling strategy, to explore underlying principles of a series of LLV tasks. Furthermore, we construct a differentiable strategy to cooperatively search specific scene and task architectures for RUAS. Last but not least, we demonstrate how to apply RUAS for both low- and high-level LLV applications (e.g., enhancement, detection and segmentation). Extensive experiments verify the flexibility, effectiveness, and efficiency of RUAS. </p> </div> </dd> <dt>[83] arXiv:2112.04720 [pdf, other]</dt> <dd> <div > <div > Title: Amicable Aid: Turning Adversarial Attack to Benefit Classification </div> <div > Authors: Juyeop Kim, <a >Jun-Ho Choi</a>, <a >Soobeom Jang</a>, <a >Jong-Seok Lee</a> </div> <div > Comments: 16 pages (3 pages for appendix) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >While adversarial attacks on deep image classification models pose serious security concerns in practice, this paper suggests a novel paradigm where the concept of adversarial attacks can benefit classification performance, which we call amicable aid. We show that by taking the opposite search direction of perturbation, an image can be converted to another yielding higher confidence by the classification model and even a wrongly classified image can be made to be correctly classified. Furthermore, with a large amount of perturbation, an image can be made unrecognizable by human eyes, while it is correctly recognized by the model. The mechanism of the amicable aid is explained in the viewpoint of the underlying natural image manifold. We also consider universal amicable perturbations, i.e., a fixed perturbation can be applied to multiple images to improve their classification results. While it is challenging to find such perturbations, we show that making the decision boundary as perpendicular to the image manifold as possible via training with modified data is effective to obtain a model for which universal amicable perturbations are more easily found. Finally, we discuss several application scenarios where the amicable aid can be useful, including secure image communication, privacy-preserving image communication, and protection against adversarial attacks. </p> </div> </dd> <dt>[84] arXiv:2112.04726 [pdf, other]</dt> <dd> <div > <div > Title: Noise-robust blind reverberation time estimation using noise-aware time-frequency masking </div> <div > Authors: Kaitong Zheng, <a >Chengshi Zheng</a>, <a >Jinqiu Sang</a>, <a >Yulong Zhang</a>, <a >Xiaodong Li</a> </div> <div > Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p >The reverberation time is one of the most important parameters used to characterize the acoustic property of an enclosure. In real-world scenarios, it is much more convenient to estimate the reverberation time blindly from recorded speech compared to the traditional acoustic measurement techniques using professional measurement instruments. However, the recorded speech is often corrupted by noise, which has a detrimental effect on the estimation accuracy of the reverberation time. To address this issue, this paper proposes a two-stage blind reverberation time estimation method based on noise-aware time-frequency masking. This proposed method has a good ability to distinguish the reverberation tails from the noise, thus improving the estimation accuracy of reverberation time in noisy scenarios. The simulated and real-world acoustic experimental results show that the proposed method significantly outperforms other methods in challenging scenarios. </p> </div> </dd> <dt>[85] arXiv:2112.04728 [pdf, other]</dt> <dd> <div > <div > Title: Reducing Catastrophic Forgetting in Self Organizing Maps with Internally-Induced Generative Replay </div> <div > Authors: Hitesh Vaidya, <a >Travis Desell</a>, <a >Alexander Ororbia</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >A lifelong learning agent is able to continually learn from potentially infinite streams of pattern sensory data. One major historic difficulty in building agents that adapt in this way is that neural systems struggle to retain previously-acquired knowledge when learning from new samples. This problem is known as catastrophic forgetting (interference) and remains an unsolved problem in the domain of machine learning to this day. While forgetting in the context of feedforward networks has been examined extensively over the decades, far less has been done in the context of alternative architectures such as the venerable self-organizing map (SOM), an unsupervised neural model that is often used in tasks such as clustering and dimensionality reduction. Although the competition among its internal neurons might carry the potential to improve memory retention, we observe that a fixed-sized SOM trained on task incremental data, i.e., it receives data points related to specific classes at certain temporal increments, experiences significant forgetting. In this study, we propose the continual SOM (c-SOM), a model that is capable of reducing its own forgetting when processing information. </p> </div> </dd> <dt>[86] arXiv:2112.04731 [pdf, other]</dt> <dd> <div > <div > Title: Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning </div> <div > Authors: Yujun Shi, <a >Kuangqi Zhou</a>, <a >Jian Liang</a>, <a >Zihang Jiang</a>, <a >Jiashi Feng</a>, <a >Philip Torr</a>, <a >Song Bai</a>, <a >Vincent Y.F. Tan</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >Class Incremental Learning (CIL) aims at learning a multi-class classifier in a phase-by-phase manner, in which only data of a subset of the classes are provided at each phase. Previous works mainly focus on mitigating forgetting in phases after the initial one. However, we find that improving CIL at its initial phase is also a promising direction. Specifically, we experimentally show that directly encouraging CIL Learner at the initial phase to output similar representations as the model jointly trained on all classes can greatly boost the CIL performance. Motivated by this, we study the difference between a na\"ively-trained initial-phase model and the oracle model. Specifically, since one major difference between these two models is the number of training classes, we investigate how such difference affects the model representations. We find that, with fewer training classes, the data representations of each class lie in a long and narrow region; with more training classes, the representations of each class scatter more uniformly. Inspired by this observation, we propose Class-wise Decorrelation (CwD) that effectively regularizes representations of each class to scatter more uniformly, thus mimicking the model jointly trained with all classes (i.e., the oracle model). Our CwD is simple to implement and easy to plug into existing methods. Extensive experiments on various benchmark datasets show that CwD consistently and significantly improves the performance of existing state-of-the-art methods by around 1\% to 3\%. Code will be released. </p> </div> </dd> <dt>[87] arXiv:2112.04734 [pdf, other]</dt> <dd> <div > <div > Title: New Tight Relaxations of Rank Minimization for Multi-Task Learning </div> <div > Authors: Wei Chang, <a >Feiping Nie</a>, <a >Rong Wang</a>, <a >Xuelong Li</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >Multi-task learning has been observed by many researchers, which supposes that different tasks can share a low-rank common yet latent subspace. It means learning multiple tasks jointly is better than learning them independently. In this paper, we propose two novel multi-task learning formulations based on two regularization terms, which can learn the optimal shared latent subspace by minimizing the exactly $k$ minimal singular values. The proposed regularization terms are the more tight approximations of rank minimization than trace norm. But it's an NP-hard problem to solve the exact rank minimization problem. Therefore, we design a novel re-weighted based iterative strategy to solve our models, which can tactically handle the exact rank minimization problem by setting a large penalizing parameter. Experimental results on benchmark datasets demonstrate that our methods can correctly recover the low-rank structure shared across tasks, and outperform related multi-task learning methods. </p> </div> </dd> <dt>[88] arXiv:2112.04735 [pdf, other]</dt> <dd> <div > <div > Title: From Good to Best: Two-Stage Training for Cross-lingual Machine Reading Comprehension </div> <div > Authors: Nuo Chen, <a >Linjun Shou</a>, <a >Min Gong</a>, <a >Jian Pei</a>, <a >Daxin Jiang</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >Cross-lingual Machine Reading Comprehension (xMRC) is challenging due to the lack of training data in low-resource languages. The recent approaches use training data only in a resource-rich language like English to fine-tune large-scale cross-lingual pre-trained language models. Due to the big difference between languages, a model fine-tuned only by a source language may not perform well for target languages. Interestingly, we observe that while the top-1 results predicted by the previous approaches may often fail to hit the ground-truth answers, the correct answers are often contained in the top-k predicted results. Based on this observation, we develop a two-stage approach to enhance the model performance. The first stage targets at recall: we design a hard-learning (HL) algorithm to maximize the likelihood that the top-k predictions contain the accurate answer. The second stage focuses on precision: an answer-aware contrastive learning (AA-CL) mechanism is developed to learn the fine difference between the accurate answer and other candidates. Our extensive experiments show that our model significantly outperforms a series of strong baselines on two cross-lingual MRC benchmark datasets. </p> </div> </dd> <dt>[89] arXiv:2112.04737 [pdf, other]</dt> <dd> <div > <div > Title: Asynchronous Semi-Decentralized Federated Edge Learning for Heterogeneous Clients </div> <div > Authors: Yuchang Sun, <a >Jiawei Shao</a>, <a >Yuyi Mao</a>, <a >Jun Zhang</a> </div> <div > Subjects: Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG) </div> <p >Federated edge learning (FEEL) has drawn much attention as a privacy-preserving distributed learning framework for mobile edge networks. In this work, we investigate a novel semi-decentralized FEEL (SD-FEEL) architecture where multiple edge servers collaborate to incorporate more data from edge devices in training. Despite the low training latency enabled by fast edge aggregation, the device heterogeneity in computational resources deteriorates the efficiency. This paper proposes an asynchronous training algorithm for SD-FEEL to overcome this issue, where edge servers can independently set deadlines for the associated client nodes and trigger the model aggregation. To deal with different levels of staleness, we design a staleness-aware aggregation scheme and analyze its convergence performance. Simulation results demonstrate the effectiveness of our proposed algorithm in achieving faster convergence and better learning performance. </p> </div> </dd> <dt>[90] arXiv:2112.04741 [pdf, other]</dt> <dd> <div > <div > Title: Learning multiple gaits of quadruped robot using hierarchical reinforcement learning </div> <div > Authors: Yunho Kim, <a >Bukun Son</a>, <a >Dongjun Lee</a> </div> <div > Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI) </div> <p >There is a growing interest in learning a velocity command tracking controller of quadruped robot using reinforcement learning due to its robustness and scalability. However, a single policy, trained end-to-end, usually shows a single gait regardless of the command velocity. This could be a suboptimal solution considering the existence of optimal gait according to the velocity for quadruped animals. In this work, we propose a hierarchical controller for quadruped robot that could generate multiple gaits (i.e. pace, trot, bound) while tracking velocity command. Our controller is composed of two policies, each working as a central pattern generator and local feedback controller, and trained with hierarchical reinforcement learning. Experiment results show 1) the existence of optimal gait for specific velocity range 2) the efficiency of our hierarchical controller compared to a controller composed of a single policy, which usually shows a single gait. Codes are publicly available. </p> </div> </dd> <dt>[91] arXiv:2112.04744 [pdf, other]</dt> <dd> <div > <div > Title: Superpixel-Based Building Damage Detection from Post-earthquake Very High Resolution Imagery Using Deep Neural Networks </div> <div > Authors: Jun Wang, <a >Zhoujing Li</a>, <a >Yixuan Qiao</a>, <a >Qiming Qin</a>, <a >Peng Gao</a>, <a >Guotong Xie</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p >Building damage detection after natural disasters like earthquakes is crucial for initiating effective emergency response actions. Remotely sensed very high spatial resolution (VHR) imagery can provide vital information due to their ability to map the affected buildings with high geometric precision. Many approaches have been developed to detect damaged buildings due to earthquakes. However, little attention has been paid to exploiting rich features represented in VHR images using Deep Neural Networks (DNN). This paper presents a novel super-pixel based approach combining DNN and a modified segmentation method, to detect damaged buildings from VHR imagery. Firstly, a modified Fast Scanning and Adaptive Merging method is extended to create initial over-segmentation. Secondly, the segments are merged based on the Region Adjacent Graph (RAG), considered an improved semantic similarity criterion composed of Local Binary Patterns (LBP) texture, spectral, and shape features. Thirdly, a pre-trained DNN using Stacked Denoising Auto-Encoders called SDAE-DNN is presented, to exploit the rich semantic features for building damage detection. Deep-layer feature abstraction of SDAE-DNN could boost detection accuracy through learning more intrinsic and discriminative features, which outperformed other methods using state-of-the-art alternative classifiers. We demonstrate the feasibility and effectiveness of our method using a subset of WorldView-2 imagery, in the complex urban areas of Bhaktapur, Nepal, which was affected by the Nepal Earthquake of April 25, 2015. </p> </div> </dd> <dt>[92] arXiv:2112.04745 [pdf, other]</dt> <dd> <div > <div > Title: OPTT: Optimal Piecewise Transformation Technique for Analyzing Numerical Data under Local Differential Privacy </div> <div > Authors: Fei Ma, <a >Renbo Zhu</a>, <a >Ping Wang</a> </div> <div > Subjects: Cryptography and Security (cs.CR) </div> <p >Privacy preserving data analysis (PPDA) has received increasing attention due to a great variety of applications. Local differential privacy (LDP), as an emerging standard that is suitable for PPDA, has been widely deployed into various real-world scenarios to analyze massive data while protecting against many forms of privacy breach. In this study, we are mainly concerned with piecewise transformation technique (PTT) for analyzing numerical data under local differential privacy. We provide a principled framework for PTT in the context of LDP, based on which PTT is studied systematically. As a result, we show that (1) many members in PTTs are asymptotically optimal when used to obtain an unbiased estimator for mean of numerical data, and (2) for a given privacy budget, there is PTT that reaches the theoretical low bound with respect to variance. Next, we prove by studying two classes of PTTs in detail that (1) there do not exist optimal PTTs compared to the well-used technique, i.e., Duchi's scheme, in terms of the consistency noisy variance, (2) on the other hand, one has the ability to find a great number of PTTs that are consistently more optimal than the latter with regard to the worst-case noisy variance, which is never reported so far. When we are restricted to consider only the high privacy level, enough PTTs turn out to be optimal than the well-known Laplace mechanism. Lastly, we prove that for a family of PTTs, the correspondingly theoretical low bound of noisy variance follows $O(\epsilon^{-2})$ when considering the high privacy level. </p> </div> </dd> <dt>[93] arXiv:2112.04748 [pdf, other]</dt> <dd> <div > <div > Title: LipSound2: Self-Supervised Pre-Training for Lip-to-Speech Reconstruction and Lip Reading </div> <div > Authors: Leyuan Qu, <a >Cornelius Weber</a>, <a >Stefan Wermter</a> </div> <div > Comments: SUBMITTED TO IEEE Transaction on Neural Networks and Learning Systems </div> <div > Subjects: Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS) </div> <p >The aim of this work is to investigate the impact of crossmodal self-supervised pre-training for speech reconstruction (video-to-audio) by leveraging the natural co-occurrence of audio and visual streams in videos. We propose LipSound2 which consists of an encoder-decoder architecture and location-aware attention mechanism to map face image sequences to mel-scale spectrograms directly without requiring any human annotations. The proposed LipSound2 model is firstly pre-trained on $\sim$2400h multi-lingual (e.g. English and German) audio-visual data (VoxCeleb2). To verify the generalizability of the proposed method, we then fine-tune the pre-trained model on domain-specific datasets (GRID, TCD-TIMIT) for English speech reconstruction and achieve a significant improvement on speech quality and intelligibility compared to previous approaches in speaker-dependent and -independent settings. In addition to English, we conduct Chinese speech reconstruction on the CMLR dataset to verify the impact on transferability. Lastly, we train the cascaded lip reading (video-to-text) system by fine-tuning the generated audios on a pre-trained speech recognition system and achieve state-of-the-art performance on both English and Chinese benchmark datasets. </p> </div> </dd> <dt>[94] arXiv:2112.04749 [pdf, other]</dt> <dd> <div > <div > Title: Experimental Demonstration of Neuromorphic Network with STT MTJ Synapses </div> <div > Authors: Peng Zhou, <a >Alexander J. Edwards</a>, <a >Fred B. Mancoff</a>, <a >Dimitri Houssameddine</a>, <a >Sanjeev Aggarwal</a>, <a >Joseph S. Friedman</a> </div> <div > Subjects: Neural and Evolutionary Computing (cs.NE) </div> <p >We present the first experimental demonstration of a neuromorphic network with magnetic tunnel junction (MTJ) synapses, which performs image recognition via vector-matrix multiplication. We also simulate a large MTJ network performing MNIST handwritten digit recognition, demonstrating that MTJ crossbars can match memristor accuracy while providing increased precision, stability, and endurance. </p> </div> </dd> <dt>[95] arXiv:2112.04751 [pdf]</dt> <dd> <div > <div > Title: Co-evolutionary hybrid intelligence </div> <div > Authors: Kirill Krinkin, <a >Yulia Shichkina</a>, <a >Andrey Ignatyev</a> </div> <div > Comments: 4 pages </div> <div > Subjects: Artificial Intelligence (cs.AI) </div> <p >Artificial intelligence is one of the drivers of modern technological development. The current approach to the development of intelligent systems is data-centric. It has several limitations: it is fundamentally impossible to collect data for modeling complex objects and processes; training neural networks requires huge computational and energy resources; solutions are not explainable. The article discusses an alternative approach to the development of artificial intelligence systems based on human-machine hybridization and their co-evolution. </p> </div> </dd> <dt>[96] arXiv:2112.04752 [pdf, other]</dt> <dd> <div > <div > Title: BLPnet: A New DNN model for Automatic License Plate Detection with Bengali OCR </div> <div > Authors: Md Saif Hassan Onim, <a >Hussain Nyeem</a>, <a >Koushik Roy</a>, <a >Mahmudul Hasan</a>, <a >Abtahi Ishmam</a>, <a >Md. Akiful Hoque Akif</a>, <a >Tareque Bashar Ovi</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Deep Neural Network (DNN) models with image processing and object localization have the potential to advance the automatic traffic control and monitoring system. Despite some notable progress in developing robust license plate detection models, research endeavours continue to reduce computational complexities with higher detection accuracy. This paper reports a computationally efficient and reasonably accurate Automatic License Plate Recognition (ALPR) system for Bengali characters with a new DNN model that we call Bengali License Plate Network (BLPnet). Additionally, the cascaded architectures for detecting vehicle regions prior to VLP in the proposed model, would significantly reduce computational cost and false-positives making the system faster and more accurate. Besides, with a new Bengali OCR engine and word-mapping process, the model can readily extract, detect and output the complete license-plate number of a vehicle. The model feeding with17 frames per second (fps) on real-time video footage can detect a vehicle with the Mean Squared Error (MSE) of 0.0152, and the mean license plate character recognition accuracy of 95%. While compared to the other models, an improvement of 5% and 20% were recorded for the BLPnet over the prominent YOLO-based ALPR model and Tesseract model for the number-plate detection accuracy and time requirement, respectively. </p> </div> </dd> <dt>[97] arXiv:2112.04757 [pdf, other]</dt> <dd> <div > <div > Title: DP-GCN: Node Classification Based on Both Connectivity and Topology Structure Convolutions for Risky Seller Detection </div> <div > Authors: Chen Zhe, <a >Aixin Sun</a> </div> <div > Subjects: Social and Information Networks (cs.SI) </div> <p >A payment network contains transactions between sellers and buyers. Detecting risky (or bad) sellers on such a payment network is crucial to payment service providers for risk management and legal compliance. In this research, we formulate this task as a node classification task. Specifically, we aim to predict a label for each seller in a payment network, by analysing its properties and/or interactions. Nodes residing in different parts of a payment network can have similar local topology structures. Such local topology structures reveal sellers' business roles, eg., supplier, drop-shipper, or retailer. We note that many existing solutions for graph-based node classification only consider node connectivity but not the similarity between node's local topology structure. Motivated by business need, we present a dual-path graph convolution network, named DP-GCN, for node classification. DP-GCN considers both node connectivity and topology structure similarity. The proposed model consists of three main modules: (i) a C-GCN module to capture connectivity relationships between nodes, (ii) a T-GCN module to capture topology structure similarities between nodes, and (iii) a multi-head self-attention module to align both properties. We evaluate DP-GCN on seven benchmark datasets against diverse baselines. We also provide a case study of running DP-GCN on three large-scale payment networks from PayPal, one of the leading payment service providers. Experimental results demonstrate DP-GCN's effectiveness and practicability. </p> </div> </dd> <dt>[98] arXiv:2112.04758 [pdf, other]</dt> <dd> <div > <div > Title: Does Redundancy in AI Perception Systems Help to Test for Super-Human Automated Driving Performance? </div> <div > Authors: Hanno Gottschalk, Matthias Rottmann, <a >Maida Saltagic</a> </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML) </div> <p >While automated driving is often advertised with better-than-human driving performance, this work reviews that it is nearly impossible to provide direct statistical evidence on the system level that this is actually the case. The amount of labeled data needed would exceed dimensions of present day technical and economical capabilities. A commonly used strategy therefore is the use of redundancy along with the proof of sufficient subsystems' performances. As it is known, this strategy is efficient especially for the case of subsystems operating independently, i.e. the occurrence of errors is independent in a statistical sense. Here, we give some first considerations and experimental evidence that this strategy is not a free ride as the errors of neural networks fulfilling the same computer vision task, at least for some cases, show correlated occurrences of errors. This remains true, if training data, architecture, and training are kept separate or independence is trained using special loss functions. Using data from different sensors (realized by up to five 2D projections of the 3D MNIST data set) in our experiments is more efficiently reducing correlations, however not to an extent that is realizing the potential of reduction of testing data that can be obtained for redundant and statistically independent subsystems. </p> </div> </dd> <dt>[99] arXiv:2112.04761 [pdf, other]</dt> <dd> <div > <div > Title: HBReID: Harder Batch for Re-identification </div> <div > Authors: Wen Li, <a >Furong Xu</a>, <a >Jianan Zhao</a>, <a >Ruobing Zheng</a>, <a >Cheng Zou</a>, <a >Meng Wang</a>, <a >Yuan Cheng</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Triplet loss is a widely adopted loss function in ReID task which pulls the hardest positive pairs close and pushes the hardest negative pairs far away. However, the selected samples are not the hardest globally, but the hardest only in a mini-batch, which will affect the performance. In this report, a hard batch mining method is proposed to mine the hardest samples globally to make triplet harder. More specifically, the most similar classes are selected into a same mini-batch so that the similar classes could be pushed further away. Besides, an adversarial scene removal module composed of a scene classifier and an adversarial loss is used to learn scene invariant feature representations. Experiments are conducted on dataset MSMT17 to prove the effectiveness, and our method surpasses all of the previous methods and sets state-of-the-art result. </p> </div> </dd> <dt>[100] arXiv:2112.04764 [pdf, other]</dt> <dd> <div > <div > Title: 3D-VField: Learning to Adversarially Deform Point Clouds for Robust 3D Object Detection </div> <div > Authors: Alexander Lehner, <a >Stefano Gasperini</a>, <a >Alvaro Marcos-Ramiro</a>, <a >Michael Schmidt</a>, <a >Mohammad-Ali Nikouei Mahani</a>, <a >Nassir Navab</a>, <a >Benjamin Busam</a>, <a >Federico Tombari</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO) </div> <p >As 3D object detection on point clouds relies on the geometrical relationships between the points, non-standard object shapes can hinder a method's detection capability. However, in safety-critical settings, robustness on out-of-distribution and long-tail samples is fundamental to circumvent dangerous issues, such as the misdetection of damaged or rare cars. In this work, we substantially improve the generalization of 3D object detectors to out-of-domain data by taking into account deformed point clouds during training. We achieve this with 3D-VField: a novel method that plausibly deforms objects via vectors learned in an adversarial fashion. Our approach constrains 3D points to slide along their sensor view rays while neither adding nor removing any of them. The obtained vectors are transferrable, sample-independent and preserve shape smoothness and occlusions. By augmenting normal samples with the deformations produced by these vector fields during training, we significantly improve robustness against differently shaped objects, such as damaged/deformed cars, even while training only on KITTI. Towards this end, we propose and share open source CrashD: a synthetic dataset of realistic damaged and rare cars, with a variety of crash scenarios. Extensive experiments on KITTI, Waymo, our CrashD and SUN RGB-D show the high generalizability of our techniques to out-of-domain data, different models and sensors, namely LiDAR and ToF cameras, for both indoor and outdoor scenes. Our CrashD dataset is available at https://crashd-cars.github.io. </p> </div> </dd> <dt>[101] arXiv:2112.04766 [pdf, other]</dt> <dd> <div > <div > Title: Adaptive Methods for Aggregated Domain Generalization </div> <div > Authors: Xavier Thomas, <a >Dhruv Mahajan</a>, <a >Alex Pentland</a>, <a >Abhimanyu Dubey</a> </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Domain generalization involves learning a classifier from a heterogeneous collection of training sources such that it generalizes to data drawn from similar unknown target domains, with applications in large-scale learning and personalized inference. In many settings, privacy concerns prohibit obtaining domain labels for the training data samples, and instead only have an aggregated collection of training points. Existing approaches that utilize domain labels to create domain-invariant feature representations are inapplicable in this setting, requiring alternative approaches to learn generalizable classifiers. In this paper, we propose a domain-adaptive approach to this problem, which operates in two steps: (a) we cluster training data within a carefully chosen feature space to create pseudo-domains, and (b) using these pseudo-domains we learn a domain-adaptive classifier that makes predictions using information about both the input and the pseudo-domain it belongs to. Our approach achieves state-of-the-art performance on a variety of domain generalization benchmarks without using domain labels whatsoever. Furthermore, we provide novel theoretical guarantees on domain generalization using cluster information. Our approach is amenable to ensemble-based methods and provides substantial gains even on large-scale benchmark datasets. The code can be found at: https://github.com/xavierohan/AdaClust_DomainBed </p> </div> </dd> <dt>[102] arXiv:2112.04771 [pdf, other]</dt> <dd> <div > <div > Title: Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection </div> <div > Authors: Jiaqi Tang, <a >Zhaoyang Liu</a>, <a >Chen Qian</a>, <a >Wayne Wu</a>, <a >Limin Wang</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Generic event boundary detection is an important yet challenging task in video understanding, which aims at detecting the moments where humans naturally perceive event boundaries. The main challenge of this task is perceiving various temporal variations of diverse event boundaries. To this end, this paper presents an effective and end-to-end learnable framework (DDM-Net). To tackle the diversity and complicated semantics of event boundaries, we make three notable improvements. First, we construct a feature bank to store multi-level features of space and time, prepared for difference calculation at multiple scales. Second, to alleviate inadequate temporal modeling of previous methods, we present dense difference maps (DDM) to comprehensively characterize the motion pattern. Finally, we exploit progressive attention on multi-level DDM to jointly aggregate appearance and motion clues. As a result, DDM-Net respectively achieves a significant boost of 14% and 8% on Kinetics-GEBD and TAPOS benchmark, and outperforms the top-1 winner solution of LOVEU Challenge@CVPR 2021 without bells and whistles. The state-of-the-art result demonstrates the effectiveness of richer motion representation and more sophisticated aggregation, in handling the diversity of generic event boundary detection. Our codes will be made available soon. </p> </div> </dd> <dt>[103] arXiv:2112.04778 [pdf]</dt> <dd> <div > <div > Title: Justifying the Dependability and Security of Business-Critical Blockchain-based Applications </div> <div > Authors: Pierre-Yves Piriou, <a >Olivier Boudeville</a>, <a >Gilles Deleuze</a>, <a >Sara Tucci-Piergiovanni</a>, <a >Önder Gürcan</a> </div> <div > Comments: 8 pages, 6 figures, The Third IEEE International Conference on Blockchain Computing and Applications (BCCA 2021) </div> <div > Subjects: Software Engineering (cs.SE); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA) </div> <p >In the industry, blockchains are increasingly used as the backbone of product and process traceability. Blockchain-based traceability participates in the demonstration of product and/or process compliance with existing safety standards or quality criteria. In this perspective, services and applications built on top of blockchains are business-critical applications, because an intended failure or corruption of the system can lead to an important reputation loss regarding the products or the processes involved. The development of a blockchain-based business-critical application must be then conducted carefully, requiring a thorough justification of its dependability and security. To this end, this paper encourages an engineering perspective rooted in well-understood tools and concepts borrowed from the engineering of safety-critical systems. Concretely, we use a justification framework, called CAE (Claim, Argument, Evidence), by following an approach based on assurance cases, in order to provide convincing arguments that a business-critical blockchain-based application is dependable and secure. The application of this approach is sketched with a case study based on the blockchain HYPERLEDGER FABRIC. </p> </div> </dd> <dt>[104] arXiv:2112.04785 [pdf, other]</dt> <dd> <div > <div > Title: VMAgent: Scheduling Simulator for Reinforcement Learning </div> <div > Authors: Junjie Sheng, <a >Shengliang Cai</a>, <a >Haochuan Cui</a>, <a >Wenhao Li</a>, <a >Yun Hua</a>, <a >Bo Jin</a>, <a >Wenli Zhou</a>, <a >Yiqiu Hu</a>, <a >Lei Zhu</a>, <a >Qian Peng</a>, <a >Hongyuan Zha</a>, <a >Xiangfeng Wang</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >A novel simulator called VMAgent is introduced to help RL researchers better explore new methods, especially for virtual machine scheduling. VMAgent is inspired by practical virtual machine (VM) scheduling tasks and provides an efficient simulation platform that can reflect the real situations of cloud computing. Three scenarios (fading, recovering, and expansion) are concluded from practical cloud computing and corresponds to many reinforcement learning challenges (high dimensional state and action spaces, high non-stationarity, and life-long demand). VMAgent provides flexible configurations for RL researchers to design their customized scheduling environments considering different problem features. From the VM scheduling perspective, VMAgent also helps to explore better learning-based scheduling solutions. </p> </div> </dd> <dt>[105] arXiv:2112.04788 [pdf, other]</dt> <dd> <div > <div > Title: "What can I cook with these ingredients?" -- Understanding cooking-related information needs in conversational search </div> <div > Authors: Alexander Frummet, <a >David Elsweiler</a>, <a >Bernd Ludwig</a> </div> <div > Subjects: Information Retrieval (cs.IR) </div> <p >As conversational search becomes more pervasive, it becomes increasingly important to understand the user's underlying information needs when they converse with such systems in diverse domains. We conduct an in-situ study to understand information needs arising in a home cooking context as well as how they are verbally communicated to an assistant. A human experimenter plays this role in our study. Based on the transcriptions of utterances, we derive a detailed hierarchical taxonomy of diverse information needs occurring in this context, which require different levels of assistance to be solved. The taxonomy shows that needs can be communicated through different linguistic means and require different amounts of context to be understood. In a second contribution we perform classification experiments to determine the feasibility of predicting the type of information need a user has during a dialogue using the turn provided. For this multi-label classification problem, we achieve average F1 measures of 40% using BERT-based models. We demonstrate with examples, which types of need are difficult to predict and show why, concluding that models need to include more context information in order to improve both information need classification and assistance to make such systems usable. </p> </div> </dd> <dt>[106] arXiv:2112.04796 [pdf]</dt> <dd> <div > <div > Title: Detecting Potentially Harmful and Protective Suicide-related Content on Twitter: A Machine Learning Approach </div> <div > Authors: Hannah Metzler, <a >Hubert Baginski</a>, <a >Thomas Niederkrotenthaler</a>, <a >David Garcia</a> </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >Research shows that exposure to suicide-related news media content is associated with suicide rates, with some content characteristics likely having harmful and others potentially protective effects. Although good evidence exists for a few selected characteristics, systematic large scale investigations are missing in general, and in particular for social media data. We apply machine learning methods to automatically label large quantities of Twitter data. We developed a novel annotation scheme that classifies suicide-related tweets into different message types and problem- vs. solution-focused perspectives. We then trained a benchmark of machine learning models including a majority classifier, an approach based on word frequency (TF-IDF with a linear SVM) and two state-of-the-art deep learning models (BERT, XLNet). The two deep learning models achieved the best performance in two classification tasks: First, we classified six main content categories, including personal stories about either suicidal ideation and attempts or coping, calls for action intending to spread either problem awareness or prevention-related information, reportings of suicide cases, and other suicide-related and off-topic tweets. The deep learning models reach accuracy scores above 73% on average across the six categories, and F1-scores in between 69% and 85% for all but the suicidal ideation and attempts category (55%). Second, in separating postings referring to actual suicide from off-topic tweets, they correctly labelled around 88% of tweets, with BERT achieving F1-scores of 93% and 74% for the two categories. These classification performances are comparable to the state-of-the-art on similar tasks. By making data labeling more efficient, this work enables future large-scale investigations on harmful and protective effects of various kinds of social media content on suicide rates and on help-seeking behavior. </p> </div> </dd> <dt>[107] arXiv:2112.04797 [pdf, ps, other]</dt> <dd> <div > <div > Title: Complexity assessments for decidable fragments of Set Theory. III: A quadratic reduction of constraints over nested sets to Boolean formulae </div> <div > Authors: Domenico Cantone, <a >Andrea De Domenico</a>, <a >Pietro Maugeri</a>, <a >Eugenio G. Omodeo</a> </div> <div > Subjects: Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI) </div> <p >As a contribution to quantitative set-theoretic inferencing, a translation is proposed of conjunctions of literals of the forms $x=y\setminus z$, $x eq y\setminus z$, and $z =\{x\}$, where $x,y,z$ stand for variables ranging over the von Neumann universe of sets, into unquantified Boolean formulae of a rather simple conjunctive normal form. The formulae in the target language involve variables ranging over a Boolean ring of sets, along with a difference operator and relators designating equality, non-disjointness and inclusion. Moreover, the result of each translation is a conjunction of literals of the forms $x=y\setminus z$, $xeq y\setminus z$ and of implications whose antecedents are isolated literals and whose consequents are either inclusions (strict or non-strict) between variables, or equalities between variables. Besides reflecting a simple and natural semantics, which ensures satisfiability-preservation, the proposed translation has quadratic algorithmic time-complexity, and bridges two languages both of which are known to have an NP-complete satisfiability problem. </p> </div> </dd> <dt>[108] arXiv:2112.04800 [pdf, other]</dt> <dd> <div > <div > Title: GPU backed Data Mining on Android Devices </div> <div > Authors: Robert Fritze, <a >Claudia Plant</a> </div> <div > Comments: 11 pages </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG) </div> <p >Choosing an appropriate programming paradigm for high-performance computing on low-power devices can be useful to speed up calculations. Many Android devices have an integrated GPU and - although not officially supported - the OpenCL framework can be used on Android devices for addressing these GPUs. OpenCL supports thread and data parallelism. Applications that use the GPU must account for the fact that they can be suspended by the user or the Android operating system at any moment. We have created a wrapper library that allows to use OpenCL on Android devices. Already written OpenCL programs can be executed with almost no modification. We have used this library to compare the performance of the DBSCAN and Kmeans algorithms on an integrated GPU of an Arm-v7 tablet with other single and multithreaded implementations on the same device. We have investigated which programming paradigm and language allows the best tradeoff between execution speed and energy consumption. Using the GPU for HPC on Android devices can help to carry out computationally intensive machine learning or data mining tasks in remote areas, under harsh environmental conditions and in areas where energy supply is an issue. </p> </div> </dd> <dt>[109] arXiv:2112.04803 [pdf, other]</dt> <dd> <div > <div > Title: Combining Textual Features for the Detection of Hateful and Offensive Language </div> <div > Authors: Sherzod Hakimov, <a >Ralph Ewerth</a> </div> <div > Comments: HASOC 2021, Forum for Information Retrieval Evaluation, 2021 </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >The detection of offensive, hateful and profane language has become a critical challenge since many users in social networks are exposed to cyberbullying activities on a daily basis. In this paper, we present an analysis of combining different textual features for the detection of hateful or offensive posts on Twitter. We provide a detailed experimental evaluation to understand the impact of each building block in a neural network architecture. The proposed architecture is evaluated on the English Subtask 1A: Identifying Hate, offensive and profane content from the post datasets of HASOC-2021 dataset under the team name TIB-VA. We compared different variants of the contextual word embeddings combined with the character level embeddings and the encoding of collected hate terms. </p> </div> </dd> <dt>[110] arXiv:2112.04807 [pdf, other]</dt> <dd> <div > <div > Title: Effective dimension of machine learning models </div> <div > Authors: Amira Abbas, David Sutter, <a >Alessio Figalli</a>, <a >Stefan Woerner</a> </div> <div > Comments: 17 pages, 2 figures </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Making statements about the performance of trained models on tasks involving new data is one of the primary goals of machine learning, i.e., to understand the generalization power of a model. Various capacity measures try to capture this ability, but usually fall short in explaining important characteristics of models that we observe in practice. In this study, we propose the local effective dimension as a capacity measure which seems to correlate well with generalization error on standard data sets. Importantly, we prove that the local effective dimension bounds the generalization error and discuss the aptness of this capacity measure for machine learning models. </p> </div> </dd> <dt>[111] arXiv:2112.04809 [pdf, other]</dt> <dd> <div > <div > Title: Next Steps: Learning a Disentangled Gait Representation for Versatile Quadruped Locomotion </div> <div > Authors: Alexander L. Mitchell, <a >Wolfgang Merkt</a>, <a >Mathieu Geisert</a>, <a >Siddhant Gangapurwala</a>, <a >Martin Engelcke</a>, <a >Oiwi Parker Jones</a>, <a >Ioannis Havoutis</a>, <a >Ingmar Posner</a> </div> <div > Comments: 8 pages, 6 figures, under review at Robotics and Automation Letters (RA-L) </div> <div > Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p >Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, foot step height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation and robustly capture a richness of movement significantly exceeding the relatively narrow behaviour seen during training. In addition, the use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on a real ANYmal quadruped robot and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations. </p> </div> </dd> <dt>[112] arXiv:2112.04810 [pdf, ps, other]</dt> <dd> <div > <div > Title: From Scattered Sources to Comprehensive Technology Landscape: A Recommendation-based Retrieval Approach </div> <div > Authors: Chi Thang Duong, <a >Dimitri Percia David</a>, <a >Ljiljana Dolamic</a>, <a >Alain Mermoud</a>, <a >Vincent Lenders</a>, <a >Karl Aberer</a> </div> <div > Subjects: Information Retrieval (cs.IR) </div> <p >Mapping the technology landscape is crucial for market actors to take informed investment decisions. However, given the large amount of data on the Web and its subsequent information overload, manually retrieving information is a seemingly ineffective and incomplete approach. In this work, we propose an end-to-end recommendation based retrieval approach to support automatic retrieval of technologies and their associated companies from raw Web data. This is a two-task setup involving (i) technology classification of entities extracted from company corpus, and (ii) technology and company retrieval based on classified technologies. Our proposed framework approaches the first task by leveraging DistilBERT which is a state-of-the-art language model. For the retrieval task, we introduce a recommendation-based retrieval technique to simultaneously support retrieving related companies, technologies related to a specific company and companies relevant to a technology. To evaluate these tasks, we also construct a data set that includes company documents and entities extracted from these documents together with company categories and technology labels. Experiments show that our approach is able to return 4 times more relevant companies while outperforming traditional retrieval baseline in retrieving technologies. </p> </div> </dd> <dt>[113] arXiv:2112.04812 [pdf, other]</dt> <dd> <div > <div > Title: Learning Neural Implicit Functions as Object Representations for Robotic Manipulation </div> <div > Authors: Jung-Su Ha, <a >Danny Driess</a>, <a >Marc Toussaint</a> </div> <div > Subjects: Robotics (cs.RO) </div> <p >Robotic manipulation planning is the problem of finding a sequence of robot configurations that involves interactions with objects in the scene, e.g., grasp, placement, tool-use, etc. To achieve such interactions, traditional approaches require hand-designed features and object representations, and it still remains an open question how to describe such interactions with arbitrary objects in a flexible and efficient way. Inspired by recent advances in 3D modeling, e.g. NeRF, we propose a method to represent objects as neural implicit functions upon which we can define and jointly train interaction constraint functions. The proposed pixel-aligned representation is directly inferred from camera images with known camera geometry, naturally acting as a perception component in the whole manipulation pipeline, while at the same time enabling sequential robot manipulation planning. </p> </div> </dd> <dt>[114] arXiv:2112.04827 [pdf, other]</dt> <dd> <div > <div > Title: Explainability of the Implications of Supervised and Unsupervised Face Image Quality Estimations Through Activation Map Variation Analyses in Face Recognition Models </div> <div > Authors: Biying Fu, <a >Naser Damer</a> </div> <div > Comments: accepted at the IEEE Winter Conference on Applications of Computer Vision Workshops, WACV Workshops 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p >It is challenging to derive explainability for unsupervised or statistical-based face image quality assessment (FIQA) methods. In this work, we propose a novel set of explainability tools to derive reasoning for different FIQA decisions and their face recognition (FR) performance implications. We avoid limiting the deployment of our tools to certain FIQA methods by basing our analyses on the behavior of FR models when processing samples with different FIQA decisions. This leads to explainability tools that can be applied for any FIQA method with any CNN-based FR solution using activation mapping to exhibit the network's activation derived from the face embedding. To avoid the low discrimination between the general spatial activation mapping of low and high-quality images in FR models, we build our explainability tools in a higher derivative space by analyzing the variation of the FR activation maps of image sets with different quality decisions. We demonstrate our tools and analyze the findings on four FIQA methods, by presenting inter and intra-FIQA method analyses. Our proposed tools and the analyses based on them point out, among other conclusions, that high-quality images typically cause consistent low activation on the areas outside of the central face region, while low-quality images, despite general low activation, have high variations of activation in such areas. Our explainability tools also extend to analyzing single images where we show that low-quality images tend to have an FR model spatial activation that strongly differs from what is expected from a high-quality image where this difference also tends to appear more in areas outside of the central face region and does correspond to issues like extreme poses and facial occlusions. The implementation of the proposed tools is accessible here [link]. </p> </div> </dd> <dt>[115] arXiv:2112.04831 [pdf, other]</dt> <dd> <div > <div > Title: Multimodal Fake News Detection </div> <div > Authors: Santiago Alonso-Bartolome, <a >Isabel Segura-Bedmar</a> </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >Over the last years, there has been an unprecedented proliferation of fake news. As a consequence, we are more susceptible to the pernicious impact that misinformation and disinformation spreading can have in different segments of our society. Thus, the development of tools for automatic detection of fake news plays and important role in the prevention of its negative effects. Most attempts to detect and classify false content focus only on using textual information. Multimodal approaches are less frequent and they typically classify news either as true or fake. In this work, we perform a fine-grained classification of fake news on the Fakeddit dataset, using both unimodal and multimodal approaches. Our experiments show that the multimodal approach based on a Convolutional Neural Network (CNN) architecture combining text and image data achieves the best results, with an accuracy of 87%. Some fake news categories such as Manipulated content, Satire or False connection strongly benefit from the use of images. Using images also improves the results of the other categories, but with less impact. Regarding the unimodal approaches using only text, Bidirectional Encoder Representations from Transformers (BERT) is the best model with an accuracy of 78%. Therefore, exploiting both text and image data significantly improves the performance of fake news detection. </p> </div> </dd> <dt>[116] arXiv:2112.04838 [pdf, other]</dt> <dd> <div > <div > Title: How Not to Protect Your IP -- An Industry-Wide Break of IEEE 1735 Implementations </div> <div > Authors: Julian Speith, Florian Schweins, <a >Maik Ender</a>, <a >Marc Fyrbiak</a>, <a >Alexander May</a>, <a >Christof Paar</a> </div> <div > Subjects: Cryptography and Security (cs.CR) </div> <p >Modern hardware systems are composed of a variety of third-party Intellectual Property (IP) cores to implement their overall functionality. Since hardware design is a globalized process involving various (untrusted) stakeholders, a secure management of the valuable IP between authors and users is inevitable to protect them from unauthorized access and modification. To this end, the widely adopted IEEE standard 1735-2014 was created to ensure confidentiality and integrity. In this paper, we outline structural weaknesses in IEEE 1735 that cannot be fixed with cryptographic solutions (given the contemporary hardware design process) and thus render the standard inherently insecure. We practically demonstrate the weaknesses by recovering the private keys of IEEE 1735 implementations from major Electronic Design Automation (EDA) tool vendors, namely Intel, Xilinx, Cadence, Siemens, Microsemi, and Lattice, while results on a seventh case study are withheld. As a consequence, we can decrypt, modify, and re-encrypt all allegedly protected IP cores designed for the respective tools, thus leading to an industry-wide break. As part of this analysis, we are the first to publicly disclose three RSA-based white-box schemes that are used in real-world products and present cryptanalytical attacks for all of them, finally resulting in key recovery. </p> </div> </dd> <dt>[117] arXiv:2112.04839 [pdf, other]</dt> <dd> <div > <div > Title: Design and Implementation of Real-Time Localization System (RTLS) based on UWB and TDoA Algorithm </div> <div > Authors: Fengyun Zhang, <a >Li Yang</a>, <a >Yuhuan Liu</a>, <a >Yulong Ding</a>, <a >Shuang-Hua Yang</a>, <a >Hao Li</a> </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >Nowadays, accurate localization plays an essential role in many fields, like target tracking and path planning. The challenges of indoor localization include inadequate localization accuracy, unreasonable anchor deployment in complex scenarios, lack of stability, and high cost. So the universal positioning technologies cannot meet the real application requirements scarcely. To overcome these shortcomings, a comprehensive Ultra Wide-Band (UWB) based RTLS is presented in this paper. We first introduce the architecture of the real-time localization system, then propose a new wireless clock synchronization (WCS) scheme, finally discuss the time difference of arrival (TDoA) algorithm. We define the time-base selection strategy for the TDoA algorithm, and analyze the relationship between anchor deployment and positioning accuracy. The Extended Kalman Filter (EKF) method is presented for non-linear dynamic localization estimation, and it performs well in terms of stability and accuracy in moving targets. </p> </div> </dd> <dt>[118] arXiv:2112.04840 [pdf, other]</dt> <dd> <div > <div > Title: Knowledge Distillation for Object Detection via Rank Mimicking and Prediction-guided Feature Imitation </div> <div > Authors: Gang Li, <a >Xiang Li</a>, <a >Yujie Wang</a>, <a >Shanshan Zhang</a>, <a >Yichao Wu</a>, <a >Ding Liang</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Knowledge Distillation (KD) is a widely-used technology to inherit information from cumbersome teacher models to compact student models, consequently realizing model compression and acceleration. Compared with image classification, object detection is a more complex task, and designing specific KD methods for object detection is non-trivial. In this work, we elaborately study the behaviour difference between the teacher and student detection models, and obtain two intriguing observations: First, the teacher and student rank their detected candidate boxes quite differently, which results in their precision discrepancy. Second, there is a considerable gap between the feature response differences and prediction differences between teacher and student, indicating that equally imitating all the feature maps of the teacher is the sub-optimal choice for improving the student's accuracy. Based on the two observations, we propose Rank Mimicking (RM) and Prediction-guided Feature Imitation (PFI) for distilling one-stage detectors, respectively. RM takes the rank of candidate boxes from teachers as a new form of knowledge to distill, which consistently outperforms the traditional soft label distillation. PFI attempts to correlate feature differences with prediction differences, making feature imitation directly help to improve the student's accuracy. On MS COCO and PASCAL VOC benchmarks, extensive experiments are conducted on various detectors with different backbones to validate the effectiveness of our method. Specifically, RetinaNet with ResNet50 achieves 40.4% mAP in MS COCO, which is 3.5% higher than its baseline, and also outperforms previous KD methods. </p> </div> </dd> <dt>[119] arXiv:2112.04842 [pdf, other]</dt> <dd> <div > <div > Title: Siamese Attribute-missing Graph Auto-encoder </div> <div > Authors: Wenxuan Tu, <a >Sihang Zhou</a>, <a >Yue Liu</a>, <a >Xinwang Liu</a> </div> <div > Comments: under review </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >Graph representation learning (GRL) on attribute-missing graphs, which is a common yet challenging problem, has recently attracted considerable attention. We observe that existing literature: 1) isolates the learning of attribute and structure embedding thus fails to take full advantages of the two types of information; 2) imposes too strict distribution assumption on the latent space variables, leading to less discriminative feature representations. In this paper, based on the idea of introducing intimate information interaction between the two information sources, we propose our Siamese Attribute-missing Graph Auto-encoder (SAGA). Specifically, three strategies have been conducted. First, we entangle the attribute embedding and structure embedding by introducing a siamese network structure to share the parameters learned by both processes, which allows the network training to benefit from more abundant and diverse information. Second, we introduce a K-nearest neighbor (KNN) and structural constraint enhanced learning mechanism to improve the quality of latent features of the missing attributes by filtering unreliable connections. Third, we manually mask the connections on multiple adjacent matrices and force the structural information embedding sub-network to recover the true adjacent matrix, thus enforcing the resulting network to be able to selectively exploit more high-order discriminative features for data completion. Extensive experiments on six benchmark datasets demonstrate the superiority of our SAGA against the state-of-the-art methods. </p> </div> </dd> <dt>[120] arXiv:2112.04845 [pdf, other]</dt> <dd> <div > <div > Title: High performance computing on Android devices -- a case study </div> <div > Authors: Robert Fritze, <a >Claudia Plant</a> </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> <p >High performance computing for low power devices can be useful to speed up calculations on processors that use a lower clock rate than computers for which energy efficiency is not an issue. In this trial, different high performance techniques for Android devices have been compared, with a special focus on the use of the GPU. Although not officially supported, the OpenCL framework can be used on Android tablets. For the comparison of the different parallel programming paradigms, a benchmark was chosen that could be implemented easily with all frameworks. The Mandelbrot algorithm is computationally intensive and has very few input and output operations. The algorithm has been implemented in Java, C, C with assembler, C with SIMD assembler, C with OpenCL and scalar instructions and C with OpenCL and vector instructions. The implementations have been tested for all architectures currently supported by Android. High speedups can be achieved using SIMD and OpenCL, although the implementation is not straightforward for either one. Apps that use the GPU must account for the fact that they can be suspended by the user at any moment. In using the OpenCL framework on the GPU of Android devices, a computational power comparable to those of modern high speed CPUs can be made available to the software developer. </p> </div> </dd> <dt>[121] arXiv:2112.04846 [pdf, other]</dt> <dd> <div > <div > Title: ScaleNet: A Shallow Architecture for Scale Estimation </div> <div > Authors: Axel Barroso-Laguna, <a >Yurun Tian</a>, <a >Krystian Mikolajczyk</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >In this paper, we address the problem of estimating scale factors between images. We formulate the scale estimation problem as a prediction of a probability distribution over scale factors. We design a new architecture, ScaleNet, that exploits dilated convolutions as well as self and cross-correlation layers to predict the scale between images. We demonstrate that rectifying images with estimated scales leads to significant performance improvements for various tasks and methods. Specifically, we show how ScaleNet can be combined with sparse local features and dense correspondence networks to improve camera pose estimation, 3D reconstruction, or dense geometric matching in different benchmarks and datasets. We provide an extensive evaluation on several tasks and analyze the computational overhead of ScaleNet. The code, evaluation protocols, and trained models are publicly available at https://github.com/axelBarroso/ScaleNet. </p> </div> </dd> <dt>[122] arXiv:2112.04854 [pdf, other]</dt> <dd> <div > <div > Title: Properties of Large 2-Crossing-Critical Graphs </div> <div > Authors: Drago Bokal, <a >Markus Chimani</a>, <a >Alexander Nover</a>, <a >Jöran Schierbaum</a>, <a >Tobias Stolzmann</a>, <a >Mirko H. Wagner</a>, <a >Tilo Wiedera</a> </div> <div > Comments: 29 pages, 14 figures </div> <div > Subjects: Discrete Mathematics (cs.DM); Combinatorics (math.CO) </div> <p >A $c$-crossing-critical graph is one that has crossing number at least $c$ but each of its proper subgraphs has crossing number less than $c$. Recently, a set of explicit construction rules was identified by Bokal, Oporowski, Richter, and Salazar to generate all large $2$-crossing-critical graphs (i.e., all apart from a finite set of small sporadic graphs). They share the property of containing a generalized Wagner graph $V_{10}$ as a subdivision. In this paper, we study these graphs and establish their order, simple crossing number, edge cover number, clique number, maximum degree, chromatic number, chromatic index, and treewidth. We also show that the graphs are linear-time recognizable and that all our proofs lead to efficient algorithms for the above measures. </p> </div> </dd> <dt>[123] arXiv:2112.04855 [pdf]</dt> <dd> <div > <div > Title: An Australian DER Bill of Rights and Responsibilities </div> <div > Authors: Niraj Lal </div> <div > Comments: 17 pages, 1 figure, 1 table, 1 appenxix </div> <div > Subjects: Systems and Control (eess.SY) </div> <p >Australia's world-leading penetration of distributed solar photovoltaics (PV) is now impacting power system security and, as a result, how customers can use and export their own PV-generated energy. Several programs of Australian regulatory reform for distributed energy resources (DER) have emphasised the importance of placing consumers at the centre of any energy transition, but this has occurred against a haphazard backdrop of proposals for solar export taxes, updated inverter standards, and diminishing feed-in-tariffs. Absent from the discussion is a coherent espousal of reasonable consumer expectations with practical technical definitions of how these may be applied. Whilst American legislation has enshrined initial rights to connect PV, they do not consider the evolution of rights in a DER-dominated future. This paper proposes a first attempt at an Australian 'DER Bill of Rights and Responsibilities' for both passive and active participation in energy markets, to support an environment of customer trust and sector confidence in the guiderails of DER integration. Guiding principles are presented with practical definitions referencing existing instruments including inverter standards, network connection agreements and central ancillary service markets. We highlight how these proposed rights are already being breached regularly in Australia, before outlining a pathway to enshrine them for a DER-dominated future with broad sector endorsement. </p> </div> </dd> <dt>[124] arXiv:2112.04857 [pdf, other]</dt> <dd> <div > <div > Title: A New Measure of Model Redundancy for Compressed Convolutional Neural Networks </div> <div > Authors: Feiqing Huang, <a >Yuefeng Si</a>, <a >Yao Zheng</a>, <a >Guodong Li</a> </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >While recently many designs have been proposed to improve the model efficiency of convolutional neural networks (CNNs) on a fixed resource budget, theoretical understanding of these designs is still conspicuously lacking. This paper aims to provide a new framework for answering the question: Is there still any remaining model redundancy in a compressed CNN? We begin by developing a general statistical formulation of CNNs and compressed CNNs via the tensor decomposition, such that the weights across layers can be summarized into a single tensor. Then, through a rigorous sample complexity analysis, we reveal an important discrepancy between the derived sample complexity and the naive parameter counting, which serves as a direct indicator of the model redundancy. Motivated by this finding, we introduce a new model redundancy measure for compressed CNNs, called the $K/R$ ratio, which further allows for nonlinear activations. The usefulness of this new measure is supported by ablation studies on popular block designs and datasets. </p> </div> </dd> <dt>[125] arXiv:2112.04870 [pdf, other]</dt> <dd> <div > <div > Title: Eigenfunction martingale estimators for interacting particle systems and their mean field limit </div> <div > Authors: Grigorios A. Pavliotis, <a >Andrea Zanoni</a> </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >We study the problem of parameter estimation for large exchangeable interacting particle systems when a sample of discrete observations from a single particle is known. We propose a novel method based on martingale estimating functions constructed by employing the eigenvalues and eigenfunctions of the generator of the mean field limit, linearized around the (unique) invariant measure of the mean field dynamics. We then prove that our estimator is asymptotically unbiased and asymptotically normal when the number of observations and the number of particles tend to infinity, and we provide a rate of convergence towards the exact value of the parameters. Finally, we present several numerical experiments which show the accuracy of our estimator and corroborate our theoretical findings, even in the case the mean field dynamics exhibit more than one steady states. </p> </div> </dd> <dt>[126] arXiv:2112.04871 [pdf, other]</dt> <dd> <div > <div > Title: KGE-CL: Contrastive Learning of Knowledge Graph Embeddings </div> <div > Authors: Wentao Xu, <a >Zhiping Luo</a>, <a >Weiqing Liu</a>, <a >Jiang Bian</a>, <a >Jian Yin</a>, <a >Tie-Yan Liu</a> </div> <div > Subjects: Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >Learning the embeddings of knowledge graphs is vital in artificial intelligence, and can benefit various downstream applications, such as recommendation and question answering. In recent years, many research efforts have been proposed for knowledge graph embedding. However, most previous knowledge graph embedding methods ignore the semantic similarity between the related entities and entity-relation couples in different triples since they separately optimize each triple with the scoring function. To address this problem, we propose a simple yet efficient contrastive learning framework for knowledge graph embeddings, which can shorten the semantic distance of the related entities and entity-relation couples in different triples and thus improve the expressiveness of knowledge graph embeddings. We evaluate our proposed method on three standard knowledge graph benchmarks. It is noteworthy that our method can yield some new state-of-the-art results, achieving 51.2% MRR, 46.8% Hits@1 on the WN18RR dataset, and 59.1% MRR, 51.8% Hits@1 on the YAGO3-10 dataset. </p> </div> </dd> <dt>[127] arXiv:2112.04873 [pdf, other]</dt> <dd> <div > <div > Title: Nice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation </div> <div > Authors: Poorav Desai, <a >Tanmoy Chakraborty</a>, <a >Md Shad Akhtar</a> </div> <div > Comments: Accepted for publication in AAAI-2022 </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >Sarcasm is a pervading linguistic phenomenon and highly challenging to explain due to its subjectivity, lack of context and deeply-felt opinion. In the multimodal setup, sarcasm is conveyed through the incongruity between the text and visual entities. Although recent approaches deal with sarcasm as a classification problem, it is unclear why an online post is identified as sarcastic. Without proper explanation, end users may not be able to perceive the underlying sense of irony. In this paper, we propose a novel problem -- Multimodal Sarcasm Explanation (MuSE) -- given a multimodal sarcastic post containing an image and a caption, we aim to generate a natural language explanation to reveal the intended sarcasm. To this end, we develop MORE, a new dataset with explanation of 3510 sarcastic multimodal posts. Each explanation is a natural language (English) sentence describing the hidden irony. We benchmark MORE by employing a multimodal Transformer-based architecture. It incorporates a cross-modal attention in the Transformer's encoder which attends to the distinguishing features between the two modalities. Subsequently, a BART-based auto-regressive decoder is used as the generator. Empirical results demonstrate convincing results over various baselines (adopted for MuSE) across five evaluation metrics. We also conduct human evaluation on predictions and obtain Fleiss' Kappa score of 0.4 as a fair agreement among 25 evaluators. </p> </div> </dd> <dt>[128] arXiv:2112.04886 [pdf, other]</dt> <dd> <div > <div > Title: Semantic Search as Extractive Paraphrase Span Detection </div> <div > Authors: Jenna Kanerva, <a >Hanna Kitti</a>, <a >Li-Hsin Chang</a>, <a >Teemu Vahtola</a>, <a >Mathias Creutz</a>, <a >Filip Ginter</a> </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >In this paper, we approach the problem of semantic search by framing the search task as paraphrase span detection, i.e. given a segment of text as a query phrase, the task is to identify its paraphrase in a given document, the same modelling setup as typically used in extractive question answering. On the Turku Paraphrase Corpus of 100,000 manually extracted Finnish paraphrase pairs including their original document context, we find that our paraphrase span detection model outperforms two strong retrieval baselines (lexical similarity and BERT sentence embeddings) by 31.9pp and 22.4pp respectively in terms of exact match, and by 22.3pp and 12.9pp in terms of token-level F-score. This demonstrates a strong advantage of modelling the task in terms of span retrieval, rather than sentence similarity. Additionally, we introduce a method for creating artificial paraphrase data through back-translation, suitable for languages where manually annotated paraphrase resources for training the span detection model are not available. </p> </div> </dd> <dt>[129] arXiv:2112.04888 [pdf, other]</dt> <dd> <div > <div > Title: A Bilingual, OpenWorld Video Text Dataset and End-to-end Video Text Spotter with Transformer </div> <div > Authors: Weijia Wu, <a >Yuanqiang Cai</a>, <a >Debing Zhang</a>, <a >Sibo Wang</a>, <a >Zhuang Li</a>, <a >Jiahong Li</a>, <a >Yejun Tang</a>, <a >Hong Zhou</a> </div> <div > Comments: 20 pages, 6 figures </div> <div > Journal-ref: NeurIPS 2021 Track on Datasets and Benchmarks </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL) </div> <p >Most existing video text spotting benchmarks focus on evaluating a single language and scenario with limited data. In this work, we introduce a large-scale, Bilingual, Open World Video text benchmark dataset(BOVText). There are four features for BOVText. Firstly, we provide 2,000+ videos with more than 1,750,000+ frames, 25 times larger than the existing largest dataset with incidental text in videos. Secondly, our dataset covers 30+ open categories with a wide selection of various scenarios, e.g., Life Vlog, Driving, Movie, etc. Thirdly, abundant text types annotation (i.e., title, caption or scene text) are provided for the different representational meanings in video. Fourthly, the BOVText provides bilingual text annotation to promote multiple cultures live and communication. Besides, we propose an end-to-end video text spotting framework with Transformer, termed TransVTSpotter, which solves the multi-orient text spotting in video with a simple, but efficient attention-based query-key mechanism. It applies object features from the previous frame as a tracking query for the current frame and introduces a rotation angle prediction to fit the multiorient text instance. On ICDAR2015(video), TransVTSpotter achieves the state-of-the-art performance with 44.1% MOTA, 9 fps. The dataset and code of TransVTSpotter can be found at github:com=weijiawu=BOVText and github:com=weijiawu=TransVTSpotter, respectively. </p> </div> </dd> <dt>[130] arXiv:2112.04889 [pdf]</dt> <dd> <div > <div > Title: Artificial Intelligence and Design of Experiments for Assessing Security of Electricity Supply: A Review and Strategic Outlook </div> <div > Authors: Jan Priesmann, <a >Justin Münch</a>, <a >Elias Ridha</a>, <a >Thomas Spiegel</a>, <a >Marius Reich</a>, <a >Mario Adam</a>, <a >Lars Nolting</a>, <a >Aaron Praktiknjo</a> </div> <div > Subjects: Artificial Intelligence (cs.AI); Systems and Control (eess.SY) </div> <p >Assessing the effects of the energy transition and liberalization of energy markets on resource adequacy is an increasingly important and demanding task. The rising complexity in energy systems requires adequate methods for energy system modeling leading to increased computational requirements. Furthermore, with complexity, uncertainty increases likewise calling for probabilistic assessments and scenario analyses. To adequately and efficiently address these various requirements, new methods from the field of data science are needed to accelerate current methods. With our systematic literature review, we want to close the gap between the three disciplines (1) assessment of security of electricity supply, (2) artificial intelligence, and (3) design of experiments. For this, we conduct a large-scale quantitative review on selected fields of application and methods and make a synthesis that relates the different disciplines to each other. Among other findings, we identify metamodeling of complex security of electricity supply models using AI methods and applications of AI-based methods for forecasts of storage dispatch and (non-)availabilities as promising fields of application that have not sufficiently been covered, yet. We end with deriving a new methodological pipeline for adequately and efficiently addressing the present and upcoming challenges in the assessment of security of electricity supply. </p> </div> </dd> <dt>[131] arXiv:2112.04891 [pdf, other]</dt> <dd> <div > <div > Title: Multi-Task Learning on Networks </div> <div > Authors: Andrea Ponti </div> <div > Comments: 94 pages, 53 figures, 8 tables </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Methodology (stat.ME) </div> <p >The multi-task learning (MTL) paradigm can be traced back to an early paper of Caruana (1997) in which it was argued that data from multiple tasks can be used with the aim to obtain a better performance over learning each task independently. A solution of MTL with conflicting objectives requires modelling the trade-off among them which is generally beyond what a straight linear combination can achieve. A theoretically principled and computationally effective strategy is finding solutions which are not dominated by others as it is addressed in the Pareto analysis. Multi-objective optimization problems arising in the multi-task learning context have specific features and require adhoc methods. The analysis of these features and the proposal of a new computational approach represent the focus of this work. Multi-objective evolutionary algorithms (MOEAs) can easily include the concept of dominance and therefore the Pareto analysis. The major drawback of MOEAs is a low sample efficiency with respect to function evaluations. The key reason for this drawback is that most of the evolutionary approaches do not use models for approximating the objective function. Bayesian Optimization takes a radically different approach based on a surrogate model, such as a Gaussian Process. In this thesis the solutions in the Input Space are represented as probability distributions encapsulating the knowledge contained in the function evaluations. In this space of probability distributions, endowed with the metric given by the Wasserstein distance, a new algorithm MOEA/WST can be designed in which the model is not directly on the objective function but in an intermediate Information Space where the objects from the input space are mapped into histograms. Computational results show that the sample efficiency and the quality of the Pareto set provided by MOEA/WST are significantly better than in the standard MOEA. </p> </div> </dd> <dt>[132] arXiv:2112.04893 [pdf, other]</dt> <dd> <div > <div > Title: Real-World Dexterous Object Manipulation based Deep Reinforcement Learning </div> <div > Authors: Qingfeng Yao, <a >Jilong Wang</a>, <a >Shuyu Yang</a> </div> <div > Comments: Best Paper Award Runner Up winner submission for Real Robot Challenge 2021 </div> <div > Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p >Deep reinforcement learning has shown its advantages in real-time decision-making based on the state of the agent. In this stage, we solved the task of using a real robot to manipulate the cube to a given trajectory. The task is broken down into different procedures and we propose a hierarchical structure, the high-level deep reinforcement learning model selects appropriate contact positions and the low-level control module performs the position control under the corresponding trajectory. Our framework reduces the disadvantage of low sample efficiency of deep reinforcement learning and lacking adaptability of traditional robot control methods. Our algorithm is trained in simulation and migrated to reality without fine-tuning. The experimental results show the effectiveness of our method both simulation and reality. Our code and video can be found at https://github.com/42jaylonw/RRC2021ThreeWolves and https://youtu.be/Jr176xsn9wg. </p> </div> </dd> <dt>[133] arXiv:2112.04895 [pdf, other]</dt> <dd> <div > <div > Title: Latent Space Explanation by Intervention </div> <div > Authors: Itai Gat, <a >Guy Lorberbom</a>, <a >Idan Schwartz</a>, <a >Tamir Hazan</a> </div> <div > Comments: Accepted to AAAI22 </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p >The success of deep neural nets heavily relies on their ability to encode complex relations between their input and their output. While this property serves to fit the training data well, it also obscures the mechanism that drives prediction. This study aims to reveal hidden concepts by employing an intervention mechanism that shifts the predicted class based on discrete variational autoencoders. An explanatory model then visualizes the encoded information from any hidden layer and its corresponding intervened representation. By the assessment of differences between the original representation and the intervened representation, one can determine the concepts that can alter the class, hence providing interpretability. We demonstrate the effectiveness of our approach on CelebA, where we show various visualizations for bias in the data and suggest different interventions to reveal and change bias. </p> </div> </dd> <dt>[134] arXiv:2112.04899 [pdf, other]</dt> <dd> <div > <div > Title: Assessing Fairness in the Presence of Missing Data </div> <div > Authors: Yiliang Zhang, <a >Qi Long</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >Missing data are prevalent and present daunting challenges in real data analysis. While there is a growing body of literature on fairness in analysis of fully observed data, there has been little theoretical work on investigating fairness in analysis of incomplete data. In practice, a popular analytical approach for dealing with missing data is to use only the set of complete cases, i.e., observations with all features fully observed to train a prediction algorithm. However, depending on the missing data mechanism, the distribution of complete cases and the distribution of the complete data may be substantially different. When the goal is to develop a fair algorithm in the complete data domain where there are no missing values, an algorithm that is fair in the complete case domain may show disproportionate bias towards some marginalized groups in the complete data domain. To fill this significant gap, we study the problem of estimating fairness in the complete data domain for an arbitrary model evaluated merely using complete cases. We provide upper and lower bounds on the fairness estimation error and conduct numerical experiments to assess our theoretical results. Our work provides the first known theoretical results on fairness guarantee in analysis of incomplete data. </p> </div> </dd> <dt>[135] arXiv:2112.04902 [pdf, other]</dt> <dd> <div > <div > Title: Learning Personal Representations from fMRIby Predicting Neurofeedback Performance </div> <div > Authors: Jhonathan Osin, <a >Lior Wolf</a>, <a >Guy Gurevitch</a>, <a >Jackob Nimrod Keynan</a>, <a >Tom Fruchtman-Steinbok</a>, <a >Ayelet Or-Borichev</a>, <a >Shira Reznik Balter</a>, <a >Talma Hendler</a> </div> <div > Journal-ref: MICCAI 2020, https://link.springer.com/chapter/10.1007/978-3-030-59728-3_46 </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p >We present a deep neural network method for learning a personal representation for individuals that are performing a self neuromodulation task, guided by functional MRI (fMRI). This neurofeedback task (watch vs. regulate) provides the subjects with a continuous feedback contingent on down regulation of their Amygdala signal and the learning algorithm focuses on this region's time-course of activity. The representation is learned by a self-supervised recurrent neural network, that predicts the Amygdala activity in the next fMRI frame given recent fMRI frames and is conditioned on the learned individual representation. It is shown that the individuals' representation improves the next-frame prediction considerably. Moreover, this personal representation, learned solely from fMRI images, yields good performance in linear prediction of psychiatric traits, which is better than performing such a prediction based on clinical data and personality tests. Our code is attached as supplementary and the data would be shared subject to ethical approvals. </p> </div> </dd> <dt>[136] arXiv:2112.04903 [pdf, other]</dt> <dd> <div > <div > Title: PRA-Net: Point Relation-Aware Network for 3D Point Cloud Analysis </div> <div > Authors: Silin Cheng, <a >Xiwu Chen</a>, <a >Xinwei He</a>, <a >Zhe Liu</a>, <a >Xiang Bai</a> </div> <div > Comments: 13 pages </div> <div > Journal-ref: IEEE Transactions on Image Processing, vol. 30, pp. 4436-4448, 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Learning intra-region contexts and inter-region relations are two effective strategies to strengthen feature representations for point cloud analysis. However, unifying the two strategies for point cloud representation is not fully emphasized in existing methods. To this end, we propose a novel framework named Point Relation-Aware Network (PRA-Net), which is composed of an Intra-region Structure Learning (ISL) module and an Inter-region Relation Learning (IRL) module. The ISL module can dynamically integrate the local structural information into the point features, while the IRL module captures inter-region relations adaptively and efficiently via a differentiable region partition scheme and a representative point-based strategy. Extensive experiments on several 3D benchmarks covering shape classification, keypoint estimation, and part segmentation have verified the effectiveness and the generalization ability of PRA-Net. Code will be available at https://github.com/XiwuChen/PRA-Net . </p> </div> </dd> <dt>[137] arXiv:2112.04905 [pdf, other]</dt> <dd> <div > <div > Title: i-SpaSP: Structured Neural Pruning via Sparse Signal Recovery </div> <div > Authors: Cameron R. Wolfe, <a >Anastasios Kyrillidis</a> </div> <div > Comments: 27 pages, 4 figures </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML) </div> <p >We propose a novel, structured pruning algorithm for neural networks -- the iterative, Sparse Structured Pruning algorithm, dubbed as i-SpaSP. Inspired by ideas from sparse signal recovery, i-SpaSP operates by iteratively identifying a larger set of important parameter groups (e.g., filters or neurons) within a network that contribute most to the residual between pruned and dense network output, then thresholding these groups based on a smaller, pre-defined pruning ratio. For both two-layer and multi-layer network architectures with ReLU activations, we show the error induced by pruning with i-SpaSP decays polynomially, where the degree of this polynomial becomes arbitrarily large based on the sparsity of the dense network's hidden representations. In our experiments, i-SpaSP is evaluated across a variety of datasets (i.e., MNIST and ImageNet) and architectures (i.e., feed forward networks, ResNet34, and MobileNetV2), where it is shown to discover high-performing sub-networks and improve upon the pruning efficiency of provable baseline methodologies by several orders of magnitude. Put simply, i-SpaSP is easy to implement with automatic differentiation, achieves strong empirical results, comes with theoretical convergence guarantees, and is efficient, thus distinguishing itself as one of the few computationally efficient, practical, and provable pruning algorithms. </p> </div> </dd> <dt>[138] arXiv:2112.04907 [pdf, other]</dt> <dd> <div > <div > Title: JueWu-MC: Playing Minecraft with Sample-efficient Hierarchical Reinforcement Learning </div> <div > Authors: Zichuan Lin, <a >Junyou Li</a>, <a >Jianing Shi</a>, <a >Deheng Ye</a>, <a >Qiang Fu</a>, <a >Wei Yang</a> </div> <div > Comments: The champion solution of NeurIPS 2021 MineRL research competition ( <a >this https URL</a> ) </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p >Learning rational behaviors in open-world games like Minecraft remains to be challenging for Reinforcement Learning (RL) research due to the compound challenge of partial observability, high-dimensional visual perception and delayed reward. To address this, we propose JueWu-MC, a sample-efficient hierarchical RL approach equipped with representation learning and imitation learning to deal with perception and exploration. Specifically, our approach includes two levels of hierarchy, where the high-level controller learns a policy to control over options and the low-level workers learn to solve each sub-task. To boost the learning of sub-tasks, we propose a combination of techniques including 1) action-aware representation learning which captures underlying relations between action and representation, 2) discriminator-based self-imitation learning for efficient exploration, and 3) ensemble behavior cloning with consistency filtering for policy robustness. Extensive experiments show that JueWu-MC significantly improves sample efficiency and outperforms a set of baselines by a large margin. Notably, we won the championship of the NeurIPS MineRL 2021 research competition and achieved the highest performance score ever. </p> </div> </dd> <dt>[139] arXiv:2112.04910 [pdf, other]</dt> <dd> <div > <div > Title: Few-Shot Keypoint Detection as Task Adaptation via Latent Embeddings </div> <div > Authors: Mel Vecerik, <a >Jackie Kay</a>, <a >Raia Hadsell</a>, <a >Lourdes Agapito</a>, <a >Jon Scholz</a> </div> <div > Comments: Supplementary material available at: <a >this https URL</a> </div> <div > Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Dense object tracking, the ability to localize specific object points with pixel-level accuracy, is an important computer vision task with numerous downstream applications in robotics. Existing approaches either compute dense keypoint embeddings in a single forward pass, meaning the model is trained to track everything at once, or allocate their full capacity to a sparse predefined set of points, trading generality for accuracy. In this paper we explore a middle ground based on the observation that the number of relevant points at a given time are typically relatively few, e.g. grasp points on a target object. Our main contribution is a novel architecture, inspired by few-shot task adaptation, which allows a sparse-style network to condition on a keypoint embedding that indicates which point to track. Our central finding is that this approach provides the generality of dense-embedding models, while offering accuracy significantly closer to sparse-keypoint approaches. We present results illustrating this capacity vs. accuracy trade-off, and demonstrate the ability to zero-shot transfer to new object instances (within-class) using a real-robot pick-and-place task. </p> </div> </dd> <dt>[140] arXiv:2112.04912 [pdf, ps, other]</dt> <dd> <div > <div > Title: Scalable and Decentralized Algorithms for Anomaly Detection via Learning-Based Controlled Sensing </div> <div > Authors: Geethu Joseph, <a >Chen Zhong</a>, <a >M. Cenk Gursoy</a>, <a >Senem Velipasalar</a>, <a >Pramod K.Varshney</a> </div> <div > Comments: 13 pages, 4 figures. arXiv admin note: substantial text overlap with <a >arXiv:2105.06289</a> </div> <div > Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML) </div> <p >We address the problem of sequentially selecting and observing processes from a given set to find the anomalies among them. The decision-maker observes a subset of the processes at any given time instant and obtains a noisy binary indicator of whether or not the corresponding process is anomalous. In this setting, we develop an anomaly detection algorithm that chooses the processes to be observed at a given time instant, decides when to stop taking observations, and declares the decision on anomalous processes. The objective of the detection algorithm is to identify the anomalies with an accuracy exceeding the desired value while minimizing the delay in decision making. We devise a centralized algorithm where the processes are jointly selected by a common agent as well as a decentralized algorithm where the decision of whether to select a process is made independently for each process. Our algorithms rely on a Markov decision process defined using the marginal probability of each process being normal or anomalous, conditioned on the observations. We implement the detection algorithms using the deep actor-critic reinforcement learning framework. Unlike prior work on this topic that has exponential complexity in the number of processes, our algorithms have computational and memory requirements that are both polynomial in the number of processes. We demonstrate the efficacy of these algorithms using numerical experiments by comparing them with state-of-the-art methods. </p> </div> </dd> <dt>[141] arXiv:2112.04913 [pdf, other]</dt> <dd> <div > <div > Title: Identification of Twitter Bots based on an Explainable ML Framework: the US 2020 Elections Case Study </div> <div > Authors: Alexander Shevtsov, <a >Christos Tzagkarakis</a>, <a >Despoina Antonakaki</a>, <a >Sotiris Ioannidis</a> </div> <div > Subjects: Social and Information Networks (cs.SI); Machine Learning (cs.LG) </div> <p >Twitter is one of the most popular social networks attracting millions of users, while a considerable proportion of online discourse is captured. It provides a simple usage framework with short messages and an efficient application programming interface (API) enabling the research community to study and analyze several aspects of this social network. However, the Twitter usage simplicity can lead to malicious handling by various bots. The malicious handling phenomenon expands in online discourse, especially during the electoral periods, where except the legitimate bots used for dissemination and communication purposes, the goal is to manipulate the public opinion and the electorate towards a certain direction, specific ideology, or political party. This paper focuses on the design of a novel system for identifying Twitter bots based on labeled Twitter data. To this end, a supervised machine learning (ML) framework is adopted using an Extreme Gradient Boosting (XGBoost) algorithm, where the hyper-parameters are tuned via cross-validation. Our study also deploys Shapley Additive Explanations (SHAP) for explaining the ML model predictions by calculating feature importance, using the game theoretic-based Shapley values. Experimental evaluation on distinct Twitter datasets demonstrate the superiority of our approach, in terms of bot detection accuracy, when compared against a recent state-of-the-art Twitter bot detection method. </p> </div> </dd> <dt>[142] arXiv:2112.04919 [pdf, ps, other]</dt> <dd> <div > <div > Title: A Qualitative Study on the Sources, Impacts, and Mitigation Strategies of Flaky Tests </div> <div > Authors: Sarra Habchi, <a >Guillaume Haben</a>, <a >Mike Papadakis</a>, <a >Maxime Cordy</a>, <a >Yves Le Traon</a> </div> <div > Subjects: Software Engineering (cs.SE) </div> <p >Test flakiness forms a major testing concern. Flaky tests manifest non-deterministic outcomes that cripple continuous integration and lead developers to investigate false alerts. Industrial reports indicate that on a large scale, the accrual of flaky tests breaks the trust in test suites and entails significant computational cost. To alleviate this, practitioners are constrained to identify flaky tests and investigate their impact. To shed light on such mitigation mechanisms, we interview 14 practitioners with the aim to identify (i) the sources of flakiness within the testing ecosystem, (ii) the impacts of flakiness, (iii) the measures adopted by practitioners when addressing flakiness, and (iv) the automation opportunities for these measures. Our analysis shows that, besides the tests and code, flakiness stems from interactions between the system components, the testing infrastructure, and external factors. We also highlight the impact of flakiness on testing practices and product quality and show that the adoption of guidelines together with a stable infrastructure are key measures in mitigating the problem. </p> </div> </dd> <dt>[143] arXiv:2112.04928 [pdf, other]</dt> <dd> <div > <div > Title: Self-Supervised Image-to-Text and Text-to-Image Synthesis </div> <div > Authors: Anindya Sundar Das, <a >Sriparna Saha</a> </div> <div > Comments: ICONIP 2021 : The 28th International Conference on Neural Information Processing </div> <div > Journal-ref: ICONIP 2021. Lecture Notes in Computer Science, vol 13111, pp 415-426. Springer, Cham </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >A comprehensive understanding of vision and language and their interrelation are crucial to realize the underlying similarities and differences between these modalities and to learn more generalized, meaningful representations. In recent years, most of the works related to Text-to-Image synthesis and Image-to-Text generation, focused on supervised generative deep architectures to solve the problems, where very little interest was placed on learning the similarities between the embedding spaces across modalities. In this paper, we propose a novel self-supervised deep learning based approach towards learning the cross-modal embedding spaces; for both image to text and text to image generations. In our approach, we first obtain dense vector representations of images using StackGAN-based autoencoder model and also dense vector representations on sentence-level utilizing LSTM based text-autoencoder; then we study the mapping from embedding space of one modality to embedding space of the other modality utilizing GAN and maximum mean discrepancy based generative networks. We, also demonstrate that our model learns to generate textual description from image data as well as images from textual data both qualitatively and quantitatively. </p> </div> </dd> <dt>[144] arXiv:2112.04934 [pdf, other]</dt> <dd> <div > <div > Title: Model Doctor: A Simple Gradient Aggregation Strategy for Diagnosing and Treating CNN Classifiers </div> <div > Authors: Zunlei Feng, <a >Jiacong Hu</a>, <a >Sai Wu</a>, <a >Xiaotian Yu</a>, <a >Jie Song</a>, <a >Mingli Song</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >Recently, Convolutional Neural Network (CNN) has achieved excellent performance in the classification task. It is widely known that CNN is deemed as a 'black-box', which is hard for understanding the prediction mechanism and debugging the wrong prediction. Some model debugging and explanation works are developed for solving the above drawbacks. However, those methods focus on explanation and diagnosing possible causes for model prediction, based on which the researchers handle the following optimization of models manually. In this paper, we propose the first completely automatic model diagnosing and treating tool, termed as Model Doctor. Based on two discoveries that 1) each category is only correlated with sparse and specific convolution kernels, and 2) adversarial samples are isolated while normal samples are successive in the feature space, a simple aggregate gradient constraint is devised for effectively diagnosing and optimizing CNN classifiers. The aggregate gradient strategy is a versatile module for mainstream CNN classifiers. Extensive experiments demonstrate that the proposed Model Doctor applies to all existing CNN classifiers, and improves the accuracy of $16$ mainstream CNN classifiers by 1%-5%. </p> </div> </dd> <dt>[145] arXiv:2112.04937 [pdf, other]</dt> <dd> <div > <div > Title: DVHN: A Deep Hashing Framework for Large-scale Vehicle Re-identification </div> <div > Authors: Yongbiao Chen, <a >Sheng Zhang</a>, <a >Fangxin Liu</a>, <a >Chenggang Wu</a>, <a >Kaicheng Guo</a>, <a >Zhengwei Qi</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p >In this paper, we make the very first attempt to investigate the integration of deep hash learning with vehicle re-identification. We propose a deep hash-based vehicle re-identification framework, dubbed DVHN, which substantially reduces memory usage and promotes retrieval efficiency while reserving nearest neighbor search accuracy. Concretely,~DVHN directly learns discrete compact binary hash codes for each image by jointly optimizing the feature learning network and the hash code generating module. Specifically, we directly constrain the output from the convolutional neural network to be discrete binary codes and ensure the learned binary codes are optimal for classification. To optimize the deep discrete hashing framework, we further propose an alternating minimization method for learning binary similarity-preserved hashing codes. Extensive experiments on two widely-studied vehicle re-identification datasets- extbf{VehicleID} and extbf{VeRi}-~have demonstrated the superiority of our method against the state-of-the-art deep hash methods. extbf{DVHN} of $2048$ bits can achieve 13.94\% and 10.21\% accuracy improvement in terms of extbf{mAP} and extbf{Rank@1} for extbf{VehicleID (800)} dataset. For extbf{VeRi}, we achieve 35.45\% and 32.72\% performance gains for extbf{Rank@1} and extbf{mAP}, respectively. </p> </div> </dd> <dt>[146] arXiv:2112.04940 [pdf, other]</dt> <dd> <div > <div > Title: A Simple but Effective Bidirectional Extraction Framework for Relational Triple Extraction </div> <div > Authors: Feiliang Ren, <a >Longhui Zhang</a>, <a >Xiaofeng Zhao</a>, <a >Shujuan Yin</a>, <a >Shilei Liu</a>, <a >Bochao Li</a> </div> <div > Comments: WSDM2022 </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >Tagging based relational triple extraction methods are attracting growing research attention recently. However, most of these methods take a unidirectional extraction framework that first extracts all subjects and then extracts objects and relations simultaneously based on the subjects extracted. This framework has an obvious deficiency that it is too sensitive to the extraction results of subjects. To overcome this deficiency, we propose a bidirectional extraction framework based method that extracts triples based on the entity pairs extracted from two complementary directions. Concretely, we first extract all possible subject-object pairs from two paralleled directions. These two extraction directions are connected by a shared encoder component, thus the extraction features from one direction can flow to another direction and vice versa. By this way, the extractions of two directions can boost and complement each other. Next, we assign all possible relations for each entity pair by a biaffine model. During training, we observe that the share structure will lead to a convergence rate inconsistency issue which is harmful to performance. So we propose a share-aware learning mechanism to address it. We evaluate the proposed model on multiple benchmark datasets. Extensive experimental results show that the proposed model is very effective and it achieves state-of-the-art results on all of these datasets. Moreover, experiments show that both the proposed bidirectional extraction framework and the share-aware learning mechanism have good adaptability and can be used to improve the performance of other tagging based methods. The source code of our work is available at: https://github.com/neukg/BiRTE. </p> </div> </dd> <dt>[147] arXiv:2112.04941 [pdf, ps, other]</dt> <dd> <div > <div > Title: Testing Probabilistic Circuits </div> <div > Authors: Yash Pote, <a >Kuldeep S. Meel</a> </div> <div > Subjects: Data Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM) </div> <p >Probabilistic circuits (PCs) are a powerful modeling framework for representing tractable probability distributions over combinatorial spaces. In machine learning and probabilistic programming, one is often interested in understanding whether the distributions learned using PCs are close to the desired distribution. Thus, given two probabilistic circuits, a fundamental problem of interest is to determine whether their distributions are close to each other. The primary contribution of this paper is a closeness test for PCs with respect to the total variation distance metric. Our algorithm utilizes two common PC queries, counting and sampling. In particular, we provide a poly-time probabilistic algorithm to check the closeness of two PCs when the PCs support tractable approximate counting and sampling. We demonstrate the practical efficiency of our algorithmic framework via a detailed experimental evaluation of a prototype implementation against a set of 475 PC benchmarks. We find that our test correctly decides the closeness of all 475 PCs within 3600 seconds. </p> </div> </dd> <dt>[148] arXiv:2112.04947 [pdf, other]</dt> <dd> <div > <div > Title: Automated Side Channel Analysis of Media Software with Manifold Learning </div> <div > Authors: Yuanyuan Yuan, <a >Qi Pang</a>, <a >Shuai Wang</a> </div> <div > Subjects: Cryptography and Security (cs.CR); Machine Learning (cs.LG) </div> <p >The prosperous development of cloud computing and machine learning as a service has led to the widespread use of media software to process confidential media data. This paper explores an adversary's ability to launch side channel analyses (SCA) against media software to reconstruct confidential media inputs. Recent advances in representation learning and perceptual learning inspired us to consider the reconstruction of media inputs from side channel traces as a cross-modality manifold learning task that can be addressed in a unified manner with an autoencoder framework trained to learn the mapping between media inputs and side channel observations. We further enhance the autoencoder with attention to localize the program points that make the primary contribution to SCA, thus automatically pinpointing information-leakage points in media software. We also propose a novel and highly effective defensive technique called perception blinding that can perturb media inputs with perception masks and mitigate manifold learning-based SCA. Our evaluation exploits three popular media software to reconstruct inputs in image, audio, and text formats. We analyze three common side channels - cache bank, cache line, and page tables - and userspace-only cache set accesses logged by standard Prime+Probe. Our framework successfully reconstructs high-quality confidential inputs from the assessed media software and automatically pinpoint their vulnerable program points, many of which are unknown to the public. We further show that perception blinding can mitigate manifold learning-based SCA with negligible extra cost. </p> </div> </dd> <dt>[149] arXiv:2112.04948 [pdf, other]</dt> <dd> <div > <div > Title: PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function </div> <div > Authors: Manaar Alam, <a >Shubhajit Datta</a>, <a >Debdeep Mukhopadhyay</a>, <a >Arijit Mondal</a>, <a >Partha Pratim Chakrabarti</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >The security of Deep Learning classifiers is a critical field of study because of the existence of adversarial attacks. Such attacks usually rely on the principle of transferability, where an adversarial example crafted on a surrogate classifier tends to mislead the target classifier trained on the same dataset even if both classifiers have quite different architecture. Ensemble methods against adversarial attacks demonstrate that an adversarial example is less likely to mislead multiple classifiers in an ensemble having diverse decision boundaries. However, recent ensemble methods have either been shown to be vulnerable to stronger adversaries or shown to lack an end-to-end evaluation. This paper attempts to develop a new ensemble methodology that constructs multiple diverse classifiers using a Pairwise Adversarially Robust Loss (PARL) function during the training procedure. PARL utilizes gradients of each layer with respect to input in every classifier within the ensemble simultaneously. The proposed training procedure enables PARL to achieve higher robustness against black-box transfer attacks compared to previous ensemble methods without adversely affecting the accuracy of clean examples. We also evaluate the robustness in the presence of white-box attacks, where adversarial examples are crafted using parameters of the target classifier. We present extensive experiments using standard image classification datasets like CIFAR-10 and CIFAR-100 trained using standard ResNet20 classifier against state-of-the-art adversarial attacks to demonstrate the robustness of the proposed ensemble methodology. </p> </div> </dd> <dt>[150] arXiv:2112.04953 [pdf, other]</dt> <dd> <div > <div > Title: Machine Learning for Utility Prediction in Argument-Based Computational Persuasion </div> <div > Authors: Ivan Donadello, <a >Anthony Hunter</a>, <a >Stefano Teso</a>, <a >Mauro Dragoni</a> </div> <div > Subjects: Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Automated persuasion systems (APS) aim to persuade a user to believe something by entering into a dialogue in which arguments and counterarguments are exchanged. To maximize the probability that an APS is successful in persuading a user, it can identify a global policy that will allow it to select the best arguments it presents at each stage of the dialogue whatever arguments the user presents. However, in real applications, such as for healthcare, it is unlikely the utility of the outcome of the dialogue will be the same, or the exact opposite, for the APS and user. In order to deal with this situation, games in extended form have been harnessed for argumentation in Bi-party Decision Theory. This opens new problems that we address in this paper: (1) How can we use Machine Learning (ML) methods to predict utility functions for different subpopulations of users? and (2) How can we identify for a new user the best utility function from amongst those that we have learned? To this extent, we develop two ML methods, EAI and EDS, that leverage information coming from the users to predict their utilities. EAI is restricted to a fixed amount of information, whereas EDS can choose the information that best detects the subpopulations of a user. We evaluate EAI and EDS in a simulation setting and in a realistic case study concerning healthy eating habits. Results are promising in both cases, but EDS is more effective at predicting useful utility functions. </p> </div> </dd> <dt>[151] arXiv:2112.04957 [pdf]</dt> <dd> <div > <div > Title: Smart Support for Mission Success </div> <div > Authors: Juliette Mattioli, <a >Pierre-Olivier Robic</a> </div> <div > Comments: 8 pages, 2 figures </div> <div > Subjects: Other Computer Science (cs.OH); Artificial Intelligence (cs.AI) </div> <p >Today's battlefield environment is complex, dynamic and uncertain, and requires efficient support to ensure mission success. This relies on a proper support strategy to provide supported equipment able to fulfill the mission. In the context of defense where both systems and organization are complex, having a holistic approach is challenging by nature, forces and support agencies need to rely on an efficient decision support system. Logistics, readiness and sustainability are critical factors for asset management, which can benefit from AI to reach "Smart In Service" level relying especially on predictive and prescriptive approaches and on effective management of operational re-sources. Smart Support capacities can be then monitored by appropriate metrics and improved by multi-criteria decision support and knowledge management system. Depending on the operational context in terms of information and the objective, different AI paradigms (data-driven AI, knowledge-based AI) are suitable even a combination through hybrid AI. </p> </div> </dd> <dt>[152] arXiv:2112.04960 [pdf, other]</dt> <dd> <div > <div > Title: mechanoChemML: A software library for machine learning in computational materials physics </div> <div > Authors: X. Zhang, <a >G.H. Teichert</a>, <a >Z. Wang</a>, <a >M. Duschenes</a>, <a >S. Srivastava</a>, <a >A. Sunderarajan</a>, <a >E. Livingston</a>, <a >K. Garikipati</a> </div> <div > Subjects: Computational Engineering, Finance, and Science (cs.CE) </div> <p >We present mechanoChemML, a machine learning software library for computational materials physics. mechanoChemML is designed to function as an interface between platforms that are widely used for machine learning on one hand, and others for solution of partial differential equations-based models of physics. Of special interest here, and the focus of mechanoChemML, are applications to computational materials physics. These typically feature the coupled solution of material transport, reaction, phase transformation, mechanics, heat transport and electrochemistry. Central to the organization of mechanoChemML are machine learning workflows that arise in the context of data-driven computational materials physics. The mechanoChemML code structure is described, the machine learning workflows are laid out and their application to the solution of several problems in materials physics is outlined. </p> </div> </dd> <dt>[153] arXiv:2112.04963 [pdf, other]</dt> <dd> <div > <div > Title: Model-Agnostic Hybrid Numerical Weather Prediction and Machine Learning Paradigm for Solar Forecasting in the Tropics </div> <div > Authors: Nigel Yuan Yun Ng, <a >Harish Gopalan</a>, <a >Venugopalan S.G. Raghavan</a>, <a >Chin Chun Ooi</a> </div> <div > Subjects: Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph) </div> <p >Numerical weather prediction (NWP) and machine learning (ML) methods are popular for solar forecasting. However, NWP models have multiple possible physical parameterizations, which requires site-specific NWP optimization. This is further complicated when regional NWP models are used with global climate models with different possible parameterizations. In this study, an alternative approach is proposed and evaluated for four radiation models. Weather Research and Forecasting (WRF) model is run in both global and regional mode to provide an estimate for solar irradiance. This estimate is then post-processed using ML to provide a final prediction. Normalized root-mean-square error from WRF is reduced by up to 40-50% with this ML error correction model. Results obtained using CAM, GFDL, New Goddard and RRTMG radiation models were comparable after this correction, negating the need for WRF parameterization tuning. Other models incorporating nearby locations and sensor data are also evaluated, with the latter being particularly promising. </p> </div> </dd> <dt>[154] arXiv:2112.04966 [pdf, other]</dt> <dd> <div > <div > Title: CaSP: Class-agnostic Semi-Supervised Pretraining for Detection and Segmentation </div> <div > Authors: Lu Qi, <a >Jason Kuen</a>, <a >Zhe Lin</a>, <a >Jiuxiang Gu</a>, <a >Fengyun Rao</a>, <a >Dian Li</a>, <a >Weidong Guo</a>, <a >Zhen Wen</a>, <a >Jiaya Jia</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >To improve instance-level detection/segmentation performance, existing self-supervised and semi-supervised methods extract either very task-unrelated or very task-specific training signals from unlabeled data. We argue that these two approaches, at the two extreme ends of the task-specificity spectrum, are suboptimal for the task performance. Utilizing too little task-specific training signals causes underfitting to the ground-truth labels of downstream tasks, while the opposite causes overfitting to the ground-truth labels. To this end, we propose a novel Class-agnostic Semi-supervised Pretraining (CaSP) framework to achieve a more favorable task-specificity balance in extracting training signals from unlabeled data. Compared to semi-supervised learning, CaSP reduces the task specificity in training signals by ignoring class information in the pseudo labels and having a separate pretraining stage that uses only task-unrelated unlabeled data. On the other hand, CaSP preserves the right amount of task specificity by leveraging box/mask-level pseudo labels. As a result, our pretrained model can better avoid underfitting/overfitting to ground-truth labels when finetuned on the downstream task. Using 3.6M unlabeled data, we achieve a remarkable performance gain of 4.7% over ImageNet-pretrained baseline on object detection. Our pretrained model also demonstrates excellent transferability to other detection and segmentation tasks/frameworks. </p> </div> </dd> <dt>[155] arXiv:2112.04968 [pdf, ps, other]</dt> <dd> <div > <div > Title: Tradeoff between Diversity and Multiplexing Gains in Block Fading Optical Wireless Channels </div> <div > Authors: Sufang Yang, <a >Longguang Li</a>, <a >Haoyue Tang</a>, <a >Jintao Wang</a> </div> <div > Subjects: Information Theory (cs.IT) </div> <p >The diversity-multiplexing tradeoff (DMT) provides a fundamental performance metric for different multiple-input multiple-output (MIMO) schemes in wireless communications. In this paper, we explore the block fading optical wireless communication (OWC) channels and characterize the DMT in the presence of both optical peak- and average-power constraints. Three different fading distributions are considered, which reflect different channel conditions. In each channel condition, we obtain the optimal DMT when the block length is sufficiently large, and we also derive the lower and upper bounds of the DMT curve when the block length is small. These results are dramatically different from the existing DMT results in radio-frequency (RF) channels. These differences may be due to the fact that the optical input signal is real and bounded, while its RF counterpart is usually complex and unbounded. </p> </div> </dd> <dt>[156] arXiv:2112.04971 [pdf, other]</dt> <dd> <div > <div > Title: How Universal is Genre in Universal Dependencies? </div> <div > Authors: Max Müller-Eberstein, <a >Rob van der Goot</a>, <a >Barbara Plank</a> </div> <div > Comments: Accepted at SyntaxFest 2021 </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >This work provides the first in-depth analysis of genre in Universal Dependencies (UD). In contrast to prior work on genre identification which uses small sets of well-defined labels in mono-/bilingual setups, UD contains 18 genres with varying degrees of specificity spread across 114 languages. As most treebanks are labeled with multiple genres while lacking annotations about which instances belong to which genre, we propose four methods for predicting instance-level genre using weak supervision from treebank metadata. The proposed methods recover instance-level genre better than competitive baselines as measured on a subset of UD with labeled instances and adhere better to the global expected distribution. Our analysis sheds light on prior work using UD genre metadata for treebank selection, finding that metadata alone are a noisy signal and must be disentangled within treebanks before it can be universally applied. </p> </div> </dd> <dt>[157] arXiv:2112.04974 [pdf, other]</dt> <dd> <div > <div > Title: AdaStereo: An Efficient Domain-Adaptive Stereo Matching Approach </div> <div > Authors: Xiao Song, <a >Guorun Yang</a>, <a >Xinge Zhu</a>, <a >Hui Zhou</a>, <a >Yuexin Ma</a>, <a >Zhe Wang</a>, <a >Jianping Shi</a> </div> <div > Comments: To be published in International Journal of Computer Vision (IJCV) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Recently, records on stereo matching benchmarks are constantly broken by end-to-end disparity networks. However, the domain adaptation ability of these deep models is quite limited. Addressing such problem, we present a novel domain-adaptive approach called AdaStereo that aims to align multi-level representations for deep stereo matching networks. Compared to previous methods, our AdaStereo realizes a more standard, complete and effective domain adaptation pipeline. Firstly, we propose a non-adversarial progressive color transfer algorithm for input image-level alignment. Secondly, we design an efficient parameter-free cost normalization layer for internal feature-level alignment. Lastly, a highly related auxiliary task, self-supervised occlusion-aware reconstruction is presented to narrow the gaps in output space. We perform intensive ablation studies and break-down comparisons to validate the effectiveness of each proposed module. With no extra inference overhead and only a slight increase in training complexity, our AdaStereo models achieve state-of-the-art cross-domain performance on multiple benchmarks, including KITTI, Middlebury, ETH3D and DrivingStereo, even outperforming some state-of-the-art disparity networks finetuned with target-domain ground-truths. Moreover, based on two additional evaluation metrics, the superiority of our domain-adaptive stereo matching pipeline is further uncovered from more perspectives. Finally, we demonstrate that our method is robust to various domain adaptation settings, and can be easily integrated into quick adaptation application scenarios and real-world deployments. </p> </div> </dd> <dt>[158] arXiv:2112.04975 [pdf, ps, other]</dt> <dd> <div > <div > Title: Personalized musically induced emotions of not-so-popular Colombian music </div> <div > Authors: Juan Sebastián Gómez-Cañón, <a >Perfecto Herrera</a>, <a >Estefanía Cano</a>, <a >Emilia Gómez</a> </div> <div > Journal-ref: HCAI Human Centered AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div > Subjects: Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS) </div> <p >This work presents an initial proof of concept of how Music Emotion Recognition (MER) systems could be intentionally biased with respect to annotations of musically induced emotions in a political context. In specific, we analyze traditional Colombian music containing politically charged lyrics of two types: (1) vallenatos and social songs from the "left-wing" guerrilla Fuerzas Armadas Revolucionarias de Colombia (FARC) and (2) corridos from the "right-wing" paramilitaries Autodefensas Unidas de Colombia (AUC). We train personalized machine learning models to predict induced emotions for three users with diverse political views - we aim at identifying the songs that may induce negative emotions for a particular user, such as anger and fear. To this extent, a user's emotion judgements could be interpreted as problematizing data - subjective emotional judgments could in turn be used to influence the user in a human-centered machine learning environment. In short, highly desired "emotion regulation" applications could potentially deviate to "emotion manipulation" - the recent discredit of emotion recognition technologies might transcend ethical issues of diversity and inclusion. </p> </div> </dd> <dt>[159] arXiv:2112.04977 [pdf, other]</dt> <dd> <div > <div > Title: Bringing Atomistic Deep Learning to Prime Time </div> <div > Authors: Nathan C. Frey, <a >Siddharth Samsi</a>, <a >Bharath Ramsundar</a>, <a >Connor W. Coley</a>, <a >Vijay Gadepally</a> </div> <div > Comments: 6 pages, 1 figure, NeurIPS 2021 AI for Science workshop </div> <div > Subjects: Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Chemical Physics (physics.chem-ph) </div> <p >Artificial intelligence has not yet revolutionized the design of materials and molecules. In this perspective, we identify four barriers preventing the integration of atomistic deep learning, molecular science, and high-performance computing. We outline focused research efforts to address the opportunities presented by these challenges. </p> </div> </dd> <dt>[160] arXiv:2112.04981 [pdf, other]</dt> <dd> <div > <div > Title: PE-former: Pose Estimation Transformer </div> <div > Authors: Paschalis Panteleris, <a >Antonis Argyros</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >Vision transformer architectures have been demonstrated to work very effectively for image classification tasks. Efforts to solve more challenging vision tasks with transformers rely on convolutional backbones for feature extraction. In this paper we investigate the use of a pure transformer architecture (i.e., one with no CNN backbone) for the problem of 2D body pose estimation. We evaluate two ViT architectures on the COCO dataset. We demonstrate that using an encoder-decoder transformer architecture yields state of the art results on this estimation problem. </p> </div> </dd> <dt>[161] arXiv:2112.04989 [pdf, ps, other]</dt> <dd> <div > <div > Title: The geometry of one-weight codes in the sum-rank metric </div> <div > Authors: Alessandro Neri, <a >Paolo Santonastaso</a>, <a >Ferdinando Zullo</a> </div> <div > Subjects: Information Theory (cs.IT); Combinatorics (math.CO) </div> <p >We provide a geometric characterization of $k$-dimensional $\mathbb{F}_{q^m}$-linear sum-rank metric codes as tuples of $\mathbb{F}_q$-subspaces of $\mathbb{F}_{q^m}^k$. We then use this characterization to study one-weight codes in the sum-rank metric. This leads us to extend the family of linearized Reed-Solomon codes in order to obtain a doubly-extended version of them. We prove that these codes are still maximum sum-rank distance (MSRD) codes and, when $k=2$, they are one-weight, as in the Hamming-metric case. We then focus on constant rank-profile codes in the sum-rank metric, which are a special family of one weight-codes, and derive constraints on their parameters with the aid of an associated Hamming-metric code. Furthermore, we introduce the $n$-simplex codes in the sum-rank metric, which are obtained as the orbit of a Singer subgroup of $\mathrm{GL}(k,q^m)$. They turn out to be constant rank-profile - and hence one-weight - and generalize the simplex codes in both the Hamming and the rank metric. Finally, we focus on $2$-dimensional one-weight codes, deriving constraints on the parameters of those which are also MSRD, and we find a new construction of one-weight MSRD codes when $q=2$. </p> </div> </dd> <dt>[162] arXiv:2112.04999 [pdf, other]</dt> <dd> <div > <div > Title: Few-Shot NLU with Vector Projection Distance and Abstract Triangular CRF </div> <div > Authors: Su Zhu, <a >Lu Chen</a>, <a >Ruisheng Cao</a>, <a >Zhi Chen</a>, <a >Qingliang Miao</a>, <a >Kai Yu</a> </div> <div > Comments: Accepted by NLPCC 2021 </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >Data sparsity problem is a key challenge of Natural Language Understanding (NLU), especially for a new target domain. By training an NLU model in source domains and applying the model to an arbitrary target domain directly (even without fine-tuning), few-shot NLU becomes crucial to mitigate the data scarcity issue. In this paper, we propose to improve prototypical networks with vector projection distance and abstract triangular Conditional Random Field (CRF) for the few-shot NLU. The vector projection distance exploits projections of contextual word embeddings on label vectors as word-label similarities, which is equivalent to a normalized linear model. The abstract triangular CRF learns domain-agnostic label transitions for joint intent classification and slot filling tasks. Extensive experiments demonstrate that our proposed methods can significantly surpass strong baselines. Specifically, our approach can achieve a new state-of-the-art on two few-shot NLU benchmarks (Few-Joint and SNIPS) in Chinese and English without fine-tuning on target domains. </p> </div> </dd> <dt>[163] arXiv:2112.05000 [pdf, other]</dt> <dd> <div > <div > Title: The Peril of Popular Deep Learning Uncertainty Estimation Methods </div> <div > Authors: Yehao Liu, <a >Matteo Pagliardini</a>, <a >Tatjana Chavdarova</a>, <a >Sebastian U. Stich</a> </div> <div > Comments: Presented at the Bayesian Deep Learning Workshop at NeurIPS 2021 </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Uncertainty estimation (UE) techniques -- such as the Gaussian process (GP), Bayesian neural networks (BNN), Monte Carlo dropout (MCDropout) -- aim to improve the interpretability of machine learning models by assigning an estimated uncertainty value to each of their prediction outputs. However, since too high uncertainty estimates can have fatal consequences in practice, this paper analyzes the above techniques. Firstly, we show that GP methods always yield high uncertainty estimates on out of distribution (OOD) data. Secondly, we show on a 2D toy example that both BNNs and MCDropout do not give high uncertainty estimates on OOD samples. Finally, we show empirically that this pitfall of BNNs and MCDropout holds on real world datasets as well. Our insights (i) raise awareness for the more cautious use of currently popular UE methods in Deep Learning, (ii) encourage the development of UE methods that approximate GP-based methods -- instead of BNNs and MCDropout, and (iii) our empirical setups can be used for verifying the OOD performances of any other UE method. The source code is available at https://github.com/epfml/uncertainity-estimation. </p> </div> </dd> <dt>[164] arXiv:2112.05003 [pdf, other]</dt> <dd> <div > <div > Title: Wikidated 1.0: An Evolving Knowledge Graph Dataset of Wikidata's Revision History </div> <div > Authors: Lukas Schmelzeisen, <a >Corina Dima</a>, <a >Steffen Staab</a> </div> <div > Comments: 15 pages, 4 figures. Published at Wikidata@ISWC 2021 </div> <div > Journal-ref: Wikidata@ISWC 2021 </div> <div > Subjects: Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG) </div> <p >Wikidata is the largest general-interest knowledge base that is openly available. It is collaboratively edited by thousands of volunteer editors and has thus evolved considerably since its inception in 2012. In this paper, we present Wikidated 1.0, a dataset of Wikidata's full revision history, which encodes changes between Wikidata revisions as sets of deletions and additions of RDF triples. To the best of our knowledge, it constitutes the first large dataset of an evolving knowledge graph, a recently emerging research subject in the Semantic Web community. We introduce the methodology for generating Wikidated 1.0 from dumps of Wikidata, discuss its implementation and limitations, and present statistical characteristics of the dataset. </p> </div> </dd> <dt>[165] arXiv:2112.05005 [pdf, other]</dt> <dd> <div > <div > Title: Mutual Adversarial Training: Learning together is better than going alone </div> <div > Authors: Jiang Liu, <a >Chun Pong Lau</a>, <a >Hossein Souri</a>, <a >Soheil Feizi</a>, <a >Rama Chellappa</a> </div> <div > Comments: Under submission </div> <div > Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Recent studies have shown that robustness to adversarial attacks can be transferred across networks. In other words, we can make a weak model more robust with the help of a strong teacher model. We ask if instead of learning from a static teacher, can models "learn together" and "teach each other" to achieve better robustness? In this paper, we study how interactions among models affect robustness via knowledge distillation. We propose mutual adversarial training (MAT), in which multiple models are trained together and share the knowledge of adversarial examples to achieve improved robustness. MAT allows robust models to explore a larger space of adversarial samples, and find more robust feature spaces and decision boundaries. Through extensive experiments on CIFAR-10 and CIFAR-100, we demonstrate that MAT can effectively improve model robustness and outperform state-of-the-art methods under white-box attacks, bringing $\sim$8% accuracy gain to vanilla adversarial training (AT) under PGD-100 attacks. In addition, we show that MAT can also mitigate the robustness trade-off among different perturbation types, bringing as much as 13.1% accuracy gain to AT baselines against the union of $l_\infty$, $l_2$ and $l_1$ attacks. These results show the superiority of the proposed method and demonstrate that collaborative learning is an effective strategy for designing robust models. </p> </div> </dd> <dt>[166] arXiv:2112.05006 [pdf, other]</dt> <dd> <div > <div > Title: Exploring Event-driven Dynamic Context for Accident Scene Segmentation </div> <div > Authors: Jiaming Zhang, <a >Kailun Yang</a>, <a >Rainer Stiefelhagen</a> </div> <div > Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS), extended version of <a >arXiv:2008.08974</a>, dataset and code will be made publicly available at <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >The robustness of semantic segmentation on edge cases of traffic scene is a vital factor for the safety of intelligent transportation. However, most of the critical scenes of traffic accidents are extremely dynamic and previously unseen, which seriously harm the performance of semantic segmentation methods. In addition, the delay of the traditional camera during high-speed driving will further reduce the contextual information in the time dimension. Therefore, we propose to extract dynamic context from event-based data with a higher temporal resolution to enhance static RGB images, even for those from traffic accidents with motion blur, collisions, deformations, overturns, etc. Moreover, in order to evaluate the segmentation performance in traffic accidents, we provide a pixel-wise annotated accident dataset, namely DADA-seg, which contains a variety of critical scenarios from traffic accidents. Our experiments indicate that event-based data can provide complementary information to stabilize semantic segmentation under adverse conditions by preserving fine-grained motion of fast-moving foreground (crash objects) in accidents. Our approach achieves +8.2% performance gain on the proposed accident dataset, exceeding more than 20 state-of-the-art semantic segmentation methods. The proposal has been demonstrated to be consistently effective for models learned on multiple source databases including Cityscapes, KITTI-360, BDD, and ApolloScape. </p> </div> </dd> <dt>[167] arXiv:2112.05008 [pdf, other]</dt> <dd> <div > <div > Title: Millimeter Wave Localization with Imperfect Training Data using Shallow Neural Networks </div> <div > Authors: Anish Shastri, <a >Joan Palacios</a>, <a >Paolo Casari</a> </div> <div > Comments: 6 pages, 9 figures. The paper is submitted to IEEE WCNC 2022 </div> <div > Subjects: Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG) </div> <p >Millimeter wave (mmWave) localization algorithms exploit the quasi-optical propagation of mmWave signals, which yields sparse angular spectra at the receiver. Geometric approaches to angle-based localization typically require to know the map of the environment and the location of the access points. Thus, several works have resorted to automated learning in order to infer a device's location from the properties of the received mmWave signals. However, collecting training data for such models is a significant burden. In this work, we propose a shallow neural network model to localize mmWave devices indoors. This model requires significantly fewer weights than those proposed in the literature. Therefore, it is amenable for implementation in resource-constrained hardware, and needs fewer training samples to converge. We also propose to relieve training data collection efforts by retrieving (inherently imperfect) location estimates from geometry-based mmWave localization algorithms. Even in this case, our results show that the proposed neural networks perform as good as or better than state-of-the-art algorithms. </p> </div> </dd> <dt>[168] arXiv:2112.05019 [pdf, other]</dt> <dd> <div > <div > Title: Uncovering the Size of the Illegal Corporate Service Provider Industry in the Netherlands: a Network Approach </div> <div > Authors: Javier Garcia-Bernardo, <a >Joost Witteman</a>, <a >Marilou Vlaanderen</a> </div> <div > Subjects: Social and Information Networks (cs.SI) </div> <p >Economic crimes such as money laundering, terrorism financing, tax evasion or corruption almost invariably involve the use of a corporate entity. Such entities are regularly incorporated and managed by corporate services providers (CSPs). Given this potential for enabling economic crime, the CSP industry in the Netherlands is heavily regulated and CSPs require a license to operate. Operating without a licence is illegal. In this paper we develop a classification method to detect potentially illegal CSPs based on their similarity with licensed CSPs. Similarity is computed based on their position within the network of directors, companies and addresses, and the characteristics of such entities. We manually annotate a sample of the potential illegal CSPs and estimate that illegal CSPs constitute 45\% of the total number of CSPs and manage 15--30\% of all companies managed by CSPs.Our analysis provides a tool to regulators to improve detection and prevention of economic crime, and can be extended to the detection of other illegal activities. </p> </div> </dd> <dt>[169] arXiv:2112.05023 [pdf, other]</dt> <dd> <div > <div > Title: Polynomial XL: A Variant of the XL Algorithm Using Macaulay Matrices over Polynomial Rings </div> <div > Authors: Hiroki Furue, <a >Momonari Kudo</a> </div> <div > Comments: 28 pages, 1 figure </div> <div > Subjects: Symbolic Computation (cs.SC); Cryptography and Security (cs.CR); Commutative Algebra (math.AC) </div> <p >Solving a system of $m$ multivariate quadratic equations in $n$ variables (the $\mathcal MQ$ problem) is one of the main challenges of algebraic cryptanalysis. The XL algorithm (XL for short) is a major approach for solving the $\mathcal MQ$ problem with linearization over a coefficient field. Furthermore, the hybrid approach with XL (h-XL) is a variant of XL guessing some variables beforehand. In this paper, we present a variant of h-XL, which we call the polynomial XL (PXL). In PXL, the whole $n$ variables are divided into $k$ variables to be fixed and the remaining $n-k$ variables as "main variables", and we generate the Macaulay matrix with respect to the $n-k$ main variables over a polynomial ring of the $k$ variables. By eliminating some columns of the Macaulay matrix over the polynomial ring before guessing $k$ variables, the amount of manipulations required for each guessed value can be reduced. Our complexity analysis indicates that PXL is efficient on the system with $n \approx m$. For example, on systems over ${\mathbb F}_{2^8}$ with $n=m=80$, the number of manipulations required by the hybrid approaches with XL and Wiedemann XL and PXL is estimated as $2^{252}$, $2^{234}$, and $2^{220}$, respectively. </p> </div> </dd> <dt>[170] arXiv:2112.05025 [pdf, other]</dt> <dd> <div > <div > Title: Gradient-matching coresets for continual learning </div> <div > Authors: Lukas Balles, Giovanni Zappella, <a >Cédric Archambeau</a> </div> <div > Comments: Accepted at the NeurIPS '21 Workshop on Distribution Shifts </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >We devise a coreset selection method based on the idea of gradient matching: The gradients induced by the coreset should match, as closely as possible, those induced by the original training dataset. We evaluate the method in the context of continual learning, where it can be used to curate a rehearsal memory. Our method performs strong competitors such as reservoir sampling across a range of memory sizes. </p> </div> </dd> <dt>[171] arXiv:2112.05028 [pdf, other]</dt> <dd> <div > <div > Title: Almost complete analytical integration in Galerkin BEM </div> <div > Authors: Daniel Seibel </div> <div > Comments: 27 pages, 7 figures </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >In this work, semi-analytical formulae for the numerical evaluation of surface integrals occurring in Galerkin boundary element methods (BEM) in 3D are derived. The integrals appear as the entries of BEM matrices and are formed over pairs of surface triangles. Since the integrands become singular if the triangles have non-empty intersection, the transformation presented by Sauter and Schwab is used to remove the singularities. It is shown that the resulting integrals admit analytical formulae if the triangles are identical or share a common edge. Moreover, the four-dimensional integrals are reduced to one- or two-dimensional integrals for triangle pairs with common vertices or disjoint triangles respectively. The efficiency and accuracy of the formulae is demonstrated in numerical experiments. </p> </div> </dd> <dt>[172] arXiv:2112.05036 [pdf, other]</dt> <dd> <div > <div > Title: Domain Adaptation and Autoencoder Based Unsupervised Speech Enhancement </div> <div > Authors: Yi Li, <a >Yang Sun</a>, <a >Kirill Horoshenkov</a>, <a >Syed Mohsen Naqvi</a> </div> <div > Journal-ref: IEEE Transactions on Artificial Intelligence. (2021) </div> <div > Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p >As a category of transfer learning, domain adaptation plays an important role in generalizing the model trained in one task and applying it to other similar tasks or settings. In speech enhancement, a well-trained acoustic model can be exploited to obtain the speech signal in the context of other languages, speakers, and environments. Recent domain adaptation research was developed more effectively with various neural networks and high-level abstract features. However, the related studies are more likely to transfer the well-trained model from a rich and more diverse domain to a limited and similar domain. Therefore, in this study, the domain adaptation method is proposed in unsupervised speech enhancement for the opposite circumstance that transferring to a larger and richer domain. On the one hand, the importance-weighting (IW) approach is exploited with a variance constrained autoencoder to reduce the shift of shared weights between the source and target domains. On the other hand, in order to train the classifier with the worst-case weights and minimize the risk, the minimax method is proposed. Both the proposed IW and minimax methods are evaluated from the VOICE BANK and IEEE datasets to the TIMIT dataset. The experiment results show that the proposed methods outperform the state-of-the-art approaches. </p> </div> </dd> <dt>[173] arXiv:2112.05050 [pdf]</dt> <dd> <div > <div > Title: End-to-End Learning of Joint Geometric and Probabilistic Constellation Shaping </div> <div > Authors: Vahid Aref, <a >Mathieu Chagnon</a> </div> <div > Comments: Will be presented at OFC 2022 (invited talk) </div> <div > Subjects: Information Theory (cs.IT); Artificial Intelligence (cs.AI); Signal Processing (eess.SP) </div> <p >We present a novel autoencoder-based learning of joint geometric and probabilistic constellation shaping for coded-modulation systems. It can maximize either the mutual information (for symbol-metric decoding) or the generalized mutual information (for bit-metric decoding). </p> </div> </dd> <dt>[174] arXiv:2112.05051 [pdf, other]</dt> <dd> <div > <div > Title: Preconditioning Richards Equations: spectral analysis and parallel solution at very large scale </div> <div > Authors: Daniele Bertaccini, <a >Pasqua D'Ambra</a>, <a >Fabio Durastante</a>, <a >Salvatore Filippone</a> </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >We consider here a cell-centered finite difference approximation of the Richards equation in three dimensions, averaging for interface values the hydraulic conductivity $K=K(p)$, a highly nonlinear function, by arithmetic, upstream, and harmonic means. The nonlinearities in the equation can lead to changes in soil conductivity over several orders of magnitude and discretizations with respect to space variables often produce stiff systems of differential equations. Fully implicit time discretization is provided by backward Euler one-step formula; the resulting nonlinear algebraic system is solved by an inexact Newton Armijo-Goldstein algorithm, requiring the solution of a sequence of linear systems involving Jacobian matrices. We prove some new results concerning the distribution of the Jacobians eigenvalues and the explicit expression of their entries. Moreover, we explore some connections between the saturation of the soil and the ill-conditioning of the Jacobians. The information on eigenvalues justifies the effectiveness of some preconditioner approaches which are widely used in the solution of the Richards equation. We propose a new software framework to experiment with scalable and robust preconditioners suitable for efficient parallel simulations at very large scales. Performance results on a literature test case show that our framework is very promising in the advance towards realistic simulations at extreme scale. </p> </div> </dd> <dt>[175] arXiv:2112.05053 [pdf]</dt> <dd> <div > <div > Title: Illumination and Temperature-Aware Multispectral Networks for Edge-Computing-Enabled Pedestrian Detection </div> <div > Authors: Yifan Zhuang, <a >Ziyuan Pu</a>, <a >Jia Hu</a>, <a >Yinhai Wang</a> </div> <div > Comments: 13 pages, 12 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Accurate and efficient pedestrian detection is crucial for the intelligent transportation system regarding pedestrian safety and mobility, e.g., Advanced Driver Assistance Systems, and smart pedestrian crosswalk systems. Among all pedestrian detection methods, vision-based detection method is demonstrated to be the most effective in previous studies. However, the existing vision-based pedestrian detection algorithms still have two limitations that restrict their implementations, those being real-time performance as well as the resistance to the impacts of environmental factors, e.g., low illumination conditions. To address these issues, this study proposes a lightweight Illumination and Temperature-aware Multispectral Network (IT-MN) for accurate and efficient pedestrian detection. The proposed IT-MN is an efficient one-stage detector. For accommodating the impacts of environmental factors and enhancing the sensing accuracy, thermal image data is fused by the proposed IT-MN with visual images to enrich useful information when visual image quality is limited. In addition, an innovative and effective late fusion strategy is also developed to optimize the image fusion performance. To make the proposed model implementable for edge computing, the model quantization is applied to reduce the model size by 75% while shortening the inference time significantly. The proposed algorithm is evaluated by comparing with the selected state-of-the-art algorithms using a public dataset collected by in-vehicle cameras. The results show that the proposed algorithm achieves a low miss rate and inference time at 14.19% and 0.03 seconds per image pair on GPU. Besides, the quantized IT-MN achieves an inference time of 0.21 seconds per image pair on the edge device, which also demonstrates the potentiality of deploying the proposed model on edge devices as a highly efficient pedestrian detection algorithm. </p> </div> </dd> <dt>[176] arXiv:2112.05055 [pdf, ps, other]</dt> <dd> <div > <div > Title: Multivariate analysis-suitable T-splines of arbitrary degree </div> <div > Authors: Robin Görmer, <a >Philipp Morgenstern</a> </div> <div > Comments: 13 pages, 4 figures </div> <div > Subjects: Numerical Analysis (math.NA) </div> <p >This paper defines analysis-suitable T-splines for arbitrary degree (including even and mixed degrees) and arbitrary dimension. We generalize the concept of anchor elements known from the two-dimensional setting, extend two existing concepts of analysis-suitability and justify their sufficiency for linear independence of the T-spline basis. Finally, we propose a local refinement scheme for multivariate T-splines that allows anisotropic refinement and preserves weak geometric analysis-suitability. </p> </div> </dd> <dt>[177] arXiv:2112.05056 [pdf]</dt> <dd> <div > <div > Title: Opinion Extraction as A Structured Sentiment Analysis using Transformers </div> <div > Authors: Yucheng Liu, <a >Tian Zhu</a> </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >Relationship extraction and named entity recognition have always been considered as two distinct tasks that require different input data, labels, and models. However, both are essential for structured sentiment analysis. We believe that both tasks can be combined into a single stacked model with the same input data. We performed different experiments to find the best model to extract multiple opinion tuples from a single sentence. The opinion tuples will consist of holders, targets, and expressions. With the opinion tuples, we will be able to extract the relationship we need. </p> </div> </dd> <dt>[178] arXiv:2112.05061 [pdf]</dt> <dd> <div > <div > Title: Deep Learning based Differential Distinguisher for Lightweight Block Ciphers </div> <div > Authors: Aayush Jain, <a >Varun Kohli</a>, <a >Girish Mishra</a> </div> <div > Comments: 12 pages, 6 figures, 3 tables, 1 algorithm </div> <div > Subjects: Cryptography and Security (cs.CR) </div> <p >Recent years have seen an increasing involvement of Deep Learning in the cryptanalysis of various ciphers. The present study is inspired by past works on differential distinguishers, to develop a Deep Neural Network-based differential distinguisher for round reduced lightweight block ciphers PRESENT and Simeck. We make improvements in the state-of-the-art approach and extend its use to the two structurally different block ciphers, PRESENT-80 and Simeck64/128. The obtained results suggest the universality of our cryptanalysis method. The proposed method can distinguish random data from the cipher data obtained until 6 rounds of PRESENT and 7 rounds of Simeck encryption with high accuracy. In addition to this, we explore a new approach to select good input differentials, which to the best of our knowledge has not been explored in the past. We also provide a minimum-security requirement for the discussed ciphers against our differential attack. </p> </div> </dd> <dt>[179] arXiv:2112.05062 [pdf, other]</dt> <dd> <div > <div > Title: Learning Transferable Motor Skills with Hierarchical Latent Mixture Policies </div> <div > Authors: Dushyant Rao, <a >Fereshteh Sadeghi</a>, <a >Leonard Hasenclever</a>, <a >Markus Wulfmeier</a>, <a >Martina Zambelli</a>, <a >Giulia Vezzani</a>, <a >Dhruva Tirumala</a>, <a >Yusuf Aytar</a>, <a >Josh Merel</a>, <a >Nicolas Heess</a>, <a >Raia Hadsell</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO) </div> <p >For robots operating in the real world, it is desirable to learn reusable behaviours that can effectively be transferred and adapted to numerous tasks and scenarios. We propose an approach to learn abstract motor skills from data using a hierarchical mixture latent variable model. In contrast to existing work, our method exploits a three-level hierarchy of both discrete and continuous latent variables, to capture a set of high-level behaviours while allowing for variance in how they are executed. We demonstrate in manipulation domains that the method can effectively cluster offline data into distinct, executable behaviours, while retaining the flexibility of a continuous latent variable model. The resulting skills can be transferred and fine-tuned on new tasks, unseen objects, and from state to vision-based policies, yielding better sample efficiency and asymptotic performance compared to existing skill- and imitation-based methods. We further analyse how and when the skills are most beneficial: they encourage directed exploration to cover large regions of the state space relevant to the task, making them most effective in challenging sparse-reward settings. </p> </div> </dd> <dt>[180] arXiv:2112.05068 [pdf, other]</dt> <dd> <div > <div > Title: A Bayesian Treatment of Real-to-Sim for Deformable Object Manipulation </div> <div > Authors: Rika Antonova, <a >Jingyun Yang</a>, <a >Priya Sundaresan</a>, <a >Dieter Fox</a>, <a >Fabio Ramos</a>, <a >Jeannette Bohg</a> </div> <div > Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p >Deformable object manipulation remains a challenging task in robotics research. Conventional techniques for parameter inference and state estimation typically rely on a precise definition of the state space and its dynamics. While this is appropriate for rigid objects and robot states, it is challenging to define the state space of a deformable object and how it evolves in time. In this work, we pose the problem of inferring physical parameters of deformable objects as a probabilistic inference task defined with a simulator. We propose a novel methodology for extracting state information from image sequences via a technique to represent the state of a deformable object as a distribution embedding. This allows to incorporate noisy state observations directly into modern Bayesian simulation-based inference tools in a principled manner. Our experiments confirm that we can estimate posterior distributions of physical properties, such as elasticity, friction and scale of highly deformable objects, such as cloth and ropes. Overall, our method addresses the real-to-sim problem probabilistically and helps to better represent the evolution of the state of deformable objects. </p> </div> </dd> <dt>[181] arXiv:2112.05070 [pdf, other]</dt> <dd> <div > <div > Title: Unique Assembly Verification in Two-Handed Self-Assembly </div> <div > Authors: David Caballero, <a >Timothy Gomez</a>, <a >Robert Schweller</a>, <a >Tim Wylie</a> </div> <div > Subjects: Computational Geometry (cs.CG); Computational Complexity (cs.CC) </div> <p >One of the most fundamental and well-studied problems in Tile Self-Assembly is the Unique Assembly Verification (UAV) problem. This algorithmic problem asks whether a given tile system uniquely assembles a specific assembly. The complexity of this problem in the 2-Handed Assembly Model (2HAM) at a constant temperature is a long-standing open problem since the model was introduced. Previously, only membership in the class coNP was known and that the problem is in P if the temperature is one ($au=1$). The problem is known to be hard for many generalizations of the model, such as allowing one step into the third dimension or allowing the temperature of the system to be a variable, but the most fundamental version has remained open. In this paper, we prove the UAV problem in the 2HAM is hard even with a small constant temperature ($au = 2$), and finally answer the complexity of this problem (open since 2013). Further, this result proves that UAV in the staged self-assembly model is coNP-complete with a single bin and stage (open since 2007), and that UAV in the q-tile model is also coNP-complete (open since 2004). We reduce from Monotone Planar 3-SAT with Neighboring Variable Pairs, a special case of 3SAT recently proven to be NP-hard. We accompany this reduction with a positive result showing that UAV is solvable in polynomial time with the promise that the given target assembly will have a tree-shaped bond graph, i.e., contains no cycles. We provide a $\mathcal{O}(n^5)$ algorithm for UAV on tree-bonded assemblies when the temperature is fixed to $2$, and a $\mathcal{O}(n^5\log au)$ time algorithm when the temperature is part of the input. </p> </div> </dd> <dt>[182] arXiv:2112.05071 [pdf, other]</dt> <dd> <div > <div > Title: A Novel Tropical Geometry-based Interpretable Machine Learning Method: Application in Prognosis of Advanced Heart Failure </div> <div > Authors: Heming Yao, <a >Harm Derksen</a>, <a >Jessica R. Golbus</a>, <a >Justin Zhang</a>, <a >Keith D. Aaronson</a>, <a >Jonathan Gryak</a>, <a >Kayvan Najarian</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> <p >A model's interpretability is essential to many practical applications such as clinical decision support systems. In this paper, a novel interpretable machine learning method is presented, which can model the relationship between input variables and responses in humanly understandable rules. The method is built by applying tropical geometry to fuzzy inference systems, wherein variable encoding functions and salient rules can be discovered by supervised learning. Experiments using synthetic datasets were conducted to investigate the performance and capacity of the proposed algorithm in classification and rule discovery. Furthermore, the proposed method was applied to a clinical application that identified heart failure patients that would benefit from advanced therapies such as heart transplant or durable mechanical circulatory support. Experimental results show that the proposed network achieved great performance on the classification tasks. In addition to learning humanly understandable rules from the dataset, existing fuzzy domain knowledge can be easily transferred into the network and used to facilitate model training. From our results, the proposed model and the ability of learning existing domain knowledge can significantly improve the model generalizability. The characteristics of the proposed network make it promising in applications requiring model reliability and justification. </p> </div> </dd> <dt>[183] arXiv:2112.05077 [pdf, other]</dt> <dd> <div > <div > Title: Generating Useful Accident-Prone Driving Scenarios via a Learned Traffic Prior </div> <div > Authors: Davis Rempe, <a >Jonah Philion</a>, <a >Leonidas J. Guibas</a>, <a >Sanja Fidler</a>, <a >Or Litany</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO) </div> <p >Evaluating and improving planning for autonomous vehicles requires scalable generation of long-tail traffic scenarios. To be useful, these scenarios must be realistic and challenging, but not impossible to drive through safely. In this work, we introduce STRIVE, a method to automatically generate challenging scenarios that cause a given planner to produce undesirable behavior, like collisions. To maintain scenario plausibility, the key idea is to leverage a learned model of traffic motion in the form of a graph-based conditional VAE. Scenario generation is formulated as an optimization in the latent space of this traffic model, effected by perturbing an initial real-world scene to produce trajectories that collide with a given planner. A subsequent optimization is used to find a "solution" to the scenario, ensuring it is useful to improve the given planner. Further analysis clusters generated scenarios based on collision type. We attack two planners and show that STRIVE successfully generates realistic, challenging scenarios in both cases. We additionally "close the loop" and use these scenarios to optimize hyperparameters of a rule-based planner. </p> </div> </dd> <dt>[184] arXiv:2112.05080 [pdf, other]</dt> <dd> <div > <div > Title: Locally Shifted Attention With Early Global Integration </div> <div > Authors: Shelly Sheynin, <a >Sagie Benaim</a>, <a >Adam Polyak</a>, <a >Lior Wolf</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p >Recent work has shown the potential of transformers for computer vision applications. An image is first partitioned into patches, which are then used as input tokens for the attention mechanism. Due to the expensive quadratic cost of the attention mechanism, either a large patch size is used, resulting in coarse-grained global interactions, or alternatively, attention is applied only on a local region of the image, at the expense of long-range interactions. In this work, we propose an approach that allows for both coarse global interactions and fine-grained local interactions already at early layers of a vision transformer. At the core of our method is the application of local and global attention layers. In the local attention layer, we apply attention to each patch and its local shifts, resulting in virtually located local patches, which are not bound to a single, specific location. These virtually located patches are then used in a global attention layer. The separation of the attention layer into local and global counterparts allows for a low computational cost in the number of patches, while still supporting data-dependent localization already at the first layer, as opposed to the static positioning in other visual transformers. Our method is shown to be superior to both convolutional and transformer-based methods for image classification on CIFAR10, CIFAR100, and ImageNet. Code is available at: https://github.com/shellysheynin/Locally-SAG-Transformer. </p> </div> </dd> <dt>[185] arXiv:2112.05083 [pdf, ps, other]</dt> <dd> <div > <div > Title: Improved approximation algorithms for two Euclidean k-Center variants </div> <div > Authors: Haris Angelidakis, <a >Ivan Sergeev</a>, <a >Pontus Westermark</a> </div> <div > Comments: An approximation algorithm with the same factor for Robust Euclidean k-Supplier also recently appeared in an independent work of Lee, Nagarajan and Wang (<a >arXiv:2112.01700</a>) </div> <div > Subjects: Data Structures and Algorithms (cs.DS); Computational Geometry (cs.CG) </div> <p >The $k$-Center problem is one of the most popular clustering problems. After decades of work, the complexity of most of its variants on general metrics is now well understood. Surprisingly, this is not the case for a natural setting that often arises in practice, namely the Euclidean setting, in which the input points are points in $\mathbb{R}^d$, and the distance between them is the standard $\ell_2$ Euclidean distance. In this work, we study two Euclidean $k$-Center variants, the Matroid Center problem on the real line and the Robust Euclidean $k$-Supplier problem, and provide algorithms that improve upon the best approximation guarantees known for these problems. In particular, we present a simple $2.5$-approximation algorithm for the Matroid Center problem on the real line, thus improving upon the $3$-approximation factor algorithm of Chen, Li, Liang, and Wang (2016) that works for general metrics. Moreover, we present a $(1 + \sqrt{3})$-approximation algorithm for the Robust Euclidean $k$-Supplier problem, thus improving upon the state-of-the-art $3$-approximation algorithm for Robust $k$-Supplier on general metrics and matching the best approximation factor known for the non-robust setting by Nagarajan, Schieber and Shachnai (2020). </p> </div> </dd> <dt>[186] arXiv:2112.05084 [pdf, other]</dt> <dd> <div > <div > Title: A Survey on Echo Chambers on Social Media: Description, Detection and Mitigation </div> <div > Authors: Faisal Alatawi, <a >Lu Cheng</a>, <a >Anique Tahir</a>, <a >Mansooreh Karami</a>, <a >Bohan Jiang</a>, <a >Tyler Black</a>, <a >Huan Liu</a> </div> <div > Comments: 21 pages, 5 figures </div> <div > Subjects: Social and Information Networks (cs.SI); Machine Learning (cs.LG) </div> <p >Echo chambers on social media are a significant problem that can elicit a number of negative consequences, most recently affecting the response to COVID-19. Echo chambers promote conspiracy theories about the virus and are found to be linked to vaccine hesitancy, less compliance with mask mandates, and the practice of social distancing. Moreover, the problem of echo chambers is connected to other pertinent issues like political polarization and the spread of misinformation. An echo chamber is defined as a network of users in which users only interact with opinions that support their pre-existing beliefs and opinions, and they exclude and discredit other viewpoints. This survey aims to examine the echo chamber phenomenon on social media from a social computing perspective and provide a blueprint for possible solutions. We survey the related literature to understand the attributes of echo chambers and how they affect the individual and society at large. Additionally, we show the mechanisms, both algorithmic and psychological, that lead to the formation of echo chambers. These mechanisms could be manifested in two forms: (1) the bias of social media's recommender systems and (2) internal biases such as confirmation bias and homophily. While it is immensely challenging to mitigate internal biases, there has been great efforts seeking to mitigate the bias of recommender systems. These recommender systems take advantage of our own biases to personalize content recommendations to keep us engaged in order to watch more ads. Therefore, we further investigate different computational approaches for echo chamber detection and prevention, mainly based around recommender systems. </p> </div> </dd> <dt>[187] arXiv:2112.05090 [pdf, other]</dt> <dd> <div > <div > Title: Extending the WILDS Benchmark for Unsupervised Adaptation </div> <div > Authors: Shiori Sagawa, <a >Pang Wei Koh</a>, <a >Tony Lee</a>, <a >Irena Gao</a>, <a >Sang Michael Xie</a>, <a >Kendrick Shen</a>, <a >Ananya Kumar</a>, <a >Weihua Hu</a>, <a >Michihiro Yasunaga</a>, <a >Henrik Marklund</a>, <a >Sara Beery</a>, <a >Etienne David</a>, <a >Ian Stavness</a>, <a >Wei Guo</a>, <a >Jure Leskovec</a>, <a >Kate Saenko</a>, <a >Tatsunori Hashimoto</a>, <a >Sergey Levine</a>, <a >Chelsea Finn</a>, <a >Percy Liang</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML) </div> <p >Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data. However, existing distribution shift benchmarks for unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. To maintain consistency, the labeled training, validation, and test sets, as well as the evaluation metrics, are exactly the same as in the original WILDS benchmark. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). We systematically benchmark state-of-the-art methods that leverage unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS 2.0 is limited. To facilitate method development and evaluation, we provide an open-source package that automates data loading and contains all of the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu. </p> </div> </dd> <dt>[188] arXiv:2112.05106 [pdf, other]</dt> <dd> <div > <div > Title: Estimating the Longest Increasing Subsequence in Nearly Optimal Time </div> <div > Authors: Alexandr Andoni, <a >Negev Shekel Nosatzki</a>, <a >Sandip Sinha</a>, <a >Clifford Stein</a> </div> <div > Subjects: Data Structures and Algorithms (cs.DS) </div> <p >Longest Increasing Subsequence (LIS) is a fundamental statistic of a sequence, and has been studied for decades. While the LIS of a sequence of length $n$ can be computed exactly in time $O(n\log n)$, the complexity of estimating the (length of the) LIS in sublinear time, especially when LIS $\ll n$, is still open. We show that for any integer $n$ and any $\lambda = o(1)$, there exists a (randomized) non-adaptive algorithm that, given a sequence of length $n$ with LIS $\ge \lambda n$, approximates the LIS up to a factor of $1/\lambda^{o(1)}$ in $n^{o(1)} / \lambda$ time. Our algorithm improves upon prior work substantially in terms of both approximation and run-time: (i) we provide the first sub-polynomial approximation for LIS in sub-linear time; and (ii) our run-time complexity essentially matches the trivial sample complexity lower bound of $\Omega(1/\lambda)$, which is required to obtain any non-trivial approximation of the LIS. As part of our solution, we develop two novel ideas which may be of independent interest: First, we define a new Genuine-LIS problem, where each sequence element may either be genuine or corrupted. In this model, the user receives unrestricted access to actual sequence, but does not know apriori which elements are genuine. The goal is to estimate the LIS using genuine elements only, with the minimal number of "genuiness tests". The second idea, Precision Forest, enables accurate estimations for composition of general functions from "coarse" (sub-)estimates. Precision Forest essentially generalizes classical precision sampling, which works only for summations. As a central tool, the Precision Forest is initially pre-processed on a set of samples, which thereafter is repeatedly reused by multiple sub-parts of the algorithm, improving their amortized complexity. </p> </div> </dd> <dt>[189] arXiv:2112.05112 [pdf, other]</dt> <dd> <div > <div > Title: BLT: Bidirectional Layout Transformer for Controllable Layout Generation </div> <div > Authors: Xiang Kong, <a >Lu Jiang</a>, <a >Huiwen Chang</a>, <a >Han Zhang</a>, <a >Yuan Hao</a>, <a >Haifeng Gong</a>, <a >Irfan Essa</a> </div> <div > Comments: 14 pages, under review </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Creating visual layouts is an important step in graphic design. Automatic generation of such layouts is important as we seek scale-able and diverse visual designs. Prior works on automatic layout generation focus on unconditional generation, in which the models generate layouts while neglecting user needs for specific problems. To advance conditional layout generation, we introduce BLT, a bidirectional layout transformer. BLT differs from autoregressive decoding as it first generates a draft layout that satisfies the user inputs and then refines the layout iteratively. We verify the proposed model on multiple benchmarks with various fidelity metrics. Our results demonstrate two key advances to the state-of-the-art layout transformer models. First, our model empowers layout transformers to fulfill controllable layout generation. Second, our model slashes the linear inference time in autoregressive decoding into a constant complexity, thereby achieving 4x-10x speedups in generating a layout at inference time. </p> </div> </dd> <dt>[190] arXiv:2112.05118 [pdf, other]</dt> <dd> <div > <div > Title: Web Platform for Visualisation of Kinematic Data captured from a Motor Tele-rehabilitation System </div> <div > Authors: Praveena Satkunarajah, <a >Kat Agres</a> </div> <div > Subjects: Human-Computer Interaction (cs.HC) </div> <p >Stroke can have a severe impact on an individual's quality of life, leading to consequences such as motor loss and communication problems, especially among the elderly. Studies have shown that early and easy access to stroke rehabilitation can improve an elderly individual's quality of life, and that telerehabilitation is a solution that facilitates this improvement. In this work, we visualize movement to music during rehabilitation exercises captured by the Kinect motion sensor, using a dedicated Serious Game called `Move to the Music'(MoMu). Our system provides a quantitative view of progress made by patients during a motor rehabilitation regime for healthcare professionals to track remotely (tele-rehab). </p> </div> </dd> <dt>[191] arXiv:2112.05121 [pdf, other]</dt> <dd> <div > <div > Title: Self-Supervised Keypoint Discovery in Behavioral Videos </div> <div > Authors: Jennifer J. Sun, Serim Ryou, <a >Roni Goldshmid</a>, <a >Brandon Weissbourd</a>, <a >John Dabiri</a>, <a >David J. Anderson</a>, <a >Ann Kennedy</a>, <a >Yisong Yue</a>, <a >Pietro Perona</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We propose a method for learning the posture and structure of agents from unlabelled behavioral videos. Starting from the observation that behaving agents are generally the main sources of movement in behavioral videos, our method uses an encoder-decoder architecture with a geometric bottleneck to reconstruct the difference between video frames. By focusing only on regions of movement, our approach works directly on input videos without requiring manual annotations, such as keypoints or bounding boxes. Experiments on a variety of agent types (mouse, fly, human, jellyfish, and trees) demonstrate the generality of our approach and reveal that our discovered keypoints represent semantically meaningful body parts, which achieve state-of-the-art performance on keypoint regression among self-supervised methods. Additionally, our discovered keypoints achieve comparable performance to supervised keypoints on downstream tasks, such as behavior classification, suggesting that our method can dramatically reduce the cost of model training vis-a-vis supervised methods. </p> </div> </dd> <dt>[192] arXiv:2112.05124 [pdf, other]</dt> <dd> <div > <div > Title: Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation </div> <div > Authors: Anthony Simeonov, <a >Yilun Du</a>, <a >Andrea Tagliasacchi</a>, <a >Joshua B. Tenenbaum</a>, <a >Alberto Rodriguez</a>, <a >Pulkit Agrawal</a>, <a >Vincent Sitzmann</a> </div> <div > Comments: Website: <a >this https URL</a> First two authors contributed equally (order determined by coin flip), last two authors equal advising </div> <div > Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (5-10) demonstrations both in simulation and on a real robot. Our performance generalizes across both object instances and 6-DoF object poses, and significantly outperforms a recent baseline that relies on 2D descriptors. Project website: https://yilundu.github.io/ndf/. </p> </div> </dd> <dt>[193] arXiv:2112.05125 [pdf, other]</dt> <dd> <div > <div > Title: Transferring BERT-like Transformers' Knowledge for Authorship Verification </div> <div > Authors: Andrei Manolache, <a >Florin Brad</a>, <a >Elena Burceanu</a>, <a >Antonio Barbalau</a>, <a >Radu Ionescu</a>, <a >Marius Popescu</a> </div> <div > Comments: 16 pages, 3 figures </div> <div > Subjects: Computation and Language (cs.CL) </div> <p >The task of identifying the author of a text spans several decades and was tackled using linguistics, statistics, and, more recently, machine learning. Inspired by the impressive performance gains across a broad range of natural language processing tasks and by the recent availability of the PAN large-scale authorship dataset, we first study the effectiveness of several BERT-like transformers for the task of authorship verification. Such models prove to achieve very high scores consistently. Next, we empirically show that they focus on topical clues rather than on author writing style characteristics, taking advantage of existing biases in the dataset. To address this problem, we provide new splits for PAN-2020, where training and test data are sampled from disjoint topics or authors. Finally, we introduce DarkReddit, a dataset with a different input data distribution. We further use it to analyze the domain generalization performance of models in a low-data regime and how performance varies when using the proposed PAN-2020 splits for fine-tuning. We show that those splits can enhance the models' capability to transfer knowledge over a new, significantly different dataset. </p> </div> </dd> <dt>[194] arXiv:2112.05126 [pdf, other]</dt> <dd> <div > <div > Title: IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo </div> <div > Authors: Fangjinhua Wang, <a >Silvano Galliani</a>, <a >Christoph Vogel</a>, <a >Marc Pollefeys</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We present IterMVS, a new data-driven method for high-resolution multi-view stereo. We propose a novel GRU-based estimator that encodes pixel-wise probability distributions of depth in its hidden state. Ingesting multi-scale matching information, our model refines these distributions over multiple iterations and infers depth and confidence. To extract the depth maps, we combine traditional classification and regression in a novel manner. We verify the efficiency and effectiveness of our method on DTU, TanksTemples and ETH3D. While being the most efficient method in both memory and run-time, our model achieves competitive performance on DTU and better generalization ability on TanksTemples as well as ETH3D than most state-of-the-art methods. Code is available at https://github.com/FangjinhuaWang/IterMVS. </p> </div> </dd> <dt>[195] arXiv:2112.05129 [pdf, other]</dt> <dd> <div > <div > Title: Assistive Tele-op: Leveraging Transformers to Collect Robotic Task Demonstrations </div> <div > Authors: Henry M. Clever, <a >Ankur Handa</a>, <a >Hammad Mazhar</a>, <a >Kevin Parker</a>, <a >Omer Shapira</a>, <a >Qian Wan</a>, <a >Yashraj Narang</a>, <a >Iretiayo Akinola</a>, <a >Maya Cakmak</a>, <a >Dieter Fox</a> </div> <div > Comments: 9 pages, 4 figures, 1 table. NeurIPS 2021 Workshop on Robot Learning: Self-Supervised and Lifelong Learning, Virtual, Virtual </div> <div > Subjects: Robotics (cs.RO) </div> <p >Sharing autonomy between robots and human operators could facilitate data collection of robotic task demonstrations to continuously improve learned models. Yet, the means to communicate intent and reason about the future are disparate between humans and robots. We present Assistive Tele-op, a virtual reality (VR) system for collecting robot task demonstrations that displays an autonomous trajectory forecast to communicate the robot's intent. As the robot moves, the user can switch between autonomous and manual control when desired. This allows users to collect task demonstrations with both a high success rate and with greater ease than manual teleoperation systems. Our system is powered by transformers, which can provide a window of potential states and actions far into the future -- with almost no added computation time. A key insight is that human intent can be injected at any location within the transformer sequence if the user decides that the model-predicted actions are inappropriate. At every time step, the user can (1) do nothing and allow autonomous operation to continue while observing the robot's future plan sequence, or (2) take over and momentarily prescribe a different set of actions to nudge the model back on track. We host the videos and other supplementary material at https://sites.google.com/view/assistive-teleop. </p> </div> </dd> <dt>[196] arXiv:2112.05130 [pdf, other]</dt> <dd> <div > <div > Title: Multimodal Conditional Image Synthesis with Product-of-Experts GANs </div> <div > Authors: Xun Huang, <a >Arun Mallya</a>, <a >Ting-Chun Wang</a>, <a >Ming-Yu Liu</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Existing conditional image synthesis frameworks generate images based on user inputs in a single modality, such as text, segmentation, sketch, or style reference. They are often unable to leverage multimodal user inputs when available, which reduces their practicality. To address this limitation, we propose the Product-of-Experts Generative Adversarial Networks (PoE-GAN) framework, which can synthesize images conditioned on multiple input modalities or any subset of them, even the empty set. PoE-GAN consists of a product-of-experts generator and a multimodal multiscale projection discriminator. Through our carefully designed training scheme, PoE-GAN learns to synthesize images with high quality and diversity. Besides advancing the state of the art in multimodal conditional image synthesis, PoE-GAN also outperforms the best existing unimodal conditional image synthesis approaches when tested in the unimodal setting. The project website is available at https://deepimagination.github.io/PoE-GAN . </p> </div> </dd> <dt>[197] arXiv:2112.05131 [pdf, other]</dt> <dd> <div > <div > Title: Plenoxels: Radiance Fields without Neural Networks </div> <div > Authors: Alex Yu, <a >Sara Fridovich-Keil</a>, <a >Matthew Tancik</a>, <a >Qinhong Chen</a>, <a >Benjamin Recht</a>, <a >Angjoo Kanazawa</a> </div> <div > Comments: For video and code, please see <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p >We introduce Plenoxels (plenoptic voxels), a system for photorealistic view synthesis. Plenoxels represent a scene as a sparse 3D grid with spherical harmonics. This representation can be optimized from calibrated images via gradient methods and regularization without any neural components. On standard, benchmark tasks, Plenoxels are optimized two orders of magnitude faster than Neural Radiance Fields with no loss in visual quality. </p> </div> </dd> <dt>[198] arXiv:2112.05132 [pdf, other]</dt> <dd> <div > <div > Title: Spatio-temporal Relation Modeling for Few-shot Action Recognition </div> <div > Authors: Anirudh Thatipelli, <a >Sanath Narayan</a>, <a >Salman Khan</a>, <a >Rao Muhammad Anwer</a>, <a >Fahad Shahbaz Khan</a>, <a >Bernard Ghanem</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We propose a novel few-shot action recognition framework, STRM, which enhances class-specific feature discriminability while simultaneously learning higher-order temporal representations. The focus of our approach is a novel spatio-temporal enrichment module that aggregates spatial and temporal contexts with dedicated local patch-level and global frame-level feature enrichment sub-modules. Local patch-level enrichment captures the appearance-based characteristics of actions. On the other hand, global frame-level enrichment explicitly encodes the broad temporal context, thereby capturing the relevant object features over time. The resulting spatio-temporally enriched representations are then utilized to learn the relational matching between query and support action sub-sequences. We further introduce a query-class similarity classifier on the patch-level enriched features to enhance class-specific feature discriminability by reinforcing the feature learning at different stages in the proposed framework. Experiments are performed on four few-shot action recognition benchmarks: Kinetics, SSv2, HMDB51 and UCF101. Our extensive ablation study reveals the benefits of the proposed contributions. Furthermore, our approach sets a new state-of-the-art on all four benchmarks. On the challenging SSv2 benchmark, our approach achieves an absolute gain of 3.5% in classification accuracy, as compared to the best existing method in the literature. Our code and models will be publicly released. </p> </div> </dd> <dt>[199] arXiv:2112.05134 [pdf, other]</dt> <dd> <div > <div > Title: A Shared Representation for Photorealistic Driving Simulators </div> <div > Authors: Saeed Saadatnejad, <a >Siyuan Li</a>, <a >Taylor Mordan</a>, <a >Alexandre Alahi</a> </div> <div > Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >A powerful simulator highly decreases the need for real-world tests when training and evaluating autonomous vehicles. Data-driven simulators flourished with the recent advancement of conditional Generative Adversarial Networks (cGANs), providing high-fidelity images. The main challenge is synthesizing photorealistic images while following given constraints. In this work, we propose to improve the quality of generated images by rethinking the discriminator architecture. The focus is on the class of problems where images are generated given semantic inputs, such as scene segmentation maps or human body poses. We build on successful cGAN models to propose a new semantically-aware discriminator that better guides the generator. We aim to learn a shared latent representation that encodes enough information to jointly do semantic segmentation, content reconstruction, along with a coarse-to-fine grained adversarial reasoning. The achieved improvements are generic and simple enough to be applied to any architecture of conditional image synthesis. We demonstrate the strength of our method on the scene, building, and human synthesis tasks across three different datasets. The code is available at https://github.com/vita-epfl/SemDisc. </p> </div> </dd> <dt>[200] arXiv:2112.05135 [pdf, other]</dt> <dd> <div > <div > Title: PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures </div> <div > Authors: Dan Hendrycks, <a >Andy Zou</a>, <a >Mantas Mazeika</a>, <a >Leonard Tang</a>, <a >Dawn Song</a>, <a >Jacob Steinhardt</a> </div> <div > Comments: Code and models are available at <a >this https URL</a> </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p >In real-world applications of machine learning, reliable and safe systems must consider measures of performance beyond standard test set accuracy. These other goals include out-of-distribution (OOD) robustness, prediction consistency, resilience to adversaries, calibrated uncertainty estimates, and the ability to detect anomalous inputs. However, improving performance towards these goals is often a balancing act that today's methods cannot achieve without sacrificing performance on other safety axes. For instance, adversarial training improves adversarial robustness but sharply degrades other classifier performance metrics. Similarly, strong data augmentation and regularization techniques often improve OOD robustness but harm anomaly detection, raising the question of whether a Pareto improvement on all existing safety measures is possible. To meet this challenge, we design a new data augmentation strategy utilizing the natural structural complexity of pictures such as fractals, which outperforms numerous baselines, is near Pareto-optimal, and roundly improves safety measures. </p> </div> </dd> <dt>[201] arXiv:2112.05136 [pdf, other]</dt> <dd> <div > <div > Title: PTR: A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning </div> <div > Authors: Yining Hong, <a >Li Yi</a>, <a >Joshua B. Tenenbaum</a>, <a >Antonio Torralba</a>, <a >Chuang Gan</a> </div> <div > Comments: NeurIPS 2021. Project page: <a >this http URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p >A critical aspect of human visual perception is the ability to parse visual scenes into individual objects and further into object parts, forming part-whole hierarchies. Such composite structures could induce a rich set of semantic concepts and relations, thus playing an important role in the interpretation and organization of visual signals as well as for the generalization of visual perception and reasoning. However, existing visual reasoning benchmarks mostly focus on objects rather than parts. Visual reasoning based on the full part-whole hierarchy is much more challenging than object-centric reasoning due to finer-grained concepts, richer geometry relations, and more complex physics. Therefore, to better serve for part-based conceptual, relational and physical reasoning, we introduce a new large-scale diagnostic visual reasoning dataset named PTR. PTR contains around 70k RGBD synthetic images with ground truth object and part level annotations regarding semantic instance segmentation, color attributes, spatial and geometric relationships, and certain physical properties such as stability. These images are paired with 700k machine-generated questions covering various types of reasoning types, making them a good testbed for visual reasoning models. We examine several state-of-the-art visual reasoning models on this dataset and observe that they still make many surprising mistakes in situations where humans can easily infer the correct answer. We believe this dataset will open up new opportunities for part-based reasoning. </p> </div> </dd> <dt>[202] arXiv:2112.05138 [pdf, other]</dt> <dd> <div > <div > Title: Searching Parameterized AP Loss for Object Detection </div> <div > Authors: Chenxin Tao, <a >Zizhang Li</a>, <a >Xizhou Zhu</a>, <a >Gao Huang</a>, <a >Yong Liu</a>, <a >Jifeng Dai</a> </div> <div > Comments: Accepted by NeurIPS 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Loss functions play an important role in training deep-network-based object detectors. The most widely used evaluation metric for object detection is Average Precision (AP), which captures the performance of localization and classification sub-tasks simultaneously. However, due to the non-differentiable nature of the AP metric, traditional object detectors adopt separate differentiable losses for the two sub-tasks. Such a mis-alignment issue may well lead to performance degradation. To address this, existing works seek to design surrogate losses for the AP metric manually, which requires expertise and may still be sub-optimal. In this paper, we propose Parameterized AP Loss, where parameterized functions are introduced to substitute the non-differentiable components in the AP calculation. Different AP approximations are thus represented by a family of parameterized functions in a unified formula. Automatic parameter search algorithm is then employed to search for the optimal parameters. Extensive experiments on the COCO benchmark with three different object detectors (i.e., RetinaNet, Faster R-CNN, and Deformable DETR) demonstrate that the proposed Parameterized AP Loss consistently outperforms existing handcrafted losses. Code is released at https://github.com/fundamentalvision/Parameterized-AP-Loss. </p> </div> </dd> <dt>[203] arXiv:2112.05139 [pdf, other]</dt> <dd> <div > <div > Title: CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields </div> <div > Authors: Can Wang, <a >Menglei Chai</a>, <a >Mingming He</a>, <a >Dongdong Chen</a>, <a >Jing Liao</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p >We present CLIP-NeRF, a multi-modal 3D object manipulation method for neural radiance fields (NeRF). By leveraging the joint language-image embedding space of the recent Contrastive Language-Image Pre-Training (CLIP) model, we propose a unified framework that allows manipulating NeRF in a user-friendly way, using either a short text prompt or an exemplar image. Specifically, to combine the novel view synthesis capability of NeRF and the controllable manipulation ability of latent representations from generative models, we introduce a disentangled conditional NeRF architecture that allows individual control over both shape and appearance. This is achieved by performing the shape conditioning via applying a learned deformation field to the positional encoding and deferring color conditioning to the volumetric rendering stage. To bridge this disentangled latent representation to the CLIP embedding, we design two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing. The mappers are trained with a CLIP-based matching loss to ensure the manipulation accuracy. Furthermore, we propose an inverse optimization method that accurately projects an input image to the latent codes for manipulation to enable editing on real images. We evaluate our approach by extensive experiments on a variety of text prompts and exemplar images and also provide an intuitive interface for interactive editing. Our implementation is available at https://cassiepython.github.io/clipnerf/ </p> </div> </dd> <dt>[204] arXiv:2112.05140 [pdf, other]</dt> <dd> <div > <div > Title: Neural Radiance Fields for Outdoor Scene Relighting </div> <div > Authors: Viktor Rudnev, <a >Mohamed Elgharib</a>, <a >William Smith</a>, <a >Lingjie Liu</a>, <a >Vladislav Golyanik</a>, <a >Christian Theobalt</a> </div> <div > Comments: 13 pages, 8 figures, 2 tables; project web page: <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p >Photorealistic editing of outdoor scenes from photographs requires a profound understanding of the image formation process and an accurate estimation of the scene geometry, reflectance and illumination. A delicate manipulation of the lighting can then be performed while keeping the scene albedo and geometry unaltered. We present NeRF-OSR, i.e., the first approach for outdoor scene relighting based on neural radiance fields. In contrast to the prior art, our technique allows simultaneous editing of both scene illumination and camera viewpoint using only a collection of outdoor photos shot in uncontrolled settings. Moreover, it enables direct control over the scene illumination, as defined through a spherical harmonics model. It also includes a dedicated network for shadow reproduction, which is crucial for high-quality outdoor scene relighting. To evaluate the proposed method, we collect a new benchmark dataset of several outdoor sites, where each site is photographed from multiple viewpoints and at different timings. For each timing, a 360 degrees environment map is captured together with a colour-calibration chequerboard to allow accurate numerical evaluations on real data against ground truth. Comparisons against state of the art show that NeRF-OSR enables controllable lighting and viewpoint editing at higher quality and with realistic self-shadowing reproduction. Our method and the dataset will be made publicly available at https://4dqv.mpi-inf.mpg.de/NeRF-OSR/. </p> </div> </dd> <dt>[205] arXiv:2112.05141 [pdf, other]</dt> <dd> <div > <div > Title: Exploring the Equivalence of Siamese Self-Supervised Learning via A Unified Gradient Framework </div> <div > Authors: Chenxin Tao, <a >Honghui Wang</a>, <a >Xizhou Zhu</a>, <a >Jiahua Dong</a>, <a >Shiji Song</a>, <a >Gao Huang</a>, <a >Jifeng Dai</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >Self-supervised learning has shown its great potential to extract powerful visual representations without human annotations. Various works are proposed to deal with self-supervised learning from different perspectives: (1) contrastive learning methods (e.g., MoCo, SimCLR) utilize both positive and negative samples to guide the training direction; (2) asymmetric network methods (e.g., BYOL, SimSiam) get rid of negative samples via the introduction of a predictor network and the stop-gradient operation; (3) feature decorrelation methods (e.g., Barlow Twins, VICReg) instead aim to reduce the redundancy between feature dimensions. These methods appear to be quite different in the designed loss functions from various motivations. The final accuracy numbers also vary, where different networks and tricks are utilized in different works. In this work, we demonstrate that these methods can be unified into the same form. Instead of comparing their loss functions, we derive a unified formula through gradient analysis. Furthermore, we conduct fair and detailed experiments to compare their performances. It turns out that there is little gap between these methods, and the use of momentum encoder is the key factor to boost performance. From this unified framework, we propose UniGrad, a simple but effective gradient form for self-supervised learning. It does not require a memory bank or a predictor network, but can still achieve state-of-the-art performance and easily adopt other training strategies. Extensive experiments on linear evaluation and many downstream tasks also show its effectiveness. Code shall be released. </p> </div> </dd> <dt>[206] arXiv:2112.05142 [pdf, other]</dt> <dd> <div > <div > Title: HairCLIP: Design Your Hair by Text and Reference Image </div> <div > Authors: Tianyi Wei, <a >Dongdong Chen</a>, <a >Wenbo Zhou</a>, <a >Jing Liao</a>, <a >Zhentao Tan</a>, <a >Lu Yuan</a>, <a >Weiming Zhang</a>, <a >Nenghai Yu</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p >Hair editing is an interesting and challenging problem in computer vision and graphics. Many existing methods require well-drawn sketches or masks as conditional inputs for editing, however these interactions are neither straightforward nor efficient. In order to free users from the tedious interaction process, this paper proposes a new hair editing interaction mode, which enables manipulating hair attributes individually or jointly based on the texts or reference images provided by users. For this purpose, we encode the image and text conditions in a shared embedding space and propose a unified hair editing framework by leveraging the powerful image text representation capability of the Contrastive Language-Image Pre-Training (CLIP) model. With the carefully designed network structures and loss functions, our framework can perform high-quality hair editing in a disentangled manner. Extensive experiments demonstrate the superiority of our approach in terms of manipulation accuracy, visual realism of editing results, and irrelevant attribute preservation. Project repo is https://github.com/wty-ustc/HairCLIP. </p> </div> </dd> <dt>[207] arXiv:2112.05143 [pdf, other]</dt> <dd> <div > <div > Title: GAN-Supervised Dense Visual Alignment </div> <div > Authors: William Peebles, <a >Jun-Yan Zhu</a>, <a >Richard Zhang</a>, <a >Antonio Torralba</a>, <a >Alexei Efros</a>, <a >Eli Shechtman</a> </div> <div > Comments: Code available at <a >this https URL</a> . Project page and videos available at <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p >We propose GAN-Supervised Learning, a framework for learning discriminative models and their GAN-generated training data jointly end-to-end. We apply our framework to the dense visual alignment problem. Inspired by the classic Congealing method, our GANgealing algorithm trains a Spatial Transformer to map random samples from a GAN trained on unaligned data to a common, jointly-learned target mode. We show results on eight datasets, all of which demonstrate our method successfully aligns complex data and discovers dense correspondences. GANgealing significantly outperforms past self-supervised correspondence algorithms and performs on-par with (and sometimes exceeds) state-of-the-art supervised correspondence algorithms on several datasets -- without making use of any correspondence supervision or data augmentation and despite being trained exclusively on GAN-generated data. For precise correspondence, we improve upon state-of-the-art supervised methods by as much as $3imes$. We show applications of our method for augmented reality, image editing and automated pre-processing of image datasets for downstream GAN training. </p> </div> </dd> </dl> <h3>Cross-lists for Fri, 10 Dec 21</h3> <dl> <dt>[208] arXiv:2112.04489 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning </div> <div > Authors: Alessa Hering, <a >Lasse Hansen</a>, <a >Tony C. W. Mok</a>, <a >Albert C. S. Chung</a>, <a >Hanna Siebert</a>, <a >Stephanie Häger</a>, <a >Annkristin Lange</a>, <a >Sven Kuckertz</a>, <a >Stefan Heldmann</a>, <a >Wei Shao</a>, <a >Sulaiman Vesal</a>, <a >Mirabela Rusu</a>, <a >Geoffrey Sonn</a>, <a >Théo Estienne</a>, <a >Maria Vakalopoulou</a>, <a >Luyi Han</a>, <a >Yunzhi Huang</a>, <a >Mikael Brudfors</a>, <a >Yaël Balbastre</a>, <a >Samuel Joutard</a>, <a >Marc Modat</a>, <a >Gal Lifshitz</a>, <a >Dan Raviv</a>, <a >Jinxin Lv</a>, <a >Qiang Li</a>, <a >Vincent Jaouen</a>, <a >Dimitris Visvikis</a>, <a >Constance Fourcade</a>, <a >Mathieu Rubeaux</a>, <a >Wentao Pan</a>, <a >Zhe Xu</a>, <a >Bailiang Jian</a>, <a >Francesca De Benetti</a>, <a >Marek Wodzinski</a>, <a >Niklas Gunnarsson</a>, <a >Huaqi Qiu</a>, <a >Zeju Li</a>, <a >Christoph Großbröhmer</a>, <a >Andrew Hoopes</a>, <a >Ingerid Reinertsen</a>, <a >Yiming Xiao</a>, <a >Bennett Landman</a>, <a >Yuankai Huo</a>, <a >Keelin Murphy</a>, <a >Bram van Ginneken</a>, <a >Adrian Dalca</a>, <a >Mattias P. Heinrich</a> </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >To date few studies have comprehensively compared medical image registration approaches on a wide-range of complementary clinically relevant tasks. This limits the adoption of advances in research into practice and prevents fair benchmarks across competing approaches. Many newer learning-based methods have been explored within the last five years, but the question which optimisation, architectural or metric strategy is ideally suited remains open. Learn2Reg covers a wide range of anatomies: brain, abdomen and thorax, modalities: ultrasound, CT, MRI, populations: intra- and inter-patient and levels of supervision. We established a lower entry barrier for training and validation of 3D registration, which helped us compile results of over 65 individual method submissions from more than 20 unique teams. Our complementary set of metrics, including robustness, accuracy, plausibility and speed enables unique insight into the current-state-of-the-art of medical image registration. Further analyses into transferability, bias and importance of supervision question the superiority of primarily deep learning based approaches and open exiting new research directions into hybrid methods that leverage GPU-accelerated conventional optimisation. </p> </div> </dd> <dt>[209] arXiv:2112.04490 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms </div> <div > Authors: Huyen T. X. Nguyen, <a >Sam B. Tran</a>, <a >Dung B. Nguyen</a>, <a >Hieu H. Pham</a>, <a >Ha Q. Nguyen</a> </div> <div > Comments: Under review by IEEE EMBC </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Advanced deep learning (DL) algorithms may predict the patient's risk of developing breast cancer based on the Breast Imaging Reporting and Data System (BI-RADS) and density standards. Recent studies have suggested that the combination of multi-view analysis improved the overall breast exam classification. In this paper, we propose a novel multi-view DL approach for BI-RADS and density assessment of mammograms. The proposed approach first deploys deep convolutional networks for feature extraction on each view separately. The extracted features are then stacked and fed into a Light Gradient Boosting Machine (LightGBM) classifier to predict BI-RADS and density scores. We conduct extensive experiments on both the internal mammography dataset and the public dataset Digital Database for Screening Mammography (DDSM). The experimental results demonstrate that the proposed approach outperforms the single-view classification approach on two benchmark datasets by huge margins (5% on the internal dataset and 10% on the DDSM dataset). These results highlight the vital role of combining multi-view information to improve the performance of breast cancer risk prediction. </p> </div> </dd> <dt>[210] arXiv:2112.04491 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Revisiting Global Statistics Aggregation for Improving Image Restoration </div> <div > Authors: Xiaojie Chu, <a >Liangyu Chen</a>, <a >Chengpeng Chen</a>, <a >Xin Lu</a> </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Global spatial statistics, which are aggregated along entire spatial dimensions, are widely used in top-performance image restorers. For example, mean, variance in Instance Normalization (IN) which is adopted by HINet, and global average pooling (i.e. mean) in Squeeze and Excitation (SE) which is applied to MPRNet. This paper first shows that statistics aggregated on the patches-based/entire-image-based feature in the training/testing phase respectively may distribute very differently and lead to performance degradation in image restorers. It has been widely overlooked by previous works. To solve this issue, we propose a simple approach, Test-time Local Statistics Converter (TLSC), that replaces the region of statistics aggregation operation from global to local, only in the test time. Without retraining or finetuning, our approach significantly improves the image restorer's performance. In particular, by extending SE with TLSC to the state-of-the-art models, MPRNet boost by 0.65 dB in PSNR on GoPro dataset, achieves 33.31 dB, exceeds the previous best result 0.6 dB. In addition, we simply apply TLSC to the high-level vision task, i.e. semantic segmentation, and achieves competitive results. Extensive quantity and quality experiments are conducted to demonstrate TLSC solves the issue with marginal costs while significant gain. The code is available at https://github.com/megvii-research/tlsc. </p> </div> </dd> <dt>[211] arXiv:2112.04493 (cross-list from eess.IV) [pdf]</dt> <dd> <div > <div > Title: Binary Change Guided Hyperspectral Multiclass Change Detection </div> <div > Authors: Meiqi Hu, <a >Chen Wu</a>, <a >Bo Du</a>, <a >Liangpei Zhang</a> </div> <div > Comments: 14 pages,17 figures </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Characterized by tremendous spectral information, hyperspectral image is able to detect subtle changes and discriminate various change classes for change detection. The recent research works dominated by hyperspectral binary change detection, however, cannot provide fine change classes information. And most methods incorporating spectral unmixing for hyperspectral multiclass change detection (HMCD), yet suffer from the neglection of temporal correlation and error accumulation. In this study, we proposed an unsupervised Binary Change Guided hyperspectral multiclass change detection Network (BCG-Net) for HMCD, which aims at boosting the multiclass change detection result and unmixing result with the mature binary change detection approaches. In BCG-Net, a novel partial-siamese united-unmixing module is designed for multi-temporal spectral unmixing, and a groundbreaking temporal correlation constraint directed by the pseudo-labels of binary change detection result is developed to guide the unmixing process from the perspective of change detection, encouraging the abundance of the unchanged pixels more coherent and that of the changed pixels more accurate. Moreover, an innovative binary change detection rule is put forward to deal with the problem that traditional rule is susceptible to numerical values. The iterative optimization of the spectral unmixing process and the change detection process is proposed to eliminate the accumulated errors and bias from unmixing result to change detection result. The experimental results demonstrate that our proposed BCG-Net could achieve comparative or even outstanding performance of multiclass change detection among the state-of-the-art approaches and gain better spectral unmixing results at the same time. </p> </div> </dd> <dt>[212] arXiv:2112.04495 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Dynamic multi feature-class Gaussian process models </div> <div > Authors: Jean-Rassaire Fouefack, <a >Bhushan Borotikar</a>, <a >Marcel Lüthi</a>, <a >Tania S. Douglas</a>, <a >Valérie Burdin</a>, <a >Tinashe E.M. Mutsvangwa</a> </div> <div > Comments: 16 </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >In model-based medical image analysis, three features of interest are the shape of structures of interest, their relative pose, and image intensity profiles representative of some physical property. Often, these are modelled separately through statistical models by decomposing the object's features into a set of basis functions through principal geodesic analysis or principal component analysis. This study presents a statistical modelling method for automatic learning of shape, pose and intensity features in medical images which we call the Dynamic multi feature-class Gaussian process models (DMFC-GPM). A DMFC-GPM is a Gaussian process (GP)-based model with a shared latent space that encodes linear and non-linear variation. Our method is defined in a continuous domain with a principled way to represent shape, pose and intensity feature classes in a linear space, based on deformation fields. A deformation field-based metric is adapted in the method for modelling shape and intensity feature variation as well as for comparing rigid transformations (pose). Moreover, DMFC-GPMs inherit properties intrinsic to GPs including marginalisation and regression. Furthermore, they allow for adding additional pose feature variability on top of those obtained from the image acquisition process; what we term as permutation modelling. For image analysis tasks using DMFC-GPMs, we adapt Metropolis-Hastings algorithms making the prediction of features fully probabilistic. We validate the method using controlled synthetic data and we perform experiments on bone structures from CT images of the shoulder to illustrate the efficacy of the model for pose and shape feature prediction. The model performance results suggest that this new modelling paradigm is robust, accurate, accessible, and has potential applications including the management of musculoskeletal disorders and clinical decision making </p> </div> </dd> <dt>[213] arXiv:2112.04499 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Multiscale Softmax Cross Entropy for Fovea Localization on Color Fundus Photography </div> <div > Authors: Yuli Wu, <a >Peter Walter</a>, <a >Dorit Merhof</a> </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Fovea localization is one of the most popular tasks in ophthalmic medical image analysis, where the coordinates of the center point of the macula lutea, i.e. fovea centralis, should be calculated based on color fundus images. In this work, we treat the localization problem as a classification task, where the coordinates of the x- and y-axis are considered as the target classes. Moreover, the combination of the softmax activation function and the cross entropy loss function is modified to its multiscale variation to encourage the predicted coordinates to be located closely to the ground-truths. Based on color fundus photography images, we empirically show that the proposed multiscale softmax cross entropy yields better performance than the vanilla version and than the mean squared error loss with sigmoid activation, which provides a novel approach for coordinate regression. </p> </div> </dd> <dt>[214] arXiv:2112.04527 (cross-list from hep-th) [pdf, ps, other]</dt> <dd> <div > <div > Title: Building Quantum Field Theories Out of Neurons </div> <div > Authors: James Halverson </div> <div > Subjects: High Energy Physics - Theory (hep-th); Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph) </div> <p >An approach to field theory is studied in which fields are comprised of $N$ constituent random neurons. Gaussian theories arise in the infinite-$N$ limit when neurons are independently distributed, via the Central Limit Theorem, while interactions arise due to finite-$N$ effects or non-independently distributed neurons. Euclidean-invariant ensembles of neurons are engineered, with tunable two-point function, yielding families of Euclidean-invariant field theories. Some Gaussian, Euclidean invariant theories are reflection positive, which allows for analytic continuation to a Lorentz-invariant quantum field theory. Examples are presented that yield dual theories at infinite-$N$, but have different symmetries at finite-$N$. Landscapes of classical field configurations are determined by local maxima of parameter distributions. Predictions arise from mixed field-neuron correlators. Near-Gaussianity is exhibited at large-$N$, potentially explaining a feature of field theories in Nature. </p> </div> </dd> <dt>[215] arXiv:2112.04553 (cross-list from q-fin.MF) [pdf, other]</dt> <dd> <div > <div > Title: Recent Advances in Reinforcement Learning in Finance </div> <div > Authors: Ben Hambly, <a >Renyuan Xu</a>, <a >Huining Yang</a> </div> <div > Comments: 60 pages, 1 figure </div> <div > Subjects: Mathematical Finance (q-fin.MF); Machine Learning (cs.LG); Computational Finance (q-fin.CP); Trading and Market Microstructure (q-fin.TR) </div> <p >The rapid changes in the finance industry due to the increasing amount of data have revolutionized the techniques on data processing and data analysis and brought new theoretical and computational challenges. In contrast to classical stochastic control theory and other analytical approaches for solving financial decision-making problems that heavily reply on model assumptions, new developments from reinforcement learning (RL) are able to make full use of the large amount of financial data with fewer model assumptions and to improve decisions in complex financial environments. This survey paper aims to review the recent developments and use of RL approaches in finance. We give an introduction to Markov decision processes, which is the setting for many of the commonly used RL approaches. Various algorithms are then introduced with a focus on value and policy based methods that do not require any model assumptions. Connections are made with neural networks to extend the framework to encompass deep RL algorithms. Our survey concludes by discussing the application of these RL algorithms in a variety of decision-making problems in finance, including optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising. </p> </div> </dd> <dt>[216] arXiv:2112.04586 (cross-list from quant-ph) [pdf, other]</dt> <dd> <div > <div > Title: Monolithic Integration of Quantum Resonant Tunneling Gate on a 22nm FD-SOI CMOS Process </div> <div > Authors: Imran Bashir, <a >Dirk Leipold</a>, <a >Elena Blokhina</a>, <a >Mike Asker</a>, <a >David Redmond</a>, <a >Ali Esmailiyan</a>, <a >Panagiotis Giounanlis</a>, <a >Hans Haenlein</a>, <a >Xuton Wu</a>, <a >Andrii Sokolov</a>, <a >Dennis Andrade-Miceli</a>, <a >Robert Bogdan Staszewski</a> </div> <div > Subjects: Quantum Physics (quant-ph); Systems and Control (eess.SY) </div> <p >The proliferation of quantum computing technologies has fueled the race to build a practical quantum computer. The spectrum of the innovation is wide and encompasses many aspects of this technology, such as the qubit, control and detection mechanism, cryogenic electronics, and system integration. A few of those emerging technologies are poised for successful monolithic integration of cryogenic electronics with the quantum structure where the qubits reside. In this work, we present a fully integrated Quantum Processor Unit in which the quantum core is co-located with control and detection circuits on the same die in a commercial 22-nm FD-SOI process from GlobalFoundries. The system described in this work comprises a two dimensional (2D) 240 qubits array integrated with 8 detectors and 32 injectors operating at 3K and inside a two-stage Gifford-McMahon cryo-cooler. The power consumption of each detector and injector is 1mW and 0.27mW, respectively. The control sequence is programmed into an on-chip pattern generator that acts as a command and control block for all hardware in the Quantum Processor Unit. Using the aforementioned apparatus, we performed a quantum resonant tunneling experiment on two qubits inside the 2D qubit array. With supporting lab measurements, we demonstrate the feasibility of the proposed architecture in scaling-up the existing quantum core to thousands of qubits. </p> </div> </dd> <dt>[217] arXiv:2112.04599 (cross-list from math.CT) [pdf, ps, other]</dt> <dd> <div > <div > Title: Quotients of span categories that are allegories and the representation of regular categories </div> <div > Authors: S. Naser Hosseini, <a >Amir R. Shir Ali Nasab</a>, <a >Walter Tholen</a>, <a >Leila Yeganeh</a> </div> <div > Subjects: Category Theory (math.CT); Logic in Computer Science (cs.LO) </div> <p >We consider the ordinary category Span(C) of (isomorphism classes of) spans of morphisms in a category C with finite limits as needed, composed horizontally via pullback, and give a general criterion for a quotient of Span(C) to be an allegory. In particular, when C carries a pullback-stable, but not necessarily proper, (E, M)-factorization system, we establish a quotient category Span_E(C) that is isomorphic to the category Rel_M(C) of M-relations in C, and show that it is a (unitary and tabular) allegory precisely when M is a class of monomorphisms in C. Without this restriction, one can still find a least pullback-stable and composition-closed class E. containing E such that Span_E.(C) is a unitary and tabular allegory. In this way one obtains a left adjoint to the 2-functor that assigns to every unitary and tabular allegory the regular category of its Lawverian maps. With the Freyd-Scedrov Representation Theorem for regular categories, we conclude that every finitely complete category with a stable factorization system has a reflection into the huge 2-category of all regular categories. </p> </div> </dd> <dt>[218] arXiv:2112.04624 (cross-list from q-bio.QM) [pdf, other]</dt> <dd> <div > <div > Title: Deep Molecular Representation Learning via Fusing Physical and Chemical Information </div> <div > Authors: Shuwen Yang, <a >Ziyao Li</a>, <a >Guojie Song</a>, <a >Lingsheng Cai</a> </div> <div > Comments: In NeurIPS-2021, 18 pages, 5 figures, appendix included </div> <div > Subjects: Quantitative Methods (q-bio.QM); Machine Learning (cs.LG) </div> <p >Molecular representation learning is the first yet vital step in combining deep learning and molecular science. To push the boundaries of molecular representation learning, we present PhysChem, a novel neural architecture that learns molecular representations via fusing physical and chemical information of molecules. PhysChem is composed of a physicist network (PhysNet) and a chemist network (ChemNet). PhysNet is a neural physical engine that learns molecular conformations through simulating molecular dynamics with parameterized forces; ChemNet implements geometry-aware deep message-passing to learn chemical / biomedical properties of molecules. Two networks specialize in their own tasks and cooperate by providing expertise to each other. By fusing physical and chemical information, PhysChem achieved state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark. The effectiveness of PhysChem was further corroborated on cutting-edge datasets of SARS-CoV-2. </p> </div> </dd> <dt>[219] arXiv:2112.04653 (cross-list from eess.IV) [pdf, ps, other]</dt> <dd> <div > <div > Title: Extending nn-UNet for brain tumor segmentation </div> <div > Authors: Huan Minh Luu, <a >Sung-Hong Park</a> </div> <div > Comments: 12 pages, 4 figures, BraTS competition paper </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Brain tumor segmentation is essential for the diagnosis and prognosis of patients with gliomas. The brain tumor segmentation challenge has continued to provide a great source of data to develop automatic algorithms to perform the task. This paper describes our contribution to the 2021 competition. We developed our methods based on nn-UNet, the winning entry of last year competition. We experimented with several modifications, including using a larger network, replacing batch normalization with group normalization, and utilizing axial attention in the decoder. Internal 5-fold cross validation as well as online evaluation from the organizers showed the effectiveness of our approach, with minor improvement in quantitative metrics when compared to the baseline. The proposed models won first place in the final ranking on unseen test data. The codes, pretrained weights, and docker image for the winning submission are publicly available at https://github.com/rixez/Brats21_KAIST_MRI_Lab </p> </div> </dd> <dt>[220] arXiv:2112.04677 (cross-list from stat.ML) [pdf, other]</dt> <dd> <div > <div > Title: A Note on Comparison of F-measures </div> <div > Authors: Wei Ju, <a >Wenxin Jiang</a> </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p >We comment on a recent TKDE paper "Linear Approximation of F-measure for the Performance Evaluation of Classification Algorithms on Imbalanced Data Sets", and make two improvements related to comparison of F-measures for two prediction rules. </p> </div> </dd> <dt>[221] arXiv:2112.04721 (cross-list from eess.IV) [pdf]</dt> <dd> <div > <div > Title: One-dimensional Deep Low-rank and Sparse Network for Accelerated MRI </div> <div > Authors: Zi Wang, <a >Chen Qian</a>, <a >Di Guo</a>, <a >Hongwei Sun</a>, <a >Rushuai Li</a>, <a >Bo Zhao</a>, <a >Xiaobo Qu</a> </div> <div > Comments: 16 pages </div> <div > Subjects: Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph) </div> <p >Deep learning has shown astonishing performance in accelerated magnetic resonance imaging (MRI). Most state-of-the-art deep learning reconstructions adopt the powerful convolutional neural network and perform 2D convolution since many magnetic resonance images or their corresponding k-space are in 2D. In this work, we present a new approach that explores the 1D convolution, making the deep network much easier to be trained and generalized. We further integrate the 1D convolution into the proposed deep network, named as One-dimensional Deep Low-rank and Sparse network (ODLS), which unrolls the iteration procedure of a low-rank and sparse reconstruction model. Extensive results on in vivo knee and brain datasets demonstrate that, the proposed ODLS is very suitable for the case of limited training subjects and provides improved reconstruction performance than state-of-the-art methods both visually and quantitatively. Additionally, ODLS also shows nice robustness to different undersampling scenarios and some mismatches between the training and test data. In summary, our work demonstrates that the 1D deep learning scheme is memory-efficient and robust in fast MRI. </p> </div> </dd> <dt>[222] arXiv:2112.04755 (cross-list from q-fin.PM) [pdf, other]</dt> <dd> <div > <div > Title: High-Dimensional Stock Portfolio Trading with Deep Reinforcement Learning </div> <div > Authors: Uta Pigorsch, <a >Sebastian Schäfer</a> </div> <div > Comments: 14 pages, 5 figures, 2 tables </div> <div > Subjects: Portfolio Management (q-fin.PM); Machine Learning (cs.LG); Computational Finance (q-fin.CP) </div> <p >This paper proposes a Deep Reinforcement Learning algorithm for financial portfolio trading based on Deep Q-learning. The algorithm is capable of trading high-dimensional portfolios from cross-sectional datasets of any size which may include data gaps and non-unique history lengths in the assets. We sequentially set up environments by sampling one asset for each environment while rewarding investments with the resulting asset's return and cash reservation with the average return of the set of assets. This enforces the agent to strategically assign capital to assets that it predicts to perform above-average. We apply our methodology in an out-of-sample analysis to 48 US stock portfolio setups, varying in the number of stocks from ten up to 500 stocks, in the selection criteria and in the level of transaction costs. The algorithm on average outperforms all considered passive and active benchmark investment strategies by a large margin using only one hyperparameter setup for all portfolios. </p> </div> </dd> <dt>[223] arXiv:2112.04768 (cross-list from quant-ph) [pdf, other]</dt> <dd> <div > <div > Title: Quantum Link Prediction in Complex Networks </div> <div > Authors: João P. Moutinho, <a >André Melo</a>, <a >Bruno Coutinho</a>, <a >István A. Kovács</a>, <a >Yasser Omar</a> </div> <div > Comments: Keywords: Complex Networks, Quantum Algorithms, Link Prediction, Social Networks, Protein-Protein Interaction Networks </div> <div > Subjects: Quantum Physics (quant-ph); Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI); Biological Physics (physics.bio-ph) </div> <p >Predicting new links in physical, biological, social, or technological networks has a significant scientific and societal impact. Network-based link prediction methods utilize topological patterns in a network to infer new or unobserved links. Here, we propose a quantum algorithm for link prediction, QLP, which uses quantum walks to infer unknown links based on even and odd length paths. By sampling new links from quantum measurements, QLP avoids the need to explicitly calculate all pairwise scores in the network. We study the complexity of QLP and discuss in which cases one may achieve a polynomial speedup over classical link prediction methods. Furthermore, tests with real-world datasets show that QLP is at least as precise as state-of-the-art classical link prediction methods, both in cross-validation tests and in the prediction of experimentally verified protein-protein interactions. </p> </div> </dd> <dt>[224] arXiv:2112.04779 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd> <div > <div > Title: Regularized Modal Regression on Markov-dependent Observations: A Theoretical Assessment </div> <div > Authors: Tielang Gong, <a >Yuxin Dong</a>, <a >Hong Chen</a>, <a >Bo Dong</a>, <a >Wei Feng</a>, <a >Chen Li</a> </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p >Modal regression, a widely used regression protocol, has been extensively investigated in statistical and machine learning communities due to its robustness to outliers and heavy-tailed noises. Understanding modal regression's theoretical behavior can be fundamental in learning theory. Despite significant progress in characterizing its statistical property, the majority of the results are based on the assumption that samples are independent and identical distributed (i.i.d.), which is too restrictive for real-world applications. This paper concerns the statistical property of regularized modal regression (RMR) within an important dependence structure - Markov dependent. Specifically, we establish the upper bound for RMR estimator under moderate conditions and give an explicit learning rate. Our results show that the Markov dependence impacts on the generalization error in the way that sample size would be discounted by a multiplicative factor depending on the spectral gap of underlying Markov chain. This result shed a new light on characterizing the theoretical underpinning for robust regression. </p> </div> </dd> <dt>[225] arXiv:2112.04814 (cross-list from q-bio.BM) [pdf, other]</dt> <dd> <div > <div > Title: Multimodal Pre-Training Model for Sequence-based Prediction of Protein-Protein Interaction </div> <div > Authors: Yang Xue, <a >Zijing Liu</a>, <a >Xiaomin Fang</a>, <a >Fan Wang</a> </div> <div > Comments: MLCB 2021 Spotlight </div> <div > Subjects: Biomolecules (q-bio.BM); Machine Learning (cs.LG) </div> <p >Protein-protein interactions (PPIs) are essentials for many biological processes where two or more proteins physically bind together to achieve their functions. Modeling PPIs is useful for many biomedical applications, such as vaccine design, antibody therapeutics, and peptide drug discovery. Pre-training a protein model to learn effective representation is critical for PPIs. Most pre-training models for PPIs are sequence-based, which naively adopt the language models used in natural language processing to amino acid sequences. More advanced works utilize the structure-aware pre-training technique, taking advantage of the contact maps of known protein structures. However, neither sequences nor contact maps can fully characterize structures and functions of the proteins, which are closely related to the PPI problem. Inspired by this insight, we propose a multimodal protein pre-training model with three modalities: sequence, structure, and function (S2F). Notably, instead of using contact maps to learn the amino acid-level rigid structures, we encode the structure feature with the topology complex of point clouds of heavy atoms. It allows our model to learn structural information about not only the backbones but also the side chains. Moreover, our model incorporates the knowledge from the functional description of proteins extracted from literature or manual annotations. Our experiments show that the S2F learns protein embeddings that achieve good performances on a variety of PPIs tasks, including cross-species PPI, antibody-antigen affinity prediction, antibody neutralization prediction for SARS-CoV-2, and mutation-driven binding affinity change prediction. </p> </div> </dd> <dt>[226] arXiv:2112.04828 (cross-list from stat.ML) [pdf, other]</dt> <dd> <div > <div > Title: Evaluation of survival distribution predictions with discrimination measures </div> <div > Authors: Raphael Sonabend, <a >Andreas Bender</a>, <a >Sebastian Vollmer</a> </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME) </div> <p >In this paper we consider how to evaluate survival distribution predictions with measures of discrimination. This is a non-trivial problem as discrimination measures are the most commonly used in survival analysis and yet there is no clear method to derive a risk prediction from a distribution prediction. We survey methods proposed in literature and software and consider their respective advantages and disadvantages. Whilst distributions are frequently evaluated by discrimination measures, we find that the method for doing so is rarely described in the literature and often leads to unfair comparisons. We find that the most robust method of reducing a distribution to a risk is to sum over the predicted cumulative hazard. We recommend that machine learning survival analysis software implements clear transformations between distribution and risk predictions in order to allow more transparent and accessible model evaluation. </p> </div> </dd> <dt>[227] arXiv:2112.04841 (cross-list from eess.AS) [pdf, other]</dt> <dd> <div > <div > Title: On The Effect Of Coding Artifacts On Acoustic Scene Classification </div> <div > Authors: Nagashree K. S. Rao, <a >Nils Peters</a> </div> <div > Comments: paper presented at the 2021 Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE) </div> <div > Subjects: Audio and Speech Processing (eess.AS); Multimedia (cs.MM); Sound (cs.SD); Signal Processing (eess.SP) </div> <p >Previous DCASE challenges contributed to an increase in the performance of acoustic scene classification systems. State-of-the-art classifiers demand significant processing capabilities and memory which is challenging for resource-constrained mobile or IoT edge devices. Thus, it is more likely to deploy these models on more powerful hardware and classify audio recordings previously uploaded (or streamed) from low-power edge devices. In such scenario, the edge device may apply perceptual audio coding to reduce the transmission data rate. This paper explores the effect of perceptual audio coding on the classification performance using a DCASE 2020 challenge contribution [1]. We found that classification accuracy can degrade by up to 57% compared to classifying original (uncompressed) audio. We further demonstrate how lossy audio compression techniques during model training can improve classification accuracy of compressed audio signals even for audio codecs and codec bitrates not included in the training process. </p> </div> </dd> <dt>[228] arXiv:2112.04863 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: 3D Medical Point Transformer: Introducing Convolution to Attention Networks for Medical Point Cloud Analysis </div> <div > Authors: Jianhui Yu, <a >Chaoyi Zhang</a>, <a >Heng Wang</a>, <a >Dingxin Zhang</a>, <a >Yang Song</a>, <a >Tiange Xiang</a>, <a >Dongnan Liu</a>, <a >Weidong Cai</a> </div> <div > Comments: technical report </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >General point clouds have been increasingly investigated for different tasks, and recently Transformer-based networks are proposed for point cloud analysis. However, there are barely related works for medical point clouds, which are important for disease detection and treatment. In this work, we propose an attention-based model specifically for medical point clouds, namely 3D medical point Transformer (3DMedPT), to examine the complex biological structures. By augmenting contextual information and summarizing local responses at query, our attention module can capture both local context and global content feature interactions. However, the insufficient training samples of medical data may lead to poor feature learning, so we apply position embeddings to learn accurate local geometry and Multi-Graph Reasoning (MGR) to examine global knowledge propagation over channel graphs to enrich feature representations. Experiments conducted on IntrA dataset proves the superiority of 3DMedPT, where we achieve the best classification and segmentation results. Furthermore, the promising generalization ability of our method is validated on general 3D point cloud benchmarks: ModelNet40 and ShapeNetPart. Code will be released soon. </p> </div> </dd> <dt>[229] arXiv:2112.04882 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Evaluating saliency methods on artificial data with different background types </div> <div > Authors: Céline Budding, <a >Fabian Eitel</a>, <a >Kerstin Ritter</a>, <a >Stefan Haufe</a> </div> <div > Comments: 6 pages, 2 figures. Presented at Medical Imaging meets NeurIPS 2021 (poster presentation) </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p >Over the last years, many 'explainable artificial intelligence' (xAI) approaches have been developed, but these have not always been objectively evaluated. To evaluate the quality of heatmaps generated by various saliency methods, we developed a framework to generate artificial data with synthetic lesions and a known ground truth map. Using this framework, we evaluated two data sets with different backgrounds, Perlin noise and 2D brain MRI slices, and found that the heatmaps vary strongly between saliency methods and backgrounds. We strongly encourage further evaluation of saliency maps and xAI methods using this framework before applying these in clinical or other safety-critical settings. </p> </div> </dd> <dt>[230] arXiv:2112.04887 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd> <div > <div > Title: Forecast Evaluation in Large Cross-Sections of Realized Volatility </div> <div > Authors: Christis Katsouris </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p >In this paper, we consider the forecast evaluation of realized volatility measures under cross-section dependence using equal predictive accuracy testing procedures. We evaluate the predictive accuracy of the model based on the augmented cross-section when forecasting Realized Volatility. Under the null hypothesis of equal predictive accuracy the benchmark model employed is a standard HAR model while under the alternative of non-equal predictive accuracy the forecast model is an augmented HAR model estimated via the LASSO shrinkage. We study the sensitivity of forecasts to the model specification by incorporating a measurement error correction as well as cross-sectional jump component measures. The out-of-sample forecast evaluation of the models is assessed with numerical implementations. </p> </div> </dd> <dt>[231] arXiv:2112.04894 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Semi-Supervised Medical Image Segmentation via Cross Teaching between CNN and Transformer </div> <div > Authors: Xiangde Luo, <a >Minhao Hu</a>, <a >Tao Song</a>, <a >Guotai Wang</a>, <a >Shaoting Zhang</a> </div> <div > Comments: A technical report about SSL4MIS:<a >this https URL</a> </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Recently, deep learning with Convolutional Neural Networks (CNNs) and Transformers has shown encouraging results in fully supervised medical image segmentation. However, it is still challenging for them to achieve good performance with limited annotations for training. In this work, we present a very simple yet efficient framework for semi-supervised medical image segmentation by introducing the cross teaching between CNN and Transformer. Specifically, we simplify the classical deep co-training from consistency regularization to cross teaching, where the prediction of a network is used as the pseudo label to supervise the other network directly end-to-end. Considering the difference in learning paradigm between CNN and Transformer, we introduce the Cross Teaching between CNN and Transformer rather than just using CNNs. Experiments on a public benchmark show that our method outperforms eight existing semi-supervised learning methods just with a simpler framework. Notably, this work may be the first attempt to combine CNN and transformer for semi-supervised medical image segmentation and achieve promising results on a public benchmark. The code will be released at: https://github.com/HiLab-git/SSL4MIS. </p> </div> </dd> <dt>[232] arXiv:2112.04906 (cross-list from math.OC) [pdf, ps, other]</dt> <dd> <div > <div > Title: Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring </div> <div > Authors: Yunzhuang Shen, <a >Yuan Sun</a>, <a >Xiaodong Li</a>, <a >Andrew Eberhard</a>, <a >Andreas Ernst</a> </div> <div > Comments: Machine learning for column generation and branch-and-price; accepted to AAAI 2022 </div> <div > Subjects: Optimization and Control (math.OC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >Column Generation (CG) is an effective method for solving large-scale optimization problems. CG starts by solving a sub-problem with a subset of columns (i.e., variables) and gradually includes new columns that can improve the solution of the current subproblem. The new columns are generated as needed by repeatedly solving a pricing problem, which is often NP-hard and is a bottleneck of the CG approach. To tackle this, we propose a Machine-Learning-based Pricing Heuristic (MLPH)that can generate many high-quality columns efficiently. In each iteration of CG, our MLPH leverages an ML model to predict the optimal solution of the pricing problem, which is then used to guide a sampling method to efficiently generate multiple high-quality columns. Using the graph coloring problem, we empirically show that MLPH significantly enhancesCG as compared to six state-of-the-art methods, and the improvement in CG can lead to substantially better performance of the branch-and-price exact method. </p> </div> </dd> <dt>[233] arXiv:2112.04914 (cross-list from eess.AS) [pdf, other]</dt> <dd> <div > <div > Title: End-to-end Alexa Device Arbitration </div> <div > Authors: Jarred Barber, <a >Yifeng Fan</a>, <a >Tao Zhang</a> </div> <div > Comments: Submitted to ICASSP 2022 </div> <div > Subjects: Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD) </div> <p >We introduce a variant of the speaker localization problem, which we call device arbitration. In the device arbitration problem, a user utters a keyword that is detected by multiple distributed microphone arrays (smart home devices), and we want to determine which device was closest to the user. Rather than solving the full localization problem, we propose an end-to-end machine learning system. This system learns a feature embedding that is computed independently on each device. The embeddings from each device are then aggregated together to produce the final arbitration decision. We use a large-scale room simulation to generate training and evaluation data, and compare our system against a signal processing baseline. </p> </div> </dd> <dt>[234] arXiv:2112.04922 (cross-list from math.OC) [pdf, ps, other]</dt> <dd> <div > <div > Title: A More Stable Accelerated Gradient Method Inspired by Continuous-Time Perspective </div> <div > Authors: Yasong Feng, <a >Weiguo Gao</a> </div> <div > Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computation (stat.CO) </div> <p >Nesterov's accelerated gradient method (NAG) is widely used in problems with machine learning background including deep learning, and is corresponding to a continuous-time differential equation. From this connection, the property of the differential equation and its numerical approximation can be investigated to improve the accelerated gradient method. In this work we present a new improvement of NAG in terms of stability inspired by numerical analysis. We give the precise order of NAG as a numerical approximation of its continuous-time limit and then present a new method with higher order. We show theoretically that our new method is more stable than NAG for large step size. Experiments of matrix completion and handwriting digit recognition demonstrate that the stability of our new method is better. Furthermore, better stability leads to higher computational speed in experiments. </p> </div> </dd> <dt>[235] arXiv:2112.04933 (cross-list from stat.AP) [pdf, other]</dt> <dd> <div > <div > Title: Measuring Wind Turbine Health Using Drifting Concepts </div> <div > Authors: Agnieszka Jastrzebska, <a >Alejandro Morales-Hernández</a>, <a >Gonzalo Nápoles</a>, <a >Yamisleydi Salgueiro</a>, <a >Koen Vanhoof</a> </div> <div > Subjects: Applications (stat.AP); Machine Learning (cs.LG) </div> <p >Time series processing is an essential aspect of wind turbine health monitoring. Despite the progress in this field, there is still room for new methods to improve modeling quality. In this paper, we propose two new approaches for the analysis of wind turbine health. Both approaches are based on abstract concepts, implemented using fuzzy sets, which summarize and aggregate the underlying raw data. By observing the change in concepts, we infer about the change in the turbine's health. Analyzes are carried out separately for different external conditions (wind speed and temperature). We extract concepts that represent relative low, moderate, and high power production. The first method aims at evaluating the decrease or increase in relatively high and low power production. This task is performed using a regression-like model. The second method evaluates the overall drift of the extracted concepts. Large drift indicates that the power production process undergoes fluctuations in time. Concepts are labeled using linguistic labels, thus equipping our model with improved interpretability features. We applied the proposed approach to process publicly available data describing four wind turbines. The simulation results have shown that the aging process is not homogeneous in all wind turbines. </p> </div> </dd> <dt>[236] arXiv:2112.04939 (cross-list from eess.AS) [pdf, other]</dt> <dd> <div > <div > Title: A Training Framework for Stereo-Aware Speech Enhancement using Deep Neural Networks </div> <div > Authors: Bahareh Tolooshams, <a >Kazuhito Koishida</a> </div> <div > Comments: Submitted to ICASSP 2022 </div> <div > Subjects: Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD) </div> <p >Deep learning-based speech enhancement has shown unprecedented performance in recent years. The most popular mono speech enhancement frameworks are end-to-end networks mapping the noisy mixture into an estimate of the clean speech. With growing computational power and availability of multichannel microphone recordings, prior works have aimed to incorporate spatial statistics along with spectral information to boost up performance. Despite an improvement in enhancement performance of mono output, the spatial image preservation and subjective evaluations have not gained much attention in the literature. This paper proposes a novel stereo-aware framework for speech enhancement, i.e., a training loss for deep learning-based speech enhancement to preserve the spatial image while enhancing the stereo mixture. The proposed framework is model independent, hence it can be applied to any deep learning based architecture. We provide an extensive objective and subjective evaluation of the trained models through a listening test. We show that by regularizing for an image preservation loss, the overall performance is improved, and the stereo aspect of the speech is better preserved. </p> </div> </dd> <dt>[237] arXiv:2112.04949 (cross-list from eess.AS) [pdf, ps, other]</dt> <dd> <div > <div > Title: Harmonic and non-Harmonic Based Noisy Reverberant Speech Enhancement in Time Domain </div> <div > Authors: G. Zucatelli, <a >R. Coelho</a> </div> <div > Comments: 9 pages </div> <div > Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> <p >This paper introduces the single step time domain method named HnH-NRSE, whihc is designed for simultaneous speech intelligibility and quality improvement under noisy-reverberant conditions. In this solution, harmonic and non-harmonic elements of speech are separated by applying zero-crossing and energy criteria. An objective evaluation of the its non-stationarity degree is further used for an adaptive gain to treat masking components. No prior knowledge of speech statistics or room information is required for this technique. Additionally, two combined solutions, IRMO and IRMN, are proposed as composite methods for improvement on noisy-reverberant speech signals. The proposed and baseline methods are evaluated considering two intelligibility and three quality measures, applied for the objective prediction. The results show that the proposed scheme leads to a higher intelligibility and quality improvement when compared to competing methods in most scenarios. Additionally, a perceptual intelligibility listening test is performed, which corroborates with these results. Furthermore, the proposed HnH-NRSE solution attains SRMR quality measure with similar results when compared to the composed IRMO and IRMN techniques. </p> </div> </dd> <dt>[238] arXiv:2112.04979 (cross-list from physics.flu-dyn) [pdf, other]</dt> <dd> <div > <div > Title: A fully-differentiable compressible high-order computational fluid dynamics solver </div> <div > Authors: Deniz A. Bezgin, <a >Aaron B. Buhendwa</a>, <a >Nikolaus A. Adams</a> </div> <div > Subjects: Fluid Dynamics (physics.flu-dyn); Machine Learning (cs.LG) </div> <p >Fluid flows are omnipresent in nature and engineering disciplines. The reliable computation of fluids has been a long-lasting challenge due to nonlinear interactions over multiple spatio-temporal scales. The compressible Navier-Stokes equations govern compressible flows and allow for complex phenomena like turbulence and shocks. Despite tremendous progress in hardware and software, capturing the smallest length-scales in fluid flows still introduces prohibitive computational cost for real-life applications. We are currently witnessing a paradigm shift towards machine learning supported design of numerical schemes as a means to tackle aforementioned problem. While prior work has explored differentiable algorithms for one- or two-dimensional incompressible fluid flows, we present a fully-differentiable three-dimensional framework for the computation of compressible fluid flows using high-order state-of-the-art numerical methods. Firstly, we demonstrate the efficiency of our solver by computing classical two- and three-dimensional test cases, including strong shocks and transition to turbulence. Secondly, and more importantly, our framework allows for end-to-end optimization to improve existing numerical schemes inside computational fluid dynamics algorithms. In particular, we are using neural networks to substitute a conventional numerical flux function. </p> </div> </dd> <dt>[239] arXiv:2112.04984 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Robust Weakly Supervised Learning for COVID-19 Recognition Using Multi-Center CT Images </div> <div > Authors: Qinghao Ye, <a >Yuan Gao</a>, <a >Weiping Ding</a>, <a >Zhangming Niu</a>, <a >Chengjia Wang</a>, <a >Yinghui Jiang</a>, <a >Minhao Wang</a>, <a >Evandro Fei Fang</a>, <a >Wade Menpes-Smith</a>, <a >Jun Xia</a>, <a >Guang Yang</a> </div> <div > Comments: 32 pages, 8 figures, Applied Soft Computing </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p >The world is currently experiencing an ongoing pandemic of an infectious disease named coronavirus disease 2019 (i.e., COVID-19), which is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Computed Tomography (CT) plays an important role in assessing the severity of the infection and can also be used to identify those symptomatic and asymptomatic COVID-19 carriers. With a surge of the cumulative number of COVID-19 patients, radiologists are increasingly stressed to examine the CT scans manually. Therefore, an automated 3D CT scan recognition tool is highly in demand since the manual analysis is time-consuming for radiologists and their fatigue can cause possible misjudgment. However, due to various technical specifications of CT scanners located in different hospitals, the appearance of CT images can be significantly different leading to the failure of many automated image recognition approaches. The multi-domain shift problem for the multi-center and multi-scanner studies is therefore nontrivial that is also crucial for a dependable recognition and critical for reproducible and objective diagnosis and prognosis. In this paper, we proposed a COVID-19 CT scan recognition model namely coronavirus information fusion and diagnosis network (CIFD-Net) that can efficiently handle the multi-domain shift problem via a new robust weakly supervised learning paradigm. Our model can resolve the problem of different appearance in CT scan images reliably and efficiently while attaining higher accuracy compared to other state-of-the-art methods. </p> </div> </dd> <dt>[240] arXiv:2112.04998 (cross-list from eess.IV) [pdf, other]</dt> <dd> <div > <div > Title: Sparse-View CT Reconstruction using Recurrent Stacked Back Projection </div> <div > Authors: Wenrui Li, <a >Gregery T. Buzzard</a>, <a >Charles A. Bouman</a> </div> <div > Comments: 5 pages, 5 pages, 2021 Asilomar Conference on Signals, Systems, and Computers </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p >Sparse-view CT reconstruction is important in a wide range of applications due to limitations on cost, acquisition time, or dosage. However, traditional direct reconstruction methods such as filtered back-projection (FBP) lead to low-quality reconstructions in the sub-Nyquist regime. In contrast, deep neural networks (DNNs) can produce high-quality reconstructions from sparse and noisy data, e.g. through post-processing of FBP reconstructions, as can model-based iterative reconstruction (MBIR), albeit at a higher computational cost. In this paper, we introduce a direct-reconstruction DNN method called Recurrent Stacked Back Projection (RSBP) that uses sequentially-acquired backprojections of individual views as input to a recurrent convolutional LSTM network. The SBP structure maintains all information in the sinogram, while the recurrent processing exploits the correlations between adjacent views and produces an updated reconstruction after each new view. We train our network on simulated data and test on both simulated and real data and demonstrate that RSBP outperforms both DNN post-processing of FBP images and basic MBIR, with a lower computational cost than MBIR. </p> </div> </dd> <dt>[241] arXiv:2112.05004 (cross-list from math.NT) [pdf, other]</dt> <dd> <div > <div > Title: Explicit Bounds for Linear Forms in the Exponentials of Algebraic Numbers </div> <div > Authors: Cheng-Chao Huang </div> <div > Subjects: Number Theory (math.NT); Computational Complexity (cs.CC); Symbolic Computation (cs.SC) </div> <p >In this paper, we study linear forms $\lambda = \beta_1{\mathrm{e}}^{\alpha_1}+\cdots+\beta_m{\mathrm{e}}^{\alpha_m}$, where $\alpha_i$ and $\beta_i$ are algebraic numbers. An explicit lower bound for $|\lambda|$ is proved, which is derived from "th\'eor\`eme de Lindemann--Weierstrass effectif" via constructive methods in algebraic computation. Besides, an explicit upper bound for the minimal $|\lambda|$ is established on systematic results of counting algebraic numbers. </p> </div> </dd> <dt>[242] arXiv:2112.05016 (cross-list from eess.AS) [pdf]</dt> <dd> <div > <div > Title: X-Vector based voice activity detection for multi-genre broadcast speech-to-text </div> <div > Authors: Misa Ogura, <a >Matt Haynes</a> </div> <div > Comments: 7 pages, 3 figures, 4 tables </div> <div > Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> <p >Voice Activity Detection (VAD) is a fundamental preprocessing step in automatic speech recognition. This is especially true within the broadcast industry where a wide variety of audio materials and recording conditions are encountered. Based on previous studies which indicate that xvector embeddings can be applied to a diverse set of audio classification tasks, we investigate the suitability of x-vectors in discriminating speech from noise. We find that the proposed x-vector based VAD system achieves the best reported score in detecting clean speech on AVA-Speech, whilst retaining robust VAD performance in the presence of noise and music. Furthermore, we integrate the x-vector based VAD system into an existing STT pipeline and compare its performance on multiple broadcast datasets against a baseline system with WebRTC VAD. Crucially, our proposed x-vector based VAD improves the accuracy of STT transcription on real-world broadcast audio </p> </div> </dd> <dt>[243] arXiv:2112.05020 (cross-list from math.OC) [pdf, other]</dt> <dd> <div > <div > Title: A Preconditioned Inexact Active-Set Method for Large-Scale Nonlinear Optimal Control Problems </div> <div > Authors: John W. Pearson, <a >Andreas Potschka</a> </div> <div > Comments: 26 pages </div> <div > Subjects: Optimization and Control (math.OC); Numerical Analysis (math.NA) </div> <p >We provide a global convergence proof of the recently proposed sequential homotopy method with an inexact Krylov--semismooth-Newton method employed as a local solver. The resulting method constitutes an active-set method in function space. After discretization, it allows for efficient application of Krylov-subspace methods. For a certain class of optimal control problems with PDE constraints, in which the control enters the Lagrangian only linearly, we propose and analyze an efficient, parallelizable, symmetric positive definite preconditioner based on a double Schur complement approach. We conclude with numerical results for a badly conditioned and highly nonlinear benchmark optimization problem with elliptic partial differential equations and control bounds. The resulting method is faster than using direct linear algebra for the 2D benchmark and allows for the parallel solution of large 3D problems. </p> </div> </dd> <dt>[244] arXiv:2112.05042 (cross-list from math.CO) [pdf, other]</dt> <dd> <div > <div > Title: A solution to Ringel's circle problem </div> <div > Authors: James Davies, Chaya Keller, <a >Linda Kleist</a>, <a >Shakhar Smorodinsky</a>, <a >Bartosz Walczak</a> </div> <div > Comments: 14 pages, 5 figures </div> <div > Subjects: Combinatorics (math.CO); Discrete Mathematics (cs.DM) </div> <p >We construct families of circles in the plane such that their tangency graphs have arbitrarily large girth and chromatic number. This provides a strong negative answer to Ringel's circle problem (1959). The proof relies on a (multidimensional) version of Gallai's theorem with polynomial constraints, which we derive from the Hales-Jewett theorem and which may be of independent interest. </p> </div> </dd> <dt>[245] arXiv:2112.05074 (cross-list from math.AG) [pdf, other]</dt> <dd> <div > <div > Title: Critical configurations for two projective views, a new approach </div> <div > Authors: Martin Bråtelund </div> <div > Comments: 22 pages, 6 figures </div> <div > Subjects: Algebraic Geometry (math.AG); Computer Vision and Pattern Recognition (cs.CV) </div> <p >The problem of structure from motion is concerned with recovering 3-dimensional structure of an object from a set of 2-dimensional images. Generally, all information can be uniquely recovered if enough images and image points are provided, but there are certain cases where unique recovery is impossible; these are called critical configurations. In this paper we use an algebraic approach to study the critical configurations for two projective cameras. We show that all critical configurations lie on quadric surfaces, and classify exactly which quadrics constitute a critical configuration. The paper also describes the relation between the different reconstructions when unique reconstruction is impossible. </p> </div> </dd> <dt>[246] arXiv:2112.05082 (cross-list from eess.SP) [pdf, other]</dt> <dd> <div > <div > Title: Fast Electromagnetic Validations of Large-Scale Digital Coding Metasurfaces Accelerated by Recurrence Rebuild and Retrieval Method </div> <div > Authors: Yu Zhao, <a >Shang Xiang</a>, <a >Long Li</a> </div> <div > Subjects: Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE) </div> <p >The recurrence rebuild and retrieval method (R3M) is proposed in this paper to accelerate the electromagnetic (EM) validations of large-scale digital coding metasurfaces (DCMs). R3M aims to accelerate the EM validations of DCMs with varied codebooks, which involves the analysis of a group of similar but distinct coding patterns. The method transforms general DCMs to rigorously periodic arrays by replacing each coding unit with the macro unit, which comprises all possible coding states. The system matrix corresponding to the rigorously periodic array is globally shared for DCMs with arbitrary codebooks via implicit retrieval. The discrepancy of the interactions for edge and corner units are precluded by the basis extension of periodic boundaries. Moreover, the hierarchical pattern exploitation algorithm is leveraged to efficiently assemble the system matrix for further acceleration. Due to the fully utilization of the rigid periodicity, the computational complexity of R3M is theoretically lower than that of $\mathcal{H}$-matrix within the same paradigm. Numerical results for two types of DCMs indicate that R3M is accurate in comparison with commercial software. Besides, R3M is also compatible with the preconditioning for efficient iterative solutions. The efficiency of R3M for DCMs outperforms the conventional fast algorithms by a large margin in both the storage and CPU time cost. </p> </div> </dd> <dt>[247] arXiv:2112.05095 (cross-list from stat.ML) [pdf, other]</dt> <dd> <div > <div > Title: Provable Continual Learning via Sketched Jacobian Approximations </div> <div > Authors: Reinhard Heckel </div> <div > Subjects: Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p >An important problem in machine learning is the ability to learn tasks in a sequential manner. If trained with standard first-order methods most models forget previously learned tasks when trained on a new task, which is often referred to as catastrophic forgetting. A popular approach to overcome forgetting is to regularize the loss function by penalizing models that perform poorly on previous tasks. For example, elastic weight consolidation (EWC) regularizes with a quadratic form involving a diagonal matrix build based on past data. While EWC works very well for some setups, we show that, even under otherwise ideal conditions, it can provably suffer catastrophic forgetting if the diagonal matrix is a poor approximation of the Hessian matrix of previous tasks. We propose a simple approach to overcome this: Regularizing training of a new task with sketches of the Jacobian matrix of past data. This provably enables overcoming catastrophic forgetting for linear models and for wide neural networks, at the cost of memory. The overarching goal of this paper is to provided insights on when regularization-based continual learning algorithms work and under what memory costs. </p> </div> </dd> <dt>[248] arXiv:2112.05104 (cross-list from math.OC) [pdf, other]</dt> <dd> <div > <div > Title: Continuation Path with Linear Convergence Rate </div> <div > Authors: Eugene Ndiaye, <a >Ichiro Takeuchi</a> </div> <div > Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG) </div> <p >Path-following algorithms are frequently used in composite optimization problems where a series of subproblems, with varying regularization hyperparameters, are solved sequentially. By reusing the previous solutions as initialization, better convergence speeds have been observed numerically. This makes it a rather useful heuristic to speed up the execution of optimization algorithms in machine learning. We present a primal dual analysis of the path-following algorithm and explore how to design its hyperparameters as well as determining how accurately each subproblem should be solved to guarantee a linear convergence rate on a target problem. Furthermore, considering optimization with a sparsity-inducing penalty, we analyze the change of the active sets with respect to the regularization parameter. The latter can then be adaptively calibrated to finely determine the number of features that will be selected along the solution path. This leads to simple heuristics for calibrating hyperparameters of active set approaches to reduce their complexity and improve their execution time. </p> </div> </dd> <dt>[249] arXiv:2112.05120 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd> <div > <div > Title: On Convergence of Federated Averaging Langevin Dynamics </div> <div > Authors: Wei Deng, <a >Yi-An Ma</a>, <a >Zhao Song</a>, <a >Qian Zhang</a>, <a >Guang Lin</a> </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p >We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions with distributed clients. In particular, we generalize beyond normal posterior distributions and consider a general class of models. We develop theoretical guarantees for FA-LD for strongly log-concave distributions with non-i.i.d data and study how the injected noise and the stochastic-gradient noise, the heterogeneity of data, and the varying learning rates affect the convergence. Such an analysis sheds light on the optimal choice of local updates to minimize communication costs. Important to our approach is that the communication efficiency does not deteriorate with the injected noise in the Langevin algorithms. In addition, we examine in our FA-LD algorithm both independent and correlated noise used over different clients. We observe that there is also a trade-off between federation and communication cost there. As local devices may become inactive in the federated network, we also show convergence results based on different averaging schemes where only partial device updates are available. </p> </div> </dd> <dt>[250] arXiv:2112.05128 (cross-list from stat.ML) [pdf, other]</dt> <dd> <div > <div > Title: Fair Structure Learning in Heterogeneous Graphical Models </div> <div > Authors: Davoud Ataee Tarzanagh, <a >Laura Balzano</a>, <a >Alfred O. Hero</a> </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p >Inference of community structure in probabilistic graphical models may not be consistent with fairness constraints when nodes have demographic attributes. Certain demographics may be over-represented in some detected communities and under-represented in others. This paper defines a novel $\ell_1$-regularized pseudo-likelihood approach for fair graphical model selection. In particular, we assume there is some community or clustering structure in the true underlying graph, and we seek to learn a sparse undirected graph and its communities from the data such that demographic groups are fairly represented within the communities. Our optimization approach uses the demographic parity definition of fairness, but the framework is easily extended to other definitions of fairness. We establish statistical consistency of the proposed method for both a Gaussian graphical model and an Ising model for, respectively, continuous and binary data, proving that our method can recover the graphs and their fair communities with high probability. </p> </div> </dd> </dl> <h3>Replacements for Fri, 10 Dec 21</h3> <dl> <dt>[251] arXiv:1411.2785 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Faster Compressed Quadtrees </div> <div > Authors: Guillermo de Bernardo, <a >Travis Gagie</a>, <a >Susana Ladra</a>, <a >Gonzalo Navarro</a>, <a >Diego Seco</a> </div> <div > Comments: Journal version of DCC '15 paper </div> <div > Subjects: Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt>[252] arXiv:1805.07984 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Adversarial Attacks on Neural Networks for Graph Data </div> <div > Authors: Daniel Zügner, <a >Amir Akbarnejad</a>, <a >Stephan Günnemann</a> </div> <div > Comments: Accepted as a full paper at KDD 2018 on May 6, 2018 </div> <div > Journal-ref: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery Data Mining, KDD 2018, pp. 2847-2856 </div> <div > Subjects: Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG) </div> </div> </dd> <dt>[253] arXiv:1901.06234 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: SPARCs for Unsourced Random Access </div> <div > Authors: Alexander Fengler, <a >Peter Jung</a>, <a >Giuseppe Caire</a> </div> <div > Comments: v3: Corrected some errors in Thm 2 and 4, v2: Major revision; Parts of this work have been presented at ISIT 2019 and ISIT 2020 </div> <div > Journal-ref: IEEE Transactions on Information Theory, vol. 67, no. 10, pp. 6894-6915, Oct. 2021 </div> <div > Subjects: Information Theory (cs.IT) </div> </div> </dd> <dt>[254] arXiv:1902.10905 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: PixelSteganalysis: Pixel-wise Hidden Information Removal with Low Visual Degradation </div> <div > Authors: Dahuin Jung, <a >Ho Bae</a>, <a >Hyun-Soo Choi</a>, <a >Sungroh Yoon</a> </div> <div > Comments: IEEE TDSC </div> <div > Subjects: Multimedia (cs.MM); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[255] arXiv:1905.07718 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Geometric Pose Affordance: 3D Human Pose with Scene Constraints </div> <div > Authors: Zhe Wang, <a >Liyan Chen</a>, <a >Shaurya Rathore</a>, <a >Daeyun Shin</a>, <a >Charless Fowlkes</a> </div> <div > Comments: $\href{<a >this https URL</a>}{Project Page}$, in submission to CVIU </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[256] arXiv:1905.10711 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction </div> <div > Authors: Qiangeng Xu, <a >Weiyue Wang</a>, <a >Duygu Ceylan</a>, <a >Radomir Mech</a>, <a >Ulrich Neumann</a> </div> <div > Journal-ref: 33rd Annual Conference on Neural Information Processing Systems (NeurIPS 2019) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[257] arXiv:1905.12346 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Nyström landmark sampling and regularized Christoffel functions </div> <div > Authors: Michaël Fanuel, <a >Joachim Schreurs</a>, <a >Johan A.K. Suykens</a> </div> <div > Comments: More details in the proofs. Typos corrected </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[258] arXiv:1906.06397 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations </div> <div > Authors: Rohan Paleja, <a >Andrew Silva</a>, <a >Letian Chen</a>, <a >Matthew Gombolay</a> </div> <div > Journal-ref: Proceedings of the 34th International Conference on Neural Information Processing Systems 2020, 6417-6428 </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) </div> </div> </dd> <dt>[259] arXiv:1906.10462 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Policy Optimization with Stochastic Mirror Descent </div> <div > Authors: Long Yang, <a >Yu Zhang</a>, <a >Gang Zheng</a>, <a >Qian Zheng</a>, <a >Pengfei Li</a>, <a >Jun Wen</a>, <a >Gang Pan</a> </div> <div > Journal-ref: AAAI2022 </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[260] arXiv:1912.10784 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: An improper estimator with optimal excess risk in misspecified density estimation and logistic regression </div> <div > Authors: Jaouad Mourtada, <a >Stéphane Gaïffas</a> </div> <div > Comments: 43 pages, minor revision </div> <div > Subjects: Statistics Theory (math.ST); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[261] arXiv:2003.03710 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Trajectory Grouping with Curvature Regularization for Tubular Structure Tracking </div> <div > Authors: Li Liu, <a >Da Chen</a>, <a >Minglei Shu</a>, <a >Baosheng Li</a>, <a >Huazhong Shu</a>, <a >Michel Paques</a>, <a >Laurent D. Cohen</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[262] arXiv:2003.07695 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Online Assortment and Market Segmentation under Bertrand Competition with Set-Dependent Revenues </div> <div > Authors: S. Rasoul Etesami </div> <div > Subjects: Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC) </div> </div> </dd> <dt>[263] arXiv:2003.12112 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: The Network Dynamics of Social and Technological Conventions </div> <div > Authors: Joshua Becker </div> <div > Comments: 21 pages, 6 figures </div> <div > Subjects: Physics and Society (physics.soc-ph); Social and Information Networks (cs.SI); General Economics (econ.GN) </div> </div> </dd> <dt>[264] arXiv:2004.07861 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: The Co-Production of Service: Modeling Service Times in Contact Centers Using Hawkes Processes </div> <div > Authors: Andrew Daw, Antonio Castellanos, <a >Galit B. Yom-Tov</a>, <a >Jamol Pender</a>, <a >Leor Gruendlinger</a> </div> <div > Subjects: Social and Information Networks (cs.SI) </div> </div> </dd> <dt>[265] arXiv:2005.08551 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Omni-supervised Facial Expression Recognition via Distilled Data </div> <div > Authors: Ping Liu, <a >Yunchao Wei</a>, <a >Zibo Meng</a>, <a >Weihong Deng</a>, <a >Joey Tianyi Zhou</a>, <a >Yi Yang</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[266] arXiv:2006.00808 (replaced) [src]</dt> <dd> <div > <div > Title: Note to "An efficient Data Structure for Lattice Operation" </div> <div > Authors: Maurizio Talamo, <a >Paola Vocca</a> </div> <div > Comments: There is one error that I have to ammend </div> <div > Subjects: Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt>[267] arXiv:2006.01578 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Deep Learning in Target Space </div> <div > Authors: Michael Fairbank, <a >Spyridon Samothrakis</a>, <a >Luca Citi</a> </div> <div > Subjects: Neural and Evolutionary Computing (cs.NE) </div> </div> </dd> <dt>[268] arXiv:2007.13437 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Energy-based View of Retrosynthesis </div> <div > Authors: Ruoxi Sun, <a >Hanjun Dai</a>, <a >Li Li</a>, <a >Steven Kearnes</a>, <a >Bo Dai</a> </div> <div > Subjects: Chemical Physics (physics.chem-ph); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM) </div> </div> </dd> <dt>[269] arXiv:2007.14769 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: A convergence analysis of the price of anarchy in atomic congestion games </div> <div > Authors: Zijun Wu, <a >Rolf H. Moehring</a>, <a >Chunying Ren</a>, <a >Dachuan Xu</a> </div> <div > Comments: 57 pages </div> <div > Subjects: Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH) </div> </div> </dd> <dt>[270] arXiv:2008.04088 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: mpNet: variable depth unfolded neural network for massive MIMO channel estimation </div> <div > Authors: Taha Yassine (IRT b-com, Hypermedia), <a >Luc Le Magoarou</a> (IRT b-com, Hypermedia) </div> <div > Subjects: Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI) </div> </div> </dd> <dt>[271] arXiv:2008.08974 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: ISSAFE: Improving Semantic Segmentation in Accidents by Fusing Event-based Data </div> <div > Authors: Jiaming Zhang, <a >Kailun Yang</a>, <a >Rainer Stiefelhagen</a> </div> <div > Comments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[272] arXiv:2008.12552 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Probabilistic Random Indexing for Continuous Event Detection </div> <div > Authors: Yashank Singh, <a >Niladri Chatterjee</a> </div> <div > Comments: 8 pages, 12 figures </div> <div > Subjects: Machine Learning (cs.LG); Computation and Language (cs.CL) </div> </div> </dd> <dt>[273] arXiv:2009.01845 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Qibo: a framework for quantum simulation with hardware acceleration </div> <div > Authors: Stavros Efthymiou, Sergi Ramos-Calderer, <a >Carlos Bravo-Prieto</a>, <a >Adrián Pérez-Salinas</a>, <a >Diego García-Martín</a>, <a >Artur Garcia-Saez</a>, <a >José Ignacio Latorre</a>, <a >Stefano Carrazza</a> </div> <div > Comments: 15 pages, 12 figures, 5 tables,code available at <a >this https URL</a>, final version published in QST </div> <div > Subjects: Quantum Physics (quant-ph); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG) </div> </div> </dd> <dt>[274] arXiv:2009.08687 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Chemical Property Prediction Under Experimental Biases </div> <div > Authors: Yang Liu, <a >Hisashi Kashima</a> </div> <div > Subjects: Quantitative Methods (q-bio.QM); Machine Learning (cs.LG) </div> </div> </dd> <dt>[275] arXiv:2009.10007 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Learning Realistic Patterns from Unrealistic Stimuli: Generalization and Data Anonymization </div> <div > Authors: Konstantinos Nikolaidis, <a >Stein Kristiansen</a>, <a >Thomas Plagemann</a>, <a >Vera Goebel</a>, <a >Knut Liestøl</a>, <a >Mohan Kankanhalli</a>, <a >Gunn Marit Traaen</a>, <a >Britt Øverland</a>, <a >Harriet Akre</a>, <a >Lars Aakerøy</a>, <a >Sigurd Steinshamn</a> </div> <div > Journal-ref: Journal of Artificial Intelligence Research 72 (2021): 1163-1214 </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[276] arXiv:2010.00145 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Entropy Regularization for Mean Field Games with Learning </div> <div > Authors: Xin Guo, <a >Renyuan Xu</a>, <a >Thaleia Zariphopoulou</a> </div> <div > Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[277] arXiv:2010.05998 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Counting Subgraphs in Degenerate Graphs </div> <div > Authors: Suman K. Bera, <a >Lior Gishboliner</a>, <a >Yevgeny Levanzov</a>, <a >C. Seshadhri</a>, <a >Asaf Shapira</a> </div> <div > Subjects: Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO) </div> </div> </dd> <dt>[278] arXiv:2011.00628 (replaced) [pdf]</dt> <dd> <div > <div > Title: Brain Tumor Classification Using Medial Residual Encoder Layers </div> <div > Authors: Zahra SobhaniNia, <a >Nader Karimi</a>, <a >Pejman Khadivi</a>, <a >Roshank Roshandel</a>, <a >Shadrokh Samavi</a> </div> <div > Comments: 4 pages, 4 figures </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[279] arXiv:2011.04843 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Multi-document Summarization via Deep Learning Techniques: A Survey </div> <div > Authors: Congbo Ma, <a >Wei Emma Zhang</a>, <a >Mingyu Guo</a>, <a >Hu Wang</a>, <a >Quan Z. Sheng</a> </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[280] arXiv:2011.09168 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Multiscale Scattering in Nonlinear Kerr-Type Media </div> <div > Authors: Roland Maier, <a >Barbara Verfürth</a> </div> <div > Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt>[281] arXiv:2011.09588 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification </div> <div > Authors: Youngseog Chung, Willie Neiswanger, <a >Ian Char</a>, <a >Jeff Schneider</a> </div> <div > Comments: Appears in Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[282] arXiv:2011.12984 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Enabling GPU Accelerated Computing in the SUNDIALS Time Integration Library </div> <div > Authors: Cody J. Balos, <a >David J. Gardner</a>, <a >Carol S. Woodward</a>, <a >Daniel R. Reynolds</a> </div> <div > Journal-ref: Parallel Computing, Volume 108, 2021, 102836, ISSN 0167-8191 </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS) </div> </div> </dd> <dt>[283] arXiv:2011.14473 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Kinetics-Informed Neural Networks </div> <div > Authors: Gabriel S. Gusmão, <a >Adhika P. Retnanto</a>, <a >Shashwati C. da Cunha</a>, <a >Andrew J. Medford</a> </div> <div > Comments: Pre-print for first submission </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA) </div> </div> </dd> <dt>[284] arXiv:2012.04567 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Bayesian Image Reconstruction using Deep Generative Models </div> <div > Authors: Razvan V Marinescu, <a >Daniel Moyer</a>, <a >Polina Golland</a> </div> <div > Comments: 27 pages, 17 figures, 5 tables </div> <div > Journal-ref: NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Image and Video Processing (eess.IV); Machine Learning (stat.ML) </div> </div> </dd> <dt>[285] arXiv:2012.05062 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Finite-dimensional observer-based PI regulation control of a reaction-diffusion equation </div> <div > Authors: Hugo Lhachemi, <a >Christophe Prieur</a> </div> <div > Subjects: Optimization and Control (math.OC); Systems and Control (eess.SY) </div> </div> </dd> <dt>[286] arXiv:2012.12868 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Flat-Combining-Based Persistent Data Structures for Non-Volatile Memory </div> <div > Authors: Matan Rusanovsky, <a >Hagit Attiya</a>, <a >Ohad Ben-Baruch</a>, <a >Tom Gerby</a>, <a >Danny Hendler</a>, <a >Pedro Ramalhete</a> </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Operating Systems (cs.OS) </div> </div> </dd> <dt>[287] arXiv:2012.13577 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification </div> <div > Authors: Jiangjie Chen, <a >Qiaoben Bao</a>, <a >Changzhi Sun</a>, <a >Xinbo Zhang</a>, <a >Jiaze Chen</a>, <a >Hao Zhou</a>, <a >Yanghua Xiao</a>, <a >Lei Li</a> </div> <div > Comments: Accepted to AAAI 2022 </div> <div > Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[288] arXiv:2101.07009 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Separating Polarization from Noise: Comparison and Normalization of Structural Polarization Measures </div> <div > Authors: Ali Salloum, <a >Ted Hsuan Yun Chen</a>, <a >Mikko Kivelä</a> </div> <div > Subjects: Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph); Applications (stat.AP) </div> </div> </dd> <dt>[289] arXiv:2102.00487 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Nonlinear Evolutionary PDE-Based Refinement of Optical Flow </div> <div > Authors: Hirak Doshi, <a >N. Uday Kiran</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Analysis of PDEs (math.AP) </div> </div> </dd> <dt>[290] arXiv:2102.01606 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Structure-preserving Gaussian Process Dynamics </div> <div > Authors: Katharina Ensinger, <a >Friedrich Solowjow</a>, <a >Sebastian Ziesche</a>, <a >Michael Tiemann</a>, <a >Sebastian Trimpe</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[291] arXiv:2102.04738 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: End-to-End Deep Learning of Lane Detection and Path Prediction for Real-Time Autonomous Driving </div> <div > Authors: Der-Hau Lee, <a >Jinn-Liang Liu</a> </div> <div > Comments: 6 pages, 4 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO) </div> </div> </dd> <dt>[292] arXiv:2102.07074 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up </div> <div > Authors: Yifan Jiang, <a >Shiyu Chang</a>, <a >Zhangyang Wang</a> </div> <div > Comments: Accepted to NeruIPS 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[293] arXiv:2102.07148 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A New Look and Convergence Rate of Federated Multi-Task Learning with Laplacian Regularization </div> <div > Authors: Canh T. Dinh, <a >Tung T. Vu</a>, <a >Nguyen H. Tran</a>, <a >Minh N. Dao</a>, <a >Hongyu Zhang</a> </div> <div > Subjects: Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt>[294] arXiv:2102.08138 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: IronMan: GNN-assisted Design Space Exploration in High-Level Synthesis via Reinforcement Learning </div> <div > Authors: Nan Wu, <a >Yuan Xie</a>, <a >Cong Hao</a> </div> <div > Journal-ref: GLSVLSI 2021 </div> <div > Subjects: Hardware Architecture (cs.AR); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[295] arXiv:2102.09277 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Locally Checkable Problems in Rooted Trees </div> <div > Authors: Alkida Balliu, <a >Sebastian Brandt</a>, <a >Yi-Jun Chang</a>, <a >Dennis Olivetti</a>, <a >Jan Studený</a>, <a >Jukka Suomela</a>, <a >Aleksandr Tereshchenko</a> </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt>[296] arXiv:2103.00167 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Inferring Unobserved Events in Systems With Shared Resources and Queues </div> <div > Authors: Dirk Fahland, <a >Vadim Denisov</a>, <a >Wil. M.P. van der Aalst</a> </div> <div > Comments: Final formatted version at Fundamenta Informatica </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Performance (cs.PF) </div> </div> </dd> <dt>[297] arXiv:2103.02313 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Open community platform for hearing aid algorithm research: open Master Hearing Aid (openMHA) </div> <div > Authors: Hendrik Kayser, <a >Tobias Herzke</a>, <a >Paul Maanen</a>, <a >Max Zimmermann</a>, <a >Giso Grimm</a>, <a >Volker Hohmann</a> </div> <div > Comments: 29 pages, 5 figures, resubmitted to SoftwareX after revision </div> <div > Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP) </div> </div> </dd> <dt>[298] arXiv:2103.02895 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: On the privacy-utility trade-off in differentially private hierarchical text classification </div> <div > Authors: Dominik Wunderlich, <a >Daniel Bernau</a>, <a >Francesco Aldà</a>, <a >Javier Parra-Arnau</a>, <a >Thorsten Strufe</a> </div> <div > Subjects: Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[299] arXiv:2103.05577 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Parametrized quantum policies for reinforcement learning </div> <div > Authors: Sofiene Jerbi, <a >Casper Gyurik</a>, <a >Simon C. Marshall</a>, <a >Hans J. Briegel</a>, <a >Vedran Dunjko</a> </div> <div > Comments: NeurIPS 2021 camera-ready version </div> <div > Subjects: Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[300] arXiv:2103.07454 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: EventGraD: Event-Triggered Communication in Parallel Machine Learning </div> <div > Authors: Soumyadip Ghosh, <a >Bernardo Aquino</a>, <a >Vijay Gupta</a> </div> <div > Comments: Published in Neurocomputing, Nov 2021 </div> <div > Subjects: Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY) </div> </div> </dd> <dt>[301] arXiv:2103.10994 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Self-Supervised Classification Network </div> <div > Authors: Elad Amrani, <a >Leonid Karlinsky</a>, <a >Alex Bronstein</a> </div> <div > Comments: Update method and add experiments </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[302] arXiv:2103.13056 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Minimax Regret for Stochastic Shortest Path </div> <div > Authors: Alon Cohen, <a >Yonathan Efroni</a>, <a >Yishay Mansour</a>, <a >Aviv Rosenberg</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[303] arXiv:2103.15924 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: How Far Can We Go in Compute-less Networking: Computation Correctness and Accuracy </div> <div > Authors: Boubakr Nour, <a >Soumaya Cherkaoui</a> </div> <div > Comments: Accepted for publication by the IEEE Network Magazine </div> <div > Subjects: Networking and Internet Architecture (cs.NI) </div> </div> </dd> <dt>[304] arXiv:2103.16634 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Exploiting Invariance in Training Deep Neural Networks </div> <div > Authors: Chengxi Ye, <a >Xiong Zhou</a>, <a >Tristan McKinney</a>, <a >Yanfeng Liu</a>, <a >Qinggang Zhou</a>, <a >Fedor Zhdanov</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> </div> </dd> <dt>[305] arXiv:2104.02446 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Upper paired domination versus upper domination </div> <div > Authors: Hadi Alizadeh, <a >Didem Gözüpek</a> </div> <div > Subjects: Combinatorics (math.CO); Discrete Mathematics (cs.DM) </div> </div> </dd> <dt>[306] arXiv:2104.04258 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Counter-Strike Deathmatch with Large-Scale Behavioural Cloning </div> <div > Authors: Tim Pearce, <a >Jun Zhu</a> </div> <div > Comments: Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2021 </div> <div > Subjects: Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[307] arXiv:2104.04896 (replaced) [pdf]</dt> <dd> <div > <div > Title: A Toolbox for Construction and Analysis of Speech Datasets </div> <div > Authors: Evelina Bakhturina, <a >Vitaly Lavrukhin</a>, <a >Boris Ginsburg</a> </div> <div > Subjects: Audio and Speech Processing (eess.AS); Computation and Language (cs.CL); Sound (cs.SD) </div> </div> </dd> <dt>[308] arXiv:2104.05002 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Learning the CSI Denoising and Feedback Without Supervision </div> <div > Authors: Valentina Rizzello, <a >Wolfgang Utschick</a> </div> <div > Comments: Final version </div> <div > Subjects: Information Theory (cs.IT); Signal Processing (eess.SP) </div> </div> </dd> <dt>[309] arXiv:2104.05256 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A Coq Formalization of Lebesgue Integration of Nonnegative Functions </div> <div > Authors: Sylvie Boldo (TOCCATA), <a >François Clément</a> (SERENA, CERMICS), <a >Florian Faissole</a> (TOCCATA), <a >Vincent Martin</a> (LMAC), <a >Micaela Mayero</a> (LIPN) </div> <div > Subjects: Logic in Computer Science (cs.LO); Functional Analysis (math.FA) </div> </div> </dd> <dt>[310] arXiv:2104.05463 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Scalable Power Control/Beamforming in Heterogeneous Wireless Networks with Graph Neural Networks </div> <div > Authors: Xiaochen Zhang, <a >Haitao Zhao</a>, <a >Jun Xiong</a>, <a >Li Zhou</a>, <a >Jibo Wei</a> </div> <div > Comments: 6 pages, 6 figures, accepted by IEEE GLOBECOM 2021. Copyright may be transferred without notice, after which this version may no longer be accessible </div> <div > Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP) </div> </div> </dd> <dt>[311] arXiv:2104.10029 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images: Techniques and Clinical Applications </div> <div > Authors: Yang Ma, <a >Chaoyi Zhang</a>, <a >Mariano Cabezas</a>, <a >Yang Song</a>, <a >Zihao Tang</a>, <a >Dongnan Liu</a>, <a >Weidong Cai</a>, <a >Michael Barnett</a>, <a >Chenyu Wang</a> </div> <div > Comments: 14 pages, 3 Figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Applications (stat.AP) </div> </div> </dd> <dt>[312] arXiv:2104.12138 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Learning to Address Intra-segment Misclassification in Retinal Imaging </div> <div > Authors: Yukun Zhou, <a >Moucheng Xu</a>, <a >Yipeng Hu</a>, <a >Hongxiang Lin</a>, <a >Joseph Jacob</a>, <a >Pearse A. Keane</a>, <a >Daniel C. Alexander</a> </div> <div > Comments: 13 pages, 9 figures, and 2 tables </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt>[313] arXiv:2104.13020 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding </div> <div > Authors: Jose M. Peña </div> <div > Subjects: Methodology (stat.ME); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[314] arXiv:2104.13247 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: IATos: AI-powered pre-screening tool for COVID-19 from cough audio samples </div> <div > Authors: D. Trejo Pizzo, <a >S. Esteban</a> </div> <div > Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> </div> </dd> <dt>[315] arXiv:2104.14118 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: REGRAD: A Large-Scale Relational Grasp Dataset for Safe and Object-Specific Robotic Grasping in Clutter </div> <div > Authors: Hanbo Zhang, Deyu Yang, <a >Han Wang</a>, <a >Binglei Zhao</a>, <a >Xuguang Lan</a>, <a >Jishiyu Ding</a>, <a >Nanning Zheng</a> </div> <div > Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[316] arXiv:2105.04504 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Deep Neural Networks as Point Estimates for Deep Gaussian Processes </div> <div > Authors: Vincent Dutordoir, <a >James Hensman</a>, <a >Mark van der Wilk</a>, <a >Carl Henrik Ek</a>, <a >Zoubin Ghahramani</a>, <a >Nicolas Durrande</a> </div> <div > Comments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div > Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> </div> </dd> <dt>[317] arXiv:2105.07324 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Data-driven Algorithms for signal processing with trigonometric rational functions </div> <div > Authors: Heather Wilber, <a >Anil Damle</a>, <a >Alex Townsend</a> </div> <div > Comments: 25 pages, 7 figures </div> <div > Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt>[318] arXiv:2105.13647 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Hybrid Beamforming for Intelligent Reflecting Surface Aided Millimeter Wave MIMO Systems </div> <div > Authors: Sung Hyuck Hong, <a >Jaeyong Park</a>, <a >Sung-Jin Kim</a>, <a >Junil Choi</a> </div> <div > Comments: 13 pages, 6 figures </div> <div > Subjects: Signal Processing (eess.SP); Information Theory (cs.IT) </div> </div> </dd> <dt>[319] arXiv:2106.00214 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Game-Theoretic Frameworks for Epidemic Spreading and Human Decision Making: A Review </div> <div > Authors: Yunhan Huang, <a >Quanyan Zhu</a> </div> <div > Subjects: Systems and Control (eess.SY); Computer Science and Game Theory (cs.GT) </div> </div> </dd> <dt>[320] arXiv:2106.01040 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling </div> <div > Authors: Chuhan Wu, <a >Fangzhao Wu</a>, <a >Tao Qi</a>, <a >Yongfeng Huang</a> </div> <div > Comments: ACL 2021 </div> <div > Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt>[321] arXiv:2106.02249 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Robustifying Reinforcement Learning Policies with $\mathcal{L}_1$ Adaptive Control </div> <div > Authors: Yikun Cheng, <a >Pan Zhao</a>, <a >Manan Gandhi</a>, <a >Bo Li</a>, <a >Evangelos Theodorou</a>, <a >Naira Hovakimyan</a> </div> <div > Comments: A significantly extended version of this paper has been uploaded to arXiv. <a >arXiv:2112.01953</a> </div> <div > Subjects: Machine Learning (cs.LG); Systems and Control (eess.SY) </div> </div> </dd> <dt>[322] arXiv:2106.03027 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Model Zoo: A Growing "Brain" That Learns Continually </div> <div > Authors: Rahul Ramesh, <a >Pratik Chaudhari</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[323] arXiv:2106.04906 (replaced) [pdf]</dt> <dd> <div > <div > Title: Engineering-Economic Evaluation of Diffractive Non-Line-Of-Sight Backhaul (e3nb): A Techno-economic Model for 3D Wireless Backhaul Assessment </div> <div > Authors: Edward J. Oughton, <a >Erik Boch</a>, <a >Julius Kusuma</a> </div> <div > Subjects: Networking and Internet Architecture (cs.NI); Computers and Society (cs.CY); Emerging Technologies (cs.ET); General Economics (econ.GN) </div> </div> </dd> <dt>[324] arXiv:2106.05206 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Avoiding Traps in Nonconvex Problems </div> <div > Authors: Sean Deyo, <a >Veit Elser</a> </div> <div > Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Dynamical Systems (math.DS) </div> </div> </dd> <dt>[325] arXiv:2106.06168 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Generate, Annotate, and Learn: NLP with Synthetic Text </div> <div > Authors: Xuanli He, <a >Islam Nassar</a>, <a >Jamie Kiros</a>, <a >Gholamreza Haffari</a>, <a >Mohammad Norouzi</a> </div> <div > Comments: 28 pages, 3 figures </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[326] arXiv:2106.07153 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Iterative Methods for Private Synthetic Data: Unifying Framework and New Methods </div> <div > Authors: Terrance Liu, <a >Giuseppe Vietri</a>, <a >Zhiwei Steven Wu</a> </div> <div > Comments: NeurIPS 2021 </div> <div > Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt>[327] arXiv:2106.07464 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Meta-Interpretive Learning as Metarule Specialisation </div> <div > Authors: Stassa Patsantzis, <a >Stephen H. Muggleton</a> </div> <div > Comments: 29 pages. Submitted to the Machine Learning Journal Special Issue on Learning and Reasoning on June 1st, 2021. Revised and resubmitted on 16/09/21. Revised again and resubmitted on 09/12/2021 </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO) </div> </div> </dd> <dt>[328] arXiv:2106.11808 (replaced) [pdf]</dt> <dd> <div > <div > Title: Fully CMOS-compatible passive TiO2-based memristor crossbars for in-memory computing </div> <div > Authors: Abdelouadoud El Mesoudy, <a >Gwénaëlle Lamri</a>, <a >Raphaël Dawant</a>, <a >Javier Arias-Zapata</a>, <a >Pierre Gliech</a>, <a >Yann Beilliard</a>, <a >Serge Ecoffey</a>, <a >Andreas Ruediger</a>, <a >Fabien Alibart</a>, <a >Dominique Drouin</a> </div> <div > Comments: 18 pages, 4 figures in main text, 5 figures in SI </div> <div > Subjects: Emerging Technologies (cs.ET); Applied Physics (physics.app-ph) </div> </div> </dd> <dt>[329] arXiv:2106.15256 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: The Complexity of Synthesis of $b$-Bounded Petri Nets </div> <div > Authors: Ronny Tredup </div> <div > Subjects: Computational Complexity (cs.CC) </div> </div> </dd> <dt>[330] arXiv:2106.15278 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Open-Set Representation Learning through Combinatorial Embedding </div> <div > Authors: Geeho Kim, <a >Junoh Kang</a>, <a >Bohyung Han</a> </div> <div > Comments: 11 pages, 6 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> </div> </dd> <dt>[331] arXiv:2107.00644 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation </div> <div > Authors: Nicklas Hansen, <a >Hao Su</a>, <a >Xiaolong Wang</a> </div> <div > Comments: Code and videos are available at <a >this https URL</a> </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO) </div> </div> </dd> <dt>[332] arXiv:2107.05775 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Fast and Explicit Neural View Synthesis </div> <div > Authors: Pengsheng Guo, <a >Miguel Angel Bautista</a>, <a >Alex Colburn</a>, <a >Liang Yang</a>, <a >Daniel Ulbricht</a>, <a >Joshua M. Susskind</a>, <a >Qi Shan</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG) </div> </div> </dd> <dt>[333] arXiv:2107.06253 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Bottom-up Synthesis of Recursive Functional Programs using Angelic Execution </div> <div > Authors: Anders Miltner, <a >Adrian Trejo Nuñez</a>, <a >Ana Brendel</a>, <a >Swarat Chaudhuri</a>, <a >Isil Dillig</a> </div> <div > Subjects: Programming Languages (cs.PL) </div> </div> </dd> <dt>[334] arXiv:2107.09274 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Paraphrasing via Ranking Many Candidates </div> <div > Authors: Joosung Lee </div> <div > Comments: 4 pages </div> <div > Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt>[335] arXiv:2107.14735 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Neural Relighting and Expression Transfer On Video Portraits </div> <div > Authors: Youjia Wang, Taotao Zhou, <a >Minzhang Li</a>, <a >Teng Xu</a>, <a >Minye Wu</a>, <a >Lan Xu</a>, <a >Jingyi Yu</a> </div> <div > Comments: Project Page <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> </div> </dd> <dt>[336] arXiv:2108.01204 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: The RareDis corpus: a corpus annotated with rare diseases, their signs and symptoms </div> <div > Authors: Claudia Martínez-deMiguel, <a >Isabel Segura-Bedmar</a>, <a >Esteban Chacón-Solano</a>, <a >Sara Guerrero-Aspizua</a> </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[337] arXiv:2108.01483 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Research Challenges and Progress in Robotic Grasping and Manipulation Competitions </div> <div > Authors: Yu Sun, <a >Joe Falco</a>, <a >Maximo A. Roa</a>, <a >Berk Calli</a> </div> <div > Comments: Accepted for publication by IEEE Robotics and Automation Letters </div> <div > Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[338] arXiv:2108.03603 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Understanding the computational demands underlying visual reasoning </div> <div > Authors: Mohit Vaishnav, <a >Remi Cadene</a>, <a >Andrea Alamia</a>, <a >Drew Linsley</a>, <a >Rufin VanRullen</a>, <a >Thomas Serre</a> </div> <div > Comments: 26 pages, 16 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[339] arXiv:2108.05895 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Mobile-Former: Bridging MobileNet and Transformer </div> <div > Authors: Yinpeng Chen, <a >Xiyang Dai</a>, <a >Dongdong Chen</a>, <a >Mengchen Liu</a>, <a >Xiaoyi Dong</a>, <a >Lu Yuan</a>, <a >Zicheng Liu</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt>[340] arXiv:2108.10555 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: MIMO OFDM Dual-Function Radar-Communication Under Error Rate and Beampattern Constraints </div> <div > Authors: Jeremy Johnston, <a >Luca Venturino</a>, <a >Emanuele Grossi</a>, <a >Marco Lops</a>, <a >Xiaodong Wang</a> </div> <div > Comments: This work has been submitted to the IEEE Journal on Selected Areas in Communications for possible publication </div> <div > Subjects: Signal Processing (eess.SP); Information Theory (cs.IT) </div> </div> </dd> <dt>[341] arXiv:2109.02351 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Fair Federated Learning for Heterogeneous Face Data </div> <div > Authors: Samhita Kanaparthy, <a >Manisha Padala</a>, <a >Sankarshan Damle</a>, <a >Ravi Kiran Sarvadevabhatla</a>, <a >Sujit Gujar</a> </div> <div > Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY) </div> </div> </dd> <dt>[342] arXiv:2109.03188 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Optimizing Quantum Variational Circuits with Deep Reinforcement Learning </div> <div > Authors: Owen Lockwood </div> <div > Subjects: Machine Learning (cs.LG); Quantum Physics (quant-ph) </div> </div> </dd> <dt>[343] arXiv:2109.04330 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: On iterated interpolation </div> <div > Authors: Steffen Börm </div> <div > Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt>[344] arXiv:2109.04355 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Multi-sensor Joint Adaptive Birth Sampler for Labeled Random Finite Set Tracking </div> <div > Authors: Anthony Trezza, <a >Donald J. Bucci Jr.</a>, <a >Pramod K. Varshney</a> </div> <div > Comments: Submitted to IEEE Transactions on Signal Processing </div> <div > Subjects: Signal Processing (eess.SP); Systems and Control (eess.SY) </div> </div> </dd> <dt>[345] arXiv:2109.05573 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A Priority-Aware Replanning and Resequencing Framework for Coordination of Connected and Automated Vehicles </div> <div > Authors: Behdad Chalaki, <a >Andreas A. Malikopoulos</a> </div> <div > Comments: 6 pages, 4 figures </div> <div > Journal-ref: IEEE Control Systems Letters (2021) 1-6 </div> <div > Subjects: Systems and Control (eess.SY); Optimization and Control (math.OC) </div> </div> </dd> <dt>[346] arXiv:2109.06250 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: TTM: Terrain Traversability Mapping for Autonomous Excavators </div> <div > Authors: Tianrui Guan, <a >Zhenpeng He</a>, <a >Dinesh Manocha</a>, <a >Liangjun Zhang</a> </div> <div > Subjects: Robotics (cs.RO) </div> </div> </dd> <dt>[347] arXiv:2109.07193 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view Physical Adversarial Attack </div> <div > Authors: Donghua Wang, <a >Tingsong Jiang</a>, <a >Jialiang Sun</a>, <a >Weien Zhou</a>, <a >Xiaoya Zhang</a>, <a >Zhiqiang Gong</a>, <a >Wen Yao</a>, <a >Xiaoqian Chen</a> </div> <div > Comments: 9 pages, 5 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[348] arXiv:2109.08796 (replaced) [src]</dt> <dd> <div > <div > Title: Solar cell patent classification method based on keyword extraction and deep neural network </div> <div > Authors: Yongmin Yoo, <a >Dongjin Lim</a>, <a >Tak-Sung Heo</a> </div> <div > Comments: The content and quality of the thesis is too low, and the title and content have been changed and will be uploaded </div> <div > Subjects: Information Retrieval (cs.IR); Computation and Language (cs.CL) </div> </div> </dd> <dt>[349] arXiv:2109.12265 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Data-Assemble: Leveraging Multiple Datasets with Partial Labels </div> <div > Authors: Mintong Kang, <a >Yongyi Lu</a>, <a >Alan L. Yuille</a>, <a >Zongwei Zhou</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[350] arXiv:2109.14142 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: On the Provable Generalization of Recurrent Neural Networks </div> <div > Authors: Lifu Wang, <a >Bo Shen</a>, <a >Bo Hu</a>, <a >Xing Cao</a> </div> <div > Comments: Accepted to Neurips 2021, 29 pages. Some small typos have been fixed </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[351] arXiv:2110.03753 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness </div> <div > Authors: Lingxiao Zhao, <a >Wei Jin</a>, <a >Leman Akoglu</a>, <a >Neil Shah</a> </div> <div > Comments: Code is published! The version is updated extensively based on the reviewers' suggestions. Expressive GNN framework </div> <div > Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt>[352] arXiv:2110.04227 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows </div> <div > Authors: Michael Puthawala, <a >Matti Lassas</a>, <a >Ivan Dokmanić</a>, <a >Maarten de Hoop</a> </div> <div > Comments: 22 pages, 3 figures </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[353] arXiv:2110.07993 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Pose-guided Generative Adversarial Net for Novel View Action Synthesis </div> <div > Authors: Xianhang Li, <a >Junhao Zhang</a>, <a >Kunchang Li</a>, <a >Shruti Vyas</a>, <a >Yogesh S Rawat</a> </div> <div > Comments: Accepted by WACV2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[354] arXiv:2110.09396 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Streaming Machine Learning and Online Active Learning for Automated Visual Inspection </div> <div > Authors: Jože M. Rožanec, <a >Elena Trajkova</a>, <a >Paulien Dam</a>, <a >Blaž Fortuna</a>, <a >Dunja Mladenić</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> </div> </dd> <dt>[355] arXiv:2110.09554 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: TransFusion: Cross-view Fusion with Transformer for 3D Human Pose Estimation </div> <div > Authors: Haoyu Ma, <a >Liangjian Chen</a>, <a >Deying Kong</a>, <a >Zhe Wang</a>, <a >Xingwei Liu</a>, <a >Hao Tang</a>, <a >Xiangyi Yan</a>, <a >Yusheng Xie</a>, <a >Shih-Yao Lin</a>, <a >Xiaohui Xie</a> </div> <div > Comments: BMVC 2021. Code is available at: <a >this https URL</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[356] arXiv:2110.13632 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Generative Networks for Precision Enthusiasts </div> <div > Authors: Anja Butter, <a >Theo Heimel</a>, <a >Sander Hummerich</a>, <a >Tobias Krebs</a>, <a >Tilman Plehn</a>, <a >Armand Rousselot</a>, <a >Sophia Vent</a> </div> <div > Comments: 27 pages, 14 figures </div> <div > Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG) </div> </div> </dd> <dt>[357] arXiv:2110.15678 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis </div> <div > Authors: Xingang Pan, <a >Xudong Xu</a>, <a >Chen Change Loy</a>, <a >Christian Theobalt</a>, <a >Bo Dai</a> </div> <div > Comments: Accepted to NeurIPS2021. We proposed ShadeGAN, which could perform shape-accurate 3D-aware image synthesis by modeling shading in generative implicit models </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[358] arXiv:2111.00674 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Distilling Object Detectors with Feature Richness </div> <div > Authors: Zhixing Du, <a >Rui Zhang</a>, <a >Ming Chang</a>, <a >Xishan Zhang</a>, <a >Shaoli Liu</a>, <a >Tianshi Chen</a>, <a >Yunji Chen</a> </div> <div > Comments: Accepted in NeurIPS 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[359] arXiv:2111.00788 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Hierarchical Adaptable and Transferable Networks (HATN) for Driving Behavior Prediction </div> <div > Authors: Letian Wang, <a >Yeping Hu</a>, <a >Liting Sun</a>, <a >Wei Zhan</a>, <a >Masayoshi Tomizuka</a>, <a >Changliu Liu</a> </div> <div > Comments: 8 pages, 6 figures. Typo fixed. Accepted by Advances in Neural Information Processing Systems (NeurIPS 2021) Machine Learning for Autonomous Driving Workshop (ML4AD). October 2021 </div> <div > Subjects: Robotics (cs.RO) </div> </div> </dd> <dt>[360] arXiv:2111.01004 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Improving Contrastive Learning on Imbalanced Seed Data via Open-World Sampling </div> <div > Authors: Ziyu Jiang, <a >Tianlong Chen</a>, <a >Ting Chen</a>, <a >Zhangyang Wang</a> </div> <div > Comments: Neurips 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[361] arXiv:2111.01884 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Body Size and Depth Disambiguation in Multi-Person Reconstruction from Single Images </div> <div > Authors: Nicolas Ugrinovic, <a >Adria Ruiz</a>, <a >Antonio Agudo</a>, <a >Alberto Sanfeliu</a>, <a >Francesc Moreno-Noguer</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[362] arXiv:2111.04941 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Solving PDE-constrained Control Problems using Operator Learning </div> <div > Authors: Rakhoon Hwang, <a >Jae Yong Lee</a>, <a >Jin Young Shin</a>, <a >Hyung Ju Hwang</a> </div> <div > Comments: 15 pages, 12 figures. This paper is accepted to the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22) </div> <div > Subjects: Optimization and Control (math.OC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph) </div> </div> </dd> <dt>[363] arXiv:2111.05874 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A Hierarchy for Replica Quantum Advantage </div> <div > Authors: Sitan Chen, <a >Jordan Cotler</a>, <a >Hsin-Yuan Huang</a>, <a >Jerry Li</a> </div> <div > Comments: 3+17 pages, 2 figures; v2: typos fixed </div> <div > Subjects: Quantum Physics (quant-ph); Computational Complexity (cs.CC); Information Theory (cs.IT); Machine Learning (cs.LG) </div> </div> </dd> <dt>[364] arXiv:2111.06483 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Sequential Aggregation and Rematerialization: Distributed Full-batch Training of Graph Neural Networks on Large Graphs </div> <div > Authors: Hesham Mostafa </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[365] arXiv:2111.06741 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A Quantum Natural Language Processing Approach to Musical Intelligence </div> <div > Authors: Eduardo Reck Miranda, <a >Richie Yeung</a>, <a >Anna Pearson</a>, <a >Konstantinos Meichanetzidis</a>, <a >Bob Coecke</a> </div> <div > Comments: Pre-publication draft of a chapter to appear in Quantum Computer Music, E. R. Miranda (Ed.) </div> <div > Subjects: Quantum Physics (quant-ph); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[366] arXiv:2111.06931 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Solving A System Of Linear Equations By Randomized Orthogonal Projections </div> <div > Authors: Alireza Entezari, <a >Arunava Banerjee</a>, <a >Leila Kalantari</a> </div> <div > Subjects: Numerical Analysis (math.NA); Optimization and Control (math.OC) </div> </div> </dd> <dt>[367] arXiv:2111.07832 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: iBOT: Image BERT Pre-Training with Online Tokenizer </div> <div > Authors: Jinghao Zhou, <a >Chen Wei</a>, <a >Huiyu Wang</a>, <a >Wei Shen</a>, <a >Cihang Xie</a>, <a >Alan Yuille</a>, <a >Tao Kong</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[368] arXiv:2111.08162 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: On Bock's Conjecture Regarding the Adam Optimizer </div> <div > Authors: Mohamed Akrout, <a >Douglas Tweed</a> </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[369] arXiv:2111.09434 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: On the Effectiveness of Iterative Learning Control </div> <div > Authors: Anirudh Vemula, <a >Wen Sun</a>, <a >Maxim Likhachev</a>, <a >J. Andrew Bagnell</a> </div> <div > Comments: Submitted to L4DC 2022 </div> <div > Subjects: Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY) </div> </div> </dd> <dt>[370] arXiv:2111.09543 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing </div> <div > Authors: Pengcheng He, <a >Jianfeng Gao</a>, <a >Weizhu Chen</a> </div> <div > Comments: 16 pages, 10 tables, 2 Figures. The DeBERTaV3 model significantly improves performance of the downstream NLU tasks over models with a similar structure, e.g. DeBERTaV3 large achieves 91.37% average GLUE score which is 1.37% over DeBERTa large. XSmall has only 22M backbone parameters, but significantly outperforms RoBERTa/XLNet-base </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[371] arXiv:2111.10326 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Factorisation-based Image Labelling </div> <div > Authors: Yu Yan, <a >Yael Balbastre</a>, <a >Mikael Brudfors</a>, <a >John Ashburner</a> </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[372] arXiv:2111.11510 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Bootstrap Your Flow </div> <div > Authors: Laurence Illing Midgley, <a >Vincent Stimper</a>, <a >Gregor N. C. Simm</a>, <a >José Miguel Hernández-Lobato</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) </div> </div> </dd> <dt>[373] arXiv:2111.12243 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Vectorizing Sparse Matrix Codes with Dependency Driven Trace Analysis </div> <div > Authors: Zachary Cetinic, <a >Kazem Cheshmi</a>, <a >Maryam Mehri Dehnavi</a> </div> <div > Subjects: Programming Languages (cs.PL) </div> </div> </dd> <dt>[374] arXiv:2111.12555 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Serpens: A High Bandwidth Memory Based Accelerator for General-Purpose Sparse Matrix-Vector Multiplication </div> <div > Authors: Linghao Song, <a >Yuze Chi</a>, <a >Licheng Guo</a>, <a >Jason Cong</a> </div> <div > Subjects: Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt>[375] arXiv:2111.13436 (replaced) [pdf]</dt> <dd> <div > <div > Title: Towards a Secure and Reliable IT-Ecosystem in Seaports </div> <div > Authors: Tobias Brandt, <a >Dieter Hutter</a>, <a >Christian Maeder</a>, <a >Rainer Müller</a> </div> <div > Comments: Presented at the 29th Conference of the International Association of Maritime Economists, Rotterdam, November 2021 </div> <div > Subjects: Cryptography and Security (cs.CR) </div> </div> </dd> <dt>[376] arXiv:2111.13579 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: VL-LTR: Learning Class-wise Visual-Linguistic Representation for Long-Tailed Visual Recognition </div> <div > Authors: Changyao Tian, <a >Wenhai Wang</a>, <a >Xizhou Zhu</a>, <a >Xiaogang Wang</a>, <a >Jifeng Dai</a>, <a >Yu Qiao</a> </div> <div > Comments: Technical report; 14 pages, 9 figures </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[377] arXiv:2111.13755 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: A survey on multi-objective hyperparameter optimization algorithms for Machine Learning </div> <div > Authors: Alejandro Morales-Hernández, <a >Inneke Van Nieuwenhuyse</a>, <a >Sebastian Rojas Gonzalez</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC) </div> </div> </dd> <dt>[378] arXiv:2111.14259 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: 3D High-Quality Magnetic Resonance Image Restoration in Clinics Using Deep Learning </div> <div > Authors: Hao Li, <a >Jianan Liu</a> </div> <div > Comments: 14 pages, 8 figures </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph) </div> </div> </dd> <dt>[379] arXiv:2111.14301 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: PSG: Prompt-based Sequence Generation for Acronym Extraction </div> <div > Authors: Bin Li, <a >Fei Xia</a>, <a >Yixuan Weng</a>, <a >Xiusheng Huang</a>, <a >Bin Sun</a>, <a >Shutao Li</a> </div> <div > Comments: Accepted for Artificial Intelligence on Scientific Document Understanding (SDU) workshop at AAAI 2022 </div> <div > Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[380] arXiv:2111.14306 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: SimCLAD: A Simple Framework for Contrastive Learning of Acronym Disambiguation </div> <div > Authors: Bin Li, <a >Fei Xia</a>, <a >Yixuan Weng</a>, <a >Xiusheng Huang</a>, <a >Bin Sun</a> </div> <div > Comments: Accepted for Artificial Intelligence on Scientific Document Understanding (SDU) workshop at AAAI 2022 </div> <div > Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[381] arXiv:2111.14385 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: A theory of meta-factorization </div> <div > Authors: Michał P. Karpowicz </div> <div > Comments: Added references in section Related work </div> <div > Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt>[382] arXiv:2111.14592 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection </div> <div > Authors: Wanwei He, <a >Yinpei Dai</a>, <a >Yinhe Zheng</a>, <a >Yuchuan Wu</a>, <a >Zheng Cao</a>, <a >Dermot Liu</a>, <a >Peng Jiang</a>, <a >Min Yang</a>, <a >Fei Huang</a>, <a >Luo Si</a>, <a >Jian Sun</a>, <a >Yongbin Li</a> </div> <div > Comments: 7 pages, 5 figures. Accepted by AAAI 2022 </div> <div > Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt>[383] arXiv:2111.14788 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Function Approximation for High-Energy Physics: Comparing Machine Learning and Interpolation Methods </div> <div > Authors: Ibrahim Chahrour, <a >James D. Wells</a> </div> <div > Comments: 30 pages, 17 figures, added a few references </div> <div > Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG) </div> </div> </dd> <dt>[384] arXiv:2111.15438 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: FMD-cGAN: Fast Motion Deblurring using Conditional Generative Adversarial Networks </div> <div > Authors: Jatin Kumar, <a >Indra Deep Mastan</a>, <a >Shanmuganathan Raman</a> </div> <div > Comments: International Conference on Computer Vision and Image Processing 2021 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> </div> </dd> <dt>[385] arXiv:2111.15518 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Detecting Adversaries, yet Faltering to Noise? Leveraging Conditional Variational AutoEncoders for Adversary Detection in the Presence of Noisy Images </div> <div > Authors: Dvij Kalaria, <a >Aritra Hazra</a>, <a >Partha Pratim Chakrabarti</a> </div> <div > Comments: Accepted at Adversarial Machine Learning (AdvML) workshop, AAAI 2022 </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[386] arXiv:2112.00503 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence Dependency Graph </div> <div > Authors: Liyan Xu, <a >Xuchao Zhang</a>, <a >Bo Zong</a>, <a >Yanchi Liu</a>, <a >Wei Cheng</a>, <a >Jingchao Ni</a>, <a >Haifeng Chen</a>, <a >Liang Zhao</a>, <a >Jinho D. Choi</a> </div> <div > Comments: Accepted to AAAI 2022 </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[387] arXiv:2112.00702 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Semi-supervised music emotion recognition using noisy student training and harmonic pitch class profiles </div> <div > Authors: Hao Hao Tan </div> <div > Comments: MediaEval 2021 submission for Emotion and Themes in Music </div> <div > Subjects: Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS) </div> </div> </dd> <dt>[388] arXiv:2112.00828 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: The Price of Differential Privacy under Continual Observation </div> <div > Authors: Palak Jain, Sofya Raskhodnikova, <a >Satchit Sivakumar</a>, <a >Adam Smith</a> </div> <div > Comments: 28 pages </div> <div > Subjects: Data Structures and Algorithms (cs.DS); Cryptography and Security (cs.CR) </div> </div> </dd> <dt>[389] arXiv:2112.01030 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: TransMEF: A Transformer-Based Multi-Exposure Image Fusion Framework using Self-Supervised Multi-Task Learning </div> <div > Authors: Linhao Qu, <a >Shaolei Liu</a>, <a >Manning Wang</a>, <a >Zhijian Song</a> </div> <div > Comments: Accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI2022) </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[390] arXiv:2112.01332 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Towards Generating Citation Sentences for Multiple References with Intent Control </div> <div > Authors: Jia-Yan Wu, <a >Alexander Te-Wei Shieh</a>, <a >Shih-Ju Hsu</a>, <a >Yun-Nung Chen</a> </div> <div > Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt>[391] arXiv:2112.01476 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: KPDrop: An Approach to Improving Absent Keyphrase Generation </div> <div > Authors: Seoyeon Park, <a >Jishnu Ray Chowdhury</a>, <a >Tuhin Kundu</a>, <a >Cornelia Caragea</a> </div> <div > Comments: 4 pages, 1 Figure </div> <div > Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt>[392] arXiv:2112.01513 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: OW-DETR: Open-world Detection Transformer </div> <div > Authors: Akshita Gupta, <a >Sanath Narayan</a>, <a >K J Joseph</a>, <a >Salman Khan</a>, <a >Fahad Shahbaz Khan</a>, <a >Mubarak Shah</a> </div> <div > Comments: 15 pages </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[393] arXiv:2112.02646 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Diverse, Global and Amortised Counterfactual Explanations for Uncertainty Estimates </div> <div > Authors: Dan Ley, <a >Umang Bhatt</a>, <a >Adrian Weller</a> </div> <div > Comments: Accepted as a conference paper to AAAI 2022 </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML) </div> </div> </dd> <dt>[394] arXiv:2112.02864 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Autoencoders for Semivisible Jet Detection </div> <div > Authors: Florencia Canelli, <a >Annapaola de Cosa</a>, <a >Luc Le Pottier</a>, <a >Jeremi Niedziela</a>, <a >Kevin Pedro</a>, <a >Maurizio Pierini</a> </div> <div > Comments: 16 pages, 10 figures </div> <div > Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex) </div> </div> </dd> <dt>[395] arXiv:2112.03378 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Differentiable Generalised Predictive Coding </div> <div > Authors: André Ofner, <a >Sebastian Stober</a> </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE) </div> </div> </dd> <dt>[396] arXiv:2112.03462 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: SpaceSaving$^\pm$: An Optimal Algorithm for Frequency Estimation and Frequent items in the Bounded Deletion Model </div> <div > Authors: Fuheng Zhao, <a >Divyakant Agrawal</a>, <a >Amr El Abbadi</a>, <a >Ahmed Metwally</a> </div> <div > Subjects: Databases (cs.DB); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt>[397] arXiv:2112.03552 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training </div> <div > Authors: Haofei Zhang, <a >Jiarui Duan</a>, <a >Mengqi Xue</a>, <a >Jie Song</a>, <a >Li Sun</a>, <a >Mingli Song</a> </div> <div > Comments: 10 Pages </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[398] arXiv:2112.03562 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: CMA-CLIP: Cross-Modality Attention CLIP for Image-Text Classification </div> <div > Authors: Huidong Liu, <a >Shaoyuan Xu</a>, <a >Jinmiao Fu</a>, <a >Yang Liu</a>, <a >Ning Xie</a>, <a >Chien-Chih Wang</a>, <a >Bryan Wang</a>, <a >Yi Sun</a> </div> <div > Comments: 9 pages, 2 figures, 6 tables, 1 algorithm </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[399] arXiv:2112.03665 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Data-Driven Controllability Analysis and Stabilization for Linear Descriptor Systems </div> <div > Authors: Jiabao He, <a >Xuan Zhang</a>, <a >Feng Xu</a>, <a >Xueqian Wang</a> </div> <div > Subjects: Systems and Control (eess.SY) </div> </div> </dd> <dt>[400] arXiv:2112.03807 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: raceBERT -- A Transformer-based Model for Predicting Race and Ethnicity from Names </div> <div > Authors: Prasanna Parasurama </div> <div > Comments: See this http URL </div> <div > Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[401] arXiv:2112.04046 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Asymptotic MIMO Channel Model for Diffusive MC with Fully-absorbing Receivers </div> <div > Authors: Fardad Vakilipoor, <a >Marco Ferrari</a>, <a >Maurizio Magarini</a> </div> <div > Subjects: Information Theory (cs.IT) </div> </div> </dd> <dt>[402] arXiv:2112.04137 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Pareto Domain Adaptation </div> <div > Authors: Fangrui Lv, <a >Jian Liang</a>, <a >Kaixiong Gong</a>, <a >Shuang Li</a>, <a >Chi Harold Liu</a>, <a >Han Li</a>, <a >Di Liu</a>, <a >Guoren Wang</a> </div> <div > Comments: Accepted in NeurIPS 2021 </div> <div > Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt>[403] arXiv:2112.04138 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Contrastive Instruction-Trajectory Learning for Vision-Language Navigation </div> <div > Authors: Xiwen Liang, <a >Fengda Zhu</a>, <a >Yi Zhu</a>, <a >Bingqian Lin</a>, <a >Bing Wang</a>, <a >Xiaodan Liang</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt>[404] arXiv:2112.04169 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Equity Promotion in Online Resource Allocation </div> <div > Authors: Pan Xu, <a >Yifan Xu</a> </div> <div > Comments: A preliminary version will appear in the 36th AAAI Conference on Artificial Intelligence (AAAI 22) </div> <div > Subjects: Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt>[405] arXiv:2112.04178 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Topology-aware Convolutional Neural Network for Efficient Skeleton-based Action Recognition </div> <div > Authors: Kailin Xu, <a >Fanfan Ye</a>, <a >Qiaoyong Zhong</a>, <a >Di Xie</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt>[406] arXiv:2112.04274 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: On the Use of Unrealistic Predictions in Hundreds of Papers Evaluating Graph Representations </div> <div > Authors: Li-Chung Lin, <a >Cheng-Hung Liu</a>, <a >Chih-Ming Chen</a>, <a >Kai-Chin Hsu</a>, <a >I-Feng Wu</a>, <a >Ming-Feng Tsai</a>, <a >Chih-Jen Lin</a> </div> <div > Comments: Accepted by AAAI 2022 </div> <div > Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt>[407] arXiv:2112.04324 (replaced) [pdf, ps, other]</dt> <dd> <div > <div > Title: Deep Learning and Mathematical Intuition: A Review of (Davies et al. 2021) </div> <div > Authors: Ernest Davis </div> <div > Subjects: Machine Learning (cs.LG); History and Overview (math.HO) </div> </div> </dd> <dt>[408] arXiv:2112.04386 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Which images to label for few-shot medical landmark detection? </div> <div > Authors: Quan Quan, <a >Qingsong Yao</a>, <a >Jun Li</a>, <a >S. Kevin Zhou</a> </div> <div > Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt>[409] arXiv:2112.04405 (replaced) [pdf, other]</dt> <dd> <div > <div > Title: Improved Distributed Fractional Coloring Algorithms </div> <div > Authors: Alkida Balliu, <a >Fabian Kuhn</a>, <a >Dennis Olivetti</a> </div> <div > Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> </dl> <ul> <li>New submissions</li> <li><a >Cross-lists</a></li> <li><a >Replacements</a></li> </ul> <small>[ total of 409 entries: <b>1-409</b> ]</small> <small>[ showing up to 2000 entries per page: <a >fewer</a> | <font >more</font> ]</small> </div> <small><a >Disable MathJax</a> (<a >What is MathJax?</a>)</small> <p>Links to: <a >arXiv</a>, <a >form interface</a>, <a >find</a>, <a >cs</a>, <a >recent</a>, <a >2112</a>, <a >contact</a>, <a >help</a> <small>(<a >Access key</a> information)</small> </p> </div> </body>'</script>

      </head>
        <body class="valid" valid="valid" title="valid: True, node: 1, level: 1" node_number="1"> <div class="valid" valid="valid" title="valid: True, node: 2, level: 2" node_number="2"> <div class="valid" valid="valid" title="valid: True, node: 3, level: 3" node_number="3"> <a class="valid" valid="valid" title="valid: True, node: 4, level: 4" node_number="4">We gratefully acknowledge support from the Simons Foundation and member institutions.</a> </div> </div> <div class="valid" valid="valid" title="valid: True, node: 5, level: 2" node_number="5"> <h1 class="valid" valid="valid" title="valid: True, node: 6, level: 3" node_number="6"><a class="valid" valid="valid" title="valid: True, node: 7, level: 4" node_number="7">arXiv.org</a> &gt; <a class="valid" valid="valid" title="valid: True, node: 8, level: 4" node_number="8">cs</a></h1> </div> <div class="valid" valid="valid" title="valid: True, node: 9, level: 2" node_number="9"> <div class="valid" valid="valid" title="valid: True, node: 10, level: 3" node_number="10"> <h1 class="valid" valid="valid" title="valid: True, node: 11, level: 4" node_number="11">Computer Science </h1> <h2 class="valid" valid="valid" title="valid: True, node: 12, level: 4" node_number="12">New submissions</h2> <div class="valid" valid="valid" title="valid: True, node: 13, level: 4" node_number="13">Submissions received from Wed 8 Dec 21 to Thu 9 Dec 21, announced Fri, 10 Dec 21</div> <ul class="valid" valid="valid" title="valid: True, node: 14, level: 4" node_number="14"> <li class="valid" valid="valid" title="valid: True, node: 15, level: 5" node_number="15"><a class="valid" valid="valid" title="valid: True, node: 16, level: 6" node_number="16">New submissions</a></li> <li class="valid" valid="valid" title="valid: True, node: 17, level: 5" node_number="17"><a class="valid" valid="valid" title="valid: True, node: 18, level: 6" node_number="18">Cross-lists</a></li> <li class="valid" valid="valid" title="valid: True, node: 19, level: 5" node_number="19"><a class="valid" valid="valid" title="valid: True, node: 20, level: 6" node_number="20">Replacements</a></li> </ul> <small class="valid" valid="valid" title="valid: True, node: 21, level: 4" node_number="21">[ total of 409 entries: <b class="valid" valid="valid" title="valid: True, node: 22, level: 5" node_number="22">1-409</b> ]</small> <small class="valid" valid="valid" title="valid: True, node: 23, level: 4" node_number="23">[ showing up to 2000 entries per page: <a class="valid" valid="valid" title="valid: True, node: 24, level: 5" node_number="24">fewer</a> | <font class="valid" valid="valid" title="valid: True, node: 25, level: 5" node_number="25">more</font> ]</small> <h3 class="valid" valid="valid" title="valid: True, node: 26, level: 4" node_number="26">New submissions for Fri, 10 Dec 21</h3> <dl class="valid" valid="valid" title="valid: True, node: 27, level: 4" node_number="27"> <dt class="valid" valid="valid" title="valid: True, node: 28, level: 5" node_number="28"><a class="valid" valid="valid" title="valid: True, node: 29, level: 6" node_number="29">[1]</a> arXiv:2112.04492 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 30, level: 5" node_number="30"> <div class="valid" valid="valid" title="valid: True, node: 31, level: 6" node_number="31"> <div class="valid" valid="valid" title="valid: True, node: 32, level: 7" node_number="32"> Title: Daily peak electrical load forecasting with a multi-resolution approach </div> <div class="valid" valid="valid" title="valid: True, node: 33, level: 7" node_number="33"> Authors: Yvenn Amara-Ouali, <a class="valid" valid="valid" title="valid: True, node: 34, level: 8" node_number="34">Matteo Fasiolo</a>, <a class="valid" valid="valid" title="valid: True, node: 35, level: 8" node_number="35">Yannig Goude</a>, <a class="valid" valid="valid" title="valid: True, node: 36, level: 8" node_number="36">Hui Yan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 37, level: 7" node_number="37"> Subjects: Machine Learning (cs.LG); Methodology (stat.ME) </div> <p class="valid" valid="valid" title="valid: True, node: 38, level: 7" node_number="38">In the context of smart grids and load balancing, daily peak load forecasting has become a critical activity for stakeholders of the energy industry. An understanding of peak magnitude and timing is paramount for the implementation of smart grid strategies such as peak shaving. The modelling approach proposed in this paper leverages high-resolution and low-resolution information to forecast daily peak demand size and timing. The resulting multi-resolution modelling framework can be adapted to different model classes. The key contributions of this paper are a) a general and formal introduction to the multi-resolution modelling approach, b) a discussion on modelling approaches at different resolutions implemented via Generalised Additive Models and Neural Networks and c) experimental results on real data from the UK electricity market. The results confirm that the predictive performance of the proposed modelling approach is competitive with that of low- and high-resolution alternatives. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 39, level: 5" node_number="39">[2] arXiv:2112.04494 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 40, level: 5" node_number="40"> <div class="valid" valid="valid" title="valid: True, node: 41, level: 6" node_number="41"> <div class="valid" valid="valid" title="valid: True, node: 42, level: 7" node_number="42"> Title: Deep Q-Learning Market Makers in a Multi-Agent Simulated Stock Market </div> <div class="valid" valid="valid" title="valid: True, node: 43, level: 7" node_number="43"> Authors: Oscar Fern&#225;ndez Vicente, <a class="valid" valid="valid" title="valid: True, node: 44, level: 8" node_number="44">Fernando Fern&#225;ndez Rebollo</a>, <a class="valid" valid="valid" title="valid: True, node: 45, level: 8" node_number="45">Francisco Javier Garc&#237;a Polo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 46, level: 7" node_number="46"> Comments: Presented at 2nd ACM International Conference on AI in Finance </div> <div class="valid" valid="valid" title="valid: True, node: 47, level: 7" node_number="47"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 48, level: 7" node_number="48">Market makers play a key role in financial markets by providing liquidity. They usually fill order books with buy and sell limit orders in order to provide traders alternative price levels to operate. This paper focuses precisely on the study of these markets makers strategies from an agent-based perspective. In particular, we propose the application of Reinforcement Learning (RL) for the creation of intelligent market markers in simulated stock markets. This research analyzes how RL market maker agents behaves in non-competitive (only one RL market maker learning at the same time) and competitive scenarios (multiple RL market markers learning at the same time), and how they adapt their strategies in a Sim2Real scope with interesting results. Furthermore, it covers the application of policy transfer between different experiments, describing the impact of competing environments on RL agents performance. RL and deep RL techniques are proven as profitable market maker approaches, leading to a better understanding of their behavior in stock markets. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 49, level: 5" node_number="49">[3] arXiv:2112.04497 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 50, level: 5" node_number="50"> <div class="valid" valid="valid" title="valid: True, node: 51, level: 6" node_number="51"> <div class="valid" valid="valid" title="valid: True, node: 52, level: 7" node_number="52"> Title: SIRfyN: Single Image Relighting from your Neighbors </div> <div class="valid" valid="valid" title="valid: True, node: 53, level: 7" node_number="53"> Authors: D.A. Forsyth, <a class="valid" valid="valid" title="valid: True, node: 54, level: 8" node_number="54">Anand Bhattad</a>, <a class="valid" valid="valid" title="valid: True, node: 55, level: 8" node_number="55">Pranav Asthana</a>, <a class="valid" valid="valid" title="valid: True, node: 56, level: 8" node_number="56">Yuanyi Zhong</a>, <a class="valid" valid="valid" title="valid: True, node: 57, level: 8" node_number="57">Yuxiong Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 58, level: 7" node_number="58"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 59, level: 7" node_number="59">We show how to relight a scene, depicted in a single image, such that (a) the overall shading has changed and (b) the resulting image looks like a natural image of that scene. Applications for such a procedure include generating training data and building authoring environments. Naive methods for doing this fail. One reason is that shading and albedo are quite strongly related; for example, sharp boundaries in shading tend to appear at depth discontinuities, which usually apparent in albedo. The same scene can be lit in different ways, and established theory shows the different lightings form a cone (the illumination cone). Novel theory shows that one can use similar scenes to estimate the different lightings that apply to a given scene, with bounded expected error. Our method exploits this theory to estimate a representation of the available lighting fields in the form of imputed generators of the illumination cone. Our procedure does not require expensive "inverse graphics" datasets, and sees no ground truth data of any kind. Qualitative evaluation suggests the method can erase and restore soft indoor shadows, and can "steer" light around a scene. We offer a summary quantitative evaluation of the method with a novel application of the FID. An extension of the FID allows per-generated-image evaluation. Furthermore, we offer qualitative evaluation with a user study, and show that our method produces images that can successfully be used for data augmentation. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 60, level: 5" node_number="60">[4] arXiv:2112.04532 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 61, level: 5" node_number="61"> <div class="valid" valid="valid" title="valid: True, node: 62, level: 6" node_number="62"> <div class="valid" valid="valid" title="valid: True, node: 63, level: 7" node_number="63"> Title: Segment and Complete: Defending Object Detectors against Adversarial Patch Attacks with Robust Patch Detection </div> <div class="valid" valid="valid" title="valid: True, node: 64, level: 7" node_number="64"> Authors: Jiang Liu, <a class="valid" valid="valid" title="valid: True, node: 65, level: 8" node_number="65">Alexander Levine</a>, <a class="valid" valid="valid" title="valid: True, node: 66, level: 8" node_number="66">Chun Pong Lau</a>, <a class="valid" valid="valid" title="valid: True, node: 67, level: 8" node_number="67">Rama Chellappa</a>, <a class="valid" valid="valid" title="valid: True, node: 68, level: 8" node_number="68">Soheil Feizi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 69, level: 7" node_number="69"> Comments: Under submission </div> <div class="valid" valid="valid" title="valid: True, node: 70, level: 7" node_number="70"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p class="valid" valid="valid" title="valid: True, node: 71, level: 7" node_number="71">Object detection plays a key role in many security-critical systems. Adversarial patch attacks, which are easy to implement in the physical world, pose a serious threat to state-of-the-art object detectors. Developing reliable defenses for object detectors against patch attacks is critical but severely understudied. In this paper, we propose Segment and Complete defense (SAC), a general framework for defending object detectors against patch attacks through detecting and removing adversarial patches. We first train a patch segmenter that outputs patch masks that provide pixel-level localization of adversarial patches. We then propose a self adversarial training algorithm to robustify the patch segmenter. In addition, we design a robust shape completion algorithm, which is guaranteed to remove the entire patch from the images given the outputs of the patch segmenter are within a certain Hamming distance of the ground-truth patch masks. Our experiments on COCO and xView datasets demonstrate that SAC achieves superior robustness even under strong adaptive attacks with no performance drop on clean images, and generalizes well to unseen patch shapes, attack budgets, and unseen attack methods. Furthermore, we present the APRICOT-Mask dataset, which augments the APRICOT dataset with pixel-level annotations of adversarial patches. We show SAC can significantly reduce the targeted attack success rate of physical patch attacks. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 72, level: 5" node_number="72">[5] arXiv:2112.04536 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 73, level: 5" node_number="73"> <div class="valid" valid="valid" title="valid: True, node: 74, level: 6" node_number="74"> <div class="valid" valid="valid" title="valid: True, node: 75, level: 7" node_number="75"> Title: Adaptive CLF-MPC With Application To Quadrupedal Robots </div> <div class="valid" valid="valid" title="valid: True, node: 76, level: 7" node_number="76"> Authors: Maria Vittoria Minniti, <a class="valid" valid="valid" title="valid: True, node: 77, level: 8" node_number="77">Ruben Grandia</a>, <a class="valid" valid="valid" title="valid: True, node: 78, level: 8" node_number="78">Farbod Farshidian</a>, <a class="valid" valid="valid" title="valid: True, node: 79, level: 8" node_number="79">Marco Hutter</a> </div> <div class="valid" valid="valid" title="valid: True, node: 80, level: 7" node_number="80"> Journal-ref: IEEE Robotics and Automation Letters (Volume: 7, Issue: 1, Jan. 2022) </div> <div class="valid" valid="valid" title="valid: True, node: 81, level: 7" node_number="81"> Subjects: Robotics (cs.RO); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 82, level: 7" node_number="82">Modern robotic systems are endowed with superior mobility and mechanical skills that make them suited to be employed in real-world scenarios, where interactions with heavy objects and precise manipulation capabilities are required. For instance, legged robots with high payload capacity can be used in disaster scenarios to remove dangerous material or carry injured people. It is thus essential to develop planning algorithms that can enable complex robots to perform motion and manipulation tasks accurately. In addition, online adaptation mechanisms with respect to new, unknown environments are needed. In this work, we impose that the optimal state-input trajectories generated by Model Predictive Control (MPC) satisfy the Lyapunov function criterion derived in adaptive control for robotic systems. As a result, we combine the stability guarantees provided by Control Lyapunov Functions (CLFs) and the optimality offered by MPC in a unified adaptive framework, yielding an improved performance during the robot's interaction with unknown objects. We validate the proposed approach in simulation and hardware tests on a quadrupedal robot carrying un-modeled payloads and pulling heavy boxes. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 83, level: 5" node_number="83">[6] arXiv:2112.04539 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 84, level: 5" node_number="84"> <div class="valid" valid="valid" title="valid: True, node: 85, level: 6" node_number="85"> <div class="valid" valid="valid" title="valid: True, node: 86, level: 7" node_number="86"> Title: Prompt-based Zero-shot Relation Classification with Semantic Knowledge Augmentation </div> <div class="valid" valid="valid" title="valid: True, node: 87, level: 7" node_number="87"> Authors: Jiaying Gong, <a class="valid" valid="valid" title="valid: True, node: 88, level: 8" node_number="88">Hoda Eldardiry</a> </div> <div class="valid" valid="valid" title="valid: True, node: 89, level: 7" node_number="89"> Comments: 11 pages, 7 figures </div> <div class="valid" valid="valid" title="valid: True, node: 90, level: 7" node_number="90"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 91, level: 7" node_number="91">Recognizing unseen relations with no training instances is a challenging task in the real world. In this paper, we propose a prompt-based model with semantic knowledge augmentation (ZS-SKA) to recognize unseen relations under the zero-shot setting. We generate augmented instances with unseen relations from instances with seen relations following a new word-level sentence translation rule. We design prompts based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. Instead of using the actual label sets in the prompt template, we construct weighted virtual label words. By generating the representations of both seen and unseen relations with augmented instances and prompts through prototypical networks, distance is calculated to predict unseen relations. Extensive experiments conducted on three public datasets show that ZS-SKA outperforms state-of-the-art methods under the zero-shot scenarios. Our experimental results also demonstrate the effectiveness and robustness of ZS-SKA. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 92, level: 5" node_number="92">[7] arXiv:2112.04540 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 93, level: 5" node_number="93"> <div class="valid" valid="valid" title="valid: True, node: 94, level: 6" node_number="94"> <div class="valid" valid="valid" title="valid: True, node: 95, level: 7" node_number="95"> Title: Two-grid $hp$-version discontinuous Galerkin finite element methods for quasilinear elliptic PDEs on agglomerated coarse meshes </div> <div class="valid" valid="valid" title="valid: True, node: 96, level: 7" node_number="96"> Authors: Scott Congreve, <a class="valid" valid="valid" title="valid: True, node: 97, level: 8" node_number="97">Paul Houston</a> </div> <div class="valid" valid="valid" title="valid: True, node: 98, level: 7" node_number="98"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 99, level: 7" node_number="99">This article considers the extension of two-grid $hp$-version discontinuous Galerkin finite element methods for the numerical approximation of second-order quasilinear elliptic boundary value problems of monotone type to the case when agglomerated polygonal/polyhedral meshes are employed for the coarse mesh approximation. We recall that within the two-grid setting, while it is necessary to solve a nonlinear problem on the coarse approximation space, only a linear problem must be computed on the original fine finite element space. In this article, the coarse space will be constructed by agglomerating elements from the original fine mesh. Here, we extend the existing a priori and a posteriori error analysis for the two-grid $hp$-version discontinuous Galerkin finite element method from 10.1007/s10915-012-9644-1 for coarse meshes consisting of standard element shapes to include arbitrarily agglomerated coarse grids. Moreover, we develop an $hp$-adaptive two-grid algorithm to adaptively design the fine and coarse finite element spaces; we stress that this is undertaken in a fully automatic manner, and hence can be viewed as blackbox solver. Numerical experiments are presented for two- and three-dimensional problems to demonstrate the computational performance of the proposed $hp$-adaptive two-grid method. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 100, level: 5" node_number="100">[8] arXiv:2112.04548 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 101, level: 5" node_number="101"> <div class="valid" valid="valid" title="valid: True, node: 102, level: 6" node_number="102"> <div class="valid" valid="valid" title="valid: True, node: 103, level: 7" node_number="103"> Title: Relaxation of condition for convergence of dynamic regressor extension and mixing procedure </div> <div class="valid" valid="valid" title="valid: True, node: 104, level: 7" node_number="104"> Authors: Anton Glushchenko, <a class="valid" valid="valid" title="valid: True, node: 105, level: 8" node_number="105">Konstantin Lastochkin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 106, level: 7" node_number="106"> Comments: 17 pages. In Russian </div> <div class="valid" valid="valid" title="valid: True, node: 107, level: 7" node_number="107"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 108, level: 7" node_number="108">A generalization of the dynamic regressor extension and mixing procedure is proposed. First of all, it relaxes the requirement of the regressor finite excitation, which is known to be the condition for the mentioned procedure convergence. Secondly, if the weaker requirement of the regressor semi-finite-excitation is met, it guarantees the uniform ultimate boundedness of the parameter error and elementwise monotonicity for transients of some parameters to be identified. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 109, level: 5" node_number="109">[9] arXiv:2112.04549 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 110, level: 5" node_number="110"> <div class="valid" valid="valid" title="valid: True, node: 111, level: 6" node_number="111"> <div class="valid" valid="valid" title="valid: True, node: 112, level: 7" node_number="112"> Title: A Simple Algorithm for Graph Reconstruction </div> <div class="valid" valid="valid" title="valid: True, node: 113, level: 7" node_number="113"> Authors: Claire Mathieu, <a class="valid" valid="valid" title="valid: True, node: 114, level: 8" node_number="114">Hang Zhou</a> </div> <div class="valid" valid="valid" title="valid: True, node: 115, level: 7" node_number="115"> Subjects: Data Structures and Algorithms (cs.DS) </div> <p class="valid" valid="valid" title="valid: True, node: 116, level: 7" node_number="116">How efficiently can we find an unknown graph using distance queries between its vertices? We assume that the unknown graph is connected, unweighted, and has bounded degree. The goal is to find every edge in the graph. This problem admits a reconstruction algorithm based on multi-phase Voronoi-cell decomposition and using $ilde O(n^{3/2})$ distance queries. In our work, we analyze a simple reconstruction algorithm. We show that, on random $\Delta$-regular graphs, our algorithm uses $ilde O(n)$ distance queries. As by-products, we can reconstruct those graphs using $O(\log^2 n)$ queries to an all-distances oracle or $ilde O(n)$ queries to a betweenness oracle, and we bound the metric dimension of those graphs by $\log^2 n$. Our reconstruction algorithm has a very simple structure, and is highly parallelizable. On general graphs of bounded degree, our reconstruction algorithm has subquadratic query complexity. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 117, level: 5" node_number="117">[10] arXiv:2112.04550 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 118, level: 5" node_number="118"> <div class="valid" valid="valid" title="valid: True, node: 119, level: 6" node_number="119"> <div class="valid" valid="valid" title="valid: True, node: 120, level: 7" node_number="120"> Title: NOMA Empowered Integrated Sensing and Communication </div> <div class="valid" valid="valid" title="valid: True, node: 121, level: 7" node_number="121"> Authors: Zhaolin Wang, <a class="valid" valid="valid" title="valid: True, node: 122, level: 8" node_number="122">Yuanwei Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 123, level: 8" node_number="123">Xidong Mu</a>, <a class="valid" valid="valid" title="valid: True, node: 124, level: 8" node_number="124">Zhiguo Ding</a>, <a class="valid" valid="valid" title="valid: True, node: 125, level: 8" node_number="125">Octavia A. Dobre</a> </div> <div class="valid" valid="valid" title="valid: True, node: 126, level: 7" node_number="126"> Comments: 11 pages, 2 figures </div> <div class="valid" valid="valid" title="valid: True, node: 127, level: 7" node_number="127"> Subjects: Information Theory (cs.IT) </div> <p class="valid" valid="valid" title="valid: True, node: 128, level: 7" node_number="128">A non-orthogonal multiple access (NOMA) empowered integrated sensing and communication (ISAC) framework is investigated. A dual-functional base station serves multiple communication users employing NOMA, while the superimposed NOMA communication signal is simultaneously exploited for target sensing. A beamforming design problem is formulated to maximize the weighted sum of the communication throughput and the effective sensing power. To solve this problem, an efficient double-layer penalty-based algorithm is proposed by invoking successive convex approximation (SCA). Numerical results show that the proposed NOMA-ISAC approaches the ideal ISAC system and outperforms the conventional ISAC in the underloaded regime experiencing high-correlated channels and in the overloaded regime. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 129, level: 5" node_number="129">[11] arXiv:2112.04552 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 130, level: 5" node_number="130"> <div class="valid" valid="valid" title="valid: True, node: 131, level: 6" node_number="131"> <div class="valid" valid="valid" title="valid: True, node: 132, level: 7" node_number="132"> Title: PATO: Producibility-Aware Topology Optimization using Deep Learning for Metal Additive Manufacturing </div> <div class="valid" valid="valid" title="valid: True, node: 133, level: 7" node_number="133"> Authors: Naresh S. Iyer, <a class="valid" valid="valid" title="valid: True, node: 134, level: 8" node_number="134">Amir M. Mirzendehdel</a>, <a class="valid" valid="valid" title="valid: True, node: 135, level: 8" node_number="135">Sathyanarayanan Raghavan</a>, <a class="valid" valid="valid" title="valid: True, node: 136, level: 8" node_number="136">Yang Jiao</a>, <a class="valid" valid="valid" title="valid: True, node: 137, level: 8" node_number="137">Erva Ulu</a>, <a class="valid" valid="valid" title="valid: True, node: 138, level: 8" node_number="138">Morad Behandish</a>, <a class="valid" valid="valid" title="valid: True, node: 139, level: 8" node_number="139">Saigopal Nelaturi</a>, <a class="valid" valid="valid" title="valid: True, node: 140, level: 8" node_number="140">Dean M. Robinson</a> </div> <div class="valid" valid="valid" title="valid: True, node: 141, level: 7" node_number="141"> Subjects: Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 142, level: 7" node_number="142">In this paper, we propose PATO-a producibility-aware topology optimization (TO) framework to help efficiently explore the design space of components fabricated using metal additive manufacturing (AM), while ensuring manufacturability with respect to cracking. Specifically, parts fabricated through Laser Powder Bed Fusion are prone to defects such as warpage or cracking due to high residual stress values generated from the steep thermal gradients produced during the build process. Maturing the design for such parts and planning their fabrication can span months to years, often involving multiple handoffs between design and manufacturing engineers. PATO is based on the a priori discovery of crack-free designs, so that the optimized part can be built defect-free at the outset. To ensure that the design is crack free during optimization, producibility is explicitly encoded within the standard formulation of TO, using a crack index. Multiple crack indices are explored and using experimental validation, maximum shear strain index (MSSI) is shown to be an accurate crack index. Simulating the build process is a coupled, multi-physics computation and incorporating it in the TO loop can be computationally prohibitive. We leverage the current advances in deep convolutional neural networks and present a high-fidelity surrogate model based on an Attention-based U-Net architecture to predict the MSSI values as a spatially varying field over the part's domain. Further, we employ automatic differentiation to directly compute the gradient of maximum MSSI with respect to the input design variables and augment it with the performance-based sensitivity field to optimize the design while considering the trade-off between weight, manufacturability, and functionality. We demonstrate the effectiveness of the proposed method through benchmark studies in 3D as well as experimental validation. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 143, level: 5" node_number="143">[12] arXiv:2112.04554 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 144, level: 5" node_number="144"> <div class="valid" valid="valid" title="valid: True, node: 145, level: 6" node_number="145"> <div class="valid" valid="valid" title="valid: True, node: 146, level: 7" node_number="146"> Title: Whose Ground Truth? Accounting for Individual and Collective Identities Underlying Dataset Annotation </div> <div class="valid" valid="valid" title="valid: True, node: 147, level: 7" node_number="147"> Authors: Emily Denton, <a class="valid" valid="valid" title="valid: True, node: 148, level: 8" node_number="148">Mark D&#237;az</a>, <a class="valid" valid="valid" title="valid: True, node: 149, level: 8" node_number="149">Ian Kivlichan</a>, <a class="valid" valid="valid" title="valid: True, node: 150, level: 8" node_number="150">Vinodkumar Prabhakaran</a>, <a class="valid" valid="valid" title="valid: True, node: 151, level: 8" node_number="151">Rachel Rosen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 152, level: 7" node_number="152"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 153, level: 7" node_number="153">Human annotations play a crucial role in machine learning (ML) research and development. However, the ethical considerations around the processes and decisions that go into building ML datasets has not received nearly enough attention. In this paper, we survey an array of literature that provides insights into ethical considerations around crowdsourced dataset annotation. We synthesize these insights, and lay out the challenges in this space along two layers: (1) who the annotator is, and how the annotators' lived experiences can impact their annotations, and (2) the relationship between the annotators and the crowdsourcing platforms and what that relationship affords them. Finally, we put forth a concrete set of recommendations and considerations for dataset developers at various stages of the ML data pipeline: task formulation, selection of annotators, platform and infrastructure choices, dataset analysis and evaluation, and dataset documentation and release. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 154, level: 5" node_number="154">[13] arXiv:2112.04558 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 155, level: 5" node_number="155"> <div class="valid" valid="valid" title="valid: True, node: 156, level: 6" node_number="156"> <div class="valid" valid="valid" title="valid: True, node: 157, level: 7" node_number="157"> Title: SoK: Anti-Facial Recognition Technology </div> <div class="valid" valid="valid" title="valid: True, node: 158, level: 7" node_number="158"> Authors: Emily Wenger, <a class="valid" valid="valid" title="valid: True, node: 159, level: 8" node_number="159">Shawn Shan</a>, <a class="valid" valid="valid" title="valid: True, node: 160, level: 8" node_number="160">Haitao Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 161, level: 8" node_number="161">Ben Y. Zhao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 162, level: 7" node_number="162"> Comments: 13 pages </div> <div class="valid" valid="valid" title="valid: True, node: 163, level: 7" node_number="163"> Subjects: Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 164, level: 7" node_number="164">The rapid adoption of facial recognition (FR) technology by both government and commercial entities in recent years has raised concerns about civil liberties and privacy. In response, a broad suite of so-called "anti-facial recognition" (AFR) tools has been developed to help users avoid unwanted facial recognition. The set of AFR tools proposed in the last few years is wide-ranging and rapidly evolving, necessitating a step back to consider the broader design space of AFR systems and long-term challenges. This paper aims to fill that gap and provides the first comprehensive analysis of the AFR research landscape. Using the operational stages of FR systems as a starting point, we create a systematic framework for analyzing the benefits and tradeoffs of different AFR approaches. We then consider both technical and social challenges facing AFR tools and propose directions for future research in this field. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 165, level: 5" node_number="165">[14] arXiv:2112.04559 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 166, level: 5" node_number="166"> <div class="valid" valid="valid" title="valid: True, node: 167, level: 6" node_number="167"> <div class="valid" valid="valid" title="valid: True, node: 168, level: 7" node_number="168"> Title: Achieving Reliable Coordination of Residential Plug-in Electric Vehicle Charging: A Pilot Study </div> <div class="valid" valid="valid" title="valid: True, node: 169, level: 7" node_number="169"> Authors: Polina Alexeenko, <a class="valid" valid="valid" title="valid: True, node: 170, level: 8" node_number="170">Eilyan Bitar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 171, level: 7" node_number="171"> Comments: 19 pages, 12 figures </div> <div class="valid" valid="valid" title="valid: True, node: 172, level: 7" node_number="172"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 173, level: 7" node_number="173">Wide-scale electrification of the transportation sector will require careful planning and coordination with the power grid. Left unmanaged, uncoordinated charging of electric vehicles (EVs) at increased levels of penetration will amplify existing peak loads, potentially outstripping the grid's capacity to reliably meet demand. In this paper, we report findings from the OptimizEV Project - a real-world pilot study in Upstate New York exploring a novel approach to coordinated residential EV charging. The proposed coordination mechanism seeks to harness the latent flexibility in EV charging by offering EV owners monetary incentives to delay the time required to charge their EVs. Each time an EV owner initiates a charging session, they specify how long they intend to leave their vehicle plugged in by selecting from a menu of deadlines that offers lower electricity prices the longer they're willing to delay the time required to charge their EV. Given a collection of active charging requests, a smart charging system dynamically optimizes the power being drawn by each EV in real time to minimize strain on the grid, while ensuring that each customer's car is fully charged by its deadline. Under the proposed incentive mechanism, we find that customers are frequently willing to engage in optimized charging sessions, allowing the system to delay the completion of their charging requests by more than eight hours on average. Using the flexibility provided by customers, the smart charging system was shown to be highly effective in shifting the majority of EV charging loads off-peak to fill the night-time valley of the aggregate load curve. Customer opt-in rates remained stable over the span of the study, providing empirical evidence in support of the proposed coordination mechanism as a potentially viable "non-wires alternative" to meet the increased demand for electricity driven growing EV adoption. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 174, level: 5" node_number="174">[15] arXiv:2112.04563 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 175, level: 5" node_number="175"> <div class="valid" valid="valid" title="valid: True, node: 176, level: 6" node_number="176"> <div class="valid" valid="valid" title="valid: True, node: 177, level: 7" node_number="177"> Title: Homogenization of higher-order continua </div> <div class="valid" valid="valid" title="valid: True, node: 178, level: 7" node_number="178"> Authors: Felix Schmid, <a class="valid" valid="valid" title="valid: True, node: 179, level: 8" node_number="179">Melanie Kr&#252;ger</a>, <a class="valid" valid="valid" title="valid: True, node: 180, level: 8" node_number="180">Marc-Andre Keip</a>, <a class="valid" valid="valid" title="valid: True, node: 181, level: 8" node_number="181">Christian Hesch</a> </div> <div class="valid" valid="valid" title="valid: True, node: 182, level: 7" node_number="182"> Subjects: Computational Engineering, Finance, and Science (cs.CE) </div> <p class="valid" valid="valid" title="valid: True, node: 183, level: 7" node_number="183">We introduce a novel computational framework for the multiscale simulation of higher-order continua that allows for the consideration of first-, second- and third- order effects at both micro- and macro-level. In line with classical two-scale approaches, we describe the microstructure via representative volume elements (RVE) that are attached at each integration point of the macroscopic problem. To take account of the extended continuity requirements of independent fields at micro- and macro-level, we discretize both scales via isogeometric analysis (IGA). As a result, we obtain an IGA2-method that is conceptually similar to the well-known FE2-method. We demonstrate the functionality and accuracy of this novel multiscale method by means of a series of multiscale simulations involving different kinds of higher-order continua. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 184, level: 5" node_number="184">[16] arXiv:2112.04564 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 185, level: 5" node_number="185"> <div class="valid" valid="valid" title="valid: True, node: 186, level: 6" node_number="186"> <div class="valid" valid="valid" title="valid: True, node: 187, level: 7" node_number="187"> Title: CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning </div> <div class="valid" valid="valid" title="valid: True, node: 188, level: 7" node_number="188"> Authors: Yue Fan, <a class="valid" valid="valid" title="valid: True, node: 189, level: 8" node_number="189">Dengxin Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 190, level: 8" node_number="190">Bernt Schiele</a> </div> <div class="valid" valid="valid" title="valid: True, node: 191, level: 7" node_number="191"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 192, level: 7" node_number="192">In this paper, we propose a novel co-learning framework (CoSSL) with decoupled representation learning and classifier learning for imbalanced SSL. To handle the data imbalance, we devise Tail-class Feature Enhancement (TFE) for classifier learning. Furthermore, the current evaluation protocol for imbalanced SSL focuses only on balanced test sets, which has limited practicality in real-world scenarios. Therefore, we further conduct a comprehensive evaluation under various shifted test distributions. In experiments, we show that our approach outperforms other methods over a large range of shifted distributions, achieving state-of-the-art performance on benchmark datasets ranging from CIFAR-10, CIFAR-100, ImageNet, to Food-101. Our code will be made publicly available. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 193, level: 5" node_number="193">[17] arXiv:2112.04567 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 194, level: 5" node_number="194"> <div class="valid" valid="valid" title="valid: True, node: 195, level: 6" node_number="195"> <div class="valid" valid="valid" title="valid: True, node: 196, level: 7" node_number="196"> Title: A simulation driven optimization algorithm for scheduling sorting center operations </div> <div class="valid" valid="valid" title="valid: True, node: 197, level: 7" node_number="197"> Authors: Supratim Ghosh, <a class="valid" valid="valid" title="valid: True, node: 198, level: 8" node_number="198">Aritra Pal</a>, <a class="valid" valid="valid" title="valid: True, node: 199, level: 8" node_number="199">Prashant Kumar</a>, <a class="valid" valid="valid" title="valid: True, node: 200, level: 8" node_number="200">Ankush Ojha</a>, <a class="valid" valid="valid" title="valid: True, node: 201, level: 8" node_number="201">Aditya Paranjape</a>, <a class="valid" valid="valid" title="valid: True, node: 202, level: 8" node_number="202">Souvik Barat</a>, <a class="valid" valid="valid" title="valid: True, node: 203, level: 8" node_number="203">Harshad Khadilkar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 204, level: 7" node_number="204"> Comments: 12 pages, Winter Simulation Conference 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 205, level: 7" node_number="205"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 206, level: 7" node_number="206">Parcel sorting operations in logistics enterprises aim to achieve a high throughput of parcels through sorting centers. These sorting centers are composed of large circular conveyor belts on which incoming parcels are placed, with multiple arms known as chutes for sorting the parcels by destination, followed by packing into roller cages and loading onto outbound trucks. Modern sorting systems need to complement their hardware innovations with sophisticated algorithms and software to map destinations and workforce to specific chutes. While state of the art systems operate with fixed mappings, we propose an optimization approach that runs before every shift, and uses real-time forecast of destination demand and labor availability in order to maximize throughput. We use simulation to improve the performance and robustness of the optimization solution to stochasticity in the environment, through closed-loop tuning of the optimization parameters. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 207, level: 5" node_number="207">[18] arXiv:2112.04570 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 208, level: 5" node_number="208"> <div class="valid" valid="valid" title="valid: True, node: 209, level: 6" node_number="209"> <div class="valid" valid="valid" title="valid: True, node: 210, level: 7" node_number="210"> Title: Formalising Lie algebras </div> <div class="valid" valid="valid" title="valid: True, node: 211, level: 7" node_number="211"> Authors: Oliver Nash </div> <div class="valid" valid="valid" title="valid: True, node: 212, level: 7" node_number="212"> Comments: 12 pages, 1 figure, to appear in CPP 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 213, level: 7" node_number="213"> Subjects: Logic in Computer Science (cs.LO); Representation Theory (math.RT) </div> <p class="valid" valid="valid" title="valid: True, node: 214, level: 7" node_number="214">Lie algebras are an important class of algebras which arise throughout mathematics and physics. We report on the formalisation of Lie algebras in Lean's Mathlib library. Although basic knowledge of Lie theory will benefit the reader, none is assumed; the intention is that the overall themes will be accessible even to readers unfamiliar with Lie theory. Particular attention is paid to the construction of the classical and exceptional Lie algebras. Thanks to these constructions, it is possible to state the classification theorem for finite-dimensional semisimple Lie algebras over an algebraically closed field of characteristic zero. In addition to the focus on Lie theory, we also aim to highlight the unity of Mathlib. To this end, we include examples of achievements made possible only by leaning on several branches of the library simultaneously. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 215, level: 5" node_number="215">[19] arXiv:2112.04571 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 216, level: 5" node_number="216"> <div class="valid" valid="valid" title="valid: True, node: 217, level: 6" node_number="217"> <div class="valid" valid="valid" title="valid: True, node: 218, level: 7" node_number="218"> Title: Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach </div> <div class="valid" valid="valid" title="valid: True, node: 219, level: 7" node_number="219"> Authors: Soroush Saghafian </div> <div class="valid" valid="valid" title="valid: True, node: 220, level: 7" node_number="220"> Subjects: Machine Learning (cs.LG); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 221, level: 7" node_number="221">A main research goal in various studies is to use an observational data set and provide a new set of counterfactual guidelines that can yield causal improvements. Dynamic Treatment Regimes (DTRs) are widely studied to formalize this process. However, available methods in finding optimal DTRs often rely on assumptions that are violated in real-world applications (e.g., medical decision-making or public policy), especially when (a) the existence of unobserved confounders cannot be ignored, and (b) the unobserved confounders are time-varying (e.g., affected by previous actions). When such assumptions are violated, one often faces ambiguity regarding the underlying causal model that is needed to be assumed to obtain an optimal DTR. This ambiguity is inevitable, since the dynamics of unobserved confounders and their causal impact on the observed part of the data cannot be understood from the observed data. Motivated by a case study of finding superior treatment regimes for patients who underwent transplantation in our partner hospital and faced a medical condition known as New Onset Diabetes After Transplantation (NODAT), we extend DTRs to a new class termed Ambiguous Dynamic Treatment Regimes (ADTRs), in which the casual impact of treatment regimes is evaluated based on a "cloud" of potential causal models. We then connect ADTRs to Ambiguous Partially Observable Mark Decision Processes (APOMDPs) proposed by Saghafian (2018), and develop two Reinforcement Learning methods termed Direct Augmented V-Learning (DAV-Learning) and Safe Augmented V-Learning (SAV-Learning), which enable using the observed data to efficiently learn an optimal treatment regime. We establish theoretical results for these learning methods, including (weak) consistency and asymptotic normality. We further evaluate the performance of these learning methods both in our case study and in simulation experiments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 222, level: 5" node_number="222">[20] arXiv:2112.04572 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 223, level: 5" node_number="223"> <div class="valid" valid="valid" title="valid: True, node: 224, level: 6" node_number="224"> <div class="valid" valid="valid" title="valid: True, node: 225, level: 7" node_number="225"> Title: Merging Subject Matter Expertise and Deep Convolutional Neural Network for State-Based Online Machine-Part Interaction Classification </div> <div class="valid" valid="valid" title="valid: True, node: 226, level: 7" node_number="226"> Authors: Hao Wang, Yassine Qamsane, <a class="valid" valid="valid" title="valid: True, node: 227, level: 8" node_number="227">James Moyne</a>, <a class="valid" valid="valid" title="valid: True, node: 228, level: 8" node_number="228">Kira Barton</a> </div> <div class="valid" valid="valid" title="valid: True, node: 229, level: 7" node_number="229"> Comments: Published at ASME Manufacturing Science and Engineering Conference (MSEC) </div> <div class="valid" valid="valid" title="valid: True, node: 230, level: 7" node_number="230"> Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 231, level: 7" node_number="231">Machine-part interaction classification is a key capability required by Cyber-Physical Systems (CPS), a pivotal enabler of Smart Manufacturing (SM). While previous relevant studies on the subject have primarily focused on time series classification, change point detection is equally important because it provides temporal information on changes in behavior of the machine. In this work, we address point detection and time series classification for machine-part interactions with a deep Convolutional Neural Network (CNN) based framework. The CNN in this framework utilizes a two-stage encoder-classifier structure for efficient feature representation and convenient deployment customization for CPS. Though data-driven, the design and optimization of the framework are Subject Matter Expertise (SME) guided. An SME defined Finite State Machine (FSM) is incorporated into the framework to prohibit intermittent misclassifications. In the case study, we implement the framework to perform machine-part interaction classification on a milling machine, and the performance is evaluated using a testing dataset and deployment simulations. The implementation achieved an average F1-Score of 0.946 across classes on the testing dataset and an average delay of 0.24 seconds on the deployment simulations. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 232, level: 5" node_number="232">[21] arXiv:2112.04573 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 233, level: 5" node_number="233"> <div class="valid" valid="valid" title="valid: True, node: 234, level: 6" node_number="234"> <div class="valid" valid="valid" title="valid: True, node: 235, level: 7" node_number="235"> Title: Application of Artificial Intelligence and Machine Learning in Libraries: A Systematic Review </div> <div class="valid" valid="valid" title="valid: True, node: 236, level: 7" node_number="236"> Authors: Rajesh Kumar Das, <a class="valid" valid="valid" title="valid: True, node: 237, level: 8" node_number="237">Mohammad Sharif Ul Islam</a> </div> <div class="valid" valid="valid" title="valid: True, node: 238, level: 7" node_number="238"> Subjects: Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 239, level: 7" node_number="239">As the concept and implementation of cutting-edge technologies like artificial intelligence and machine learning has become relevant, academics, researchers and information professionals involve research in this area. The objective of this systematic literature review is to provide a synthesis of empirical studies exploring application of artificial intelligence and machine learning in libraries. To achieve the objectives of the study, a systematic literature review was conducted based on the original guidelines proposed by Kitchenham et al. (2009). Data was collected from Web of Science, Scopus, LISA and LISTA databases. Following the rigorous/ established selection process, a total of thirty-two articles were finally selected, reviewed and analyzed to summarize on the application of AI and ML domain and techniques which are most often used in libraries. Findings show that the current state of the AI and ML research that is relevant with the LIS domain mainly focuses on theoretical works. However, some researchers also emphasized on implementation projects or case studies. This study will provide a panoramic view of AI and ML in libraries for researchers, practitioners and educators for furthering the more technology-oriented approaches, and anticipating future innovation pathways. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 240, level: 5" node_number="240">[22] arXiv:2112.04575 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 241, level: 5" node_number="241"> <div class="valid" valid="valid" title="valid: True, node: 242, level: 6" node_number="242"> <div class="valid" valid="valid" title="valid: True, node: 243, level: 7" node_number="243"> Title: Adaptive Kernel Graph Neural Network </div> <div class="valid" valid="valid" title="valid: True, node: 244, level: 7" node_number="244"> Authors: Mingxuan Ju, <a class="valid" valid="valid" title="valid: True, node: 245, level: 8" node_number="245">Shifu Hou</a>, <a class="valid" valid="valid" title="valid: True, node: 246, level: 8" node_number="246">Yujie Fan</a>, <a class="valid" valid="valid" title="valid: True, node: 247, level: 8" node_number="247">Jianan Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 248, level: 8" node_number="248">Liang Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 249, level: 8" node_number="249">Yanfang Ye</a> </div> <div class="valid" valid="valid" title="valid: True, node: 250, level: 7" node_number="250"> Comments: To be appear at AAAI2022 </div> <div class="valid" valid="valid" title="valid: True, node: 251, level: 7" node_number="251"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 252, level: 7" node_number="252">Graph neural networks (GNNs) have demonstrated great success in representation learning for graph-structured data. The layer-wise graph convolution in GNNs is shown to be powerful at capturing graph topology. During this process, GNNs are usually guided by pre-defined kernels such as Laplacian matrix, adjacency matrix, or their variants. However, the adoptions of pre-defined kernels may restrain the generalities to different graphs: mismatch between graph and kernel would entail sub-optimal performance. For example, GNNs that focus on low-frequency information may not achieve satisfactory performance when high-frequency information is significant for the graphs, and vice versa. To solve this problem, in this paper, we propose a novel framework - i.e., namely Adaptive Kernel Graph Neural Network (AKGNN) - which learns to adapt to the optimal graph kernel in a unified manner at the first attempt. In the proposed AKGNN, we first design a data-driven graph kernel learning mechanism, which adaptively modulates the balance between all-pass and low-pass filters by modifying the maximal eigenvalue of the graph Laplacian. Through this process, AKGNN learns the optimal threshold between high and low frequency signals to relieve the generality problem. Later, we further reduce the number of parameters by a parameterization trick and enhance the expressive power by a global readout function. Extensive experiments are conducted on acknowledged benchmark datasets and promising results demonstrate the outstanding performance of our proposed AKGNN by comparison with state-of-the-art GNNs. The source code is publicly available at: https://github.com/jumxglhf/AKGNN. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 253, level: 5" node_number="253">[23] arXiv:2112.04577 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 254, level: 5" node_number="254"> <div class="valid" valid="valid" title="valid: True, node: 255, level: 6" node_number="255"> <div class="valid" valid="valid" title="valid: True, node: 256, level: 7" node_number="256"> Title: Gaussian Random Number Generator with Reconfigurable Mean and Variance using Stochastic Magnetic Tunnel Junctions </div> <div class="valid" valid="valid" title="valid: True, node: 257, level: 7" node_number="257"> Authors: Punyashloka Debashis, <a class="valid" valid="valid" title="valid: True, node: 258, level: 8" node_number="258">Hai Li</a>, <a class="valid" valid="valid" title="valid: True, node: 259, level: 8" node_number="259">Dmitri Nikonov</a>, <a class="valid" valid="valid" title="valid: True, node: 260, level: 8" node_number="260">Ian Young</a> </div> <div class="valid" valid="valid" title="valid: True, node: 261, level: 7" node_number="261"> Comments: 14 pages, 5 figures </div> <div class="valid" valid="valid" title="valid: True, node: 262, level: 7" node_number="262"> Subjects: Emerging Technologies (cs.ET); Disordered Systems and Neural Networks (cond-mat.dis-nn); Mesoscale and Nanoscale Physics (cond-mat.mes-hall) </div> <p class="valid" valid="valid" title="valid: True, node: 263, level: 7" node_number="263">Generating high-quality random numbers with a Gaussian probability distribution function is an important and resource consuming computational task for many applications in the fields of machine learning and Monte Carlo algorithms. Recently, CMOS-based digital hardware architectures have been explored as specialized Gaussian random number generators (GRNGs). These CMOS-based GRNGs have a large area and require entropy sources at their input which increase the computing cost. Here, we propose a GRNG that works on the principle of the Boltzmann law in a physical system made from an interconnected network of thermally unstable magnetic tunnel junctions. The proposed hardware can produce multi-bit Gaussian random numbers at a gigahertz speed and can be configured to generate distributions with a desired mean and variance. An analytical derivation of the required interconnection and bias strengths is provided followed by numerical simulations to demonstrate the functionalities of the GRNG. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 264, level: 5" node_number="264">[24] arXiv:2112.04581 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 265, level: 5" node_number="265"> <div class="valid" valid="valid" title="valid: True, node: 266, level: 6" node_number="266"> <div class="valid" valid="valid" title="valid: True, node: 267, level: 7" node_number="267"> Title: Building Usable Witness Encryption </div> <div class="valid" valid="valid" title="valid: True, node: 268, level: 7" node_number="268"> Authors: Gavin Uberti, <a class="valid" valid="valid" title="valid: True, node: 269, level: 8" node_number="269">Kevin Luo</a>, <a class="valid" valid="valid" title="valid: True, node: 270, level: 8" node_number="270">Oliver Cheng</a>, <a class="valid" valid="valid" title="valid: True, node: 271, level: 8" node_number="271">Wittmann Goh</a> </div> <div class="valid" valid="valid" title="valid: True, node: 272, level: 7" node_number="272"> Comments: 21 pages, 3 figures </div> <div class="valid" valid="valid" title="valid: True, node: 273, level: 7" node_number="273"> Subjects: Cryptography and Security (cs.CR) </div> <p class="valid" valid="valid" title="valid: True, node: 274, level: 7" node_number="274">Witness encryption using multilinear maps was first proposed in 2013, and has continued to evolve since. In this paper, we build on an open-source multilinear map implementation by Carmer and Malozemoff of the graded encoding scheme CLT13 with asymmetric modifications. Using this map, we created the world's first ciphertext encoded with a candidate witness encryption scheme. Finally, using a reduction from Sudoku to Exact Cover, we encrypted the private key to a Bitcoin wallet with 22,700 Satoshi using a Sudoku. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 275, level: 5" node_number="275">[25] arXiv:2112.04583 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 276, level: 5" node_number="276"> <div class="valid" valid="valid" title="valid: True, node: 277, level: 6" node_number="277"> <div class="valid" valid="valid" title="valid: True, node: 278, level: 7" node_number="278"> Title: Estimating Divergences in High Dimensions </div> <div class="valid" valid="valid" title="valid: True, node: 279, level: 7" node_number="279"> Authors: Loong Kuan Lee, <a class="valid" valid="valid" title="valid: True, node: 280, level: 8" node_number="280">Nico Piatkowski</a>, <a class="valid" valid="valid" title="valid: True, node: 281, level: 8" node_number="281">Fran&#231;ois Petitjean</a>, <a class="valid" valid="valid" title="valid: True, node: 282, level: 8" node_number="282">Geoffrey I. Webb</a> </div> <div class="valid" valid="valid" title="valid: True, node: 283, level: 7" node_number="283"> Comments: 13 pages, 6 Figures. Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence </div> <div class="valid" valid="valid" title="valid: True, node: 284, level: 7" node_number="284"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 285, level: 7" node_number="285">The problem of estimating the divergence between 2 high dimensional distributions with limited samples is an important problem in various fields such as machine learning. Although previous methods perform well with moderate dimensional data, their accuracy starts to degrade in situations with 100s of binary variables. Therefore, we propose the use of decomposable models for estimating divergences in high dimensional data. These allow us to factorize the estimated density of the high-dimensional distribution into a product of lower dimensional functions. We conduct formal and experimental analyses to explore the properties of using decomposable models in the context of divergence estimation. To this end, we show empirically that estimating the Kullback-Leibler divergence using decomposable models from a maximum likelihood estimator outperforms existing methods for divergence estimation in situations where dimensionality is high and useful decomposable models can be learnt from the available data. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 286, level: 5" node_number="286">[26] arXiv:2112.04585 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 287, level: 5" node_number="287"> <div class="valid" valid="valid" title="valid: True, node: 288, level: 6" node_number="288"> <div class="valid" valid="valid" title="valid: True, node: 289, level: 7" node_number="289"> Title: STAF: A Spatio-Temporal Attention Fusion Network for Few-shot Video Classification </div> <div class="valid" valid="valid" title="valid: True, node: 290, level: 7" node_number="290"> Authors: Rex Liu, <a class="valid" valid="valid" title="valid: True, node: 291, level: 8" node_number="291">Huanle Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 292, level: 8" node_number="292">Hamed Pirsiavash</a>, <a class="valid" valid="valid" title="valid: True, node: 293, level: 8" node_number="293">Xin Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 294, level: 7" node_number="294"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 295, level: 7" node_number="295">We propose STAF, a Spatio-Temporal Attention Fusion network for few-shot video classification. STAF first extracts coarse-grained spatial and temporal features of videos by applying a 3D Convolution Neural Networks embedding network. It then fine-tunes the extracted features using self-attention and cross-attention networks. Last, STAF applies a lightweight fusion network and a nearest neighbor classifier to classify each query video. To evaluate STAF, we conduct extensive experiments on three benchmarks (UCF101, HMDB51, and Something-Something-V2). The experimental results show that STAF improves state-of-the-art accuracy by a large margin, e.g., STAF increases the five-way one-shot accuracy by 5.3% and 7.0% for UCF101 and HMDB51, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 296, level: 5" node_number="296">[27] arXiv:2112.04588 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 297, level: 5" node_number="297"> <div class="valid" valid="valid" title="valid: True, node: 298, level: 6" node_number="298"> <div class="valid" valid="valid" title="valid: True, node: 299, level: 7" node_number="299"> Title: A Critical Comparison on Attitude Estimation: From Gaussian Approximate Filters to Coordinate-free Dual Optimal Control </div> <div class="valid" valid="valid" title="valid: True, node: 300, level: 7" node_number="300"> Authors: Nikolaos Koumpis, <a class="valid" valid="valid" title="valid: True, node: 301, level: 8" node_number="301">Panagiotis Panagiotou</a>, <a class="valid" valid="valid" title="valid: True, node: 302, level: 8" node_number="302">Ioannis Arvanitakis</a> </div> <div class="valid" valid="valid" title="valid: True, node: 303, level: 7" node_number="303"> Comments: Accept </div> <div class="valid" valid="valid" title="valid: True, node: 304, level: 7" node_number="304"> Journal-ref: IET Control Theory Applications, Volume 15,19 February 2021, Issue 10, p. 1297-1313 </div> <div class="valid" valid="valid" title="valid: True, node: 305, level: 7" node_number="305"> Subjects: Systems and Control (eess.SY); Dynamical Systems (math.DS) </div> <p class="valid" valid="valid" title="valid: True, node: 306, level: 7" node_number="306">This paper conveys attitude and rate estimation without rate sensors by performing a critical comparison, validated by extensive simulations. The two dominant approaches to facilitate attitude estimation are based on stochastic and set-membership reasoning. The first one mostly utilizes the commonly known Gaussian-approximate filters, namely the EKF and UKF. Although more conservative, the latter seems to be more promising as it considers the inherent geometric characteristics of the underline compact state space and accounts -- from first principles -- for large model errors. We address the set-theoretic approach from a control point of view, and we show that it can overcome reported deficiencies of the Bayesian architectures related to this problem, leading to coordinate-free optimal filters. Lastly, as an example, we derive a modified predictive filter on the tangent bundle of the special orthogonal group $\mathbb{TSO}(3)$. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 307, level: 5" node_number="307">[28] arXiv:2112.04590 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 308, level: 5" node_number="308"> <div class="valid" valid="valid" title="valid: True, node: 309, level: 6" node_number="309"> <div class="valid" valid="valid" title="valid: True, node: 310, level: 7" node_number="310"> Title: The perils of being unhinged: On the accuracy of classifiers minimizing a noise-robust convex loss </div> <div class="valid" valid="valid" title="valid: True, node: 311, level: 7" node_number="311"> Authors: Philip M. Long, <a class="valid" valid="valid" title="valid: True, node: 312, level: 8" node_number="312">Rocco A. Servedio</a> </div> <div class="valid" valid="valid" title="valid: True, node: 313, level: 7" node_number="313"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 314, level: 7" node_number="314">van Rooyen et al. introduced a notion of convex loss functions being robust to random classification noise, and established that the "unhinged" loss function is robust in this sense. In this note we study the accuracy of binary classifiers obtained by minimizing the unhinged loss, and observe that even for simple linearly separable data distributions, minimizing the unhinged loss may only yield a binary classifier with accuracy no better than random guessing. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 315, level: 5" node_number="315">[29] arXiv:2112.04591 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 316, level: 5" node_number="316"> <div class="valid" valid="valid" title="valid: True, node: 317, level: 6" node_number="317"> <div class="valid" valid="valid" title="valid: True, node: 318, level: 7" node_number="318"> Title: Variational Regularization in Inverse Problems and Machine Learning </div> <div class="valid" valid="valid" title="valid: True, node: 319, level: 7" node_number="319"> Authors: Martin Burger </div> <div class="valid" valid="valid" title="valid: True, node: 320, level: 7" node_number="320"> Subjects: Machine Learning (cs.LG); Numerical Analysis (math.NA); Optimization and Control (math.OC) </div> <p class="valid" valid="valid" title="valid: True, node: 321, level: 7" node_number="321">This paper discusses basic results and recent developments on variational regularization methods, as developed for inverse problems. In a typical setup we review basic properties needed to obtain a convergent regularization scheme and further discuss the derivation of quantitative estimates respectively needed ingredients such as Bregman distances for convex functionals. In addition to the approach developed for inverse problems we will also discuss variational regularization in machine learning and work out some connections to the classical regularization theory. In particular we will discuss a reinterpretation of machine learning problems in the framework of regularization theory and a reinterpretation of variational methods for inverse problems in the framework of risk minimization. Moreover, we establish some previously unknown connections between error estimates in Bregman distances and generalization errors. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 322, level: 5" node_number="322">[30] arXiv:2112.04596 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 323, level: 5" node_number="323"> <div class="valid" valid="valid" title="valid: True, node: 324, level: 6" node_number="324"> <div class="valid" valid="valid" title="valid: True, node: 325, level: 7" node_number="325"> Title: Refined Commonsense Knowledge from Large-Scale Web Contents </div> <div class="valid" valid="valid" title="valid: True, node: 326, level: 7" node_number="326"> Authors: Tuan-Phong Nguyen, <a class="valid" valid="valid" title="valid: True, node: 327, level: 8" node_number="327">Simon Razniewski</a>, <a class="valid" valid="valid" title="valid: True, node: 328, level: 8" node_number="328">Julien Romero</a>, <a class="valid" valid="valid" title="valid: True, node: 329, level: 8" node_number="329">Gerhard Weikum</a> </div> <div class="valid" valid="valid" title="valid: True, node: 330, level: 7" node_number="330"> Comments: This is a substantial extension of the WWW paper (<a class="valid" valid="valid" title="valid: True, node: 331, level: 8" node_number="331">arXiv:2011.00905</a>). arXiv admin note: substantial text overlap with <a class="valid" valid="valid" title="valid: True, node: 332, level: 8" node_number="332">arXiv:2011.00905</a> </div> <div class="valid" valid="valid" title="valid: True, node: 333, level: 7" node_number="333"> Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 334, level: 7" node_number="334">Commonsense knowledge (CSK) about concepts and their properties is useful for AI applications. Prior works like ConceptNet, COMET and others compiled large CSK collections, but are restricted in their expressiveness to subject-predicate-object (SPO) triples with simple concepts for S and strings for P and O. This paper presents a method, called ASCENT++, to automatically build a large-scale knowledge base (KB) of CSK assertions, with refined expressiveness and both better precision and recall than prior works. ASCENT++ goes beyond SPO triples by capturing composite concepts with subgroups and aspects, and by refining assertions with semantic facets. The latter is important to express the temporal and spatial validity of assertions and further qualifiers. ASCENT++ combines open information extraction with judicious cleaning and ranking by typicality and saliency scores. For high coverage, our method taps into the large-scale crawl C4 with broad web contents. The evaluation with human judgements shows the superior quality of the ASCENT++ KB, and an extrinsic evaluation for QA-support tasks underlines the benefits of ASCENT++. A web interface, data and code can be accessed at https://www.mpi-inf.mpg.de/ascentpp. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 335, level: 5" node_number="335">[31] arXiv:2112.04598 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 336, level: 5" node_number="336"> <div class="valid" valid="valid" title="valid: True, node: 337, level: 6" node_number="337"> <div class="valid" valid="valid" title="valid: True, node: 338, level: 7" node_number="338"> Title: InvGAN: Invertable GANs </div> <div class="valid" valid="valid" title="valid: True, node: 339, level: 7" node_number="339"> Authors: Partha Ghosh, <a class="valid" valid="valid" title="valid: True, node: 340, level: 8" node_number="340">Dominik Zietlow</a>, <a class="valid" valid="valid" title="valid: True, node: 341, level: 8" node_number="341">Michael J. Black</a>, <a class="valid" valid="valid" title="valid: True, node: 342, level: 8" node_number="342">Larry S. Davis</a>, <a class="valid" valid="valid" title="valid: True, node: 343, level: 8" node_number="343">Xiaochen Hu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 344, level: 7" node_number="344"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 345, level: 7" node_number="345">Generation of photo-realistic images, semantic editing and representation learning are a few of many potential applications of high resolution generative models. Recent progress in GANs have established them as an excellent choice for such tasks. However, since they do not provide an inference model, image editing or downstream tasks such as classification can not be done on real images using the GAN latent space. Despite numerous efforts to train an inference model or design an iterative method to invert a pre-trained generator, previous methods are dataset (e.g. human face images) and architecture (e.g. StyleGAN) specific. These methods are nontrivial to extend to novel datasets or architectures. We propose a general framework that is agnostic to architecture and datasets. Our key insight is that, by training the inference and the generative model together, we allow them to adapt to each other and to converge to a better quality model. Our extbf{InvGAN}, short for Invertable GAN, successfully embeds real images to the latent space of a high quality generative model. This allows us to perform image inpainting, merging, interpolation and online data augmentation. We demonstrate this with extensive qualitative and quantitative experiments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 346, level: 5" node_number="346">[32] arXiv:2112.04602 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 347, level: 5" node_number="347"> <div class="valid" valid="valid" title="valid: True, node: 348, level: 6" node_number="348"> <div class="valid" valid="valid" title="valid: True, node: 349, level: 7" node_number="349"> Title: Adaptive packet transmission in response to anomaly detection in software defined smart meter networks </div> <div class="valid" valid="valid" title="valid: True, node: 350, level: 7" node_number="350"> Authors: Mihnea Maris, <a class="valid" valid="valid" title="valid: True, node: 351, level: 8" node_number="351">Thomas Halpin</a>, <a class="valid" valid="valid" title="valid: True, node: 352, level: 8" node_number="352">Dubem Ezeh</a>, <a class="valid" valid="valid" title="valid: True, node: 353, level: 8" node_number="353">Karen Miu</a>, <a class="valid" valid="valid" title="valid: True, node: 354, level: 8" node_number="354">Jaudelice de Oliveira</a> </div> <div class="valid" valid="valid" title="valid: True, node: 355, level: 7" node_number="355"> Subjects: Networking and Internet Architecture (cs.NI) </div> <p class="valid" valid="valid" title="valid: True, node: 356, level: 7" node_number="356">In this paper, we examine a basic smart meter network topology in mininet and address the issue of congestion over a commodity network, proposing an adaptive algorithm to cope with varying grid data delivery latencies. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 357, level: 5" node_number="357">[33] arXiv:2112.04603 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 358, level: 5" node_number="358"> <div class="valid" valid="valid" title="valid: True, node: 359, level: 6" node_number="359"> <div class="valid" valid="valid" title="valid: True, node: 360, level: 7" node_number="360"> Title: A Unified Architecture of Semantic Segmentation and Hierarchical Generative Adversarial Networks for Expression Manipulation </div> <div class="valid" valid="valid" title="valid: True, node: 361, level: 7" node_number="361"> Authors: Rumeysa Bodur, <a class="valid" valid="valid" title="valid: True, node: 362, level: 8" node_number="362">Binod Bhattarai</a>, <a class="valid" valid="valid" title="valid: True, node: 363, level: 8" node_number="363">Tae-Kyun Kim</a> </div> <div class="valid" valid="valid" title="valid: True, node: 364, level: 7" node_number="364"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 365, level: 7" node_number="365">Editing facial expressions by only changing what we want is a long-standing research problem in Generative Adversarial Networks (GANs) for image manipulation. Most of the existing methods that rely only on a global generator usually suffer from changing unwanted attributes along with the target attributes. Recently, hierarchical networks that consist of both a global network dealing with the whole image and multiple local networks focusing on local parts are showing success. However, these methods extract local regions by bounding boxes centred around the sparse facial key points which are non-differentiable, inaccurate and unrealistic. Hence, the solution becomes sub-optimal, introduces unwanted artefacts degrading the overall quality of the synthetic images. Moreover, a recent study has shown strong correlation between facial attributes and local semantic regions. To exploit this relationship, we designed a unified architecture of semantic segmentation and hierarchical GANs. A unique advantage of our framework is that on forward pass the semantic segmentation network conditions the generative model, and on backward pass gradients from hierarchical GANs are propagated to the semantic segmentation network, which makes our framework an end-to-end differentiable architecture. This allows both architectures to benefit from each other. To demonstrate its advantages, we evaluate our method on two challenging facial expression translation benchmarks, AffectNet and RaFD, and a semantic segmentation benchmark, CelebAMask-HQ across two popular architectures, BiSeNet and UNet. Our extensive quantitative and qualitative evaluations on both face semantic segmentation and face expression manipulation tasks validate the effectiveness of our work over existing state-of-the-art methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 366, level: 5" node_number="366">[34] arXiv:2112.04604 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 367, level: 5" node_number="367"> <div class="valid" valid="valid" title="valid: True, node: 368, level: 6" node_number="368"> <div class="valid" valid="valid" title="valid: True, node: 369, level: 7" node_number="369"> Title: Regularization methods for the short-term forecasting of the Italian electric load </div> <div class="valid" valid="valid" title="valid: True, node: 370, level: 7" node_number="370"> Authors: Alessandro Incremona, <a class="valid" valid="valid" title="valid: True, node: 371, level: 8" node_number="371">Giuseppe De Nicolao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 372, level: 7" node_number="372"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 373, level: 7" node_number="373">The problem of forecasting the whole 24 profile of the Italian electric load is addressed as a multitask learning problem, whose complexity is kept under control via alternative regularization methods. In view of the quarter-hourly samplings, 96 predictors are used, each of which linearly depends on 96 regressors. The 96x96 matrix weights form a 96x96 matrix, that can be seen and displayed as a surface sampled on a square domain. Different regularization and sparsity approaches to reduce the degrees of freedom of the surface were explored, comparing the obtained forecasts with those of the Italian Transmission System Operator Terna. Besides outperforming Terna in terms of quarter-hourly mean absolute percentage error and mean absolute error, the prediction residuals turned out to be weakly correlated with Terna, which suggests that further improvement could ensue from forecasts aggregation. In fact, the aggregated forecasts yielded further relevant drops in terms of quarter-hourly and daily mean absolute percentage error, mean absolute error and root mean square error (up to 30%) over the three test years considered. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 374, level: 5" node_number="374">[35] arXiv:2112.04605 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 375, level: 5" node_number="375"> <div class="valid" valid="valid" title="valid: True, node: 376, level: 6" node_number="376"> <div class="valid" valid="valid" title="valid: True, node: 377, level: 7" node_number="377"> Title: Prediction of Adverse Biological Effects of Chemicals Using Knowledge Graph Embeddings </div> <div class="valid" valid="valid" title="valid: True, node: 378, level: 7" node_number="378"> Authors: Erik B. Myklebust, Ernesto Jim&#233;nez-Ruiz, <a class="valid" valid="valid" title="valid: True, node: 379, level: 8" node_number="379">Jiaoyan Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 380, level: 8" node_number="380">Raoul Wolf</a>, <a class="valid" valid="valid" title="valid: True, node: 381, level: 8" node_number="381">Knut Erik Tollefsen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 382, level: 7" node_number="382"> Comments: Accepted for publication in the Semantic Web Journal </div> <div class="valid" valid="valid" title="valid: True, node: 383, level: 7" node_number="383"> Subjects: Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 384, level: 7" node_number="384">We have created a knowledge graph based on major data sources used in ecotoxicological risk assessment. We have applied this knowledge graph to an important task in risk assessment, namely chemical effect prediction. We have evaluated nine knowledge graph embedding models from a selection of geometric, decomposition, and convolutional models on this prediction task. We show that using knowledge graph embeddings can increase the accuracy of effect prediction with neural networks. Furthermore, we have implemented a fine-tuning architecture which adapts the knowledge graph embeddings to the effect prediction task and leads to a better performance. Finally, we evaluate certain characteristics of the knowledge graph embedding models to shed light on the individual model performance. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 385, level: 5" node_number="385">[36] arXiv:2112.04607 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 386, level: 5" node_number="386"> <div class="valid" valid="valid" title="valid: True, node: 387, level: 6" node_number="387"> <div class="valid" valid="valid" title="valid: True, node: 388, level: 7" node_number="388"> Title: Constrained Mean Shift Using Distant Yet Related Neighbors for Representation Learning </div> <div class="valid" valid="valid" title="valid: True, node: 389, level: 7" node_number="389"> Authors: Ajinkya Tejankar, <a class="valid" valid="valid" title="valid: True, node: 390, level: 8" node_number="390">Soroush Abbasi Koohpayegani</a>, <a class="valid" valid="valid" title="valid: True, node: 391, level: 8" node_number="391">KL Navaneet</a>, <a class="valid" valid="valid" title="valid: True, node: 392, level: 8" node_number="392">Kossar Pourahmadi</a>, <a class="valid" valid="valid" title="valid: True, node: 393, level: 8" node_number="393">Akshayvarun Subramanya</a>, <a class="valid" valid="valid" title="valid: True, node: 394, level: 8" node_number="394">Hamed Pirsiavash</a> </div> <div class="valid" valid="valid" title="valid: True, node: 395, level: 7" node_number="395"> Comments: Code is available at <a class="valid" valid="valid" title="valid: True, node: 396, level: 8" node_number="396">this https URL</a> arXiv admin note: text overlap with <a class="valid" valid="valid" title="valid: True, node: 397, level: 8" node_number="397">arXiv:2110.10309</a> </div> <div class="valid" valid="valid" title="valid: True, node: 398, level: 7" node_number="398"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 399, level: 7" node_number="399">We are interested in representation learning in self-supervised, supervised, or semi-supervised settings. The prior work on applying mean-shift idea for self-supervised learning, MSF, generalizes the BYOL idea by pulling a query image to not only be closer to its other augmentation, but also to the nearest neighbors (NNs) of its other augmentation. We believe the learning can benefit from choosing far away neighbors that are still semantically related to the query. Hence, we propose to generalize MSF algorithm by constraining the search space for nearest neighbors. We show that our method outperforms MSF in SSL setting when the constraint utilizes a different augmentation of an image, and outperforms PAWS in semi-supervised setting with less training resources when the constraint ensures the NNs have the same pseudo-label as the query. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 400, level: 5" node_number="400">[37] arXiv:2112.04608 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 401, level: 5" node_number="401"> <div class="valid" valid="valid" title="valid: True, node: 402, level: 6" node_number="402"> <div class="valid" valid="valid" title="valid: True, node: 403, level: 7" node_number="403"> Title: Enhancing Food Intake Tracking in Long-Term Care with Automated Food Imaging and Nutrient Intake Tracking (AFINI-T) Technology </div> <div class="valid" valid="valid" title="valid: True, node: 404, level: 7" node_number="404"> Authors: Kaylen J. Pfisterer, <a class="valid" valid="valid" title="valid: True, node: 405, level: 8" node_number="405">Robert Amelard</a>, <a class="valid" valid="valid" title="valid: True, node: 406, level: 8" node_number="406">Jennifer Boger</a>, <a class="valid" valid="valid" title="valid: True, node: 407, level: 8" node_number="407">Audrey G. Chung</a>, <a class="valid" valid="valid" title="valid: True, node: 408, level: 8" node_number="408">Heather H. Keller</a>, <a class="valid" valid="valid" title="valid: True, node: 409, level: 8" node_number="409">Alexander Wong</a> </div> <div class="valid" valid="valid" title="valid: True, node: 410, level: 7" node_number="410"> Comments: Key words: Automatic segmentation, convolutional neural network, deep learning, food intake tracking, volume estimation, malnutrition prevention, long-term care, hospital </div> <div class="valid" valid="valid" title="valid: True, node: 411, level: 7" node_number="411"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 412, level: 7" node_number="412">Half of long-term care (LTC) residents are malnourished increasing hospitalization, mortality, morbidity, with lower quality of life. Current tracking methods are subjective and time consuming. This paper presents the automated food imaging and nutrient intake tracking (AFINI-T) technology designed for LTC. We propose a novel convolutional autoencoder for food classification, trained on an augmented UNIMIB2016 dataset and tested on our simulated LTC food intake dataset (12 meal scenarios; up to 15 classes each; top-1 classification accuracy: 88.9%; mean intake error: -0.4 mL$\pm$36.7 mL). Nutrient intake estimation by volume was strongly linearly correlated with nutrient estimates from mass ($r^2$ 0.92 to 0.99) with good agreement between methods ($\sigma$= -2.7 to -0.01; zero within each of the limits of agreement). The AFINI-T approach is a deep-learning powered computational nutrient sensing system that may provide a novel means for more accurately and objectively tracking LTC resident food intake to support and prevent malnutrition tracking strategies. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 413, level: 5" node_number="413">[38] arXiv:2112.04610 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 414, level: 5" node_number="414"> <div class="valid" valid="valid" title="valid: True, node: 415, level: 6" node_number="415"> <div class="valid" valid="valid" title="valid: True, node: 416, level: 7" node_number="416"> Title: A Simple and efficient deep Scanpath Prediction </div> <div class="valid" valid="valid" title="valid: True, node: 417, level: 7" node_number="417"> Authors: Mohamed Amine Kerkouri, <a class="valid" valid="valid" title="valid: True, node: 418, level: 8" node_number="418">Aladine Chetouani</a> </div> <div class="valid" valid="valid" title="valid: True, node: 419, level: 7" node_number="419"> Comments: Electronic Imaging Symposium 2022 (EI 2022) </div> <div class="valid" valid="valid" title="valid: True, node: 420, level: 7" node_number="420"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 421, level: 7" node_number="421">Visual scanpath is the sequence of fixation points that the human gaze travels while observing an image, and its prediction helps in modeling the visual attention of an image. To this end several models were proposed in the literature using complex deep learning architectures and frameworks. Here, we explore the efficiency of using common deep learning architectures, in a simple fully convolutional regressive manner. We experiment how well these models can predict the scanpaths on 2 datasets. We compare with other models using different metrics and show competitive results that sometimes surpass previous complex architectures. We also compare the different leveraged backbone architectures based on their performances on the experiment to deduce which ones are the most suitable for the task. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 422, level: 5" node_number="422">[39] arXiv:2112.04612 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 423, level: 5" node_number="423"> <div class="valid" valid="valid" title="valid: True, node: 424, level: 6" node_number="424"> <div class="valid" valid="valid" title="valid: True, node: 425, level: 7" node_number="425"> Title: Gaussian Process Constraint Learning for Scalable Chance-Constrained Motion Planning from Demonstrations </div> <div class="valid" valid="valid" title="valid: True, node: 426, level: 7" node_number="426"> Authors: Glen Chou, <a class="valid" valid="valid" title="valid: True, node: 427, level: 8" node_number="427">Hao Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 428, level: 8" node_number="428">Dmitry Berenson</a> </div> <div class="valid" valid="valid" title="valid: True, node: 429, level: 7" node_number="429"> Comments: Under review at RA-L + ICRA 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 430, level: 7" node_number="430"> Subjects: Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 431, level: 7" node_number="431">We propose a method for learning constraints represented as Gaussian processes (GPs) from locally-optimal demonstrations. Our approach uses the Karush-Kuhn-Tucker (KKT) optimality conditions to determine where on the demonstrations the constraint is tight, and a scaling of the constraint gradient at those states. We then train a GP representation of the constraint which is consistent with and which generalizes this information. We further show that the GP uncertainty can be used within a kinodynamic RRT to plan probabilistically-safe trajectories, and that we can exploit the GP structure within the planner to exactly achieve a specified safety probability. We demonstrate our method can learn complex, nonlinear constraints demonstrated on a 5D nonholonomic car, a 12D quadrotor, and a 3-link planar arm, all while requiring minimal prior information on the constraint. Our results suggest the learned GP constraint is accurate, outperforming previous constraint learning methods that require more a priori knowledge. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 432, level: 5" node_number="432">[40] arXiv:2112.04613 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 433, level: 5" node_number="433"> <div class="valid" valid="valid" title="valid: True, node: 434, level: 6" node_number="434"> <div class="valid" valid="valid" title="valid: True, node: 435, level: 7" node_number="435"> Title: NICE-Beam: Neural Integrated Covariance Estimators for Time-Varying Beamformers </div> <div class="valid" valid="valid" title="valid: True, node: 436, level: 7" node_number="436"> Authors: Jonah Casebeer, <a class="valid" valid="valid" title="valid: True, node: 437, level: 8" node_number="437">Jacob Donley</a>, <a class="valid" valid="valid" title="valid: True, node: 438, level: 8" node_number="438">Daniel Wong</a>, <a class="valid" valid="valid" title="valid: True, node: 439, level: 8" node_number="439">Buye Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 440, level: 8" node_number="440">Anurag Kumar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 441, level: 7" node_number="441"> Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 442, level: 7" node_number="442">Estimating a time-varying spatial covariance matrix for a beamforming algorithm is a challenging task, especially for wearable devices, as the algorithm must compensate for time-varying signal statistics due to rapid pose-changes. In this paper, we propose Neural Integrated Covariance Estimators for Beamformers, NICE-Beam. NICE-Beam is a general technique for learning how to estimate time-varying spatial covariance matrices, which we apply to joint speech enhancement and dereverberation. It is based on training a neural network module to non-linearly track and leverage scene information across time. We integrate our solution into a beamforming pipeline, which enables simple training, faster than real-time inference, and a variety of test-time adaptation options. We evaluate the proposed model against a suite of baselines in scenes with both stationary and moving microphones. Our results show that the proposed method can outperform a hand-tuned estimator, despite the hand-tuned estimator using oracle source separation knowledge. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 443, level: 5" node_number="443">[41] arXiv:2112.04619 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 444, level: 5" node_number="444"> <div class="valid" valid="valid" title="valid: True, node: 445, level: 6" node_number="445"> <div class="valid" valid="valid" title="valid: True, node: 446, level: 7" node_number="446"> Title: Taxonomy of Virtual and Augmented Reality Applications in Education </div> <div class="valid" valid="valid" title="valid: True, node: 447, level: 7" node_number="447"> Authors: Jiri Motejlek, <a class="valid" valid="valid" title="valid: True, node: 448, level: 8" node_number="448">Esat Alpay</a> </div> <div class="valid" valid="valid" title="valid: True, node: 449, level: 7" node_number="449"> Subjects: Human-Computer Interaction (cs.HC) </div> <p class="valid" valid="valid" title="valid: True, node: 450, level: 7" node_number="450">This paper presents and analyses existing taxonomies of virtual and augmented reality and demonstrates knowledge gaps and mixed terminology which may cause confusion among educators, researchers, and developers. Several such occasions of confusion are presented. A methodology is then presented to construct a taxonomy of virtual reality and augmented reality applications based on a combination of: a faceted analysis approach for the overall design of the taxonomy; an existing taxonomy of educational objectives to derive the educational purpose; an information systems analysis to establish important facets of the taxonomy; and two systematic mapping studies to identify categories within each facet. Based onUsing thisthe methodology a new taxonomy is proposed and the implications of its facets (and their combinations of facets)are demonstrated. The taxonomy focuses on technology used to provide the virtual or augmented reality as well as the content presented to the user, including the type of gamification and how it is operated. It also takes into accountaccommodates a large number of devices and approaches developed throughout the years and for multiple industries, and proposes and developsprovides a way to categorize them in order to clarify communication between researchers, developers and as well as educators. Use of the taxonomy and implications of choices made during their development is then demonstrated ion two case studies:, a virtual reality chemical plant for use in chemical engineering education and an augmented reality dog for veterinary education. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 451, level: 5" node_number="451">[42] arXiv:2112.04620 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 452, level: 5" node_number="452"> <div class="valid" valid="valid" title="valid: True, node: 453, level: 6" node_number="453"> <div class="valid" valid="valid" title="valid: True, node: 454, level: 7" node_number="454"> Title: Calibration Improves Bayesian Optimization </div> <div class="valid" valid="valid" title="valid: True, node: 455, level: 7" node_number="455"> Authors: Shachi Deshpande, <a class="valid" valid="valid" title="valid: True, node: 456, level: 8" node_number="456">Volodymyr Kuleshov</a> </div> <div class="valid" valid="valid" title="valid: True, node: 457, level: 7" node_number="457"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 458, level: 7" node_number="458">Bayesian optimization is a procedure that allows obtaining the global optimum of black-box functions and that is useful in applications such as hyper-parameter optimization. Uncertainty estimates over the shape of the objective function are instrumental in guiding the optimization process. However, these estimates can be inaccurate if the objective function violates assumptions made within the underlying model (e.g., Gaussianity). We propose a simple algorithm to calibrate the uncertainty of posterior distributions over the objective function as part of the Bayesian optimization process. We show that by improving the uncertainty estimates of the posterior distribution with calibration, Bayesian optimization makes better decisions and arrives at the global optimum in fewer steps. We show that this technique improves the performance of Bayesian optimization on standard benchmark functions and hyperparameter optimization tasks. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 459, level: 5" node_number="459">[43] arXiv:2112.04622 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 460, level: 5" node_number="460"> <div class="valid" valid="valid" title="valid: True, node: 461, level: 6" node_number="461"> <div class="valid" valid="valid" title="valid: True, node: 462, level: 7" node_number="462"> Title: Greedy Algorithm for Multiway Matching with Bounded Regret </div> <div class="valid" valid="valid" title="valid: True, node: 463, level: 7" node_number="463"> Authors: Varun Gupta </div> <div class="valid" valid="valid" title="valid: True, node: 464, level: 7" node_number="464"> Subjects: Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC); Probability (math.PR) </div> <p class="valid" valid="valid" title="valid: True, node: 465, level: 7" node_number="465">In this paper we prove the efficacy of a simple greedy algorithm for a finite horizon online resource allocation/matching problem, when the corresponding static planning linear program (SPP) exhibits a non-degeneracy condition called the general position gap (GPG). The key intuition that we formalize is that the solution of the reward maximizing SPP is the same as a feasibility LP restricted to the optimal basic activities, and under GPG this solution can be tracked with bounded regret by a greedy algorithm, i.e., without the commonly used technique of periodically resolving the SPP. The goal of the decision maker is to combine resources (from a finite set of resource types) into configurations (from a finite set of feasible configurations) where each configuration is specified by the number of resources consumed of each type and a reward. The resources are further subdivided into three types - offline (whose quantity is known and available at time 0), online-queueable (which arrive online and can be stored in a buffer), and online-nonqueueable (which arrive online and must be matched on arrival or lost). Under GRG we prove that, (i) our greedy algorithm gets bounded any-time regret for matching reward (independent of $t$) when no configuration contains both an online-queueable and an online-nonqueueable resource, and (ii) $\mathcal{O}(\log t)$ expected any-time regret otherwise (we also prove a matching lower bound). By considering the three types of resources, our matching framework encompasses several well-studied problems such as dynamic multi-sided matching, network revenue management, online stochastic packing, and multiclass queueing systems. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 466, level: 5" node_number="466">[44] arXiv:2112.04623 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 467, level: 5" node_number="467"> <div class="valid" valid="valid" title="valid: True, node: 468, level: 6" node_number="468"> <div class="valid" valid="valid" title="valid: True, node: 469, level: 7" node_number="469"> Title: Efficient Checking of Temporal Compliance Rules Over Business Process Event Logs </div> <div class="valid" valid="valid" title="valid: True, node: 470, level: 7" node_number="470"> Authors: Adriano Augusto, <a class="valid" valid="valid" title="valid: True, node: 471, level: 8" node_number="471">Ahmed Awad</a>, <a class="valid" valid="valid" title="valid: True, node: 472, level: 8" node_number="472">Marlon Dumas</a> </div> <div class="valid" valid="valid" title="valid: True, node: 473, level: 7" node_number="473"> Subjects: Data Structures and Algorithms (cs.DS); Software Engineering (cs.SE) </div> <p class="valid" valid="valid" title="valid: True, node: 474, level: 7" node_number="474">Verifying temporal compliance rules, such as a rule stating that an inquiry must be answered within a time limit, is a recurrent operation in the realm of business process compliance. In this setting, a typical use case is one where a manager seeks to retrieve all cases where a temporal rule is violated, given an event log recording the execution of a process over a time period. Existing approaches for checking temporal rules require a full scan of the log. Such approaches are unsuitable for interactive use when the log is large and the set of compliance rules is evolving. This paper proposes an approach to evaluate temporal compliance rules in sublinear time by pre-computing a data structure that summarizes the temporal relations between activities in a log. The approach caters for a wide range of temporal compliance patterns and supports incremental updates. Our evaluation on twenty real-life logs shows that our data structure allows for real-time checking of a large set of compliance rules. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 475, level: 5" node_number="475">[45] arXiv:2112.04628 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 476, level: 5" node_number="476"> <div class="valid" valid="valid" title="valid: True, node: 477, level: 6" node_number="477"> <div class="valid" valid="valid" title="valid: True, node: 478, level: 7" node_number="478"> Title: Learning Auxiliary Monocular Contexts Helps Monocular 3D Object Detection </div> <div class="valid" valid="valid" title="valid: True, node: 479, level: 7" node_number="479"> Authors: Xianpeng Liu, <a class="valid" valid="valid" title="valid: True, node: 480, level: 8" node_number="480">Nan Xue</a>, <a class="valid" valid="valid" title="valid: True, node: 481, level: 8" node_number="481">Tianfu Wu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 482, level: 7" node_number="482"> Journal-ref: Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-2022) </div> <div class="valid" valid="valid" title="valid: True, node: 483, level: 7" node_number="483"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 484, level: 7" node_number="484">Monocular 3D object detection aims to localize 3D bounding boxes in an input single 2D image. It is a highly challenging problem and remains open, especially when no extra information (e.g., depth, lidar and/or multi-frames) can be leveraged in training and/or inference. This paper proposes a simple yet effective formulation for monocular 3D object detection without exploiting any extra information. It presents the MonoCon method which learns Monocular Contexts, as auxiliary tasks in training, to help monocular 3D object detection. The key idea is that with the annotated 3D bounding boxes of objects in an image, there is a rich set of well-posed projected 2D supervision signals available in training, such as the projected corner keypoints and their associated offset vectors with respect to the center of 2D bounding box, which should be exploited as auxiliary tasks in training. The proposed MonoCon is motivated by the Cramer-Wold theorem in measure theory at a high level. In implementation, it utilizes a very simple end-to-end design to justify the effectiveness of learning auxiliary monocular contexts, which consists of three components: a Deep Neural Network (DNN) based feature backbone, a number of regression head branches for learning the essential parameters used in the 3D bounding box prediction, and a number of regression head branches for learning auxiliary contexts. After training, the auxiliary context regression branches are discarded for better inference efficiency. In experiments, the proposed MonoCon is tested in the KITTI benchmark (car, pedestrain and cyclist). It outperforms all prior arts in the leaderboard on car category and obtains comparable performance on pedestrian and cyclist in terms of accuracy. Thanks to the simple design, the proposed MonoCon method obtains the fastest inference speed with 38.7 fps in comparisons </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 485, level: 5" node_number="485">[46] arXiv:2112.04629 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 486, level: 5" node_number="486"> <div class="valid" valid="valid" title="valid: True, node: 487, level: 6" node_number="487"> <div class="valid" valid="valid" title="valid: True, node: 488, level: 7" node_number="488"> Title: Transferability Properties of Graph Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 489, level: 7" node_number="489"> Authors: Luana Ruiz, <a class="valid" valid="valid" title="valid: True, node: 490, level: 8" node_number="490">Luiz F. O. Chamon</a>, <a class="valid" valid="valid" title="valid: True, node: 491, level: 8" node_number="491">Alejandro Ribeiro</a> </div> <div class="valid" valid="valid" title="valid: True, node: 492, level: 7" node_number="492"> Comments: Submitted to IEEE TSP </div> <div class="valid" valid="valid" title="valid: True, node: 493, level: 7" node_number="493"> Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP) </div> <p class="valid" valid="valid" title="valid: True, node: 494, level: 7" node_number="494">Graph neural networks (GNNs) are deep convolutional architectures consisting of layers composed by graph convolutions and pointwise nonlinearities. Due to their invariance and stability properties, GNNs are provably successful at learning representations from network data. However, training them requires matrix computations which can be expensive for large graphs. To address this limitation, we investigate the ability of GNNs to be transferred across graphs. We consider graphons, which are both graph limits and generative models for weighted and stochastic graphs, to define limit objects of graph convolutions and GNNs -- graphon convolutions and graphon neural networks (WNNs) -- which we use as generative models for graph convolutions and GNNs. We show that these graphon filters and WNNs can be approximated by graph filters and GNNs sampled from them on weighted and stochastic graphs. Using these results, we then derive error bounds for transferring graph filters and GNNs across such graphs. These bounds show that transferability increases with the graph size, and reveal a tradeoff between transferability and spectral discriminability which in GNNs is alleviated by the pointwise nonlinearities. These findings are further verified empirically in numerical experiments in movie recommendation and decentralized robot control. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 495, level: 5" node_number="495">[47] arXiv:2112.04630 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 496, level: 5" node_number="496"> <div class="valid" valid="valid" title="valid: True, node: 497, level: 6" node_number="497"> <div class="valid" valid="valid" title="valid: True, node: 498, level: 7" node_number="498"> Title: Towards Neural Functional Program Evaluation </div> <div class="valid" valid="valid" title="valid: True, node: 499, level: 7" node_number="499"> Authors: Torsten Scholak, <a class="valid" valid="valid" title="valid: True, node: 500, level: 8" node_number="500">Jonathan Pilault</a>, <a class="valid" valid="valid" title="valid: True, node: 501, level: 8" node_number="501">Joey Velez-Ginorio</a> </div> <div class="valid" valid="valid" title="valid: True, node: 502, level: 7" node_number="502"> Comments: 9 pages. Accepted at the AIPLANS workshop at NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 503, level: 7" node_number="503"> Subjects: Computation and Language (cs.CL); Programming Languages (cs.PL) </div> <p class="valid" valid="valid" title="valid: True, node: 504, level: 7" node_number="504">This paper explores the capabilities of current transformer-based language models for program evaluation of simple functional programming languages. We introduce a new program generation mechanism that allows control over syntactic sugar for semantically equivalent programs. T5 experiments reveal that neural functional program evaluation performs surprisingly well, achieving high 90% exact program match scores for most in-distribution and out-of-distribution tests. Using pretrained T5 weights has significant advantages over random initialization. We present and evaluate on three datasets to study generalization abilities that are specific to functional programs based on: type, function composition, and reduction steps. Code and data are publicly available at https://github.com/ElementAI/neural-interpreters. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 505, level: 5" node_number="505">[48] arXiv:2112.04632 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 506, level: 5" node_number="506"> <div class="valid" valid="valid" title="valid: True, node: 507, level: 6" node_number="507"> <div class="valid" valid="valid" title="valid: True, node: 508, level: 7" node_number="508"> Title: Recurrent Glimpse-based Decoder for Detection with Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 509, level: 7" node_number="509"> Authors: Zhe Chen, <a class="valid" valid="valid" title="valid: True, node: 510, level: 8" node_number="510">Jing Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 511, level: 8" node_number="511">Dacheng Tao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 512, level: 7" node_number="512"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 513, level: 7" node_number="513">Although detection with Transformer (DETR) is increasingly popular, its global attention modeling requires an extremely long training period to optimize and achieve promising detection performance. Alternative to existing studies that mainly develop advanced feature or embedding designs to tackle the training issue, we point out that the Region-of-Interest (RoI) based detection refinement can easily help mitigate the difficulty of training for DETR methods. Based on this, we introduce a novel REcurrent Glimpse-based decOder (REGO) in this paper. In particular, the REGO employs a multi-stage recurrent processing structure to help the attention of DETR gradually focus on foreground objects more accurately. In each processing stage, visual features are extracted as glimpse features from RoIs with enlarged bounding box areas of detection results from the previous stage. Then, a glimpse-based decoder is introduced to provide refined detection results based on both the glimpse features and the attention modeling outputs of the previous stage. In practice, REGO can be easily embedded in representative DETR variants while maintaining their fully end-to-end training and inference pipelines. In particular, REGO helps Deformable DETR achieve 44.8 AP on the MSCOCO dataset with only 36 training epochs, compared with the first DETR and the Deformable DETR that require 500 and 50 epochs to achieve comparable performance, respectively. Experiments also show that REGO consistently boosts the performance of different DETR detectors by up to 7% relative gain at the same setting of 50 training epochs. Code is available via https://github.com/zhechen/Deformable-DETR-REGO. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 514, level: 5" node_number="514">[49] arXiv:2112.04634 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 515, level: 5" node_number="515"> <div class="valid" valid="valid" title="valid: True, node: 516, level: 6" node_number="516"> <div class="valid" valid="valid" title="valid: True, node: 517, level: 7" node_number="517"> Title: Process Mining-Driven Analysis of the COVID19 Impact on the Vaccinations of Victorian Patients </div> <div class="valid" valid="valid" title="valid: True, node: 518, level: 7" node_number="518"> Authors: Adriano Augusto, <a class="valid" valid="valid" title="valid: True, node: 519, level: 8" node_number="519">Timothy Deitz</a>, <a class="valid" valid="valid" title="valid: True, node: 520, level: 8" node_number="520">Noel Faux</a>, <a class="valid" valid="valid" title="valid: True, node: 521, level: 8" node_number="521">Jo-Anne Manski-Nankervis</a>, <a class="valid" valid="valid" title="valid: True, node: 522, level: 8" node_number="522">Daniel Capurro</a> </div> <div class="valid" valid="valid" title="valid: True, node: 523, level: 7" node_number="523"> Subjects: Databases (cs.DB); Computers and Society (cs.CY) </div> <p class="valid" valid="valid" title="valid: True, node: 524, level: 7" node_number="524">Process mining is a discipline sitting between data mining and process science, whose goal is to provide theoretical methods and software tools to analyse process execution data, known as event logs. Although process mining was originally conceived to facilitate business process management activities, research studies have shown the benefit of leveraging process mining tools in different contexts, including healthcare. However, applying process mining tools to analyse healthcare process execution data is not straightforward. In this paper, we report the analysis of an event log recording more than 30 million events capturing the general practice healthcare processes of more than one million patients in Victoria--Australia--over five years. Our analysis allowed us to understand benefits and limitations of the state-of-the-art process mining techniques when dealing with highly variable processes and large data-sets. While we provide solutions to the identified limitations, the overarching goal of this study was to detect differences between the patients` health services utilization pattern observed in 2020--during the COVID-19 pandemic and mandatory lock-downs --and the one observed in the prior four years, 2016 to 2019. By using a combination of process mining techniques and traditional data mining, we were able to demonstrate that vaccinations in Victoria did not drop drastically--as other interactions did. On the contrary, we observed a surge of influenza and pneumococcus vaccinations in 2020, contradicting research findings of similar studies conducted in different geographical areas. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 525, level: 5" node_number="525">[50] arXiv:2112.04635 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 526, level: 5" node_number="526"> <div class="valid" valid="valid" title="valid: True, node: 527, level: 6" node_number="527"> <div class="valid" valid="valid" title="valid: True, node: 528, level: 7" node_number="528"> Title: Decentralized Frequency Regulation of Hybrid MTDC-linked Grids </div> <div class="valid" valid="valid" title="valid: True, node: 529, level: 7" node_number="529"> Authors: Young-Jin Kim </div> <div class="valid" valid="valid" title="valid: True, node: 530, level: 7" node_number="530"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 531, level: 7" node_number="531">This paper proposes a new strategy for optimal grid frequency regulation (FR) in an interconnected power system where regional ac grids and an offshore wind farm are linked via a multi-terminal high voltage direct-current (MTDC) network. In the proposed strategy, decentralized H-infinity controllers are developed to coordinate the operations of ac synchronous generators and hybrid MTDC converters, thus achieving optimal power sharing of interconnected ac grids and minimizing frequency deviations in each grid. To develop the controllers, robust optimization problems are formulated and solved using a dynamic model of the hybrid MTDC-linked grids with model parameter uncertainty and decentralized control inputs and outputs. The model orders of the resulting controllers are then reduced using a balanced truncation algorithm to eliminate unobservable and uncontrollable state variables while preserving their dominant response characteristics. Sensitivity and eigenvalue analyses are conducted focusing on the effects of grid measurements, parameter uncertainty levels, and communication time delays. Comparative case studies are also carried out to verify that the proposed strategy improves the effectiveness, stability, and robustness of real-time FR in MTDC-linked grids under various conditions characterized mainly by load demands, communications systems, and weighting functions. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 532, level: 5" node_number="532">[51] arXiv:2112.04639 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 533, level: 5" node_number="533"> <div class="valid" valid="valid" title="valid: True, node: 534, level: 6" node_number="534"> <div class="valid" valid="valid" title="valid: True, node: 535, level: 7" node_number="535"> Title: Safe Autonomous Navigation for Systems with Learned SE(3) Hamiltonian Dynamics </div> <div class="valid" valid="valid" title="valid: True, node: 536, level: 7" node_number="536"> Authors: Zhichao Li, <a class="valid" valid="valid" title="valid: True, node: 537, level: 8" node_number="537">Thai Duong</a>, <a class="valid" valid="valid" title="valid: True, node: 538, level: 8" node_number="538">Nikolay Atanasov</a> </div> <div class="valid" valid="valid" title="valid: True, node: 539, level: 7" node_number="539"> Subjects: Robotics (cs.RO); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 540, level: 7" node_number="540">Safe autonomous navigation in unknown environments is an important problem for ground, aerial, and underwater robots. This paper proposes techniques to learn the dynamics models of a mobile robot from trajectory data and synthesize a tracking controller with safety and stability guarantees. The state of a mobile robot usually contains its position, orientation, and generalized velocity and satisfies Hamilton's equations of motion. Instead of a hand-derived dynamics model, we use a dataset of state-control trajectories to train a translation-equivariant nonlinear Hamiltonian model represented as a neural ordinary differential equation (ODE) network. The learned Hamiltonian model is used to synthesize an energy-shaping passivity-based controller and derive conditions which guarantee safe regulation to a desired reference pose. Finally, we enable adaptive tracking of a desired path, subject to safety constraints obtained from obstacle distance measurements. The trade-off between the system's energy level and the distance to safety constraint violation is used to adaptively govern the reference pose along the desired path. Our safe adaptive controller is demonstrated on a simulated hexarotor robot navigating in unknown complex environments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 541, level: 5" node_number="541">[52] arXiv:2112.04640 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 542, level: 5" node_number="542"> <div class="valid" valid="valid" title="valid: True, node: 543, level: 6" node_number="543"> <div class="valid" valid="valid" title="valid: True, node: 544, level: 7" node_number="544"> Title: Differentially Private Ensemble Classifiers for Data Streams </div> <div class="valid" valid="valid" title="valid: True, node: 545, level: 7" node_number="545"> Authors: Lovedeep Gondara, <a class="valid" valid="valid" title="valid: True, node: 546, level: 8" node_number="546">Ke Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 547, level: 8" node_number="547">Ricardo Silva Carvalho</a> </div> <div class="valid" valid="valid" title="valid: True, node: 548, level: 7" node_number="548"> Comments: Accepted at WSDM 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 549, level: 7" node_number="549"> Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 550, level: 7" node_number="550">Learning from continuous data streams via classification/regression is prevalent in many domains. Adapting to evolving data characteristics (concept drift) while protecting data owners' private information is an open challenge. We present a differentially private ensemble solution to this problem with two distinguishing features: it allows an extit{unbounded} number of ensemble updates to deal with the potentially never-ending data streams under a fixed privacy budget, and it is extit{model agnostic}, in that it treats any pre-trained differentially private classification/regression model as a black-box. Our method outperforms competitors on real-world and simulated datasets for varying settings of privacy, concept drift, and data distribution. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 551, level: 5" node_number="551">[53] arXiv:2112.04641 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 552, level: 5" node_number="552"> <div class="valid" valid="valid" title="valid: True, node: 553, level: 6" node_number="553"> <div class="valid" valid="valid" title="valid: True, node: 554, level: 7" node_number="554"> Title: Multiple Residual Dense Networks for Reconfigurable Intelligent Surfaces Cascaded Channel Estimation </div> <div class="valid" valid="valid" title="valid: True, node: 555, level: 7" node_number="555"> Authors: Yu Jin, <a class="valid" valid="valid" title="valid: True, node: 556, level: 8" node_number="556">Jiayi Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 557, level: 8" node_number="557">Chongwen Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 558, level: 8" node_number="558">Liang Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 559, level: 8" node_number="559">Huahua Xiao</a>, <a class="valid" valid="valid" title="valid: True, node: 560, level: 8" node_number="560">Bo Ai</a>, <a class="valid" valid="valid" title="valid: True, node: 561, level: 8" node_number="561">Zhiqin Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 562, level: 7" node_number="562"> Comments: to appear in IEEE TVT </div> <div class="valid" valid="valid" title="valid: True, node: 563, level: 7" node_number="563"> Subjects: Information Theory (cs.IT); Signal Processing (eess.SP) </div> <p class="valid" valid="valid" title="valid: True, node: 564, level: 7" node_number="564">Reconfigurable intelligent surface (RIS) constitutes an essential and promising paradigm that relies programmable wireless environment and provides capability for space-intensive communications, due to the use of low-cost massive reflecting elements over the entire surfaces of man-made structures. However, accurate channel estimation is a fundamental technical prerequisite to achieve the huge performance gains from RIS. By leveraging the low rank structure of RIS channels, three practical residual neural networks, named convolutional blind denoising network, convolutional denoising generative adversarial networks and multiple residual dense network, are proposed to obtain accurate channel state information, which can reflect the impact of different methods on the estimation performance. Simulation results reveal the evolution direction of these three methods and reveal their superior performance compared with existing benchmark schemes. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 565, level: 5" node_number="565">[54] arXiv:2112.04643 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 566, level: 5" node_number="566"> <div class="valid" valid="valid" title="valid: True, node: 567, level: 6" node_number="567"> <div class="valid" valid="valid" title="valid: True, node: 568, level: 7" node_number="568"> Title: Autoregressive Quantile Flows for Predictive Uncertainty Estimation </div> <div class="valid" valid="valid" title="valid: True, node: 569, level: 7" node_number="569"> Authors: Phillip Si, <a class="valid" valid="valid" title="valid: True, node: 570, level: 8" node_number="570">Allan Bishop</a>, <a class="valid" valid="valid" title="valid: True, node: 571, level: 8" node_number="571">Volodymyr Kuleshov</a> </div> <div class="valid" valid="valid" title="valid: True, node: 572, level: 7" node_number="572"> Comments: 9 pages, 4 figures, 6 tables (main body) additional 4 pages, 2 figures, 4 tables (appendix) </div> <div class="valid" valid="valid" title="valid: True, node: 573, level: 7" node_number="573"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 574, level: 7" node_number="574">Numerous applications of machine learning involve predicting flexible probability distributions over model outputs. We propose Autoregressive Quantile Flows, a flexible class of probabilistic models over high-dimensional variables that can be used to accurately capture predictive aleatoric uncertainties. These models are instances of autoregressive flows trained using a novel objective based on proper scoring rules, which simplifies the calculation of computationally expensive determinants of Jacobians during training and supports new types of neural architectures. We demonstrate that these models can be used to parameterize predictive conditional distributions and improve the quality of probabilistic predictions on time series forecasting and object detection. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 575, level: 5" node_number="575">[55] arXiv:2112.04645 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 576, level: 5" node_number="576"> <div class="valid" valid="valid" title="valid: True, node: 577, level: 6" node_number="577"> <div class="valid" valid="valid" title="valid: True, node: 578, level: 7" node_number="578"> Title: BACON: Band-limited Coordinate Networks for Multiscale Scene Representation </div> <div class="valid" valid="valid" title="valid: True, node: 579, level: 7" node_number="579"> Authors: David B. Lindell, <a class="valid" valid="valid" title="valid: True, node: 580, level: 8" node_number="580">Dave Van Veen</a>, <a class="valid" valid="valid" title="valid: True, node: 581, level: 8" node_number="581">Jeong Joon Park</a>, <a class="valid" valid="valid" title="valid: True, node: 582, level: 8" node_number="582">Gordon Wetzstein</a> </div> <div class="valid" valid="valid" title="valid: True, node: 583, level: 7" node_number="583"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 584, level: 7" node_number="584">Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, and so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has predictable behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without explicit supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 585, level: 5" node_number="585">[56] arXiv:2112.04660 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 586, level: 5" node_number="586"> <div class="valid" valid="valid" title="valid: True, node: 587, level: 6" node_number="587"> <div class="valid" valid="valid" title="valid: True, node: 588, level: 7" node_number="588"> Title: A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse </div> <div class="valid" valid="valid" title="valid: True, node: 589, level: 7" node_number="589"> Authors: Junyi Li, <a class="valid" valid="valid" title="valid: True, node: 590, level: 8" node_number="590">Bin Gu</a>, <a class="valid" valid="valid" title="valid: True, node: 591, level: 8" node_number="591">Heng Huang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 592, level: 7" node_number="592"> Comments: To appear in AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 593, level: 7" node_number="593"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 594, level: 7" node_number="594">In this paper, we propose a new Hessian inverse free Fully Single Loop Algorithm (FSLA) for bilevel optimization problems. Classic algorithms for bilevel optimization admit a double loop structure which is computationally expensive. Recently, several single loop algorithms have been proposed with optimizing the inner and outer variable alternatively. However, these algorithms not yet achieve fully single loop. As they overlook the loop needed to evaluate the hyper-gradient for a given inner and outer state. In order to develop a fully single loop algorithm, we first study the structure of the hyper-gradient and identify a general approximation formulation of hyper-gradient computation that encompasses several previous common approaches, e.g. back-propagation through time, conjugate gradient, \emph{etc.} Based on this formulation, we introduce a new state variable to maintain the historical hyper-gradient information. Combining our new formulation with the alternative update of the inner and outer variables, we propose an efficient fully single loop algorithm. We theoretically show that the error generated by the new state can be bounded and our algorithm converges with the rate of $O(\epsilon^{-2})$. Finally, we verify the efficacy our algorithm empirically through multiple bilevel optimization based machine learning tasks. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 595, level: 5" node_number="595">[57] arXiv:2112.04662 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 596, level: 5" node_number="596"> <div class="valid" valid="valid" title="valid: True, node: 597, level: 6" node_number="597"> <div class="valid" valid="valid" title="valid: True, node: 598, level: 7" node_number="598"> Title: Dual Cluster Contrastive learning for Person Re-Identification </div> <div class="valid" valid="valid" title="valid: True, node: 599, level: 7" node_number="599"> Authors: Hantao Yao, <a class="valid" valid="valid" title="valid: True, node: 600, level: 8" node_number="600">Changsheng Xu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 601, level: 7" node_number="601"> Comments: 10 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 602, level: 7" node_number="602"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 603, level: 7" node_number="603">Recently, cluster contrastive learning has been proven effective for person ReID by computing the contrastive loss between the individual feature and the cluster memory. However, existing methods that use the individual feature to momentum update the cluster memory are not robust to the noisy samples, such as the samples with wrong annotated labels or the pseudo-labels. Unlike the individual-based updating mechanism, the centroid-based updating mechanism that applies the mean feature of each cluster to update the cluster memory is robust against minority noisy samples. Therefore, we formulate the individual-based updating and centroid-based updating mechanisms in a unified cluster contrastive framework, named Dual Cluster Contrastive learning (DCC), which maintains two types of memory banks: individual and centroid cluster memory banks. Significantly, the individual cluster memory is momentum updated based on the individual feature.The centroid cluster memory applies the mean feature of each cluter to update the corresponding cluster memory. Besides the vallina contrastive loss for each memory, a consistency constraint is applied to guarantee the consistency of the output of two memories. Note that DCC can be easily applied for unsupervised or supervised person ReID by using ground-truth labels or pseudo-labels generated with clustering method, respectively. Extensive experiments on two benchmarks under supervised person ReID and unsupervised person ReID demonstrate the superior of the proposed DCC. Code is available at: https://github.com/htyao89/Dual-Cluster-Contrastive/ </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 604, level: 5" node_number="604">[58] arXiv:2112.04665 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 605, level: 5" node_number="605"> <div class="valid" valid="valid" title="valid: True, node: 606, level: 6" node_number="606"> <div class="valid" valid="valid" title="valid: True, node: 607, level: 7" node_number="607"> Title: Style Mixing and Patchwise Prototypical Matching for One-Shot Unsupervised Domain Adaptive Semantic Segmentation </div> <div class="valid" valid="valid" title="valid: True, node: 608, level: 7" node_number="608"> Authors: Xinyi Wu, <a class="valid" valid="valid" title="valid: True, node: 609, level: 8" node_number="609">Zhenyao Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 610, level: 8" node_number="610">Yuhang Lu</a>, <a class="valid" valid="valid" title="valid: True, node: 611, level: 8" node_number="611">Lili Ju</a>, <a class="valid" valid="valid" title="valid: True, node: 612, level: 8" node_number="612">Song Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 613, level: 7" node_number="613"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 614, level: 7" node_number="614"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 615, level: 7" node_number="615">In this paper, we tackle the problem of one-shot unsupervised domain adaptation (OSUDA) for semantic segmentation where the segmentors only see one unlabeled target image during training. In this case, traditional unsupervised domain adaptation models usually fail since they cannot adapt to the target domain with over-fitting to one (or few) target samples. To address this problem, existing OSUDA methods usually integrate a style-transfer module to perform domain randomization based on the unlabeled target sample, with which multiple domains around the target sample can be explored during training. However, such a style-transfer module relies on an additional set of images as style reference for pre-training and also increases the memory demand for domain adaptation. Here we propose a new OSUDA method that can effectively relieve such computational burden. Specifically, we integrate several style-mixing layers into the segmentor which play the role of style-transfer module to stylize the source images without introducing any learned parameters. Moreover, we propose a patchwise prototypical matching (PPM) method to weighted consider the importance of source pixels during the supervised training to relieve the negative adaptation. Experimental results show that our method achieves new state-of-the-art performance on two commonly used benchmarks for domain adaptive semantic segmentation under the one-shot setting and is more efficient than all comparison approaches. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 616, level: 5" node_number="616">[59] arXiv:2112.04666 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 617, level: 5" node_number="617"> <div class="valid" valid="valid" title="valid: True, node: 618, level: 6" node_number="618"> <div class="valid" valid="valid" title="valid: True, node: 619, level: 7" node_number="619"> Title: Densifying Sparse Representations for Passage Retrieval by Representational Slicing </div> <div class="valid" valid="valid" title="valid: True, node: 620, level: 7" node_number="620"> Authors: Sheng-Chieh Lin, <a class="valid" valid="valid" title="valid: True, node: 621, level: 8" node_number="621">Jimmy Lin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 622, level: 7" node_number="622"> Subjects: Information Retrieval (cs.IR) </div> <p class="valid" valid="valid" title="valid: True, node: 623, level: 7" node_number="623">Learned sparse and dense representations capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust. Prior work combines dense and sparse retrievers by fusing their model scores. As an alternative, this paper presents a simple approach to densifying sparse representations for text retrieval that does not involve any training. Our densified sparse representations (DSRs) are interpretable and can be easily combined with dense representations for end-to-end retrieval. We demonstrate that our approach can jointly learn sparse and dense representations within a single model and then combine them for dense retrieval. Experimental results suggest that combining our DSRs and dense representations yields a balanced tradeoff between effectiveness and efficiency. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 624, level: 5" node_number="624">[60] arXiv:2112.04669 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 625, level: 5" node_number="625"> <div class="valid" valid="valid" title="valid: True, node: 626, level: 6" node_number="626"> <div class="valid" valid="valid" title="valid: True, node: 627, level: 7" node_number="627"> Title: A Survey on Parameterized Inapproximability: $k$-Clique, $k$-SetCover, and More </div> <div class="valid" valid="valid" title="valid: True, node: 628, level: 7" node_number="628"> Authors: Xuandi Ren </div> <div class="valid" valid="valid" title="valid: True, node: 629, level: 7" node_number="629"> Subjects: Computational Complexity (cs.CC) </div> <p class="valid" valid="valid" title="valid: True, node: 630, level: 7" node_number="630">In the past a few years, many interesting inapproximability results have been obtained from the parameterized perspective. This article surveys some of such results, with a focus on $k$-Clique, $k$-SetCover, and other related problems. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 631, level: 5" node_number="631">[61] arXiv:2112.04674 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 632, level: 5" node_number="632"> <div class="valid" valid="valid" title="valid: True, node: 633, level: 6" node_number="633"> <div class="valid" valid="valid" title="valid: True, node: 634, level: 7" node_number="634"> Title: DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition </div> <div class="valid" valid="valid" title="valid: True, node: 635, level: 7" node_number="635"> Authors: Yuxuan Liang, <a class="valid" valid="valid" title="valid: True, node: 636, level: 8" node_number="636">Pan Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 637, level: 8" node_number="637">Roger Zimmermann</a>, <a class="valid" valid="valid" title="valid: True, node: 638, level: 8" node_number="638">Shuicheng Yan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 639, level: 7" node_number="639"> Comments: Preprint </div> <div class="valid" valid="valid" title="valid: True, node: 640, level: 7" node_number="640"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 641, level: 7" node_number="641">While transformers have shown great potential on video recognition tasks with their strong capability of capturing long-range dependencies, they often suffer high computational costs induced by self-attention operation on the huge number of 3D tokens in a video. In this paper, we propose a new transformer architecture, termed DualFormer, which can effectively and efficiently perform space-time attention for video recognition. Specifically, our DualFormer stratifies the full space-time attention into dual cascaded levels, i.e., to first learn fine-grained local space-time interactions among nearby 3D tokens, followed by the capture of coarse-grained global dependencies between the query token and the coarse-grained global pyramid contexts. Different from existing methods that apply space-time factorization or restrict attention computations within local windows for improving efficiency, our local-global stratified strategy can well capture both short- and long-range spatiotemporal dependencies, and meanwhile greatly reduces the number of keys and values in attention computation to boost efficiency. Experimental results show the superiority of DualFormer on five video benchmarks against existing methods. In particular, DualFormer sets new state-of-the-art 82.9%/85.2% top-1 accuracy on Kinetics-400/600 with around 1000G inference FLOPs which is at least 3.2 times fewer than existing methods with similar performances. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 642, level: 5" node_number="642">[62] arXiv:2112.04680 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 643, level: 5" node_number="643"> <div class="valid" valid="valid" title="valid: True, node: 644, level: 6" node_number="644"> <div class="valid" valid="valid" title="valid: True, node: 645, level: 7" node_number="645"> Title: SimIPU: Simple 2D Image and 3D Point Cloud Unsupervised Pre-Training for Spatial-Aware Visual Representations </div> <div class="valid" valid="valid" title="valid: True, node: 646, level: 7" node_number="646"> Authors: Zhenyu Li, <a class="valid" valid="valid" title="valid: True, node: 647, level: 8" node_number="647">Zehui Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 648, level: 8" node_number="648">Ang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 649, level: 8" node_number="649">Liangji Fang</a>, <a class="valid" valid="valid" title="valid: True, node: 650, level: 8" node_number="650">Qinhong Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 651, level: 8" node_number="651">Xianming Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 652, level: 8" node_number="652">Junjun Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 653, level: 8" node_number="653">Bolei Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 654, level: 8" node_number="654">Hang Zhao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 655, level: 7" node_number="655"> Comments: Accepted to 36th AAAI Conference on Artificial Intelligence (AAAI 2022) </div> <div class="valid" valid="valid" title="valid: True, node: 656, level: 7" node_number="656"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 657, level: 7" node_number="657">Pre-training has become a standard paradigm in many computer vision tasks. However, most of the methods are generally designed on the RGB image domain. Due to the discrepancy between the two-dimensional image plane and the three-dimensional space, such pre-trained models fail to perceive spatial information and serve as sub-optimal solutions for 3D-related tasks. To bridge this gap, we aim to learn a spatial-aware visual representation that can describe the three-dimensional space and is more suitable and effective for these tasks. To leverage point clouds, which are much more superior in providing spatial information compared to images, we propose a simple yet effective 2D Image and 3D Point cloud Unsupervised pre-training strategy, called SimIPU. Specifically, we develop a multi-modal contrastive learning framework that consists of an intra-modal spatial perception module to learn a spatial-aware representation from point clouds and an inter-modal feature interaction module to transfer the capability of perceiving spatial information from the point cloud encoder to the image encoder, respectively. Positive pairs for contrastive losses are established by the matching algorithm and the projection matrix. The whole framework is trained in an unsupervised end-to-end fashion. To the best of our knowledge, this is the first study to explore contrastive learning pre-training strategies for outdoor multi-modal datasets, containing paired camera images and LIDAR point clouds. Codes and models are available at https://github.com/zhyever/SimIPU. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 658, level: 5" node_number="658">[63] arXiv:2112.04682 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 659, level: 5" node_number="659"> <div class="valid" valid="valid" title="valid: True, node: 660, level: 6" node_number="660"> <div class="valid" valid="valid" title="valid: True, node: 661, level: 7" node_number="661"> Title: Clairvoyance: Intelligent Route Planning for Electric Buses Based on Urban Big Data </div> <div class="valid" valid="valid" title="valid: True, node: 662, level: 7" node_number="662"> Authors: Xiangyong Lu, <a class="valid" valid="valid" title="valid: True, node: 663, level: 8" node_number="663">Kaoru Ota</a>, <a class="valid" valid="valid" title="valid: True, node: 664, level: 8" node_number="664">Mianxiong Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 665, level: 8" node_number="665">Chen Yu</a>, <a class="valid" valid="valid" title="valid: True, node: 666, level: 8" node_number="666">Hai Jin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 667, level: 7" node_number="667"> Comments: 13 pages,12 figures </div> <div class="valid" valid="valid" title="valid: True, node: 668, level: 7" node_number="668"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 669, level: 7" node_number="669">Nowadays many cities around the world have introduced electric buses to optimize urban traffic and reduce local carbon emissions. In order to cut carbon emissions and maximize the utility of electric buses, it is important to choose suitable routes for them. Traditionally, route selection is on the basis of dedicated surveys, which are costly in time and labor. In this paper, we mainly focus attention on planning electric bus routes intelligently, depending on the unique needs of each region throughout the city. We propose Clairvoyance, a route planning system that leverages a deep neural network and a multilayer perceptron to predict the future people's trips and the future transportation carbon emission in the whole city, respectively. Given the future information of people's trips and transportation carbon emission, we utilize a greedy mechanism to recommend bus routes for electric buses that will depart in an ideal state. Furthermore, representative features of the two neural networks are extracted from the heterogeneous urban datasets. We evaluate our approach through extensive experiments on real-world data sources in Zhuhai, China. The results show that our designed neural network-based algorithms are consistently superior to the typical baselines. Additionally, the recommended routes for electric buses are helpful in reducing the peak value of carbon emissions and making full use of electric buses in the city. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 670, level: 5" node_number="670">[64] arXiv:2112.04683 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 671, level: 5" node_number="671"> <div class="valid" valid="valid" title="valid: True, node: 672, level: 6" node_number="672"> <div class="valid" valid="valid" title="valid: True, node: 673, level: 7" node_number="673"> Title: Dynamic Interaction of Transportation and Power Distribution Networks With Electric Vehicles </div> <div class="valid" valid="valid" title="valid: True, node: 674, level: 7" node_number="674"> Authors: Li Jiaqi, <a class="valid" valid="valid" title="valid: True, node: 675, level: 8" node_number="675">Xu Xiaoyuan</a>, <a class="valid" valid="valid" title="valid: True, node: 676, level: 8" node_number="676">Yan Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 677, level: 8" node_number="677">Wang Han</a>, <a class="valid" valid="valid" title="valid: True, node: 678, level: 8" node_number="678">Chen Yue</a> </div> <div class="valid" valid="valid" title="valid: True, node: 679, level: 7" node_number="679"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 680, level: 7" node_number="680">The increasing global spread of electric vehicles has introduced significant interdependence between transportation and power networks. Most of the previous studies on the coupled networks are based on static models, and the spatial and temporal variations of traffic and power flows are neglected, which is not suitable for short-term operation. This paper constructs a dynamic interaction model of coupled networks. First, the dynamic traffic assignment (DTA) model is established considering departure time and route choices simultaneously, and a nested diagonalization method is exploited to solve it. Then, based on DTA and multi-period optimal power flow, the equilibrium state of coupled networks is designed as the solution of a fixed-point problem. Moreover, the solution existence is proved based on mild assumptions. Third, the linearization and convex relaxation techniques are used to improve computational efficiency. A Monte Carlo simulation technique is developed to evaluate the influence of uncertain travel demands on coupled networks. Numerical simulations of the interaction analyses of coupled networks in both deterministic and uncertain conditions are presented. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 681, level: 5" node_number="681">[65] arXiv:2112.04684 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 682, level: 5" node_number="682"> <div class="valid" valid="valid" title="valid: True, node: 683, level: 6" node_number="683"> <div class="valid" valid="valid" title="valid: True, node: 684, level: 7" node_number="684"> Title: Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain </div> <div class="valid" valid="valid" title="valid: True, node: 685, level: 7" node_number="685"> Authors: Stefan Wapnick, <a class="valid" valid="valid" title="valid: True, node: 686, level: 8" node_number="686">Travis Manderson</a>, <a class="valid" valid="valid" title="valid: True, node: 687, level: 8" node_number="687">David Meger</a>, <a class="valid" valid="valid" title="valid: True, node: 688, level: 8" node_number="688">Gregory Dudek</a> </div> <div class="valid" valid="valid" title="valid: True, node: 689, level: 7" node_number="689"> Comments: Published in International Conference on Intelligent Robots and Systems (IROS) 2021 proceedings. Project website: <a class="valid" valid="valid" title="valid: True, node: 690, level: 8" node_number="690">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 691, level: 7" node_number="691"> Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 692, level: 7" node_number="692">We present a reward-predictive, model-based deep learning method featuring trajectory-constrained visual attention for use in mapless, local visual navigation tasks. Our method learns to place visual attention at locations in latent image space which follow trajectories caused by vehicle control actions to enhance predictive accuracy during planning. The attention model is jointly optimized by the task-specific loss and an additional trajectory-constraint loss, allowing adaptability yet encouraging a regularized structure for improved generalization and reliability. Importantly, visual attention is applied in latent feature map space instead of raw image space to promote efficient planning. We validated our model in visual navigation tasks of planning low turbulence, collision-free trajectories in off-road settings and hill climbing with locking differentials in the presence of slippery terrain. Experiments involved randomized procedural generated simulation and real-world environments. We found our method improved generalization and learning efficiency when compared to no-attention and self-attention alternatives. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 693, level: 5" node_number="693">[66] arXiv:2112.04685 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 694, level: 5" node_number="694"> <div class="valid" valid="valid" title="valid: True, node: 695, level: 6" node_number="695"> <div class="valid" valid="valid" title="valid: True, node: 696, level: 7" node_number="696"> Title: CWS-PResUNet: Music Source Separation with Channel-wise Subband Phase-aware ResUNet </div> <div class="valid" valid="valid" title="valid: True, node: 697, level: 7" node_number="697"> Authors: Haohe Liu, <a class="valid" valid="valid" title="valid: True, node: 698, level: 8" node_number="698">Qiuqiang Kong</a>, <a class="valid" valid="valid" title="valid: True, node: 699, level: 8" node_number="699">Jiafeng Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 700, level: 7" node_number="700"> Comments: Published at MDX Workshop @ ISMIR 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 701, level: 7" node_number="701"> Subjects: Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 702, level: 7" node_number="702">Music source separation (MSS) shows active progress with deep learning models in recent years. Many MSS models perform separations on spectrograms by estimating bounded ratio masks and reusing the phases of the mixture. When using convolutional neural networks (CNN), weights are usually shared within a spectrogram during convolution regardless of the different patterns between frequency bands. In this study, we propose a new MSS model, channel-wise subband phase-aware ResUNet (CWS-PResUNet), to decompose signals into subbands and estimate an unbound complex ideal ratio mask (cIRM) for each source. CWS-PResUNet utilizes a channel-wise subband (CWS) feature to limit unnecessary global weights sharing on the spectrogram and reduce computational resource consumptions. The saved computational cost and memory can in turn allow for a larger architecture. On the MUSDB18HQ test set, we propose a 276-layer CWS-PResUNet and achieve state-of-the-art (SoTA) performance on vocals with an 8.92 signal-to-distortion ratio (SDR) score. By combining CWS-PResUNet and Demucs, our ByteMSS system ranks the 2nd on vocals score and 5th on average score in the 2021 ISMIR Music Demixing (MDX) Challenge limited training data track (leaderboard A). Our code and pre-trained models are publicly available at: https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 703, level: 5" node_number="703">[67] arXiv:2112.04688 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 704, level: 5" node_number="704"> <div class="valid" valid="valid" title="valid: True, node: 705, level: 6" node_number="705"> <div class="valid" valid="valid" title="valid: True, node: 706, level: 7" node_number="706"> Title: Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single Lane Representations of Traffic-compressed </div> <div class="valid" valid="valid" title="valid: True, node: 707, level: 7" node_number="707"> Authors: Abdul Rahman Kreidieh, <a class="valid" valid="valid" title="valid: True, node: 708, level: 8" node_number="708">Yibo Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 709, level: 8" node_number="709">Samyak Parajuli</a>, <a class="valid" valid="valid" title="valid: True, node: 710, level: 8" node_number="710">Alexandre Bayen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 711, level: 7" node_number="711"> Subjects: Multiagent Systems (cs.MA); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 712, level: 7" node_number="712">Reinforcement learning techniques can provide substantial insights into the desired behaviors of future autonomous driving systems. By optimizing for societal metrics of traffic such as increased throughput and reduced energy consumption, such methods can derive maneuvers that, if adopted by even a small portion of vehicles, may significantly improve the state of traffic for all vehicles involved. These methods, however, are hindered in practice by the difficulty of designing efficient and accurate models of traffic, as well as the challenges associated with optimizing for the behaviors of dozens of interacting agents. In response to these challenges, this paper tackles the problem of learning generalizable traffic control strategies in simple representations of vehicle driving dynamics. In particular, we look to mixed-autonomy ring roads as depictions of instabilities that result in the formation of congestion. Within this problem, we design a curriculum learning paradigm that exploits the natural extendability of the network to effectively learn behaviors that reduce congestion over long horizons. Next, we study the implications of modeling lane changing on the transferability of policies. Our findings suggest that introducing lane change behaviors that even approximately match trends in more complex systems can significantly improve the generalizability of subsequent learned models to more accurate multi-lane models of traffic. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 713, level: 5" node_number="713">[68] arXiv:2112.04693 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 714, level: 5" node_number="714"> <div class="valid" valid="valid" title="valid: True, node: 715, level: 6" node_number="715"> <div class="valid" valid="valid" title="valid: True, node: 716, level: 7" node_number="716"> Title: A Monotone, Second Order Accurate Scheme for Curvature Motion </div> <div class="valid" valid="valid" title="valid: True, node: 717, level: 7" node_number="717"> Authors: Selim Esedoglu, <a class="valid" valid="valid" title="valid: True, node: 718, level: 8" node_number="718">Jiajia Guo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 719, level: 7" node_number="719"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 720, level: 7" node_number="720">We present a second order accurate in time numerical scheme for curve shortening flow in the plane that is unconditionally monotone. It is a variant of threshold dynamics, a class of algorithms in the spirit of the level set method that represent interfaces implicitly. The novelty is monotonicity: it is possible to preserve the comparison principle of the exact evolution while achieving second order in time consistency. As a consequence of monotonicity, convergence to the viscosity solution of curve shortening is ensured by existing theory. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 721, level: 5" node_number="721">[69] arXiv:2112.04698 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 722, level: 5" node_number="722"> <div class="valid" valid="valid" title="valid: True, node: 723, level: 6" node_number="723"> <div class="valid" valid="valid" title="valid: True, node: 724, level: 7" node_number="724"> Title: Explainable AI for B5G/6G: Technical Aspects, Use Cases, and Research Challenges </div> <div class="valid" valid="valid" title="valid: True, node: 725, level: 7" node_number="725"> Authors: Shen Wang, <a class="valid" valid="valid" title="valid: True, node: 726, level: 8" node_number="726">M.Atif Qureshi</a>, <a class="valid" valid="valid" title="valid: True, node: 727, level: 8" node_number="727">Luis Miralles-Pechua&#225;n</a>, <a class="valid" valid="valid" title="valid: True, node: 728, level: 8" node_number="728">Thien Huynh-The</a>, <a class="valid" valid="valid" title="valid: True, node: 729, level: 8" node_number="729">Thippa Reddy Gadekallu</a>, <a class="valid" valid="valid" title="valid: True, node: 730, level: 8" node_number="730">Madhusanka Liyanage</a> </div> <div class="valid" valid="valid" title="valid: True, node: 731, level: 7" node_number="731"> Subjects: Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 732, level: 7" node_number="732">When 5G began its commercialisation journey around 2020, the discussion on the vision of 6G also surfaced. Researchers expect 6G to have higher bandwidth, coverage, reliability, energy efficiency, lower latency, and, more importantly, an integrated "human-centric" network system powered by artificial intelligence (AI). Such a 6G network will lead to an excessive number of automated decisions made every second. These decisions can range widely, from network resource allocation to collision avoidance for self-driving cars. However, the risk of losing control over decision-making may increase due to high-speed data-intensive AI decision-making beyond designers and users' comprehension. The promising explainable AI (XAI) methods can mitigate such risks by enhancing the transparency of the black box AI decision-making process. This survey paper highlights the need for XAI towards the upcoming 6G age in every aspect, including 6G technologies (e.g., intelligent radio, zero-touch network management) and 6G use cases (e.g., industry 5.0). Moreover, we summarised the lessons learned from the recent attempts and outlined important research challenges in applying XAI for building 6G systems. This research aligns with goals 9, 11, 16, and 17 of the United Nations Sustainable Development Goals (UN-SDG), promoting innovation and building infrastructure, sustainable and inclusive human settlement, advancing justice and strong institutions, and fostering partnership at the global level. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 733, level: 5" node_number="733">[70] arXiv:2112.04699 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 734, level: 5" node_number="734"> <div class="valid" valid="valid" title="valid: True, node: 735, level: 6" node_number="735"> <div class="valid" valid="valid" title="valid: True, node: 736, level: 7" node_number="736"> Title: Contraction Analysis and Control Synthesis for Discrete-time Nonlinear Processes </div> <div class="valid" valid="valid" title="valid: True, node: 737, level: 7" node_number="737"> Authors: Lai Wei, <a class="valid" valid="valid" title="valid: True, node: 738, level: 8" node_number="738">Ryan McCloy</a>, <a class="valid" valid="valid" title="valid: True, node: 739, level: 8" node_number="739">Jie Bao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 740, level: 7" node_number="740"> Comments: Submitted to Elsevier for possible publication. arXiv admin note: text overlap with <a class="valid" valid="valid" title="valid: True, node: 741, level: 8" node_number="741">arXiv:2105.05432</a>, <a class="valid" valid="valid" title="valid: True, node: 742, level: 8" node_number="742">arXiv:2104.10352</a> </div> <div class="valid" valid="valid" title="valid: True, node: 743, level: 7" node_number="743"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 744, level: 7" node_number="744">Shifting away from the traditional mass production approach, the process industry is moving towards more agile, cost-effective and dynamic process operation (next-generation smart plants). This warrants the development of control systems for nonlinear chemical processes to be capable of tracking time-varying setpoints to produce products with different specifications as per market demand and deal with variations in the raw materials and utility (e.g., energy). This article presents a systematic approach to the implementation of contraction-based control for discrete-time nonlinear processes. Through the differential dynamic system framework, the contraction conditions to ensure the exponential convergence to feasible time-varying references are derived. The discrete-time differential dissipativity condition is further developed, which can be used for control designs for disturbance rejection. Computationally tractable equivalent conditions are then derived and additionally transformed into an SOS programming problem, such that a discrete-time control contraction metric and stabilising feedback controller can be jointly obtained. Synthesis and implementation details are provided and demonstrated through a numerical case study. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 745, level: 5" node_number="745">[71] arXiv:2112.04701 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 746, level: 5" node_number="746"> <div class="valid" valid="valid" title="valid: True, node: 747, level: 6" node_number="747"> <div class="valid" valid="valid" title="valid: True, node: 748, level: 7" node_number="748"> Title: Unsupervised Complementary-aware Multi-process Fusion for Visual Place Recognition </div> <div class="valid" valid="valid" title="valid: True, node: 749, level: 7" node_number="749"> Authors: Stephen Hausler, <a class="valid" valid="valid" title="valid: True, node: 750, level: 8" node_number="750">Tobias Fischer</a>, <a class="valid" valid="valid" title="valid: True, node: 751, level: 8" node_number="751">Michael Milford</a> </div> <div class="valid" valid="valid" title="valid: True, node: 752, level: 7" node_number="752"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 753, level: 7" node_number="753">A recent approach to the Visual Place Recognition (VPR) problem has been to fuse the place recognition estimates of multiple complementary VPR techniques simultaneously. However, selecting the optimal set of techniques to use in a specific deployment environment a-priori is a difficult and unresolved challenge. Further, to the best of our knowledge, no method exists which can select a set of techniques on a frame-by-frame basis in response to image-to-image variations. In this work, we propose an unsupervised algorithm that finds the most robust set of VPR techniques to use in the current deployment environment, on a frame-by-frame basis. The selection of techniques is determined by an analysis of the similarity scores between the current query image and the collection of database images and does not require ground-truth information. We demonstrate our approach on a wide variety of datasets and VPR techniques and show that the proposed dynamic multi-process fusion (Dyn-MPF) has superior VPR performance compared to a variety of challenging competitive methods, some of which are given an unfair advantage through access to the ground-truth information. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 754, level: 5" node_number="754">[72] arXiv:2112.04702 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 755, level: 5" node_number="755"> <div class="valid" valid="valid" title="valid: True, node: 756, level: 6" node_number="756"> <div class="valid" valid="valid" title="valid: True, node: 757, level: 7" node_number="757"> Title: Fast Point Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 758, level: 7" node_number="758"> Authors: Chunghyun Park, <a class="valid" valid="valid" title="valid: True, node: 759, level: 8" node_number="759">Yoonwoo Jeong</a>, <a class="valid" valid="valid" title="valid: True, node: 760, level: 8" node_number="760">Minsu Cho</a>, <a class="valid" valid="valid" title="valid: True, node: 761, level: 8" node_number="761">Jaesik Park</a> </div> <div class="valid" valid="valid" title="valid: True, node: 762, level: 7" node_number="762"> Comments: 16 pages, 8 figures </div> <div class="valid" valid="valid" title="valid: True, node: 763, level: 7" node_number="763"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 764, level: 7" node_number="764">The recent success of neural networks enables a better interpretation of 3D point clouds, but processing a large-scale 3D scene remains a challenging problem. Most current approaches divide a large-scale scene into small regions and combine the local predictions together. However, this scheme inevitably involves additional stages for pre- and post-processing and may also degrade the final output due to predictions in a local perspective. This paper introduces Fast Point Transformer that consists of a new lightweight self-attention layer. Our approach encodes continuous 3D coordinates, and the voxel hashing-based architecture boosts computational efficiency. The proposed method is demonstrated with 3D semantic segmentation and 3D detection. The accuracy of our approach is competitive to the best voxel-based method, and our network achieves 136 times faster inference time than the state-of-the-art, Point Transformer, with a reasonable accuracy trade-off. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 765, level: 5" node_number="765">[73] arXiv:2112.04703 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 766, level: 5" node_number="766"> <div class="valid" valid="valid" title="valid: True, node: 767, level: 6" node_number="767"> <div class="valid" valid="valid" title="valid: True, node: 768, level: 7" node_number="768"> Title: Modelling and Optimization of OAM-MIMO Communication Systems with Unaligned Antennas </div> <div class="valid" valid="valid" title="valid: True, node: 769, level: 7" node_number="769"> Authors: Xusheng Xiong, <a class="valid" valid="valid" title="valid: True, node: 770, level: 8" node_number="770">Hanqiong Lou</a>, <a class="valid" valid="valid" title="valid: True, node: 771, level: 8" node_number="771">Xiaohu Ge</a> </div> <div class="valid" valid="valid" title="valid: True, node: 772, level: 7" node_number="772"> Subjects: Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP) </div> <p class="valid" valid="valid" title="valid: True, node: 773, level: 7" node_number="773">The orbital angular momentum (OAM) wireless communication technique is emerging as one of potential techniques for the Sixth generation (6G) wireless communication system. The most advantage of OAM wireless communication technique is the natural orthogonality among different OAM states. However, one of the most disadvantages is the crosstalk among different OAM states which is widely caused by the atmospheric turbulence and misalignment between transmitting and receiving antennas. Considering the OAM-based multiple-input multiple-output (OAM-MIMO) transmission system with unaligned antennas, a new channel model is proposed for performance analysis. Moreover, a purity model of the OAM-MIMO transmission system with unaligned antennas is derived for the non-Kolmogorov turbulence. Furthermore, error probability and capacity models are derived for OAM-MIMO transmission systems with unaligned antennas. To overcome the disadvantage caused by unaligned antennas and non-Kolmogorov turbulence, a new optimization algorithm of OAM state interval is proposed to improve the capacity of OAM-MIMO transmission system. Numerical results indicate that the capacity of OAM-MIMO transmission system is improved by the optimization algorithm. Specifically, the capacity increment of OAM-MIMO transmission system adopting the optimization algorithm is up to 28.7% and 320.3% when the angle of deflection between transmitting and receiving antennas is -24 dB and -5 dB, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 774, level: 5" node_number="774">[74] arXiv:2112.04704 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 775, level: 5" node_number="775"> <div class="valid" valid="valid" title="valid: True, node: 776, level: 6" node_number="776"> <div class="valid" valid="valid" title="valid: True, node: 777, level: 7" node_number="777"> Title: Ymir: A Supervised Ensemble Framework for Multivariate Time Series Anomaly Detection </div> <div class="valid" valid="valid" title="valid: True, node: 778, level: 7" node_number="778"> Authors: Zhanxiang Zhao </div> <div class="valid" valid="valid" title="valid: True, node: 779, level: 7" node_number="779"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 780, level: 7" node_number="780">We proposed a multivariate time series anomaly detection frame-work Ymir, which leverages ensemble learning and supervisedlearning technology to efficiently learn and adapt to anomaliesin real-world system applications. Ymir integrates several currentlywidely used unsupervised anomaly detection models through anensemble learning method, and thus can provide robust frontalanomaly detection results in unsupervised scenarios. In a super-vised setting, domain experts and system users discuss and providelabels (anomalous or not) for the training data, which reflects theiranomaly detection criteria for the specific system. Ymir leveragesthe aforementioned unsupervised methods to extract rich and usefulfeature representations from the raw multivariate time series data,then combines the features and labels with a supervised classifier todo anomaly detection. We evaluated Ymir on internal multivariatetime series datasets from large monitoring systems and achievedgood anomaly detection performance. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 781, level: 5" node_number="781">[75] arXiv:2112.04706 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 782, level: 5" node_number="782"> <div class="valid" valid="valid" title="valid: True, node: 783, level: 6" node_number="783"> <div class="valid" valid="valid" title="valid: True, node: 784, level: 7" node_number="784"> Title: Kinematic Modeling of Handed Shearing Auxetics via Piecewise Constant Curvature </div> <div class="valid" valid="valid" title="valid: True, node: 785, level: 7" node_number="785"> Authors: Aman Garg, <a class="valid" valid="valid" title="valid: True, node: 786, level: 8" node_number="786">Ian Good</a>, <a class="valid" valid="valid" title="valid: True, node: 787, level: 8" node_number="787">Daniel Revier</a>, <a class="valid" valid="valid" title="valid: True, node: 788, level: 8" node_number="788">Kevin Airis</a>, <a class="valid" valid="valid" title="valid: True, node: 789, level: 8" node_number="789">Jeffrey Lipton</a> </div> <div class="valid" valid="valid" title="valid: True, node: 790, level: 7" node_number="790"> Comments: 7 pages, 10 figures, This paper has been submitted to International Conference on Soft Robotics 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 791, level: 7" node_number="791"> Subjects: Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 792, level: 7" node_number="792">Handed Shearing Auxetics (HSA) are a promising technique for making motor-driven, soft, continuum robots. Many potential applications from inspection tasks to solar tracking require accurate kinematic models to predict the position and orientation of these structures. Currently there are no models for HSA based continuum platforms. To address this gap we propose to adapt Piecewise Constant Curvature (PCC) Models using a length change coupling matrix. This models the interaction of HSA structures in a 2x2 array. The coupling matrix maps the change in motor angles to length changes and defines the configuration space in our modified PCC Model. We evaluate our model on a composite movement encompassing bending, extension and compression behavior. Our model achieves a positional accuracy with mean error of 5.5mm or 4.5% body length and standard deviation of 1.72mm. Further, we achieve an angular accuracy with mean error of -2.8$^\circ$ and standard deviation of 1.9$^\circ$. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 793, level: 5" node_number="793">[76] arXiv:2112.04709 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 794, level: 5" node_number="794"> <div class="valid" valid="valid" title="valid: True, node: 795, level: 6" node_number="795"> <div class="valid" valid="valid" title="valid: True, node: 796, level: 7" node_number="796"> Title: Implicit Feature Refinement for Instance Segmentation </div> <div class="valid" valid="valid" title="valid: True, node: 797, level: 7" node_number="797"> Authors: Lufan Ma, <a class="valid" valid="valid" title="valid: True, node: 798, level: 8" node_number="798">Tiancai Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 799, level: 8" node_number="799">Bin Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 800, level: 8" node_number="800">Jiangpeng Yan</a>, <a class="valid" valid="valid" title="valid: True, node: 801, level: 8" node_number="801">Xiu Li</a>, <a class="valid" valid="valid" title="valid: True, node: 802, level: 8" node_number="802">Xiangyu Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 803, level: 7" node_number="803"> Comments: Published at ACM MM 2021. Code is available at <a class="valid" valid="valid" title="valid: True, node: 804, level: 8" node_number="804">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 805, level: 7" node_number="805"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 806, level: 7" node_number="806">We propose a novel implicit feature refinement module for high-quality instance segmentation. Existing image/video instance segmentation methods rely on explicitly stacked convolutions to refine instance features before the final prediction. In this paper, we first give an empirical comparison of different refinement strategies,which reveals that the widely-used four consecutive convolutions are not necessary. As an alternative, weight-sharing convolution blocks provides competitive performance. When such block is iterated for infinite times, the block output will eventually convergeto an equilibrium state. Based on this observation, the implicit feature refinement (IFR) is developed by constructing an implicit function. The equilibrium state of instance features can be obtained by fixed-point iteration via a simulated infinite-depth network. Our IFR enjoys several advantages: 1) simulates an infinite-depth refinement network while only requiring parameters of single residual block; 2) produces high-level equilibrium instance features of global receptive field; 3) serves as a plug-and-play general module easily extended to most object recognition frameworks. Experiments on the COCO and YouTube-VIS benchmarks show that our IFR achieves improved performance on state-of-the-art image/video instance segmentation frameworks, while reducing the parameter burden (e.g.1% AP improvement on Mask R-CNN with only 30.0% parameters in mask head). Code is made available at https://github.com/lufanma/IFR.git </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 807, level: 5" node_number="807">[77] arXiv:2112.04710 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 808, level: 5" node_number="808"> <div class="valid" valid="valid" title="valid: True, node: 809, level: 6" node_number="809"> <div class="valid" valid="valid" title="valid: True, node: 810, level: 7" node_number="810"> Title: Auto-X3D: Ultra-Efficient Video Understanding via Finer-Grained Neural Architecture Search </div> <div class="valid" valid="valid" title="valid: True, node: 811, level: 7" node_number="811"> Authors: Yifan Jiang, <a class="valid" valid="valid" title="valid: True, node: 812, level: 8" node_number="812">Xinyu Gong</a>, <a class="valid" valid="valid" title="valid: True, node: 813, level: 8" node_number="813">Junru Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 814, level: 8" node_number="814">Humphrey Shi</a>, <a class="valid" valid="valid" title="valid: True, node: 815, level: 8" node_number="815">Zhicheng Yan</a>, <a class="valid" valid="valid" title="valid: True, node: 816, level: 8" node_number="816">Zhangyang Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 817, level: 7" node_number="817"> Comments: Accepted by WACV'2022 </div> <div class="valid" valid="valid" title="valid: True, node: 818, level: 7" node_number="818"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 819, level: 7" node_number="819">Efficient video architecture is the key to deploying video recognition systems on devices with limited computing resources. Unfortunately, existing video architectures are often computationally intensive and not suitable for such applications. The recent X3D work presents a new family of efficient video models by expanding a hand-crafted image architecture along multiple axes, such as space, time, width, and depth. Although operating in a conceptually large space, X3D searches one axis at a time, and merely explored a small set of 30 architectures in total, which does not sufficiently explore the space. This paper bypasses existing 2D architectures, and directly searched for 3D architectures in a fine-grained space, where block type, filter number, expansion ratio and attention block are jointly searched. A probabilistic neural architecture search method is adopted to efficiently search in such a large space. Evaluations on Kinetics and Something-Something-V2 benchmarks confirm our AutoX3D models outperform existing ones in accuracy up to 1.3% under similar FLOPs, and reduce the computational cost up to x1.74 when reaching similar performance. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 820, level: 5" node_number="820">[78] arXiv:2112.04711 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 821, level: 5" node_number="821"> <div class="valid" valid="valid" title="valid: True, node: 822, level: 6" node_number="822"> <div class="valid" valid="valid" title="valid: True, node: 823, level: 7" node_number="823"> Title: Feature Modulation to Improve Struggle Detection in Web Search: A Psychological Approach </div> <div class="valid" valid="valid" title="valid: True, node: 824, level: 7" node_number="824"> Authors: Jiyun Luo, <a class="valid" valid="valid" title="valid: True, node: 825, level: 8" node_number="825">Yan Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 826, level: 8" node_number="826">Valerie Nayak</a>, <a class="valid" valid="valid" title="valid: True, node: 827, level: 8" node_number="827">Grace Hui Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 828, level: 7" node_number="828"> Subjects: Information Retrieval (cs.IR) </div> <p class="valid" valid="valid" title="valid: True, node: 829, level: 7" node_number="829">Searcher struggle is important feedback to Web search engines. Existing Web search struggle detection methods rely on effort-based features to identify the struggling moments. Their underlying assumption is that the more effort a user spends, the more struggling the user may be. However, recent studies have suggested this simple association might be incorrect. This paper proposes a new feature modulation method for struggle detection and refers to the reversal theory in psychology. The reversal theory (RT) points out that instead of having a static personality trait, people constantly switch between opposite psychological states, complicating the relationship between the efforts they spend and the level of frustration they feel. Supported by the theory, our method modulates the effort-based features based on RT's bi-modal arousal model. Evaluations on week-long Web search logs confirm that the proposed method can statistically significantly improve state-of-the-art struggle detection methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 830, level: 5" node_number="830">[79] arXiv:2112.04713 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 831, level: 5" node_number="831"> <div class="valid" valid="valid" title="valid: True, node: 832, level: 6" node_number="832"> <div class="valid" valid="valid" title="valid: True, node: 833, level: 7" node_number="833"> Title: Adaptive List Decoder with Flip Operations for Polar Codes </div> <div class="valid" valid="valid" title="valid: True, node: 834, level: 7" node_number="834"> Authors: Yansong Lv, <a class="valid" valid="valid" title="valid: True, node: 835, level: 8" node_number="835">Hang Yin</a>, <a class="valid" valid="valid" title="valid: True, node: 836, level: 8" node_number="836">Zhanxin Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 837, level: 8" node_number="837">Yuhuan Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 838, level: 8" node_number="838">Jingxin Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 839, level: 8" node_number="839">Jing Huan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 840, level: 7" node_number="840"> Subjects: Information Theory (cs.IT) </div> <p class="valid" valid="valid" title="valid: True, node: 841, level: 7" node_number="841">Successive cancellation list decoders with flip operations (SCL-Flip) can utilize re-decoding attempts to significantly improve the error-correction performance of polar codes. However, these re-decoding attempts result in extra computation complexity, which thus leads to increased energy consumption and decoding latency to the communication system adopting SCL-Flip decoders. To significantly reduce the computation complexity of current SCL-Flip decoders, we design a new adaptive SCL-Flip (AD-SCLF) decoder, which can be easily implemented based on existing SCL-Flip techniques. Simulation results showed that the AD-SCLF can reduce up to 80.85\% of the computational complexity of a current SCL-Flip decoder at a matched $FER=10^{-3}$. The result implies our decoder can significantly reduce the energy consumption caused by redundant re-decoding attempts from the SCL-Flip decoder. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 842, level: 5" node_number="842">[80] arXiv:2112.04715 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 843, level: 5" node_number="843"> <div class="valid" valid="valid" title="valid: True, node: 844, level: 6" node_number="844"> <div class="valid" valid="valid" title="valid: True, node: 845, level: 7" node_number="845"> Title: Scheduling Algorithms for Hierarchical Fog Networks </div> <div class="valid" valid="valid" title="valid: True, node: 846, level: 7" node_number="846"> Authors: Amanjot Kaur, <a class="valid" valid="valid" title="valid: True, node: 847, level: 8" node_number="847">Nitin Auluck</a> </div> <div class="valid" valid="valid" title="valid: True, node: 848, level: 7" node_number="848"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> <p class="valid" valid="valid" title="valid: True, node: 849, level: 7" node_number="849">Fog computing brings the functionality of the cloud near the edge of the network with the help of fog devices/micro data centers ($mdcs$). Job scheduling in such systems is a complex problem due to the hierarchical and geo-distributed nature of fog devices. We propose two fog scheduling algorithms, named $FiFSA$ (Hierarchical $Fi$rst $F$og $S$cheduling $A$lgorithm) and $EFSA$ ( Hierarchical $E$lected $F$og $S$cheduling $A$lgorithm). We consider a hierarchical model of fog devices, where the computation power of fog devices present in higher tiers is greater than those present in lower tiers. However, the higher tier fog devices are located at greater physical distance from data generation sources as compared to lower tier fog devices. Jobs with varying granularity and cpu requirements have been considered. In general, jobs with modest cpu requirements are scheduled on lower tier fog devices, and jobs with larger cpu requirements are scheduled on higher tier fog devices or the cloud data center $(cdc)$. The performance of $FiFSA$ and $EFSA$ has been evaluated using a real life workload trace on various simulated fog hierarchies as well as on a prototype testbed. Employing $FiFSA$ offers an average improvement of 27% and 57.9% in total completion time and an improvement of 32% and 61% in cost as compared to Longest Time First ($LTF$) and cloud-only ($cdc-only$) scheduling algorithms, respectively. Employing $EFSA$ offers an average improvement of 48% and 70% in total completion time and an improvement of 52% and 72% in cost as compared to $LTF$ and $cdc-only$ respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 850, level: 5" node_number="850">[81] arXiv:2112.04716 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 851, level: 5" node_number="851"> <div class="valid" valid="valid" title="valid: True, node: 852, level: 6" node_number="852"> <div class="valid" valid="valid" title="valid: True, node: 853, level: 7" node_number="853"> Title: DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization </div> <div class="valid" valid="valid" title="valid: True, node: 854, level: 7" node_number="854"> Authors: Aviral Kumar, <a class="valid" valid="valid" title="valid: True, node: 855, level: 8" node_number="855">Rishabh Agarwal</a>, <a class="valid" valid="valid" title="valid: True, node: 856, level: 8" node_number="856">Tengyu Ma</a>, <a class="valid" valid="valid" title="valid: True, node: 857, level: 8" node_number="857">Aaron Courville</a>, <a class="valid" valid="valid" title="valid: True, node: 858, level: 8" node_number="858">George Tucker</a>, <a class="valid" valid="valid" title="valid: True, node: 859, level: 8" node_number="859">Sergey Levine</a> </div> <div class="valid" valid="valid" title="valid: True, node: 860, level: 7" node_number="860"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 861, level: 7" node_number="861">Despite overparameterization, deep networks trained via supervised learning are easy to optimize and exhibit excellent generalization. One hypothesis to explain this is that overparameterized deep networks enjoy the benefits of implicit regularization induced by stochastic gradient descent, which favors parsimonious solutions that generalize well on test inputs. It is reasonable to surmise that deep reinforcement learning (RL) methods could also benefit from this effect. In this paper, we discuss how the implicit regularization effect of SGD seen in supervised learning could in fact be harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. Our theoretical analysis shows that when existing models of implicit regularization are applied to temporal difference learning, the resulting derived regularizer favors degenerate solutions with excessive "aliasing", in stark contrast to the supervised learning case. We back up these findings empirically, showing that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, we derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. When combined with existing offline RL methods, DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 862, level: 5" node_number="862">[82] arXiv:2112.04719 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 863, level: 5" node_number="863"> <div class="valid" valid="valid" title="valid: True, node: 864, level: 6" node_number="864"> <div class="valid" valid="valid" title="valid: True, node: 865, level: 7" node_number="865"> Title: Learning with Nested Scene Modeling and Cooperative Architecture Search for Low-Light Vision </div> <div class="valid" valid="valid" title="valid: True, node: 866, level: 7" node_number="866"> Authors: Risheng Liu, <a class="valid" valid="valid" title="valid: True, node: 867, level: 8" node_number="867">Long Ma</a>, <a class="valid" valid="valid" title="valid: True, node: 868, level: 8" node_number="868">Tengyu Ma</a>, <a class="valid" valid="valid" title="valid: True, node: 869, level: 8" node_number="869">Xin Fan</a>, <a class="valid" valid="valid" title="valid: True, node: 870, level: 8" node_number="870">Zhongxuan Luo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 871, level: 7" node_number="871"> Comments: Submitted to IEEE TPAMI. Code is available at <a class="valid" valid="valid" title="valid: True, node: 872, level: 8" node_number="872">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 873, level: 7" node_number="873"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 874, level: 7" node_number="874">Images captured from low-light scenes often suffer from severe degradations, including low visibility, color cast and intensive noises, etc. These factors not only affect image qualities, but also degrade the performance of downstream Low-Light Vision (LLV) applications. A variety of deep learning methods have been proposed to enhance the visual quality of low-light images. However, these approaches mostly rely on significant architecture engineering to obtain proper low-light models and often suffer from high computational burden. Furthermore, it is still challenging to extend these enhancement techniques to handle other LLVs. To partially address above issues, we establish Retinex-inspired Unrolling with Architecture Search (RUAS), a general learning framework, which not only can address low-light enhancement task, but also has the flexibility to handle other more challenging downstream vision applications. Specifically, we first establish a nested optimization formulation, together with an unrolling strategy, to explore underlying principles of a series of LLV tasks. Furthermore, we construct a differentiable strategy to cooperatively search specific scene and task architectures for RUAS. Last but not least, we demonstrate how to apply RUAS for both low- and high-level LLV applications (e.g., enhancement, detection and segmentation). Extensive experiments verify the flexibility, effectiveness, and efficiency of RUAS. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 875, level: 5" node_number="875">[83] arXiv:2112.04720 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 876, level: 5" node_number="876"> <div class="valid" valid="valid" title="valid: True, node: 877, level: 6" node_number="877"> <div class="valid" valid="valid" title="valid: True, node: 878, level: 7" node_number="878"> Title: Amicable Aid: Turning Adversarial Attack to Benefit Classification </div> <div class="valid" valid="valid" title="valid: True, node: 879, level: 7" node_number="879"> Authors: Juyeop Kim, <a class="valid" valid="valid" title="valid: True, node: 880, level: 8" node_number="880">Jun-Ho Choi</a>, <a class="valid" valid="valid" title="valid: True, node: 881, level: 8" node_number="881">Soobeom Jang</a>, <a class="valid" valid="valid" title="valid: True, node: 882, level: 8" node_number="882">Jong-Seok Lee</a> </div> <div class="valid" valid="valid" title="valid: True, node: 883, level: 7" node_number="883"> Comments: 16 pages (3 pages for appendix) </div> <div class="valid" valid="valid" title="valid: True, node: 884, level: 7" node_number="884"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 885, level: 7" node_number="885">While adversarial attacks on deep image classification models pose serious security concerns in practice, this paper suggests a novel paradigm where the concept of adversarial attacks can benefit classification performance, which we call amicable aid. We show that by taking the opposite search direction of perturbation, an image can be converted to another yielding higher confidence by the classification model and even a wrongly classified image can be made to be correctly classified. Furthermore, with a large amount of perturbation, an image can be made unrecognizable by human eyes, while it is correctly recognized by the model. The mechanism of the amicable aid is explained in the viewpoint of the underlying natural image manifold. We also consider universal amicable perturbations, i.e., a fixed perturbation can be applied to multiple images to improve their classification results. While it is challenging to find such perturbations, we show that making the decision boundary as perpendicular to the image manifold as possible via training with modified data is effective to obtain a model for which universal amicable perturbations are more easily found. Finally, we discuss several application scenarios where the amicable aid can be useful, including secure image communication, privacy-preserving image communication, and protection against adversarial attacks. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 886, level: 5" node_number="886">[84] arXiv:2112.04726 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 887, level: 5" node_number="887"> <div class="valid" valid="valid" title="valid: True, node: 888, level: 6" node_number="888"> <div class="valid" valid="valid" title="valid: True, node: 889, level: 7" node_number="889"> Title: Noise-robust blind reverberation time estimation using noise-aware time-frequency masking </div> <div class="valid" valid="valid" title="valid: True, node: 890, level: 7" node_number="890"> Authors: Kaitong Zheng, <a class="valid" valid="valid" title="valid: True, node: 891, level: 8" node_number="891">Chengshi Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 892, level: 8" node_number="892">Jinqiu Sang</a>, <a class="valid" valid="valid" title="valid: True, node: 893, level: 8" node_number="893">Yulong Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 894, level: 8" node_number="894">Xiaodong Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 895, level: 7" node_number="895"> Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 896, level: 7" node_number="896">The reverberation time is one of the most important parameters used to characterize the acoustic property of an enclosure. In real-world scenarios, it is much more convenient to estimate the reverberation time blindly from recorded speech compared to the traditional acoustic measurement techniques using professional measurement instruments. However, the recorded speech is often corrupted by noise, which has a detrimental effect on the estimation accuracy of the reverberation time. To address this issue, this paper proposes a two-stage blind reverberation time estimation method based on noise-aware time-frequency masking. This proposed method has a good ability to distinguish the reverberation tails from the noise, thus improving the estimation accuracy of reverberation time in noisy scenarios. The simulated and real-world acoustic experimental results show that the proposed method significantly outperforms other methods in challenging scenarios. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 897, level: 5" node_number="897">[85] arXiv:2112.04728 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 898, level: 5" node_number="898"> <div class="valid" valid="valid" title="valid: True, node: 899, level: 6" node_number="899"> <div class="valid" valid="valid" title="valid: True, node: 900, level: 7" node_number="900"> Title: Reducing Catastrophic Forgetting in Self Organizing Maps with Internally-Induced Generative Replay </div> <div class="valid" valid="valid" title="valid: True, node: 901, level: 7" node_number="901"> Authors: Hitesh Vaidya, <a class="valid" valid="valid" title="valid: True, node: 902, level: 8" node_number="902">Travis Desell</a>, <a class="valid" valid="valid" title="valid: True, node: 903, level: 8" node_number="903">Alexander Ororbia</a> </div> <div class="valid" valid="valid" title="valid: True, node: 904, level: 7" node_number="904"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 905, level: 7" node_number="905">A lifelong learning agent is able to continually learn from potentially infinite streams of pattern sensory data. One major historic difficulty in building agents that adapt in this way is that neural systems struggle to retain previously-acquired knowledge when learning from new samples. This problem is known as catastrophic forgetting (interference) and remains an unsolved problem in the domain of machine learning to this day. While forgetting in the context of feedforward networks has been examined extensively over the decades, far less has been done in the context of alternative architectures such as the venerable self-organizing map (SOM), an unsupervised neural model that is often used in tasks such as clustering and dimensionality reduction. Although the competition among its internal neurons might carry the potential to improve memory retention, we observe that a fixed-sized SOM trained on task incremental data, i.e., it receives data points related to specific classes at certain temporal increments, experiences significant forgetting. In this study, we propose the continual SOM (c-SOM), a model that is capable of reducing its own forgetting when processing information. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 906, level: 5" node_number="906">[86] arXiv:2112.04731 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 907, level: 5" node_number="907"> <div class="valid" valid="valid" title="valid: True, node: 908, level: 6" node_number="908"> <div class="valid" valid="valid" title="valid: True, node: 909, level: 7" node_number="909"> Title: Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning </div> <div class="valid" valid="valid" title="valid: True, node: 910, level: 7" node_number="910"> Authors: Yujun Shi, <a class="valid" valid="valid" title="valid: True, node: 911, level: 8" node_number="911">Kuangqi Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 912, level: 8" node_number="912">Jian Liang</a>, <a class="valid" valid="valid" title="valid: True, node: 913, level: 8" node_number="913">Zihang Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 914, level: 8" node_number="914">Jiashi Feng</a>, <a class="valid" valid="valid" title="valid: True, node: 915, level: 8" node_number="915">Philip Torr</a>, <a class="valid" valid="valid" title="valid: True, node: 916, level: 8" node_number="916">Song Bai</a>, <a class="valid" valid="valid" title="valid: True, node: 917, level: 8" node_number="917">Vincent Y.F. Tan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 918, level: 7" node_number="918"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 919, level: 7" node_number="919">Class Incremental Learning (CIL) aims at learning a multi-class classifier in a phase-by-phase manner, in which only data of a subset of the classes are provided at each phase. Previous works mainly focus on mitigating forgetting in phases after the initial one. However, we find that improving CIL at its initial phase is also a promising direction. Specifically, we experimentally show that directly encouraging CIL Learner at the initial phase to output similar representations as the model jointly trained on all classes can greatly boost the CIL performance. Motivated by this, we study the difference between a na\"ively-trained initial-phase model and the oracle model. Specifically, since one major difference between these two models is the number of training classes, we investigate how such difference affects the model representations. We find that, with fewer training classes, the data representations of each class lie in a long and narrow region; with more training classes, the representations of each class scatter more uniformly. Inspired by this observation, we propose Class-wise Decorrelation (CwD) that effectively regularizes representations of each class to scatter more uniformly, thus mimicking the model jointly trained with all classes (i.e., the oracle model). Our CwD is simple to implement and easy to plug into existing methods. Extensive experiments on various benchmark datasets show that CwD consistently and significantly improves the performance of existing state-of-the-art methods by around 1\% to 3\%. Code will be released. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 920, level: 5" node_number="920">[87] arXiv:2112.04734 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 921, level: 5" node_number="921"> <div class="valid" valid="valid" title="valid: True, node: 922, level: 6" node_number="922"> <div class="valid" valid="valid" title="valid: True, node: 923, level: 7" node_number="923"> Title: New Tight Relaxations of Rank Minimization for Multi-Task Learning </div> <div class="valid" valid="valid" title="valid: True, node: 924, level: 7" node_number="924"> Authors: Wei Chang, <a class="valid" valid="valid" title="valid: True, node: 925, level: 8" node_number="925">Feiping Nie</a>, <a class="valid" valid="valid" title="valid: True, node: 926, level: 8" node_number="926">Rong Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 927, level: 8" node_number="927">Xuelong Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 928, level: 7" node_number="928"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 929, level: 7" node_number="929">Multi-task learning has been observed by many researchers, which supposes that different tasks can share a low-rank common yet latent subspace. It means learning multiple tasks jointly is better than learning them independently. In this paper, we propose two novel multi-task learning formulations based on two regularization terms, which can learn the optimal shared latent subspace by minimizing the exactly $k$ minimal singular values. The proposed regularization terms are the more tight approximations of rank minimization than trace norm. But it's an NP-hard problem to solve the exact rank minimization problem. Therefore, we design a novel re-weighted based iterative strategy to solve our models, which can tactically handle the exact rank minimization problem by setting a large penalizing parameter. Experimental results on benchmark datasets demonstrate that our methods can correctly recover the low-rank structure shared across tasks, and outperform related multi-task learning methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 930, level: 5" node_number="930">[88] arXiv:2112.04735 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 931, level: 5" node_number="931"> <div class="valid" valid="valid" title="valid: True, node: 932, level: 6" node_number="932"> <div class="valid" valid="valid" title="valid: True, node: 933, level: 7" node_number="933"> Title: From Good to Best: Two-Stage Training for Cross-lingual Machine Reading Comprehension </div> <div class="valid" valid="valid" title="valid: True, node: 934, level: 7" node_number="934"> Authors: Nuo Chen, <a class="valid" valid="valid" title="valid: True, node: 935, level: 8" node_number="935">Linjun Shou</a>, <a class="valid" valid="valid" title="valid: True, node: 936, level: 8" node_number="936">Min Gong</a>, <a class="valid" valid="valid" title="valid: True, node: 937, level: 8" node_number="937">Jian Pei</a>, <a class="valid" valid="valid" title="valid: True, node: 938, level: 8" node_number="938">Daxin Jiang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 939, level: 7" node_number="939"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 940, level: 7" node_number="940">Cross-lingual Machine Reading Comprehension (xMRC) is challenging due to the lack of training data in low-resource languages. The recent approaches use training data only in a resource-rich language like English to fine-tune large-scale cross-lingual pre-trained language models. Due to the big difference between languages, a model fine-tuned only by a source language may not perform well for target languages. Interestingly, we observe that while the top-1 results predicted by the previous approaches may often fail to hit the ground-truth answers, the correct answers are often contained in the top-k predicted results. Based on this observation, we develop a two-stage approach to enhance the model performance. The first stage targets at recall: we design a hard-learning (HL) algorithm to maximize the likelihood that the top-k predictions contain the accurate answer. The second stage focuses on precision: an answer-aware contrastive learning (AA-CL) mechanism is developed to learn the fine difference between the accurate answer and other candidates. Our extensive experiments show that our model significantly outperforms a series of strong baselines on two cross-lingual MRC benchmark datasets. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 941, level: 5" node_number="941">[89] arXiv:2112.04737 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 942, level: 5" node_number="942"> <div class="valid" valid="valid" title="valid: True, node: 943, level: 6" node_number="943"> <div class="valid" valid="valid" title="valid: True, node: 944, level: 7" node_number="944"> Title: Asynchronous Semi-Decentralized Federated Edge Learning for Heterogeneous Clients </div> <div class="valid" valid="valid" title="valid: True, node: 945, level: 7" node_number="945"> Authors: Yuchang Sun, <a class="valid" valid="valid" title="valid: True, node: 946, level: 8" node_number="946">Jiawei Shao</a>, <a class="valid" valid="valid" title="valid: True, node: 947, level: 8" node_number="947">Yuyi Mao</a>, <a class="valid" valid="valid" title="valid: True, node: 948, level: 8" node_number="948">Jun Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 949, level: 7" node_number="949"> Subjects: Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 950, level: 7" node_number="950">Federated edge learning (FEEL) has drawn much attention as a privacy-preserving distributed learning framework for mobile edge networks. In this work, we investigate a novel semi-decentralized FEEL (SD-FEEL) architecture where multiple edge servers collaborate to incorporate more data from edge devices in training. Despite the low training latency enabled by fast edge aggregation, the device heterogeneity in computational resources deteriorates the efficiency. This paper proposes an asynchronous training algorithm for SD-FEEL to overcome this issue, where edge servers can independently set deadlines for the associated client nodes and trigger the model aggregation. To deal with different levels of staleness, we design a staleness-aware aggregation scheme and analyze its convergence performance. Simulation results demonstrate the effectiveness of our proposed algorithm in achieving faster convergence and better learning performance. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 951, level: 5" node_number="951">[90] arXiv:2112.04741 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 952, level: 5" node_number="952"> <div class="valid" valid="valid" title="valid: True, node: 953, level: 6" node_number="953"> <div class="valid" valid="valid" title="valid: True, node: 954, level: 7" node_number="954"> Title: Learning multiple gaits of quadruped robot using hierarchical reinforcement learning </div> <div class="valid" valid="valid" title="valid: True, node: 955, level: 7" node_number="955"> Authors: Yunho Kim, <a class="valid" valid="valid" title="valid: True, node: 956, level: 8" node_number="956">Bukun Son</a>, <a class="valid" valid="valid" title="valid: True, node: 957, level: 8" node_number="957">Dongjun Lee</a> </div> <div class="valid" valid="valid" title="valid: True, node: 958, level: 7" node_number="958"> Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 959, level: 7" node_number="959">There is a growing interest in learning a velocity command tracking controller of quadruped robot using reinforcement learning due to its robustness and scalability. However, a single policy, trained end-to-end, usually shows a single gait regardless of the command velocity. This could be a suboptimal solution considering the existence of optimal gait according to the velocity for quadruped animals. In this work, we propose a hierarchical controller for quadruped robot that could generate multiple gaits (i.e. pace, trot, bound) while tracking velocity command. Our controller is composed of two policies, each working as a central pattern generator and local feedback controller, and trained with hierarchical reinforcement learning. Experiment results show 1) the existence of optimal gait for specific velocity range 2) the efficiency of our hierarchical controller compared to a controller composed of a single policy, which usually shows a single gait. Codes are publicly available. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 960, level: 5" node_number="960">[91] arXiv:2112.04744 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 961, level: 5" node_number="961"> <div class="valid" valid="valid" title="valid: True, node: 962, level: 6" node_number="962"> <div class="valid" valid="valid" title="valid: True, node: 963, level: 7" node_number="963"> Title: Superpixel-Based Building Damage Detection from Post-earthquake Very High Resolution Imagery Using Deep Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 964, level: 7" node_number="964"> Authors: Jun Wang, <a class="valid" valid="valid" title="valid: True, node: 965, level: 8" node_number="965">Zhoujing Li</a>, <a class="valid" valid="valid" title="valid: True, node: 966, level: 8" node_number="966">Yixuan Qiao</a>, <a class="valid" valid="valid" title="valid: True, node: 967, level: 8" node_number="967">Qiming Qin</a>, <a class="valid" valid="valid" title="valid: True, node: 968, level: 8" node_number="968">Peng Gao</a>, <a class="valid" valid="valid" title="valid: True, node: 969, level: 8" node_number="969">Guotong Xie</a> </div> <div class="valid" valid="valid" title="valid: True, node: 970, level: 7" node_number="970"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p class="valid" valid="valid" title="valid: True, node: 971, level: 7" node_number="971">Building damage detection after natural disasters like earthquakes is crucial for initiating effective emergency response actions. Remotely sensed very high spatial resolution (VHR) imagery can provide vital information due to their ability to map the affected buildings with high geometric precision. Many approaches have been developed to detect damaged buildings due to earthquakes. However, little attention has been paid to exploiting rich features represented in VHR images using Deep Neural Networks (DNN). This paper presents a novel super-pixel based approach combining DNN and a modified segmentation method, to detect damaged buildings from VHR imagery. Firstly, a modified Fast Scanning and Adaptive Merging method is extended to create initial over-segmentation. Secondly, the segments are merged based on the Region Adjacent Graph (RAG), considered an improved semantic similarity criterion composed of Local Binary Patterns (LBP) texture, spectral, and shape features. Thirdly, a pre-trained DNN using Stacked Denoising Auto-Encoders called SDAE-DNN is presented, to exploit the rich semantic features for building damage detection. Deep-layer feature abstraction of SDAE-DNN could boost detection accuracy through learning more intrinsic and discriminative features, which outperformed other methods using state-of-the-art alternative classifiers. We demonstrate the feasibility and effectiveness of our method using a subset of WorldView-2 imagery, in the complex urban areas of Bhaktapur, Nepal, which was affected by the Nepal Earthquake of April 25, 2015. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 972, level: 5" node_number="972">[92] arXiv:2112.04745 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 973, level: 5" node_number="973"> <div class="valid" valid="valid" title="valid: True, node: 974, level: 6" node_number="974"> <div class="valid" valid="valid" title="valid: True, node: 975, level: 7" node_number="975"> Title: OPTT: Optimal Piecewise Transformation Technique for Analyzing Numerical Data under Local Differential Privacy </div> <div class="valid" valid="valid" title="valid: True, node: 976, level: 7" node_number="976"> Authors: Fei Ma, <a class="valid" valid="valid" title="valid: True, node: 977, level: 8" node_number="977">Renbo Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 978, level: 8" node_number="978">Ping Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 979, level: 7" node_number="979"> Subjects: Cryptography and Security (cs.CR) </div> <p class="valid" valid="valid" title="valid: True, node: 980, level: 7" node_number="980">Privacy preserving data analysis (PPDA) has received increasing attention due to a great variety of applications. Local differential privacy (LDP), as an emerging standard that is suitable for PPDA, has been widely deployed into various real-world scenarios to analyze massive data while protecting against many forms of privacy breach. In this study, we are mainly concerned with piecewise transformation technique (PTT) for analyzing numerical data under local differential privacy. We provide a principled framework for PTT in the context of LDP, based on which PTT is studied systematically. As a result, we show that (1) many members in PTTs are asymptotically optimal when used to obtain an unbiased estimator for mean of numerical data, and (2) for a given privacy budget, there is PTT that reaches the theoretical low bound with respect to variance. Next, we prove by studying two classes of PTTs in detail that (1) there do not exist optimal PTTs compared to the well-used technique, i.e., Duchi's scheme, in terms of the consistency noisy variance, (2) on the other hand, one has the ability to find a great number of PTTs that are consistently more optimal than the latter with regard to the worst-case noisy variance, which is never reported so far. When we are restricted to consider only the high privacy level, enough PTTs turn out to be optimal than the well-known Laplace mechanism. Lastly, we prove that for a family of PTTs, the correspondingly theoretical low bound of noisy variance follows $O(\epsilon^{-2})$ when considering the high privacy level. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 981, level: 5" node_number="981">[93] arXiv:2112.04748 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 982, level: 5" node_number="982"> <div class="valid" valid="valid" title="valid: True, node: 983, level: 6" node_number="983"> <div class="valid" valid="valid" title="valid: True, node: 984, level: 7" node_number="984"> Title: LipSound2: Self-Supervised Pre-Training for Lip-to-Speech Reconstruction and Lip Reading </div> <div class="valid" valid="valid" title="valid: True, node: 985, level: 7" node_number="985"> Authors: Leyuan Qu, <a class="valid" valid="valid" title="valid: True, node: 986, level: 8" node_number="986">Cornelius Weber</a>, <a class="valid" valid="valid" title="valid: True, node: 987, level: 8" node_number="987">Stefan Wermter</a> </div> <div class="valid" valid="valid" title="valid: True, node: 988, level: 7" node_number="988"> Comments: SUBMITTED TO IEEE Transaction on Neural Networks and Learning Systems </div> <div class="valid" valid="valid" title="valid: True, node: 989, level: 7" node_number="989"> Subjects: Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 990, level: 7" node_number="990">The aim of this work is to investigate the impact of crossmodal self-supervised pre-training for speech reconstruction (video-to-audio) by leveraging the natural co-occurrence of audio and visual streams in videos. We propose LipSound2 which consists of an encoder-decoder architecture and location-aware attention mechanism to map face image sequences to mel-scale spectrograms directly without requiring any human annotations. The proposed LipSound2 model is firstly pre-trained on $\sim$2400h multi-lingual (e.g. English and German) audio-visual data (VoxCeleb2). To verify the generalizability of the proposed method, we then fine-tune the pre-trained model on domain-specific datasets (GRID, TCD-TIMIT) for English speech reconstruction and achieve a significant improvement on speech quality and intelligibility compared to previous approaches in speaker-dependent and -independent settings. In addition to English, we conduct Chinese speech reconstruction on the CMLR dataset to verify the impact on transferability. Lastly, we train the cascaded lip reading (video-to-text) system by fine-tuning the generated audios on a pre-trained speech recognition system and achieve state-of-the-art performance on both English and Chinese benchmark datasets. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 991, level: 5" node_number="991">[94] arXiv:2112.04749 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 992, level: 5" node_number="992"> <div class="valid" valid="valid" title="valid: True, node: 993, level: 6" node_number="993"> <div class="valid" valid="valid" title="valid: True, node: 994, level: 7" node_number="994"> Title: Experimental Demonstration of Neuromorphic Network with STT MTJ Synapses </div> <div class="valid" valid="valid" title="valid: True, node: 995, level: 7" node_number="995"> Authors: Peng Zhou, <a class="valid" valid="valid" title="valid: True, node: 996, level: 8" node_number="996">Alexander J. Edwards</a>, <a class="valid" valid="valid" title="valid: True, node: 997, level: 8" node_number="997">Fred B. Mancoff</a>, <a class="valid" valid="valid" title="valid: True, node: 998, level: 8" node_number="998">Dimitri Houssameddine</a>, <a class="valid" valid="valid" title="valid: True, node: 999, level: 8" node_number="999">Sanjeev Aggarwal</a>, <a class="valid" valid="valid" title="valid: True, node: 1000, level: 8" node_number="1000">Joseph S. Friedman</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1001, level: 7" node_number="1001"> Subjects: Neural and Evolutionary Computing (cs.NE) </div> <p class="valid" valid="valid" title="valid: True, node: 1002, level: 7" node_number="1002">We present the first experimental demonstration of a neuromorphic network with magnetic tunnel junction (MTJ) synapses, which performs image recognition via vector-matrix multiplication. We also simulate a large MTJ network performing MNIST handwritten digit recognition, demonstrating that MTJ crossbars can match memristor accuracy while providing increased precision, stability, and endurance. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1003, level: 5" node_number="1003">[95] arXiv:2112.04751 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1004, level: 5" node_number="1004"> <div class="valid" valid="valid" title="valid: True, node: 1005, level: 6" node_number="1005"> <div class="valid" valid="valid" title="valid: True, node: 1006, level: 7" node_number="1006"> Title: Co-evolutionary hybrid intelligence </div> <div class="valid" valid="valid" title="valid: True, node: 1007, level: 7" node_number="1007"> Authors: Kirill Krinkin, <a class="valid" valid="valid" title="valid: True, node: 1008, level: 8" node_number="1008">Yulia Shichkina</a>, <a class="valid" valid="valid" title="valid: True, node: 1009, level: 8" node_number="1009">Andrey Ignatyev</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1010, level: 7" node_number="1010"> Comments: 4 pages </div> <div class="valid" valid="valid" title="valid: True, node: 1011, level: 7" node_number="1011"> Subjects: Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1012, level: 7" node_number="1012">Artificial intelligence is one of the drivers of modern technological development. The current approach to the development of intelligent systems is data-centric. It has several limitations: it is fundamentally impossible to collect data for modeling complex objects and processes; training neural networks requires huge computational and energy resources; solutions are not explainable. The article discusses an alternative approach to the development of artificial intelligence systems based on human-machine hybridization and their co-evolution. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1013, level: 5" node_number="1013">[96] arXiv:2112.04752 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1014, level: 5" node_number="1014"> <div class="valid" valid="valid" title="valid: True, node: 1015, level: 6" node_number="1015"> <div class="valid" valid="valid" title="valid: True, node: 1016, level: 7" node_number="1016"> Title: BLPnet: A New DNN model for Automatic License Plate Detection with Bengali OCR </div> <div class="valid" valid="valid" title="valid: True, node: 1017, level: 7" node_number="1017"> Authors: Md Saif Hassan Onim, <a class="valid" valid="valid" title="valid: True, node: 1018, level: 8" node_number="1018">Hussain Nyeem</a>, <a class="valid" valid="valid" title="valid: True, node: 1019, level: 8" node_number="1019">Koushik Roy</a>, <a class="valid" valid="valid" title="valid: True, node: 1020, level: 8" node_number="1020">Mahmudul Hasan</a>, <a class="valid" valid="valid" title="valid: True, node: 1021, level: 8" node_number="1021">Abtahi Ishmam</a>, <a class="valid" valid="valid" title="valid: True, node: 1022, level: 8" node_number="1022">Md. Akiful Hoque Akif</a>, <a class="valid" valid="valid" title="valid: True, node: 1023, level: 8" node_number="1023">Tareque Bashar Ovi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1024, level: 7" node_number="1024"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1025, level: 7" node_number="1025">Deep Neural Network (DNN) models with image processing and object localization have the potential to advance the automatic traffic control and monitoring system. Despite some notable progress in developing robust license plate detection models, research endeavours continue to reduce computational complexities with higher detection accuracy. This paper reports a computationally efficient and reasonably accurate Automatic License Plate Recognition (ALPR) system for Bengali characters with a new DNN model that we call Bengali License Plate Network (BLPnet). Additionally, the cascaded architectures for detecting vehicle regions prior to VLP in the proposed model, would significantly reduce computational cost and false-positives making the system faster and more accurate. Besides, with a new Bengali OCR engine and word-mapping process, the model can readily extract, detect and output the complete license-plate number of a vehicle. The model feeding with17 frames per second (fps) on real-time video footage can detect a vehicle with the Mean Squared Error (MSE) of 0.0152, and the mean license plate character recognition accuracy of 95%. While compared to the other models, an improvement of 5% and 20% were recorded for the BLPnet over the prominent YOLO-based ALPR model and Tesseract model for the number-plate detection accuracy and time requirement, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1026, level: 5" node_number="1026">[97] arXiv:2112.04757 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1027, level: 5" node_number="1027"> <div class="valid" valid="valid" title="valid: True, node: 1028, level: 6" node_number="1028"> <div class="valid" valid="valid" title="valid: True, node: 1029, level: 7" node_number="1029"> Title: DP-GCN: Node Classification Based on Both Connectivity and Topology Structure Convolutions for Risky Seller Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1030, level: 7" node_number="1030"> Authors: Chen Zhe, <a class="valid" valid="valid" title="valid: True, node: 1031, level: 8" node_number="1031">Aixin Sun</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1032, level: 7" node_number="1032"> Subjects: Social and Information Networks (cs.SI) </div> <p class="valid" valid="valid" title="valid: True, node: 1033, level: 7" node_number="1033">A payment network contains transactions between sellers and buyers. Detecting risky (or bad) sellers on such a payment network is crucial to payment service providers for risk management and legal compliance. In this research, we formulate this task as a node classification task. Specifically, we aim to predict a label for each seller in a payment network, by analysing its properties and/or interactions. Nodes residing in different parts of a payment network can have similar local topology structures. Such local topology structures reveal sellers' business roles, eg., supplier, drop-shipper, or retailer. We note that many existing solutions for graph-based node classification only consider node connectivity but not the similarity between node's local topology structure. Motivated by business need, we present a dual-path graph convolution network, named DP-GCN, for node classification. DP-GCN considers both node connectivity and topology structure similarity. The proposed model consists of three main modules: (i) a C-GCN module to capture connectivity relationships between nodes, (ii) a T-GCN module to capture topology structure similarities between nodes, and (iii) a multi-head self-attention module to align both properties. We evaluate DP-GCN on seven benchmark datasets against diverse baselines. We also provide a case study of running DP-GCN on three large-scale payment networks from PayPal, one of the leading payment service providers. Experimental results demonstrate DP-GCN's effectiveness and practicability. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1034, level: 5" node_number="1034">[98] arXiv:2112.04758 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1035, level: 5" node_number="1035"> <div class="valid" valid="valid" title="valid: True, node: 1036, level: 6" node_number="1036"> <div class="valid" valid="valid" title="valid: True, node: 1037, level: 7" node_number="1037"> Title: Does Redundancy in AI Perception Systems Help to Test for Super-Human Automated Driving Performance? </div> <div class="valid" valid="valid" title="valid: True, node: 1038, level: 7" node_number="1038"> Authors: Hanno Gottschalk, Matthias Rottmann, <a class="valid" valid="valid" title="valid: True, node: 1039, level: 8" node_number="1039">Maida Saltagic</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1040, level: 7" node_number="1040"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1041, level: 7" node_number="1041">While automated driving is often advertised with better-than-human driving performance, this work reviews that it is nearly impossible to provide direct statistical evidence on the system level that this is actually the case. The amount of labeled data needed would exceed dimensions of present day technical and economical capabilities. A commonly used strategy therefore is the use of redundancy along with the proof of sufficient subsystems' performances. As it is known, this strategy is efficient especially for the case of subsystems operating independently, i.e. the occurrence of errors is independent in a statistical sense. Here, we give some first considerations and experimental evidence that this strategy is not a free ride as the errors of neural networks fulfilling the same computer vision task, at least for some cases, show correlated occurrences of errors. This remains true, if training data, architecture, and training are kept separate or independence is trained using special loss functions. Using data from different sensors (realized by up to five 2D projections of the 3D MNIST data set) in our experiments is more efficiently reducing correlations, however not to an extent that is realizing the potential of reduction of testing data that can be obtained for redundant and statistically independent subsystems. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1042, level: 5" node_number="1042">[99] arXiv:2112.04761 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1043, level: 5" node_number="1043"> <div class="valid" valid="valid" title="valid: True, node: 1044, level: 6" node_number="1044"> <div class="valid" valid="valid" title="valid: True, node: 1045, level: 7" node_number="1045"> Title: HBReID: Harder Batch for Re-identification </div> <div class="valid" valid="valid" title="valid: True, node: 1046, level: 7" node_number="1046"> Authors: Wen Li, <a class="valid" valid="valid" title="valid: True, node: 1047, level: 8" node_number="1047">Furong Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 1048, level: 8" node_number="1048">Jianan Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 1049, level: 8" node_number="1049">Ruobing Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 1050, level: 8" node_number="1050">Cheng Zou</a>, <a class="valid" valid="valid" title="valid: True, node: 1051, level: 8" node_number="1051">Meng Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1052, level: 8" node_number="1052">Yuan Cheng</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1053, level: 7" node_number="1053"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1054, level: 7" node_number="1054">Triplet loss is a widely adopted loss function in ReID task which pulls the hardest positive pairs close and pushes the hardest negative pairs far away. However, the selected samples are not the hardest globally, but the hardest only in a mini-batch, which will affect the performance. In this report, a hard batch mining method is proposed to mine the hardest samples globally to make triplet harder. More specifically, the most similar classes are selected into a same mini-batch so that the similar classes could be pushed further away. Besides, an adversarial scene removal module composed of a scene classifier and an adversarial loss is used to learn scene invariant feature representations. Experiments are conducted on dataset MSMT17 to prove the effectiveness, and our method surpasses all of the previous methods and sets state-of-the-art result. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1055, level: 5" node_number="1055">[100] arXiv:2112.04764 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1056, level: 5" node_number="1056"> <div class="valid" valid="valid" title="valid: True, node: 1057, level: 6" node_number="1057"> <div class="valid" valid="valid" title="valid: True, node: 1058, level: 7" node_number="1058"> Title: 3D-VField: Learning to Adversarially Deform Point Clouds for Robust 3D Object Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1059, level: 7" node_number="1059"> Authors: Alexander Lehner, <a class="valid" valid="valid" title="valid: True, node: 1060, level: 8" node_number="1060">Stefano Gasperini</a>, <a class="valid" valid="valid" title="valid: True, node: 1061, level: 8" node_number="1061">Alvaro Marcos-Ramiro</a>, <a class="valid" valid="valid" title="valid: True, node: 1062, level: 8" node_number="1062">Michael Schmidt</a>, <a class="valid" valid="valid" title="valid: True, node: 1063, level: 8" node_number="1063">Mohammad-Ali Nikouei Mahani</a>, <a class="valid" valid="valid" title="valid: True, node: 1064, level: 8" node_number="1064">Nassir Navab</a>, <a class="valid" valid="valid" title="valid: True, node: 1065, level: 8" node_number="1065">Benjamin Busam</a>, <a class="valid" valid="valid" title="valid: True, node: 1066, level: 8" node_number="1066">Federico Tombari</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1067, level: 7" node_number="1067"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 1068, level: 7" node_number="1068">As 3D object detection on point clouds relies on the geometrical relationships between the points, non-standard object shapes can hinder a method's detection capability. However, in safety-critical settings, robustness on out-of-distribution and long-tail samples is fundamental to circumvent dangerous issues, such as the misdetection of damaged or rare cars. In this work, we substantially improve the generalization of 3D object detectors to out-of-domain data by taking into account deformed point clouds during training. We achieve this with 3D-VField: a novel method that plausibly deforms objects via vectors learned in an adversarial fashion. Our approach constrains 3D points to slide along their sensor view rays while neither adding nor removing any of them. The obtained vectors are transferrable, sample-independent and preserve shape smoothness and occlusions. By augmenting normal samples with the deformations produced by these vector fields during training, we significantly improve robustness against differently shaped objects, such as damaged/deformed cars, even while training only on KITTI. Towards this end, we propose and share open source CrashD: a synthetic dataset of realistic damaged and rare cars, with a variety of crash scenarios. Extensive experiments on KITTI, Waymo, our CrashD and SUN RGB-D show the high generalizability of our techniques to out-of-domain data, different models and sensors, namely LiDAR and ToF cameras, for both indoor and outdoor scenes. Our CrashD dataset is available at https://crashd-cars.github.io. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1069, level: 5" node_number="1069">[101] arXiv:2112.04766 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1070, level: 5" node_number="1070"> <div class="valid" valid="valid" title="valid: True, node: 1071, level: 6" node_number="1071"> <div class="valid" valid="valid" title="valid: True, node: 1072, level: 7" node_number="1072"> Title: Adaptive Methods for Aggregated Domain Generalization </div> <div class="valid" valid="valid" title="valid: True, node: 1073, level: 7" node_number="1073"> Authors: Xavier Thomas, <a class="valid" valid="valid" title="valid: True, node: 1074, level: 8" node_number="1074">Dhruv Mahajan</a>, <a class="valid" valid="valid" title="valid: True, node: 1075, level: 8" node_number="1075">Alex Pentland</a>, <a class="valid" valid="valid" title="valid: True, node: 1076, level: 8" node_number="1076">Abhimanyu Dubey</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1077, level: 7" node_number="1077"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1078, level: 7" node_number="1078">Domain generalization involves learning a classifier from a heterogeneous collection of training sources such that it generalizes to data drawn from similar unknown target domains, with applications in large-scale learning and personalized inference. In many settings, privacy concerns prohibit obtaining domain labels for the training data samples, and instead only have an aggregated collection of training points. Existing approaches that utilize domain labels to create domain-invariant feature representations are inapplicable in this setting, requiring alternative approaches to learn generalizable classifiers. In this paper, we propose a domain-adaptive approach to this problem, which operates in two steps: (a) we cluster training data within a carefully chosen feature space to create pseudo-domains, and (b) using these pseudo-domains we learn a domain-adaptive classifier that makes predictions using information about both the input and the pseudo-domain it belongs to. Our approach achieves state-of-the-art performance on a variety of domain generalization benchmarks without using domain labels whatsoever. Furthermore, we provide novel theoretical guarantees on domain generalization using cluster information. Our approach is amenable to ensemble-based methods and provides substantial gains even on large-scale benchmark datasets. The code can be found at: https://github.com/xavierohan/AdaClust_DomainBed </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1079, level: 5" node_number="1079">[102] arXiv:2112.04771 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1080, level: 5" node_number="1080"> <div class="valid" valid="valid" title="valid: True, node: 1081, level: 6" node_number="1081"> <div class="valid" valid="valid" title="valid: True, node: 1082, level: 7" node_number="1082"> Title: Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1083, level: 7" node_number="1083"> Authors: Jiaqi Tang, <a class="valid" valid="valid" title="valid: True, node: 1084, level: 8" node_number="1084">Zhaoyang Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1085, level: 8" node_number="1085">Chen Qian</a>, <a class="valid" valid="valid" title="valid: True, node: 1086, level: 8" node_number="1086">Wayne Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 1087, level: 8" node_number="1087">Limin Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1088, level: 7" node_number="1088"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1089, level: 7" node_number="1089">Generic event boundary detection is an important yet challenging task in video understanding, which aims at detecting the moments where humans naturally perceive event boundaries. The main challenge of this task is perceiving various temporal variations of diverse event boundaries. To this end, this paper presents an effective and end-to-end learnable framework (DDM-Net). To tackle the diversity and complicated semantics of event boundaries, we make three notable improvements. First, we construct a feature bank to store multi-level features of space and time, prepared for difference calculation at multiple scales. Second, to alleviate inadequate temporal modeling of previous methods, we present dense difference maps (DDM) to comprehensively characterize the motion pattern. Finally, we exploit progressive attention on multi-level DDM to jointly aggregate appearance and motion clues. As a result, DDM-Net respectively achieves a significant boost of 14% and 8% on Kinetics-GEBD and TAPOS benchmark, and outperforms the top-1 winner solution of LOVEU Challenge@CVPR 2021 without bells and whistles. The state-of-the-art result demonstrates the effectiveness of richer motion representation and more sophisticated aggregation, in handling the diversity of generic event boundary detection. Our codes will be made available soon. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1090, level: 5" node_number="1090">[103] arXiv:2112.04778 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1091, level: 5" node_number="1091"> <div class="valid" valid="valid" title="valid: True, node: 1092, level: 6" node_number="1092"> <div class="valid" valid="valid" title="valid: True, node: 1093, level: 7" node_number="1093"> Title: Justifying the Dependability and Security of Business-Critical Blockchain-based Applications </div> <div class="valid" valid="valid" title="valid: True, node: 1094, level: 7" node_number="1094"> Authors: Pierre-Yves Piriou, <a class="valid" valid="valid" title="valid: True, node: 1095, level: 8" node_number="1095">Olivier Boudeville</a>, <a class="valid" valid="valid" title="valid: True, node: 1096, level: 8" node_number="1096">Gilles Deleuze</a>, <a class="valid" valid="valid" title="valid: True, node: 1097, level: 8" node_number="1097">Sara Tucci-Piergiovanni</a>, <a class="valid" valid="valid" title="valid: True, node: 1098, level: 8" node_number="1098">&#214;nder G&#252;rcan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1099, level: 7" node_number="1099"> Comments: 8 pages, 6 figures, The Third IEEE International Conference on Blockchain Computing and Applications (BCCA 2021) </div> <div class="valid" valid="valid" title="valid: True, node: 1100, level: 7" node_number="1100"> Subjects: Software Engineering (cs.SE); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA) </div> <p class="valid" valid="valid" title="valid: True, node: 1101, level: 7" node_number="1101">In the industry, blockchains are increasingly used as the backbone of product and process traceability. Blockchain-based traceability participates in the demonstration of product and/or process compliance with existing safety standards or quality criteria. In this perspective, services and applications built on top of blockchains are business-critical applications, because an intended failure or corruption of the system can lead to an important reputation loss regarding the products or the processes involved. The development of a blockchain-based business-critical application must be then conducted carefully, requiring a thorough justification of its dependability and security. To this end, this paper encourages an engineering perspective rooted in well-understood tools and concepts borrowed from the engineering of safety-critical systems. Concretely, we use a justification framework, called CAE (Claim, Argument, Evidence), by following an approach based on assurance cases, in order to provide convincing arguments that a business-critical blockchain-based application is dependable and secure. The application of this approach is sketched with a case study based on the blockchain HYPERLEDGER FABRIC. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1102, level: 5" node_number="1102">[104] arXiv:2112.04785 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1103, level: 5" node_number="1103"> <div class="valid" valid="valid" title="valid: True, node: 1104, level: 6" node_number="1104"> <div class="valid" valid="valid" title="valid: True, node: 1105, level: 7" node_number="1105"> Title: VMAgent: Scheduling Simulator for Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 1106, level: 7" node_number="1106"> Authors: Junjie Sheng, <a class="valid" valid="valid" title="valid: True, node: 1107, level: 8" node_number="1107">Shengliang Cai</a>, <a class="valid" valid="valid" title="valid: True, node: 1108, level: 8" node_number="1108">Haochuan Cui</a>, <a class="valid" valid="valid" title="valid: True, node: 1109, level: 8" node_number="1109">Wenhao Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1110, level: 8" node_number="1110">Yun Hua</a>, <a class="valid" valid="valid" title="valid: True, node: 1111, level: 8" node_number="1111">Bo Jin</a>, <a class="valid" valid="valid" title="valid: True, node: 1112, level: 8" node_number="1112">Wenli Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 1113, level: 8" node_number="1113">Yiqiu Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 1114, level: 8" node_number="1114">Lei Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 1115, level: 8" node_number="1115">Qian Peng</a>, <a class="valid" valid="valid" title="valid: True, node: 1116, level: 8" node_number="1116">Hongyuan Zha</a>, <a class="valid" valid="valid" title="valid: True, node: 1117, level: 8" node_number="1117">Xiangfeng Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1118, level: 7" node_number="1118"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1119, level: 7" node_number="1119">A novel simulator called VMAgent is introduced to help RL researchers better explore new methods, especially for virtual machine scheduling. VMAgent is inspired by practical virtual machine (VM) scheduling tasks and provides an efficient simulation platform that can reflect the real situations of cloud computing. Three scenarios (fading, recovering, and expansion) are concluded from practical cloud computing and corresponds to many reinforcement learning challenges (high dimensional state and action spaces, high non-stationarity, and life-long demand). VMAgent provides flexible configurations for RL researchers to design their customized scheduling environments considering different problem features. From the VM scheduling perspective, VMAgent also helps to explore better learning-based scheduling solutions. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1120, level: 5" node_number="1120">[105] arXiv:2112.04788 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1121, level: 5" node_number="1121"> <div class="valid" valid="valid" title="valid: True, node: 1122, level: 6" node_number="1122"> <div class="valid" valid="valid" title="valid: True, node: 1123, level: 7" node_number="1123"> Title: "What can I cook with these ingredients?" -- Understanding cooking-related information needs in conversational search </div> <div class="valid" valid="valid" title="valid: True, node: 1124, level: 7" node_number="1124"> Authors: Alexander Frummet, <a class="valid" valid="valid" title="valid: True, node: 1125, level: 8" node_number="1125">David Elsweiler</a>, <a class="valid" valid="valid" title="valid: True, node: 1126, level: 8" node_number="1126">Bernd Ludwig</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1127, level: 7" node_number="1127"> Subjects: Information Retrieval (cs.IR) </div> <p class="valid" valid="valid" title="valid: True, node: 1128, level: 7" node_number="1128">As conversational search becomes more pervasive, it becomes increasingly important to understand the user's underlying information needs when they converse with such systems in diverse domains. We conduct an in-situ study to understand information needs arising in a home cooking context as well as how they are verbally communicated to an assistant. A human experimenter plays this role in our study. Based on the transcriptions of utterances, we derive a detailed hierarchical taxonomy of diverse information needs occurring in this context, which require different levels of assistance to be solved. The taxonomy shows that needs can be communicated through different linguistic means and require different amounts of context to be understood. In a second contribution we perform classification experiments to determine the feasibility of predicting the type of information need a user has during a dialogue using the turn provided. For this multi-label classification problem, we achieve average F1 measures of 40% using BERT-based models. We demonstrate with examples, which types of need are difficult to predict and show why, concluding that models need to include more context information in order to improve both information need classification and assistance to make such systems usable. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1129, level: 5" node_number="1129">[106] arXiv:2112.04796 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1130, level: 5" node_number="1130"> <div class="valid" valid="valid" title="valid: True, node: 1131, level: 6" node_number="1131"> <div class="valid" valid="valid" title="valid: True, node: 1132, level: 7" node_number="1132"> Title: Detecting Potentially Harmful and Protective Suicide-related Content on Twitter: A Machine Learning Approach </div> <div class="valid" valid="valid" title="valid: True, node: 1133, level: 7" node_number="1133"> Authors: Hannah Metzler, <a class="valid" valid="valid" title="valid: True, node: 1134, level: 8" node_number="1134">Hubert Baginski</a>, <a class="valid" valid="valid" title="valid: True, node: 1135, level: 8" node_number="1135">Thomas Niederkrotenthaler</a>, <a class="valid" valid="valid" title="valid: True, node: 1136, level: 8" node_number="1136">David Garcia</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1137, level: 7" node_number="1137"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1138, level: 7" node_number="1138">Research shows that exposure to suicide-related news media content is associated with suicide rates, with some content characteristics likely having harmful and others potentially protective effects. Although good evidence exists for a few selected characteristics, systematic large scale investigations are missing in general, and in particular for social media data. We apply machine learning methods to automatically label large quantities of Twitter data. We developed a novel annotation scheme that classifies suicide-related tweets into different message types and problem- vs. solution-focused perspectives. We then trained a benchmark of machine learning models including a majority classifier, an approach based on word frequency (TF-IDF with a linear SVM) and two state-of-the-art deep learning models (BERT, XLNet). The two deep learning models achieved the best performance in two classification tasks: First, we classified six main content categories, including personal stories about either suicidal ideation and attempts or coping, calls for action intending to spread either problem awareness or prevention-related information, reportings of suicide cases, and other suicide-related and off-topic tweets. The deep learning models reach accuracy scores above 73% on average across the six categories, and F1-scores in between 69% and 85% for all but the suicidal ideation and attempts category (55%). Second, in separating postings referring to actual suicide from off-topic tweets, they correctly labelled around 88% of tweets, with BERT achieving F1-scores of 93% and 74% for the two categories. These classification performances are comparable to the state-of-the-art on similar tasks. By making data labeling more efficient, this work enables future large-scale investigations on harmful and protective effects of various kinds of social media content on suicide rates and on help-seeking behavior. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1139, level: 5" node_number="1139">[107] arXiv:2112.04797 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1140, level: 5" node_number="1140"> <div class="valid" valid="valid" title="valid: True, node: 1141, level: 6" node_number="1141"> <div class="valid" valid="valid" title="valid: True, node: 1142, level: 7" node_number="1142"> Title: Complexity assessments for decidable fragments of Set Theory. III: A quadratic reduction of constraints over nested sets to Boolean formulae </div> <div class="valid" valid="valid" title="valid: True, node: 1143, level: 7" node_number="1143"> Authors: Domenico Cantone, <a class="valid" valid="valid" title="valid: True, node: 1144, level: 8" node_number="1144">Andrea De Domenico</a>, <a class="valid" valid="valid" title="valid: True, node: 1145, level: 8" node_number="1145">Pietro Maugeri</a>, <a class="valid" valid="valid" title="valid: True, node: 1146, level: 8" node_number="1146">Eugenio G. Omodeo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1147, level: 7" node_number="1147"> Subjects: Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1148, level: 7" node_number="1148">As a contribution to quantitative set-theoretic inferencing, a translation is proposed of conjunctions of literals of the forms $x=y\setminus z$, $x eq y\setminus z$, and $z =\{x\}$, where $x,y,z$ stand for variables ranging over the von Neumann universe of sets, into unquantified Boolean formulae of a rather simple conjunctive normal form. The formulae in the target language involve variables ranging over a Boolean ring of sets, along with a difference operator and relators designating equality, non-disjointness and inclusion. Moreover, the result of each translation is a conjunction of literals of the forms $x=y\setminus z$, $xeq y\setminus z$ and of implications whose antecedents are isolated literals and whose consequents are either inclusions (strict or non-strict) between variables, or equalities between variables. Besides reflecting a simple and natural semantics, which ensures satisfiability-preservation, the proposed translation has quadratic algorithmic time-complexity, and bridges two languages both of which are known to have an NP-complete satisfiability problem. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1149, level: 5" node_number="1149">[108] arXiv:2112.04800 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1150, level: 5" node_number="1150"> <div class="valid" valid="valid" title="valid: True, node: 1151, level: 6" node_number="1151"> <div class="valid" valid="valid" title="valid: True, node: 1152, level: 7" node_number="1152"> Title: GPU backed Data Mining on Android Devices </div> <div class="valid" valid="valid" title="valid: True, node: 1153, level: 7" node_number="1153"> Authors: Robert Fritze, <a class="valid" valid="valid" title="valid: True, node: 1154, level: 8" node_number="1154">Claudia Plant</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1155, level: 7" node_number="1155"> Comments: 11 pages </div> <div class="valid" valid="valid" title="valid: True, node: 1156, level: 7" node_number="1156"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1157, level: 7" node_number="1157">Choosing an appropriate programming paradigm for high-performance computing on low-power devices can be useful to speed up calculations. Many Android devices have an integrated GPU and - although not officially supported - the OpenCL framework can be used on Android devices for addressing these GPUs. OpenCL supports thread and data parallelism. Applications that use the GPU must account for the fact that they can be suspended by the user or the Android operating system at any moment. We have created a wrapper library that allows to use OpenCL on Android devices. Already written OpenCL programs can be executed with almost no modification. We have used this library to compare the performance of the DBSCAN and Kmeans algorithms on an integrated GPU of an Arm-v7 tablet with other single and multithreaded implementations on the same device. We have investigated which programming paradigm and language allows the best tradeoff between execution speed and energy consumption. Using the GPU for HPC on Android devices can help to carry out computationally intensive machine learning or data mining tasks in remote areas, under harsh environmental conditions and in areas where energy supply is an issue. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1158, level: 5" node_number="1158">[109] arXiv:2112.04803 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1159, level: 5" node_number="1159"> <div class="valid" valid="valid" title="valid: True, node: 1160, level: 6" node_number="1160"> <div class="valid" valid="valid" title="valid: True, node: 1161, level: 7" node_number="1161"> Title: Combining Textual Features for the Detection of Hateful and Offensive Language </div> <div class="valid" valid="valid" title="valid: True, node: 1162, level: 7" node_number="1162"> Authors: Sherzod Hakimov, <a class="valid" valid="valid" title="valid: True, node: 1163, level: 8" node_number="1163">Ralph Ewerth</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1164, level: 7" node_number="1164"> Comments: HASOC 2021, Forum for Information Retrieval Evaluation, 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1165, level: 7" node_number="1165"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1166, level: 7" node_number="1166">The detection of offensive, hateful and profane language has become a critical challenge since many users in social networks are exposed to cyberbullying activities on a daily basis. In this paper, we present an analysis of combining different textual features for the detection of hateful or offensive posts on Twitter. We provide a detailed experimental evaluation to understand the impact of each building block in a neural network architecture. The proposed architecture is evaluated on the English Subtask 1A: Identifying Hate, offensive and profane content from the post datasets of HASOC-2021 dataset under the team name TIB-VA. We compared different variants of the contextual word embeddings combined with the character level embeddings and the encoding of collected hate terms. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1167, level: 5" node_number="1167">[110] arXiv:2112.04807 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1168, level: 5" node_number="1168"> <div class="valid" valid="valid" title="valid: True, node: 1169, level: 6" node_number="1169"> <div class="valid" valid="valid" title="valid: True, node: 1170, level: 7" node_number="1170"> Title: Effective dimension of machine learning models </div> <div class="valid" valid="valid" title="valid: True, node: 1171, level: 7" node_number="1171"> Authors: Amira Abbas, David Sutter, <a class="valid" valid="valid" title="valid: True, node: 1172, level: 8" node_number="1172">Alessio Figalli</a>, <a class="valid" valid="valid" title="valid: True, node: 1173, level: 8" node_number="1173">Stefan Woerner</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1174, level: 7" node_number="1174"> Comments: 17 pages, 2 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1175, level: 7" node_number="1175"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1176, level: 7" node_number="1176">Making statements about the performance of trained models on tasks involving new data is one of the primary goals of machine learning, i.e., to understand the generalization power of a model. Various capacity measures try to capture this ability, but usually fall short in explaining important characteristics of models that we observe in practice. In this study, we propose the local effective dimension as a capacity measure which seems to correlate well with generalization error on standard data sets. Importantly, we prove that the local effective dimension bounds the generalization error and discuss the aptness of this capacity measure for machine learning models. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1177, level: 5" node_number="1177">[111] arXiv:2112.04809 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1178, level: 5" node_number="1178"> <div class="valid" valid="valid" title="valid: True, node: 1179, level: 6" node_number="1179"> <div class="valid" valid="valid" title="valid: True, node: 1180, level: 7" node_number="1180"> Title: Next Steps: Learning a Disentangled Gait Representation for Versatile Quadruped Locomotion </div> <div class="valid" valid="valid" title="valid: True, node: 1181, level: 7" node_number="1181"> Authors: Alexander L. Mitchell, <a class="valid" valid="valid" title="valid: True, node: 1182, level: 8" node_number="1182">Wolfgang Merkt</a>, <a class="valid" valid="valid" title="valid: True, node: 1183, level: 8" node_number="1183">Mathieu Geisert</a>, <a class="valid" valid="valid" title="valid: True, node: 1184, level: 8" node_number="1184">Siddhant Gangapurwala</a>, <a class="valid" valid="valid" title="valid: True, node: 1185, level: 8" node_number="1185">Martin Engelcke</a>, <a class="valid" valid="valid" title="valid: True, node: 1186, level: 8" node_number="1186">Oiwi Parker Jones</a>, <a class="valid" valid="valid" title="valid: True, node: 1187, level: 8" node_number="1187">Ioannis Havoutis</a>, <a class="valid" valid="valid" title="valid: True, node: 1188, level: 8" node_number="1188">Ingmar Posner</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1189, level: 7" node_number="1189"> Comments: 8 pages, 6 figures, under review at Robotics and Automation Letters (RA-L) </div> <div class="valid" valid="valid" title="valid: True, node: 1190, level: 7" node_number="1190"> Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1191, level: 7" node_number="1191">Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, foot step height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation and robustly capture a richness of movement significantly exceeding the relatively narrow behaviour seen during training. In addition, the use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on a real ANYmal quadruped robot and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1192, level: 5" node_number="1192">[112] arXiv:2112.04810 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1193, level: 5" node_number="1193"> <div class="valid" valid="valid" title="valid: True, node: 1194, level: 6" node_number="1194"> <div class="valid" valid="valid" title="valid: True, node: 1195, level: 7" node_number="1195"> Title: From Scattered Sources to Comprehensive Technology Landscape: A Recommendation-based Retrieval Approach </div> <div class="valid" valid="valid" title="valid: True, node: 1196, level: 7" node_number="1196"> Authors: Chi Thang Duong, <a class="valid" valid="valid" title="valid: True, node: 1197, level: 8" node_number="1197">Dimitri Percia David</a>, <a class="valid" valid="valid" title="valid: True, node: 1198, level: 8" node_number="1198">Ljiljana Dolamic</a>, <a class="valid" valid="valid" title="valid: True, node: 1199, level: 8" node_number="1199">Alain Mermoud</a>, <a class="valid" valid="valid" title="valid: True, node: 1200, level: 8" node_number="1200">Vincent Lenders</a>, <a class="valid" valid="valid" title="valid: True, node: 1201, level: 8" node_number="1201">Karl Aberer</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1202, level: 7" node_number="1202"> Subjects: Information Retrieval (cs.IR) </div> <p class="valid" valid="valid" title="valid: True, node: 1203, level: 7" node_number="1203">Mapping the technology landscape is crucial for market actors to take informed investment decisions. However, given the large amount of data on the Web and its subsequent information overload, manually retrieving information is a seemingly ineffective and incomplete approach. In this work, we propose an end-to-end recommendation based retrieval approach to support automatic retrieval of technologies and their associated companies from raw Web data. This is a two-task setup involving (i) technology classification of entities extracted from company corpus, and (ii) technology and company retrieval based on classified technologies. Our proposed framework approaches the first task by leveraging DistilBERT which is a state-of-the-art language model. For the retrieval task, we introduce a recommendation-based retrieval technique to simultaneously support retrieving related companies, technologies related to a specific company and companies relevant to a technology. To evaluate these tasks, we also construct a data set that includes company documents and entities extracted from these documents together with company categories and technology labels. Experiments show that our approach is able to return 4 times more relevant companies while outperforming traditional retrieval baseline in retrieving technologies. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1204, level: 5" node_number="1204">[113] arXiv:2112.04812 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1205, level: 5" node_number="1205"> <div class="valid" valid="valid" title="valid: True, node: 1206, level: 6" node_number="1206"> <div class="valid" valid="valid" title="valid: True, node: 1207, level: 7" node_number="1207"> Title: Learning Neural Implicit Functions as Object Representations for Robotic Manipulation </div> <div class="valid" valid="valid" title="valid: True, node: 1208, level: 7" node_number="1208"> Authors: Jung-Su Ha, <a class="valid" valid="valid" title="valid: True, node: 1209, level: 8" node_number="1209">Danny Driess</a>, <a class="valid" valid="valid" title="valid: True, node: 1210, level: 8" node_number="1210">Marc Toussaint</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1211, level: 7" node_number="1211"> Subjects: Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 1212, level: 7" node_number="1212">Robotic manipulation planning is the problem of finding a sequence of robot configurations that involves interactions with objects in the scene, e.g., grasp, placement, tool-use, etc. To achieve such interactions, traditional approaches require hand-designed features and object representations, and it still remains an open question how to describe such interactions with arbitrary objects in a flexible and efficient way. Inspired by recent advances in 3D modeling, e.g. NeRF, we propose a method to represent objects as neural implicit functions upon which we can define and jointly train interaction constraint functions. The proposed pixel-aligned representation is directly inferred from camera images with known camera geometry, naturally acting as a perception component in the whole manipulation pipeline, while at the same time enabling sequential robot manipulation planning. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1213, level: 5" node_number="1213">[114] arXiv:2112.04827 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1214, level: 5" node_number="1214"> <div class="valid" valid="valid" title="valid: True, node: 1215, level: 6" node_number="1215"> <div class="valid" valid="valid" title="valid: True, node: 1216, level: 7" node_number="1216"> Title: Explainability of the Implications of Supervised and Unsupervised Face Image Quality Estimations Through Activation Map Variation Analyses in Face Recognition Models </div> <div class="valid" valid="valid" title="valid: True, node: 1217, level: 7" node_number="1217"> Authors: Biying Fu, <a class="valid" valid="valid" title="valid: True, node: 1218, level: 8" node_number="1218">Naser Damer</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1219, level: 7" node_number="1219"> Comments: accepted at the IEEE Winter Conference on Applications of Computer Vision Workshops, WACV Workshops 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1220, level: 7" node_number="1220"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1221, level: 7" node_number="1221">It is challenging to derive explainability for unsupervised or statistical-based face image quality assessment (FIQA) methods. In this work, we propose a novel set of explainability tools to derive reasoning for different FIQA decisions and their face recognition (FR) performance implications. We avoid limiting the deployment of our tools to certain FIQA methods by basing our analyses on the behavior of FR models when processing samples with different FIQA decisions. This leads to explainability tools that can be applied for any FIQA method with any CNN-based FR solution using activation mapping to exhibit the network's activation derived from the face embedding. To avoid the low discrimination between the general spatial activation mapping of low and high-quality images in FR models, we build our explainability tools in a higher derivative space by analyzing the variation of the FR activation maps of image sets with different quality decisions. We demonstrate our tools and analyze the findings on four FIQA methods, by presenting inter and intra-FIQA method analyses. Our proposed tools and the analyses based on them point out, among other conclusions, that high-quality images typically cause consistent low activation on the areas outside of the central face region, while low-quality images, despite general low activation, have high variations of activation in such areas. Our explainability tools also extend to analyzing single images where we show that low-quality images tend to have an FR model spatial activation that strongly differs from what is expected from a high-quality image where this difference also tends to appear more in areas outside of the central face region and does correspond to issues like extreme poses and facial occlusions. The implementation of the proposed tools is accessible here [link]. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1222, level: 5" node_number="1222">[115] arXiv:2112.04831 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1223, level: 5" node_number="1223"> <div class="valid" valid="valid" title="valid: True, node: 1224, level: 6" node_number="1224"> <div class="valid" valid="valid" title="valid: True, node: 1225, level: 7" node_number="1225"> Title: Multimodal Fake News Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1226, level: 7" node_number="1226"> Authors: Santiago Alonso-Bartolome, <a class="valid" valid="valid" title="valid: True, node: 1227, level: 8" node_number="1227">Isabel Segura-Bedmar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1228, level: 7" node_number="1228"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1229, level: 7" node_number="1229">Over the last years, there has been an unprecedented proliferation of fake news. As a consequence, we are more susceptible to the pernicious impact that misinformation and disinformation spreading can have in different segments of our society. Thus, the development of tools for automatic detection of fake news plays and important role in the prevention of its negative effects. Most attempts to detect and classify false content focus only on using textual information. Multimodal approaches are less frequent and they typically classify news either as true or fake. In this work, we perform a fine-grained classification of fake news on the Fakeddit dataset, using both unimodal and multimodal approaches. Our experiments show that the multimodal approach based on a Convolutional Neural Network (CNN) architecture combining text and image data achieves the best results, with an accuracy of 87%. Some fake news categories such as Manipulated content, Satire or False connection strongly benefit from the use of images. Using images also improves the results of the other categories, but with less impact. Regarding the unimodal approaches using only text, Bidirectional Encoder Representations from Transformers (BERT) is the best model with an accuracy of 78%. Therefore, exploiting both text and image data significantly improves the performance of fake news detection. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1230, level: 5" node_number="1230">[116] arXiv:2112.04838 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1231, level: 5" node_number="1231"> <div class="valid" valid="valid" title="valid: True, node: 1232, level: 6" node_number="1232"> <div class="valid" valid="valid" title="valid: True, node: 1233, level: 7" node_number="1233"> Title: How Not to Protect Your IP -- An Industry-Wide Break of IEEE 1735 Implementations </div> <div class="valid" valid="valid" title="valid: True, node: 1234, level: 7" node_number="1234"> Authors: Julian Speith, Florian Schweins, <a class="valid" valid="valid" title="valid: True, node: 1235, level: 8" node_number="1235">Maik Ender</a>, <a class="valid" valid="valid" title="valid: True, node: 1236, level: 8" node_number="1236">Marc Fyrbiak</a>, <a class="valid" valid="valid" title="valid: True, node: 1237, level: 8" node_number="1237">Alexander May</a>, <a class="valid" valid="valid" title="valid: True, node: 1238, level: 8" node_number="1238">Christof Paar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1239, level: 7" node_number="1239"> Subjects: Cryptography and Security (cs.CR) </div> <p class="valid" valid="valid" title="valid: True, node: 1240, level: 7" node_number="1240">Modern hardware systems are composed of a variety of third-party Intellectual Property (IP) cores to implement their overall functionality. Since hardware design is a globalized process involving various (untrusted) stakeholders, a secure management of the valuable IP between authors and users is inevitable to protect them from unauthorized access and modification. To this end, the widely adopted IEEE standard 1735-2014 was created to ensure confidentiality and integrity. In this paper, we outline structural weaknesses in IEEE 1735 that cannot be fixed with cryptographic solutions (given the contemporary hardware design process) and thus render the standard inherently insecure. We practically demonstrate the weaknesses by recovering the private keys of IEEE 1735 implementations from major Electronic Design Automation (EDA) tool vendors, namely Intel, Xilinx, Cadence, Siemens, Microsemi, and Lattice, while results on a seventh case study are withheld. As a consequence, we can decrypt, modify, and re-encrypt all allegedly protected IP cores designed for the respective tools, thus leading to an industry-wide break. As part of this analysis, we are the first to publicly disclose three RSA-based white-box schemes that are used in real-world products and present cryptanalytical attacks for all of them, finally resulting in key recovery. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1241, level: 5" node_number="1241">[117] arXiv:2112.04839 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1242, level: 5" node_number="1242"> <div class="valid" valid="valid" title="valid: True, node: 1243, level: 6" node_number="1243"> <div class="valid" valid="valid" title="valid: True, node: 1244, level: 7" node_number="1244"> Title: Design and Implementation of Real-Time Localization System (RTLS) based on UWB and TDoA Algorithm </div> <div class="valid" valid="valid" title="valid: True, node: 1245, level: 7" node_number="1245"> Authors: Fengyun Zhang, <a class="valid" valid="valid" title="valid: True, node: 1246, level: 8" node_number="1246">Li Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 1247, level: 8" node_number="1247">Yuhuan Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1248, level: 8" node_number="1248">Yulong Ding</a>, <a class="valid" valid="valid" title="valid: True, node: 1249, level: 8" node_number="1249">Shuang-Hua Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 1250, level: 8" node_number="1250">Hao Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1251, level: 7" node_number="1251"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 1252, level: 7" node_number="1252">Nowadays, accurate localization plays an essential role in many fields, like target tracking and path planning. The challenges of indoor localization include inadequate localization accuracy, unreasonable anchor deployment in complex scenarios, lack of stability, and high cost. So the universal positioning technologies cannot meet the real application requirements scarcely. To overcome these shortcomings, a comprehensive Ultra Wide-Band (UWB) based RTLS is presented in this paper. We first introduce the architecture of the real-time localization system, then propose a new wireless clock synchronization (WCS) scheme, finally discuss the time difference of arrival (TDoA) algorithm. We define the time-base selection strategy for the TDoA algorithm, and analyze the relationship between anchor deployment and positioning accuracy. The Extended Kalman Filter (EKF) method is presented for non-linear dynamic localization estimation, and it performs well in terms of stability and accuracy in moving targets. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1253, level: 5" node_number="1253">[118] arXiv:2112.04840 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1254, level: 5" node_number="1254"> <div class="valid" valid="valid" title="valid: True, node: 1255, level: 6" node_number="1255"> <div class="valid" valid="valid" title="valid: True, node: 1256, level: 7" node_number="1256"> Title: Knowledge Distillation for Object Detection via Rank Mimicking and Prediction-guided Feature Imitation </div> <div class="valid" valid="valid" title="valid: True, node: 1257, level: 7" node_number="1257"> Authors: Gang Li, <a class="valid" valid="valid" title="valid: True, node: 1258, level: 8" node_number="1258">Xiang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1259, level: 8" node_number="1259">Yujie Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1260, level: 8" node_number="1260">Shanshan Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 1261, level: 8" node_number="1261">Yichao Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 1262, level: 8" node_number="1262">Ding Liang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1263, level: 7" node_number="1263"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1264, level: 7" node_number="1264"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1265, level: 7" node_number="1265">Knowledge Distillation (KD) is a widely-used technology to inherit information from cumbersome teacher models to compact student models, consequently realizing model compression and acceleration. Compared with image classification, object detection is a more complex task, and designing specific KD methods for object detection is non-trivial. In this work, we elaborately study the behaviour difference between the teacher and student detection models, and obtain two intriguing observations: First, the teacher and student rank their detected candidate boxes quite differently, which results in their precision discrepancy. Second, there is a considerable gap between the feature response differences and prediction differences between teacher and student, indicating that equally imitating all the feature maps of the teacher is the sub-optimal choice for improving the student's accuracy. Based on the two observations, we propose Rank Mimicking (RM) and Prediction-guided Feature Imitation (PFI) for distilling one-stage detectors, respectively. RM takes the rank of candidate boxes from teachers as a new form of knowledge to distill, which consistently outperforms the traditional soft label distillation. PFI attempts to correlate feature differences with prediction differences, making feature imitation directly help to improve the student's accuracy. On MS COCO and PASCAL VOC benchmarks, extensive experiments are conducted on various detectors with different backbones to validate the effectiveness of our method. Specifically, RetinaNet with ResNet50 achieves 40.4% mAP in MS COCO, which is 3.5% higher than its baseline, and also outperforms previous KD methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1266, level: 5" node_number="1266">[119] arXiv:2112.04842 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1267, level: 5" node_number="1267"> <div class="valid" valid="valid" title="valid: True, node: 1268, level: 6" node_number="1268"> <div class="valid" valid="valid" title="valid: True, node: 1269, level: 7" node_number="1269"> Title: Siamese Attribute-missing Graph Auto-encoder </div> <div class="valid" valid="valid" title="valid: True, node: 1270, level: 7" node_number="1270"> Authors: Wenxuan Tu, <a class="valid" valid="valid" title="valid: True, node: 1271, level: 8" node_number="1271">Sihang Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 1272, level: 8" node_number="1272">Yue Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1273, level: 8" node_number="1273">Xinwang Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1274, level: 7" node_number="1274"> Comments: under review </div> <div class="valid" valid="valid" title="valid: True, node: 1275, level: 7" node_number="1275"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1276, level: 7" node_number="1276">Graph representation learning (GRL) on attribute-missing graphs, which is a common yet challenging problem, has recently attracted considerable attention. We observe that existing literature: 1) isolates the learning of attribute and structure embedding thus fails to take full advantages of the two types of information; 2) imposes too strict distribution assumption on the latent space variables, leading to less discriminative feature representations. In this paper, based on the idea of introducing intimate information interaction between the two information sources, we propose our Siamese Attribute-missing Graph Auto-encoder (SAGA). Specifically, three strategies have been conducted. First, we entangle the attribute embedding and structure embedding by introducing a siamese network structure to share the parameters learned by both processes, which allows the network training to benefit from more abundant and diverse information. Second, we introduce a K-nearest neighbor (KNN) and structural constraint enhanced learning mechanism to improve the quality of latent features of the missing attributes by filtering unreliable connections. Third, we manually mask the connections on multiple adjacent matrices and force the structural information embedding sub-network to recover the true adjacent matrix, thus enforcing the resulting network to be able to selectively exploit more high-order discriminative features for data completion. Extensive experiments on six benchmark datasets demonstrate the superiority of our SAGA against the state-of-the-art methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1277, level: 5" node_number="1277">[120] arXiv:2112.04845 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1278, level: 5" node_number="1278"> <div class="valid" valid="valid" title="valid: True, node: 1279, level: 6" node_number="1279"> <div class="valid" valid="valid" title="valid: True, node: 1280, level: 7" node_number="1280"> Title: High performance computing on Android devices -- a case study </div> <div class="valid" valid="valid" title="valid: True, node: 1281, level: 7" node_number="1281"> Authors: Robert Fritze, <a class="valid" valid="valid" title="valid: True, node: 1282, level: 8" node_number="1282">Claudia Plant</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1283, level: 7" node_number="1283"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> <p class="valid" valid="valid" title="valid: True, node: 1284, level: 7" node_number="1284">High performance computing for low power devices can be useful to speed up calculations on processors that use a lower clock rate than computers for which energy efficiency is not an issue. In this trial, different high performance techniques for Android devices have been compared, with a special focus on the use of the GPU. Although not officially supported, the OpenCL framework can be used on Android tablets. For the comparison of the different parallel programming paradigms, a benchmark was chosen that could be implemented easily with all frameworks. The Mandelbrot algorithm is computationally intensive and has very few input and output operations. The algorithm has been implemented in Java, C, C with assembler, C with SIMD assembler, C with OpenCL and scalar instructions and C with OpenCL and vector instructions. The implementations have been tested for all architectures currently supported by Android. High speedups can be achieved using SIMD and OpenCL, although the implementation is not straightforward for either one. Apps that use the GPU must account for the fact that they can be suspended by the user at any moment. In using the OpenCL framework on the GPU of Android devices, a computational power comparable to those of modern high speed CPUs can be made available to the software developer. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1285, level: 5" node_number="1285">[121] arXiv:2112.04846 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1286, level: 5" node_number="1286"> <div class="valid" valid="valid" title="valid: True, node: 1287, level: 6" node_number="1287"> <div class="valid" valid="valid" title="valid: True, node: 1288, level: 7" node_number="1288"> Title: ScaleNet: A Shallow Architecture for Scale Estimation </div> <div class="valid" valid="valid" title="valid: True, node: 1289, level: 7" node_number="1289"> Authors: Axel Barroso-Laguna, <a class="valid" valid="valid" title="valid: True, node: 1290, level: 8" node_number="1290">Yurun Tian</a>, <a class="valid" valid="valid" title="valid: True, node: 1291, level: 8" node_number="1291">Krystian Mikolajczyk</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1292, level: 7" node_number="1292"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1293, level: 7" node_number="1293">In this paper, we address the problem of estimating scale factors between images. We formulate the scale estimation problem as a prediction of a probability distribution over scale factors. We design a new architecture, ScaleNet, that exploits dilated convolutions as well as self and cross-correlation layers to predict the scale between images. We demonstrate that rectifying images with estimated scales leads to significant performance improvements for various tasks and methods. Specifically, we show how ScaleNet can be combined with sparse local features and dense correspondence networks to improve camera pose estimation, 3D reconstruction, or dense geometric matching in different benchmarks and datasets. We provide an extensive evaluation on several tasks and analyze the computational overhead of ScaleNet. The code, evaluation protocols, and trained models are publicly available at https://github.com/axelBarroso/ScaleNet. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1294, level: 5" node_number="1294">[122] arXiv:2112.04854 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1295, level: 5" node_number="1295"> <div class="valid" valid="valid" title="valid: True, node: 1296, level: 6" node_number="1296"> <div class="valid" valid="valid" title="valid: True, node: 1297, level: 7" node_number="1297"> Title: Properties of Large 2-Crossing-Critical Graphs </div> <div class="valid" valid="valid" title="valid: True, node: 1298, level: 7" node_number="1298"> Authors: Drago Bokal, <a class="valid" valid="valid" title="valid: True, node: 1299, level: 8" node_number="1299">Markus Chimani</a>, <a class="valid" valid="valid" title="valid: True, node: 1300, level: 8" node_number="1300">Alexander Nover</a>, <a class="valid" valid="valid" title="valid: True, node: 1301, level: 8" node_number="1301">J&#246;ran Schierbaum</a>, <a class="valid" valid="valid" title="valid: True, node: 1302, level: 8" node_number="1302">Tobias Stolzmann</a>, <a class="valid" valid="valid" title="valid: True, node: 1303, level: 8" node_number="1303">Mirko H. Wagner</a>, <a class="valid" valid="valid" title="valid: True, node: 1304, level: 8" node_number="1304">Tilo Wiedera</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1305, level: 7" node_number="1305"> Comments: 29 pages, 14 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1306, level: 7" node_number="1306"> Subjects: Discrete Mathematics (cs.DM); Combinatorics (math.CO) </div> <p class="valid" valid="valid" title="valid: True, node: 1307, level: 7" node_number="1307">A $c$-crossing-critical graph is one that has crossing number at least $c$ but each of its proper subgraphs has crossing number less than $c$. Recently, a set of explicit construction rules was identified by Bokal, Oporowski, Richter, and Salazar to generate all large $2$-crossing-critical graphs (i.e., all apart from a finite set of small sporadic graphs). They share the property of containing a generalized Wagner graph $V_{10}$ as a subdivision. In this paper, we study these graphs and establish their order, simple crossing number, edge cover number, clique number, maximum degree, chromatic number, chromatic index, and treewidth. We also show that the graphs are linear-time recognizable and that all our proofs lead to efficient algorithms for the above measures. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1308, level: 5" node_number="1308">[123] arXiv:2112.04855 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1309, level: 5" node_number="1309"> <div class="valid" valid="valid" title="valid: True, node: 1310, level: 6" node_number="1310"> <div class="valid" valid="valid" title="valid: True, node: 1311, level: 7" node_number="1311"> Title: An Australian DER Bill of Rights and Responsibilities </div> <div class="valid" valid="valid" title="valid: True, node: 1312, level: 7" node_number="1312"> Authors: Niraj Lal </div> <div class="valid" valid="valid" title="valid: True, node: 1313, level: 7" node_number="1313"> Comments: 17 pages, 1 figure, 1 table, 1 appenxix </div> <div class="valid" valid="valid" title="valid: True, node: 1314, level: 7" node_number="1314"> Subjects: Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 1315, level: 7" node_number="1315">Australia's world-leading penetration of distributed solar photovoltaics (PV) is now impacting power system security and, as a result, how customers can use and export their own PV-generated energy. Several programs of Australian regulatory reform for distributed energy resources (DER) have emphasised the importance of placing consumers at the centre of any energy transition, but this has occurred against a haphazard backdrop of proposals for solar export taxes, updated inverter standards, and diminishing feed-in-tariffs. Absent from the discussion is a coherent espousal of reasonable consumer expectations with practical technical definitions of how these may be applied. Whilst American legislation has enshrined initial rights to connect PV, they do not consider the evolution of rights in a DER-dominated future. This paper proposes a first attempt at an Australian 'DER Bill of Rights and Responsibilities' for both passive and active participation in energy markets, to support an environment of customer trust and sector confidence in the guiderails of DER integration. Guiding principles are presented with practical definitions referencing existing instruments including inverter standards, network connection agreements and central ancillary service markets. We highlight how these proposed rights are already being breached regularly in Australia, before outlining a pathway to enshrine them for a DER-dominated future with broad sector endorsement. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1316, level: 5" node_number="1316">[124] arXiv:2112.04857 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1317, level: 5" node_number="1317"> <div class="valid" valid="valid" title="valid: True, node: 1318, level: 6" node_number="1318"> <div class="valid" valid="valid" title="valid: True, node: 1319, level: 7" node_number="1319"> Title: A New Measure of Model Redundancy for Compressed Convolutional Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 1320, level: 7" node_number="1320"> Authors: Feiqing Huang, <a class="valid" valid="valid" title="valid: True, node: 1321, level: 8" node_number="1321">Yuefeng Si</a>, <a class="valid" valid="valid" title="valid: True, node: 1322, level: 8" node_number="1322">Yao Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 1323, level: 8" node_number="1323">Guodong Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1324, level: 7" node_number="1324"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1325, level: 7" node_number="1325">While recently many designs have been proposed to improve the model efficiency of convolutional neural networks (CNNs) on a fixed resource budget, theoretical understanding of these designs is still conspicuously lacking. This paper aims to provide a new framework for answering the question: Is there still any remaining model redundancy in a compressed CNN? We begin by developing a general statistical formulation of CNNs and compressed CNNs via the tensor decomposition, such that the weights across layers can be summarized into a single tensor. Then, through a rigorous sample complexity analysis, we reveal an important discrepancy between the derived sample complexity and the naive parameter counting, which serves as a direct indicator of the model redundancy. Motivated by this finding, we introduce a new model redundancy measure for compressed CNNs, called the $K/R$ ratio, which further allows for nonlinear activations. The usefulness of this new measure is supported by ablation studies on popular block designs and datasets. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1326, level: 5" node_number="1326">[125] arXiv:2112.04870 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1327, level: 5" node_number="1327"> <div class="valid" valid="valid" title="valid: True, node: 1328, level: 6" node_number="1328"> <div class="valid" valid="valid" title="valid: True, node: 1329, level: 7" node_number="1329"> Title: Eigenfunction martingale estimators for interacting particle systems and their mean field limit </div> <div class="valid" valid="valid" title="valid: True, node: 1330, level: 7" node_number="1330"> Authors: Grigorios A. Pavliotis, <a class="valid" valid="valid" title="valid: True, node: 1331, level: 8" node_number="1331">Andrea Zanoni</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1332, level: 7" node_number="1332"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 1333, level: 7" node_number="1333">We study the problem of parameter estimation for large exchangeable interacting particle systems when a sample of discrete observations from a single particle is known. We propose a novel method based on martingale estimating functions constructed by employing the eigenvalues and eigenfunctions of the generator of the mean field limit, linearized around the (unique) invariant measure of the mean field dynamics. We then prove that our estimator is asymptotically unbiased and asymptotically normal when the number of observations and the number of particles tend to infinity, and we provide a rate of convergence towards the exact value of the parameters. Finally, we present several numerical experiments which show the accuracy of our estimator and corroborate our theoretical findings, even in the case the mean field dynamics exhibit more than one steady states. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1334, level: 5" node_number="1334">[126] arXiv:2112.04871 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1335, level: 5" node_number="1335"> <div class="valid" valid="valid" title="valid: True, node: 1336, level: 6" node_number="1336"> <div class="valid" valid="valid" title="valid: True, node: 1337, level: 7" node_number="1337"> Title: KGE-CL: Contrastive Learning of Knowledge Graph Embeddings </div> <div class="valid" valid="valid" title="valid: True, node: 1338, level: 7" node_number="1338"> Authors: Wentao Xu, <a class="valid" valid="valid" title="valid: True, node: 1339, level: 8" node_number="1339">Zhiping Luo</a>, <a class="valid" valid="valid" title="valid: True, node: 1340, level: 8" node_number="1340">Weiqing Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1341, level: 8" node_number="1341">Jiang Bian</a>, <a class="valid" valid="valid" title="valid: True, node: 1342, level: 8" node_number="1342">Jian Yin</a>, <a class="valid" valid="valid" title="valid: True, node: 1343, level: 8" node_number="1343">Tie-Yan Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1344, level: 7" node_number="1344"> Subjects: Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1345, level: 7" node_number="1345">Learning the embeddings of knowledge graphs is vital in artificial intelligence, and can benefit various downstream applications, such as recommendation and question answering. In recent years, many research efforts have been proposed for knowledge graph embedding. However, most previous knowledge graph embedding methods ignore the semantic similarity between the related entities and entity-relation couples in different triples since they separately optimize each triple with the scoring function. To address this problem, we propose a simple yet efficient contrastive learning framework for knowledge graph embeddings, which can shorten the semantic distance of the related entities and entity-relation couples in different triples and thus improve the expressiveness of knowledge graph embeddings. We evaluate our proposed method on three standard knowledge graph benchmarks. It is noteworthy that our method can yield some new state-of-the-art results, achieving 51.2% MRR, 46.8% Hits@1 on the WN18RR dataset, and 59.1% MRR, 51.8% Hits@1 on the YAGO3-10 dataset. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1346, level: 5" node_number="1346">[127] arXiv:2112.04873 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1347, level: 5" node_number="1347"> <div class="valid" valid="valid" title="valid: True, node: 1348, level: 6" node_number="1348"> <div class="valid" valid="valid" title="valid: True, node: 1349, level: 7" node_number="1349"> Title: Nice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation </div> <div class="valid" valid="valid" title="valid: True, node: 1350, level: 7" node_number="1350"> Authors: Poorav Desai, <a class="valid" valid="valid" title="valid: True, node: 1351, level: 8" node_number="1351">Tanmoy Chakraborty</a>, <a class="valid" valid="valid" title="valid: True, node: 1352, level: 8" node_number="1352">Md Shad Akhtar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1353, level: 7" node_number="1353"> Comments: Accepted for publication in AAAI-2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1354, level: 7" node_number="1354"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1355, level: 7" node_number="1355">Sarcasm is a pervading linguistic phenomenon and highly challenging to explain due to its subjectivity, lack of context and deeply-felt opinion. In the multimodal setup, sarcasm is conveyed through the incongruity between the text and visual entities. Although recent approaches deal with sarcasm as a classification problem, it is unclear why an online post is identified as sarcastic. Without proper explanation, end users may not be able to perceive the underlying sense of irony. In this paper, we propose a novel problem -- Multimodal Sarcasm Explanation (MuSE) -- given a multimodal sarcastic post containing an image and a caption, we aim to generate a natural language explanation to reveal the intended sarcasm. To this end, we develop MORE, a new dataset with explanation of 3510 sarcastic multimodal posts. Each explanation is a natural language (English) sentence describing the hidden irony. We benchmark MORE by employing a multimodal Transformer-based architecture. It incorporates a cross-modal attention in the Transformer's encoder which attends to the distinguishing features between the two modalities. Subsequently, a BART-based auto-regressive decoder is used as the generator. Empirical results demonstrate convincing results over various baselines (adopted for MuSE) across five evaluation metrics. We also conduct human evaluation on predictions and obtain Fleiss' Kappa score of 0.4 as a fair agreement among 25 evaluators. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1356, level: 5" node_number="1356">[128] arXiv:2112.04886 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1357, level: 5" node_number="1357"> <div class="valid" valid="valid" title="valid: True, node: 1358, level: 6" node_number="1358"> <div class="valid" valid="valid" title="valid: True, node: 1359, level: 7" node_number="1359"> Title: Semantic Search as Extractive Paraphrase Span Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1360, level: 7" node_number="1360"> Authors: Jenna Kanerva, <a class="valid" valid="valid" title="valid: True, node: 1361, level: 8" node_number="1361">Hanna Kitti</a>, <a class="valid" valid="valid" title="valid: True, node: 1362, level: 8" node_number="1362">Li-Hsin Chang</a>, <a class="valid" valid="valid" title="valid: True, node: 1363, level: 8" node_number="1363">Teemu Vahtola</a>, <a class="valid" valid="valid" title="valid: True, node: 1364, level: 8" node_number="1364">Mathias Creutz</a>, <a class="valid" valid="valid" title="valid: True, node: 1365, level: 8" node_number="1365">Filip Ginter</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1366, level: 7" node_number="1366"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1367, level: 7" node_number="1367">In this paper, we approach the problem of semantic search by framing the search task as paraphrase span detection, i.e. given a segment of text as a query phrase, the task is to identify its paraphrase in a given document, the same modelling setup as typically used in extractive question answering. On the Turku Paraphrase Corpus of 100,000 manually extracted Finnish paraphrase pairs including their original document context, we find that our paraphrase span detection model outperforms two strong retrieval baselines (lexical similarity and BERT sentence embeddings) by 31.9pp and 22.4pp respectively in terms of exact match, and by 22.3pp and 12.9pp in terms of token-level F-score. This demonstrates a strong advantage of modelling the task in terms of span retrieval, rather than sentence similarity. Additionally, we introduce a method for creating artificial paraphrase data through back-translation, suitable for languages where manually annotated paraphrase resources for training the span detection model are not available. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1368, level: 5" node_number="1368">[129] arXiv:2112.04888 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1369, level: 5" node_number="1369"> <div class="valid" valid="valid" title="valid: True, node: 1370, level: 6" node_number="1370"> <div class="valid" valid="valid" title="valid: True, node: 1371, level: 7" node_number="1371"> Title: A Bilingual, OpenWorld Video Text Dataset and End-to-end Video Text Spotter with Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 1372, level: 7" node_number="1372"> Authors: Weijia Wu, <a class="valid" valid="valid" title="valid: True, node: 1373, level: 8" node_number="1373">Yuanqiang Cai</a>, <a class="valid" valid="valid" title="valid: True, node: 1374, level: 8" node_number="1374">Debing Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 1375, level: 8" node_number="1375">Sibo Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1376, level: 8" node_number="1376">Zhuang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1377, level: 8" node_number="1377">Jiahong Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1378, level: 8" node_number="1378">Yejun Tang</a>, <a class="valid" valid="valid" title="valid: True, node: 1379, level: 8" node_number="1379">Hong Zhou</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1380, level: 7" node_number="1380"> Comments: 20 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1381, level: 7" node_number="1381"> Journal-ref: NeurIPS 2021 Track on Datasets and Benchmarks </div> <div class="valid" valid="valid" title="valid: True, node: 1382, level: 7" node_number="1382"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1383, level: 7" node_number="1383">Most existing video text spotting benchmarks focus on evaluating a single language and scenario with limited data. In this work, we introduce a large-scale, Bilingual, Open World Video text benchmark dataset(BOVText). There are four features for BOVText. Firstly, we provide 2,000+ videos with more than 1,750,000+ frames, 25 times larger than the existing largest dataset with incidental text in videos. Secondly, our dataset covers 30+ open categories with a wide selection of various scenarios, e.g., Life Vlog, Driving, Movie, etc. Thirdly, abundant text types annotation (i.e., title, caption or scene text) are provided for the different representational meanings in video. Fourthly, the BOVText provides bilingual text annotation to promote multiple cultures live and communication. Besides, we propose an end-to-end video text spotting framework with Transformer, termed TransVTSpotter, which solves the multi-orient text spotting in video with a simple, but efficient attention-based query-key mechanism. It applies object features from the previous frame as a tracking query for the current frame and introduces a rotation angle prediction to fit the multiorient text instance. On ICDAR2015(video), TransVTSpotter achieves the state-of-the-art performance with 44.1% MOTA, 9 fps. The dataset and code of TransVTSpotter can be found at github:com=weijiawu=BOVText and github:com=weijiawu=TransVTSpotter, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1384, level: 5" node_number="1384">[130] arXiv:2112.04889 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1385, level: 5" node_number="1385"> <div class="valid" valid="valid" title="valid: True, node: 1386, level: 6" node_number="1386"> <div class="valid" valid="valid" title="valid: True, node: 1387, level: 7" node_number="1387"> Title: Artificial Intelligence and Design of Experiments for Assessing Security of Electricity Supply: A Review and Strategic Outlook </div> <div class="valid" valid="valid" title="valid: True, node: 1388, level: 7" node_number="1388"> Authors: Jan Priesmann, <a class="valid" valid="valid" title="valid: True, node: 1389, level: 8" node_number="1389">Justin M&#252;nch</a>, <a class="valid" valid="valid" title="valid: True, node: 1390, level: 8" node_number="1390">Elias Ridha</a>, <a class="valid" valid="valid" title="valid: True, node: 1391, level: 8" node_number="1391">Thomas Spiegel</a>, <a class="valid" valid="valid" title="valid: True, node: 1392, level: 8" node_number="1392">Marius Reich</a>, <a class="valid" valid="valid" title="valid: True, node: 1393, level: 8" node_number="1393">Mario Adam</a>, <a class="valid" valid="valid" title="valid: True, node: 1394, level: 8" node_number="1394">Lars Nolting</a>, <a class="valid" valid="valid" title="valid: True, node: 1395, level: 8" node_number="1395">Aaron Praktiknjo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1396, level: 7" node_number="1396"> Subjects: Artificial Intelligence (cs.AI); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 1397, level: 7" node_number="1397">Assessing the effects of the energy transition and liberalization of energy markets on resource adequacy is an increasingly important and demanding task. The rising complexity in energy systems requires adequate methods for energy system modeling leading to increased computational requirements. Furthermore, with complexity, uncertainty increases likewise calling for probabilistic assessments and scenario analyses. To adequately and efficiently address these various requirements, new methods from the field of data science are needed to accelerate current methods. With our systematic literature review, we want to close the gap between the three disciplines (1) assessment of security of electricity supply, (2) artificial intelligence, and (3) design of experiments. For this, we conduct a large-scale quantitative review on selected fields of application and methods and make a synthesis that relates the different disciplines to each other. Among other findings, we identify metamodeling of complex security of electricity supply models using AI methods and applications of AI-based methods for forecasts of storage dispatch and (non-)availabilities as promising fields of application that have not sufficiently been covered, yet. We end with deriving a new methodological pipeline for adequately and efficiently addressing the present and upcoming challenges in the assessment of security of electricity supply. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1398, level: 5" node_number="1398">[131] arXiv:2112.04891 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1399, level: 5" node_number="1399"> <div class="valid" valid="valid" title="valid: True, node: 1400, level: 6" node_number="1400"> <div class="valid" valid="valid" title="valid: True, node: 1401, level: 7" node_number="1401"> Title: Multi-Task Learning on Networks </div> <div class="valid" valid="valid" title="valid: True, node: 1402, level: 7" node_number="1402"> Authors: Andrea Ponti </div> <div class="valid" valid="valid" title="valid: True, node: 1403, level: 7" node_number="1403"> Comments: 94 pages, 53 figures, 8 tables </div> <div class="valid" valid="valid" title="valid: True, node: 1404, level: 7" node_number="1404"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Methodology (stat.ME) </div> <p class="valid" valid="valid" title="valid: True, node: 1405, level: 7" node_number="1405">The multi-task learning (MTL) paradigm can be traced back to an early paper of Caruana (1997) in which it was argued that data from multiple tasks can be used with the aim to obtain a better performance over learning each task independently. A solution of MTL with conflicting objectives requires modelling the trade-off among them which is generally beyond what a straight linear combination can achieve. A theoretically principled and computationally effective strategy is finding solutions which are not dominated by others as it is addressed in the Pareto analysis. Multi-objective optimization problems arising in the multi-task learning context have specific features and require adhoc methods. The analysis of these features and the proposal of a new computational approach represent the focus of this work. Multi-objective evolutionary algorithms (MOEAs) can easily include the concept of dominance and therefore the Pareto analysis. The major drawback of MOEAs is a low sample efficiency with respect to function evaluations. The key reason for this drawback is that most of the evolutionary approaches do not use models for approximating the objective function. Bayesian Optimization takes a radically different approach based on a surrogate model, such as a Gaussian Process. In this thesis the solutions in the Input Space are represented as probability distributions encapsulating the knowledge contained in the function evaluations. In this space of probability distributions, endowed with the metric given by the Wasserstein distance, a new algorithm MOEA/WST can be designed in which the model is not directly on the objective function but in an intermediate Information Space where the objects from the input space are mapped into histograms. Computational results show that the sample efficiency and the quality of the Pareto set provided by MOEA/WST are significantly better than in the standard MOEA. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1406, level: 5" node_number="1406">[132] arXiv:2112.04893 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1407, level: 5" node_number="1407"> <div class="valid" valid="valid" title="valid: True, node: 1408, level: 6" node_number="1408"> <div class="valid" valid="valid" title="valid: True, node: 1409, level: 7" node_number="1409"> Title: Real-World Dexterous Object Manipulation based Deep Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 1410, level: 7" node_number="1410"> Authors: Qingfeng Yao, <a class="valid" valid="valid" title="valid: True, node: 1411, level: 8" node_number="1411">Jilong Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1412, level: 8" node_number="1412">Shuyu Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1413, level: 7" node_number="1413"> Comments: Best Paper Award Runner Up winner submission for Real Robot Challenge 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1414, level: 7" node_number="1414"> Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1415, level: 7" node_number="1415">Deep reinforcement learning has shown its advantages in real-time decision-making based on the state of the agent. In this stage, we solved the task of using a real robot to manipulate the cube to a given trajectory. The task is broken down into different procedures and we propose a hierarchical structure, the high-level deep reinforcement learning model selects appropriate contact positions and the low-level control module performs the position control under the corresponding trajectory. Our framework reduces the disadvantage of low sample efficiency of deep reinforcement learning and lacking adaptability of traditional robot control methods. Our algorithm is trained in simulation and migrated to reality without fine-tuning. The experimental results show the effectiveness of our method both simulation and reality. Our code and video can be found at https://github.com/42jaylonw/RRC2021ThreeWolves and https://youtu.be/Jr176xsn9wg. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1416, level: 5" node_number="1416">[133] arXiv:2112.04895 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1417, level: 5" node_number="1417"> <div class="valid" valid="valid" title="valid: True, node: 1418, level: 6" node_number="1418"> <div class="valid" valid="valid" title="valid: True, node: 1419, level: 7" node_number="1419"> Title: Latent Space Explanation by Intervention </div> <div class="valid" valid="valid" title="valid: True, node: 1420, level: 7" node_number="1420"> Authors: Itai Gat, <a class="valid" valid="valid" title="valid: True, node: 1421, level: 8" node_number="1421">Guy Lorberbom</a>, <a class="valid" valid="valid" title="valid: True, node: 1422, level: 8" node_number="1422">Idan Schwartz</a>, <a class="valid" valid="valid" title="valid: True, node: 1423, level: 8" node_number="1423">Tamir Hazan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1424, level: 7" node_number="1424"> Comments: Accepted to AAAI22 </div> <div class="valid" valid="valid" title="valid: True, node: 1425, level: 7" node_number="1425"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1426, level: 7" node_number="1426">The success of deep neural nets heavily relies on their ability to encode complex relations between their input and their output. While this property serves to fit the training data well, it also obscures the mechanism that drives prediction. This study aims to reveal hidden concepts by employing an intervention mechanism that shifts the predicted class based on discrete variational autoencoders. An explanatory model then visualizes the encoded information from any hidden layer and its corresponding intervened representation. By the assessment of differences between the original representation and the intervened representation, one can determine the concepts that can alter the class, hence providing interpretability. We demonstrate the effectiveness of our approach on CelebA, where we show various visualizations for bias in the data and suggest different interventions to reveal and change bias. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1427, level: 5" node_number="1427">[134] arXiv:2112.04899 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1428, level: 5" node_number="1428"> <div class="valid" valid="valid" title="valid: True, node: 1429, level: 6" node_number="1429"> <div class="valid" valid="valid" title="valid: True, node: 1430, level: 7" node_number="1430"> Title: Assessing Fairness in the Presence of Missing Data </div> <div class="valid" valid="valid" title="valid: True, node: 1431, level: 7" node_number="1431"> Authors: Yiliang Zhang, <a class="valid" valid="valid" title="valid: True, node: 1432, level: 8" node_number="1432">Qi Long</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1433, level: 7" node_number="1433"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1434, level: 7" node_number="1434">Missing data are prevalent and present daunting challenges in real data analysis. While there is a growing body of literature on fairness in analysis of fully observed data, there has been little theoretical work on investigating fairness in analysis of incomplete data. In practice, a popular analytical approach for dealing with missing data is to use only the set of complete cases, i.e., observations with all features fully observed to train a prediction algorithm. However, depending on the missing data mechanism, the distribution of complete cases and the distribution of the complete data may be substantially different. When the goal is to develop a fair algorithm in the complete data domain where there are no missing values, an algorithm that is fair in the complete case domain may show disproportionate bias towards some marginalized groups in the complete data domain. To fill this significant gap, we study the problem of estimating fairness in the complete data domain for an arbitrary model evaluated merely using complete cases. We provide upper and lower bounds on the fairness estimation error and conduct numerical experiments to assess our theoretical results. Our work provides the first known theoretical results on fairness guarantee in analysis of incomplete data. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1435, level: 5" node_number="1435">[135] arXiv:2112.04902 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1436, level: 5" node_number="1436"> <div class="valid" valid="valid" title="valid: True, node: 1437, level: 6" node_number="1437"> <div class="valid" valid="valid" title="valid: True, node: 1438, level: 7" node_number="1438"> Title: Learning Personal Representations from fMRIby Predicting Neurofeedback Performance </div> <div class="valid" valid="valid" title="valid: True, node: 1439, level: 7" node_number="1439"> Authors: Jhonathan Osin, <a class="valid" valid="valid" title="valid: True, node: 1440, level: 8" node_number="1440">Lior Wolf</a>, <a class="valid" valid="valid" title="valid: True, node: 1441, level: 8" node_number="1441">Guy Gurevitch</a>, <a class="valid" valid="valid" title="valid: True, node: 1442, level: 8" node_number="1442">Jackob Nimrod Keynan</a>, <a class="valid" valid="valid" title="valid: True, node: 1443, level: 8" node_number="1443">Tom Fruchtman-Steinbok</a>, <a class="valid" valid="valid" title="valid: True, node: 1444, level: 8" node_number="1444">Ayelet Or-Borichev</a>, <a class="valid" valid="valid" title="valid: True, node: 1445, level: 8" node_number="1445">Shira Reznik Balter</a>, <a class="valid" valid="valid" title="valid: True, node: 1446, level: 8" node_number="1446">Talma Hendler</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1447, level: 7" node_number="1447"> Journal-ref: MICCAI 2020, https://link.springer.com/chapter/10.1007/978-3-030-59728-3_46 </div> <div class="valid" valid="valid" title="valid: True, node: 1448, level: 7" node_number="1448"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> <p class="valid" valid="valid" title="valid: True, node: 1449, level: 7" node_number="1449">We present a deep neural network method for learning a personal representation for individuals that are performing a self neuromodulation task, guided by functional MRI (fMRI). This neurofeedback task (watch vs. regulate) provides the subjects with a continuous feedback contingent on down regulation of their Amygdala signal and the learning algorithm focuses on this region's time-course of activity. The representation is learned by a self-supervised recurrent neural network, that predicts the Amygdala activity in the next fMRI frame given recent fMRI frames and is conditioned on the learned individual representation. It is shown that the individuals' representation improves the next-frame prediction considerably. Moreover, this personal representation, learned solely from fMRI images, yields good performance in linear prediction of psychiatric traits, which is better than performing such a prediction based on clinical data and personality tests. Our code is attached as supplementary and the data would be shared subject to ethical approvals. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1450, level: 5" node_number="1450">[136] arXiv:2112.04903 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1451, level: 5" node_number="1451"> <div class="valid" valid="valid" title="valid: True, node: 1452, level: 6" node_number="1452"> <div class="valid" valid="valid" title="valid: True, node: 1453, level: 7" node_number="1453"> Title: PRA-Net: Point Relation-Aware Network for 3D Point Cloud Analysis </div> <div class="valid" valid="valid" title="valid: True, node: 1454, level: 7" node_number="1454"> Authors: Silin Cheng, <a class="valid" valid="valid" title="valid: True, node: 1455, level: 8" node_number="1455">Xiwu Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 1456, level: 8" node_number="1456">Xinwei He</a>, <a class="valid" valid="valid" title="valid: True, node: 1457, level: 8" node_number="1457">Zhe Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1458, level: 8" node_number="1458">Xiang Bai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1459, level: 7" node_number="1459"> Comments: 13 pages </div> <div class="valid" valid="valid" title="valid: True, node: 1460, level: 7" node_number="1460"> Journal-ref: IEEE Transactions on Image Processing, vol. 30, pp. 4436-4448, 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1461, level: 7" node_number="1461"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1462, level: 7" node_number="1462">Learning intra-region contexts and inter-region relations are two effective strategies to strengthen feature representations for point cloud analysis. However, unifying the two strategies for point cloud representation is not fully emphasized in existing methods. To this end, we propose a novel framework named Point Relation-Aware Network (PRA-Net), which is composed of an Intra-region Structure Learning (ISL) module and an Inter-region Relation Learning (IRL) module. The ISL module can dynamically integrate the local structural information into the point features, while the IRL module captures inter-region relations adaptively and efficiently via a differentiable region partition scheme and a representative point-based strategy. Extensive experiments on several 3D benchmarks covering shape classification, keypoint estimation, and part segmentation have verified the effectiveness and the generalization ability of PRA-Net. Code will be available at https://github.com/XiwuChen/PRA-Net . </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1463, level: 5" node_number="1463">[137] arXiv:2112.04905 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1464, level: 5" node_number="1464"> <div class="valid" valid="valid" title="valid: True, node: 1465, level: 6" node_number="1465"> <div class="valid" valid="valid" title="valid: True, node: 1466, level: 7" node_number="1466"> Title: i-SpaSP: Structured Neural Pruning via Sparse Signal Recovery </div> <div class="valid" valid="valid" title="valid: True, node: 1467, level: 7" node_number="1467"> Authors: Cameron R. Wolfe, <a class="valid" valid="valid" title="valid: True, node: 1468, level: 8" node_number="1468">Anastasios Kyrillidis</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1469, level: 7" node_number="1469"> Comments: 27 pages, 4 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1470, level: 7" node_number="1470"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1471, level: 7" node_number="1471">We propose a novel, structured pruning algorithm for neural networks -- the iterative, Sparse Structured Pruning algorithm, dubbed as i-SpaSP. Inspired by ideas from sparse signal recovery, i-SpaSP operates by iteratively identifying a larger set of important parameter groups (e.g., filters or neurons) within a network that contribute most to the residual between pruned and dense network output, then thresholding these groups based on a smaller, pre-defined pruning ratio. For both two-layer and multi-layer network architectures with ReLU activations, we show the error induced by pruning with i-SpaSP decays polynomially, where the degree of this polynomial becomes arbitrarily large based on the sparsity of the dense network's hidden representations. In our experiments, i-SpaSP is evaluated across a variety of datasets (i.e., MNIST and ImageNet) and architectures (i.e., feed forward networks, ResNet34, and MobileNetV2), where it is shown to discover high-performing sub-networks and improve upon the pruning efficiency of provable baseline methodologies by several orders of magnitude. Put simply, i-SpaSP is easy to implement with automatic differentiation, achieves strong empirical results, comes with theoretical convergence guarantees, and is efficient, thus distinguishing itself as one of the few computationally efficient, practical, and provable pruning algorithms. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1472, level: 5" node_number="1472">[138] arXiv:2112.04907 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1473, level: 5" node_number="1473"> <div class="valid" valid="valid" title="valid: True, node: 1474, level: 6" node_number="1474"> <div class="valid" valid="valid" title="valid: True, node: 1475, level: 7" node_number="1475"> Title: JueWu-MC: Playing Minecraft with Sample-efficient Hierarchical Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 1476, level: 7" node_number="1476"> Authors: Zichuan Lin, <a class="valid" valid="valid" title="valid: True, node: 1477, level: 8" node_number="1477">Junyou Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1478, level: 8" node_number="1478">Jianing Shi</a>, <a class="valid" valid="valid" title="valid: True, node: 1479, level: 8" node_number="1479">Deheng Ye</a>, <a class="valid" valid="valid" title="valid: True, node: 1480, level: 8" node_number="1480">Qiang Fu</a>, <a class="valid" valid="valid" title="valid: True, node: 1481, level: 8" node_number="1481">Wei Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1482, level: 7" node_number="1482"> Comments: The champion solution of NeurIPS 2021 MineRL research competition ( <a class="valid" valid="valid" title="valid: True, node: 1483, level: 8" node_number="1483">this https URL</a> ) </div> <div class="valid" valid="valid" title="valid: True, node: 1484, level: 7" node_number="1484"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1485, level: 7" node_number="1485">Learning rational behaviors in open-world games like Minecraft remains to be challenging for Reinforcement Learning (RL) research due to the compound challenge of partial observability, high-dimensional visual perception and delayed reward. To address this, we propose JueWu-MC, a sample-efficient hierarchical RL approach equipped with representation learning and imitation learning to deal with perception and exploration. Specifically, our approach includes two levels of hierarchy, where the high-level controller learns a policy to control over options and the low-level workers learn to solve each sub-task. To boost the learning of sub-tasks, we propose a combination of techniques including 1) action-aware representation learning which captures underlying relations between action and representation, 2) discriminator-based self-imitation learning for efficient exploration, and 3) ensemble behavior cloning with consistency filtering for policy robustness. Extensive experiments show that JueWu-MC significantly improves sample efficiency and outperforms a set of baselines by a large margin. Notably, we won the championship of the NeurIPS MineRL 2021 research competition and achieved the highest performance score ever. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1486, level: 5" node_number="1486">[139] arXiv:2112.04910 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1487, level: 5" node_number="1487"> <div class="valid" valid="valid" title="valid: True, node: 1488, level: 6" node_number="1488"> <div class="valid" valid="valid" title="valid: True, node: 1489, level: 7" node_number="1489"> Title: Few-Shot Keypoint Detection as Task Adaptation via Latent Embeddings </div> <div class="valid" valid="valid" title="valid: True, node: 1490, level: 7" node_number="1490"> Authors: Mel Vecerik, <a class="valid" valid="valid" title="valid: True, node: 1491, level: 8" node_number="1491">Jackie Kay</a>, <a class="valid" valid="valid" title="valid: True, node: 1492, level: 8" node_number="1492">Raia Hadsell</a>, <a class="valid" valid="valid" title="valid: True, node: 1493, level: 8" node_number="1493">Lourdes Agapito</a>, <a class="valid" valid="valid" title="valid: True, node: 1494, level: 8" node_number="1494">Jon Scholz</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1495, level: 7" node_number="1495"> Comments: Supplementary material available at: <a class="valid" valid="valid" title="valid: True, node: 1496, level: 8" node_number="1496">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1497, level: 7" node_number="1497"> Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1498, level: 7" node_number="1498">Dense object tracking, the ability to localize specific object points with pixel-level accuracy, is an important computer vision task with numerous downstream applications in robotics. Existing approaches either compute dense keypoint embeddings in a single forward pass, meaning the model is trained to track everything at once, or allocate their full capacity to a sparse predefined set of points, trading generality for accuracy. In this paper we explore a middle ground based on the observation that the number of relevant points at a given time are typically relatively few, e.g. grasp points on a target object. Our main contribution is a novel architecture, inspired by few-shot task adaptation, which allows a sparse-style network to condition on a keypoint embedding that indicates which point to track. Our central finding is that this approach provides the generality of dense-embedding models, while offering accuracy significantly closer to sparse-keypoint approaches. We present results illustrating this capacity vs. accuracy trade-off, and demonstrate the ability to zero-shot transfer to new object instances (within-class) using a real-robot pick-and-place task. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1499, level: 5" node_number="1499">[140] arXiv:2112.04912 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1500, level: 5" node_number="1500"> <div class="valid" valid="valid" title="valid: True, node: 1501, level: 6" node_number="1501"> <div class="valid" valid="valid" title="valid: True, node: 1502, level: 7" node_number="1502"> Title: Scalable and Decentralized Algorithms for Anomaly Detection via Learning-Based Controlled Sensing </div> <div class="valid" valid="valid" title="valid: True, node: 1503, level: 7" node_number="1503"> Authors: Geethu Joseph, <a class="valid" valid="valid" title="valid: True, node: 1504, level: 8" node_number="1504">Chen Zhong</a>, <a class="valid" valid="valid" title="valid: True, node: 1505, level: 8" node_number="1505">M. Cenk Gursoy</a>, <a class="valid" valid="valid" title="valid: True, node: 1506, level: 8" node_number="1506">Senem Velipasalar</a>, <a class="valid" valid="valid" title="valid: True, node: 1507, level: 8" node_number="1507">Pramod K.Varshney</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1508, level: 7" node_number="1508"> Comments: 13 pages, 4 figures. arXiv admin note: substantial text overlap with <a class="valid" valid="valid" title="valid: True, node: 1509, level: 8" node_number="1509">arXiv:2105.06289</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1510, level: 7" node_number="1510"> Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1511, level: 7" node_number="1511">We address the problem of sequentially selecting and observing processes from a given set to find the anomalies among them. The decision-maker observes a subset of the processes at any given time instant and obtains a noisy binary indicator of whether or not the corresponding process is anomalous. In this setting, we develop an anomaly detection algorithm that chooses the processes to be observed at a given time instant, decides when to stop taking observations, and declares the decision on anomalous processes. The objective of the detection algorithm is to identify the anomalies with an accuracy exceeding the desired value while minimizing the delay in decision making. We devise a centralized algorithm where the processes are jointly selected by a common agent as well as a decentralized algorithm where the decision of whether to select a process is made independently for each process. Our algorithms rely on a Markov decision process defined using the marginal probability of each process being normal or anomalous, conditioned on the observations. We implement the detection algorithms using the deep actor-critic reinforcement learning framework. Unlike prior work on this topic that has exponential complexity in the number of processes, our algorithms have computational and memory requirements that are both polynomial in the number of processes. We demonstrate the efficacy of these algorithms using numerical experiments by comparing them with state-of-the-art methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1512, level: 5" node_number="1512">[141] arXiv:2112.04913 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1513, level: 5" node_number="1513"> <div class="valid" valid="valid" title="valid: True, node: 1514, level: 6" node_number="1514"> <div class="valid" valid="valid" title="valid: True, node: 1515, level: 7" node_number="1515"> Title: Identification of Twitter Bots based on an Explainable ML Framework: the US 2020 Elections Case Study </div> <div class="valid" valid="valid" title="valid: True, node: 1516, level: 7" node_number="1516"> Authors: Alexander Shevtsov, <a class="valid" valid="valid" title="valid: True, node: 1517, level: 8" node_number="1517">Christos Tzagkarakis</a>, <a class="valid" valid="valid" title="valid: True, node: 1518, level: 8" node_number="1518">Despoina Antonakaki</a>, <a class="valid" valid="valid" title="valid: True, node: 1519, level: 8" node_number="1519">Sotiris Ioannidis</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1520, level: 7" node_number="1520"> Subjects: Social and Information Networks (cs.SI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1521, level: 7" node_number="1521">Twitter is one of the most popular social networks attracting millions of users, while a considerable proportion of online discourse is captured. It provides a simple usage framework with short messages and an efficient application programming interface (API) enabling the research community to study and analyze several aspects of this social network. However, the Twitter usage simplicity can lead to malicious handling by various bots. The malicious handling phenomenon expands in online discourse, especially during the electoral periods, where except the legitimate bots used for dissemination and communication purposes, the goal is to manipulate the public opinion and the electorate towards a certain direction, specific ideology, or political party. This paper focuses on the design of a novel system for identifying Twitter bots based on labeled Twitter data. To this end, a supervised machine learning (ML) framework is adopted using an Extreme Gradient Boosting (XGBoost) algorithm, where the hyper-parameters are tuned via cross-validation. Our study also deploys Shapley Additive Explanations (SHAP) for explaining the ML model predictions by calculating feature importance, using the game theoretic-based Shapley values. Experimental evaluation on distinct Twitter datasets demonstrate the superiority of our approach, in terms of bot detection accuracy, when compared against a recent state-of-the-art Twitter bot detection method. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1522, level: 5" node_number="1522">[142] arXiv:2112.04919 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1523, level: 5" node_number="1523"> <div class="valid" valid="valid" title="valid: True, node: 1524, level: 6" node_number="1524"> <div class="valid" valid="valid" title="valid: True, node: 1525, level: 7" node_number="1525"> Title: A Qualitative Study on the Sources, Impacts, and Mitigation Strategies of Flaky Tests </div> <div class="valid" valid="valid" title="valid: True, node: 1526, level: 7" node_number="1526"> Authors: Sarra Habchi, <a class="valid" valid="valid" title="valid: True, node: 1527, level: 8" node_number="1527">Guillaume Haben</a>, <a class="valid" valid="valid" title="valid: True, node: 1528, level: 8" node_number="1528">Mike Papadakis</a>, <a class="valid" valid="valid" title="valid: True, node: 1529, level: 8" node_number="1529">Maxime Cordy</a>, <a class="valid" valid="valid" title="valid: True, node: 1530, level: 8" node_number="1530">Yves Le Traon</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1531, level: 7" node_number="1531"> Subjects: Software Engineering (cs.SE) </div> <p class="valid" valid="valid" title="valid: True, node: 1532, level: 7" node_number="1532">Test flakiness forms a major testing concern. Flaky tests manifest non-deterministic outcomes that cripple continuous integration and lead developers to investigate false alerts. Industrial reports indicate that on a large scale, the accrual of flaky tests breaks the trust in test suites and entails significant computational cost. To alleviate this, practitioners are constrained to identify flaky tests and investigate their impact. To shed light on such mitigation mechanisms, we interview 14 practitioners with the aim to identify (i) the sources of flakiness within the testing ecosystem, (ii) the impacts of flakiness, (iii) the measures adopted by practitioners when addressing flakiness, and (iv) the automation opportunities for these measures. Our analysis shows that, besides the tests and code, flakiness stems from interactions between the system components, the testing infrastructure, and external factors. We also highlight the impact of flakiness on testing practices and product quality and show that the adoption of guidelines together with a stable infrastructure are key measures in mitigating the problem. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1533, level: 5" node_number="1533">[143] arXiv:2112.04928 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1534, level: 5" node_number="1534"> <div class="valid" valid="valid" title="valid: True, node: 1535, level: 6" node_number="1535"> <div class="valid" valid="valid" title="valid: True, node: 1536, level: 7" node_number="1536"> Title: Self-Supervised Image-to-Text and Text-to-Image Synthesis </div> <div class="valid" valid="valid" title="valid: True, node: 1537, level: 7" node_number="1537"> Authors: Anindya Sundar Das, <a class="valid" valid="valid" title="valid: True, node: 1538, level: 8" node_number="1538">Sriparna Saha</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1539, level: 7" node_number="1539"> Comments: ICONIP 2021 : The 28th International Conference on Neural Information Processing </div> <div class="valid" valid="valid" title="valid: True, node: 1540, level: 7" node_number="1540"> Journal-ref: ICONIP 2021. Lecture Notes in Computer Science, vol 13111, pp 415-426. Springer, Cham </div> <div class="valid" valid="valid" title="valid: True, node: 1541, level: 7" node_number="1541"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1542, level: 7" node_number="1542">A comprehensive understanding of vision and language and their interrelation are crucial to realize the underlying similarities and differences between these modalities and to learn more generalized, meaningful representations. In recent years, most of the works related to Text-to-Image synthesis and Image-to-Text generation, focused on supervised generative deep architectures to solve the problems, where very little interest was placed on learning the similarities between the embedding spaces across modalities. In this paper, we propose a novel self-supervised deep learning based approach towards learning the cross-modal embedding spaces; for both image to text and text to image generations. In our approach, we first obtain dense vector representations of images using StackGAN-based autoencoder model and also dense vector representations on sentence-level utilizing LSTM based text-autoencoder; then we study the mapping from embedding space of one modality to embedding space of the other modality utilizing GAN and maximum mean discrepancy based generative networks. We, also demonstrate that our model learns to generate textual description from image data as well as images from textual data both qualitatively and quantitatively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1543, level: 5" node_number="1543">[144] arXiv:2112.04934 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1544, level: 5" node_number="1544"> <div class="valid" valid="valid" title="valid: True, node: 1545, level: 6" node_number="1545"> <div class="valid" valid="valid" title="valid: True, node: 1546, level: 7" node_number="1546"> Title: Model Doctor: A Simple Gradient Aggregation Strategy for Diagnosing and Treating CNN Classifiers </div> <div class="valid" valid="valid" title="valid: True, node: 1547, level: 7" node_number="1547"> Authors: Zunlei Feng, <a class="valid" valid="valid" title="valid: True, node: 1548, level: 8" node_number="1548">Jiacong Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 1549, level: 8" node_number="1549">Sai Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 1550, level: 8" node_number="1550">Xiaotian Yu</a>, <a class="valid" valid="valid" title="valid: True, node: 1551, level: 8" node_number="1551">Jie Song</a>, <a class="valid" valid="valid" title="valid: True, node: 1552, level: 8" node_number="1552">Mingli Song</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1553, level: 7" node_number="1553"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1554, level: 7" node_number="1554"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1555, level: 7" node_number="1555">Recently, Convolutional Neural Network (CNN) has achieved excellent performance in the classification task. It is widely known that CNN is deemed as a 'black-box', which is hard for understanding the prediction mechanism and debugging the wrong prediction. Some model debugging and explanation works are developed for solving the above drawbacks. However, those methods focus on explanation and diagnosing possible causes for model prediction, based on which the researchers handle the following optimization of models manually. In this paper, we propose the first completely automatic model diagnosing and treating tool, termed as Model Doctor. Based on two discoveries that 1) each category is only correlated with sparse and specific convolution kernels, and 2) adversarial samples are isolated while normal samples are successive in the feature space, a simple aggregate gradient constraint is devised for effectively diagnosing and optimizing CNN classifiers. The aggregate gradient strategy is a versatile module for mainstream CNN classifiers. Extensive experiments demonstrate that the proposed Model Doctor applies to all existing CNN classifiers, and improves the accuracy of $16$ mainstream CNN classifiers by 1%-5%. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1556, level: 5" node_number="1556">[145] arXiv:2112.04937 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1557, level: 5" node_number="1557"> <div class="valid" valid="valid" title="valid: True, node: 1558, level: 6" node_number="1558"> <div class="valid" valid="valid" title="valid: True, node: 1559, level: 7" node_number="1559"> Title: DVHN: A Deep Hashing Framework for Large-scale Vehicle Re-identification </div> <div class="valid" valid="valid" title="valid: True, node: 1560, level: 7" node_number="1560"> Authors: Yongbiao Chen, <a class="valid" valid="valid" title="valid: True, node: 1561, level: 8" node_number="1561">Sheng Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 1562, level: 8" node_number="1562">Fangxin Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1563, level: 8" node_number="1563">Chenggang Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 1564, level: 8" node_number="1564">Kaicheng Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 1565, level: 8" node_number="1565">Zhengwei Qi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1566, level: 7" node_number="1566"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1567, level: 7" node_number="1567">In this paper, we make the very first attempt to investigate the integration of deep hash learning with vehicle re-identification. We propose a deep hash-based vehicle re-identification framework, dubbed DVHN, which substantially reduces memory usage and promotes retrieval efficiency while reserving nearest neighbor search accuracy. Concretely,~DVHN directly learns discrete compact binary hash codes for each image by jointly optimizing the feature learning network and the hash code generating module. Specifically, we directly constrain the output from the convolutional neural network to be discrete binary codes and ensure the learned binary codes are optimal for classification. To optimize the deep discrete hashing framework, we further propose an alternating minimization method for learning binary similarity-preserved hashing codes. Extensive experiments on two widely-studied vehicle re-identification datasets- extbf{VehicleID} and extbf{VeRi}-~have demonstrated the superiority of our method against the state-of-the-art deep hash methods. extbf{DVHN} of $2048$ bits can achieve 13.94\% and 10.21\% accuracy improvement in terms of extbf{mAP} and extbf{Rank@1} for extbf{VehicleID (800)} dataset. For extbf{VeRi}, we achieve 35.45\% and 32.72\% performance gains for extbf{Rank@1} and extbf{mAP}, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1568, level: 5" node_number="1568">[146] arXiv:2112.04940 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1569, level: 5" node_number="1569"> <div class="valid" valid="valid" title="valid: True, node: 1570, level: 6" node_number="1570"> <div class="valid" valid="valid" title="valid: True, node: 1571, level: 7" node_number="1571"> Title: A Simple but Effective Bidirectional Extraction Framework for Relational Triple Extraction </div> <div class="valid" valid="valid" title="valid: True, node: 1572, level: 7" node_number="1572"> Authors: Feiliang Ren, <a class="valid" valid="valid" title="valid: True, node: 1573, level: 8" node_number="1573">Longhui Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 1574, level: 8" node_number="1574">Xiaofeng Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 1575, level: 8" node_number="1575">Shujuan Yin</a>, <a class="valid" valid="valid" title="valid: True, node: 1576, level: 8" node_number="1576">Shilei Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 1577, level: 8" node_number="1577">Bochao Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1578, level: 7" node_number="1578"> Comments: WSDM2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1579, level: 7" node_number="1579"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1580, level: 7" node_number="1580">Tagging based relational triple extraction methods are attracting growing research attention recently. However, most of these methods take a unidirectional extraction framework that first extracts all subjects and then extracts objects and relations simultaneously based on the subjects extracted. This framework has an obvious deficiency that it is too sensitive to the extraction results of subjects. To overcome this deficiency, we propose a bidirectional extraction framework based method that extracts triples based on the entity pairs extracted from two complementary directions. Concretely, we first extract all possible subject-object pairs from two paralleled directions. These two extraction directions are connected by a shared encoder component, thus the extraction features from one direction can flow to another direction and vice versa. By this way, the extractions of two directions can boost and complement each other. Next, we assign all possible relations for each entity pair by a biaffine model. During training, we observe that the share structure will lead to a convergence rate inconsistency issue which is harmful to performance. So we propose a share-aware learning mechanism to address it. We evaluate the proposed model on multiple benchmark datasets. Extensive experimental results show that the proposed model is very effective and it achieves state-of-the-art results on all of these datasets. Moreover, experiments show that both the proposed bidirectional extraction framework and the share-aware learning mechanism have good adaptability and can be used to improve the performance of other tagging based methods. The source code of our work is available at: https://github.com/neukg/BiRTE. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1581, level: 5" node_number="1581">[147] arXiv:2112.04941 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1582, level: 5" node_number="1582"> <div class="valid" valid="valid" title="valid: True, node: 1583, level: 6" node_number="1583"> <div class="valid" valid="valid" title="valid: True, node: 1584, level: 7" node_number="1584"> Title: Testing Probabilistic Circuits </div> <div class="valid" valid="valid" title="valid: True, node: 1585, level: 7" node_number="1585"> Authors: Yash Pote, <a class="valid" valid="valid" title="valid: True, node: 1586, level: 8" node_number="1586">Kuldeep S. Meel</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1587, level: 7" node_number="1587"> Subjects: Data Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM) </div> <p class="valid" valid="valid" title="valid: True, node: 1588, level: 7" node_number="1588">Probabilistic circuits (PCs) are a powerful modeling framework for representing tractable probability distributions over combinatorial spaces. In machine learning and probabilistic programming, one is often interested in understanding whether the distributions learned using PCs are close to the desired distribution. Thus, given two probabilistic circuits, a fundamental problem of interest is to determine whether their distributions are close to each other. The primary contribution of this paper is a closeness test for PCs with respect to the total variation distance metric. Our algorithm utilizes two common PC queries, counting and sampling. In particular, we provide a poly-time probabilistic algorithm to check the closeness of two PCs when the PCs support tractable approximate counting and sampling. We demonstrate the practical efficiency of our algorithmic framework via a detailed experimental evaluation of a prototype implementation against a set of 475 PC benchmarks. We find that our test correctly decides the closeness of all 475 PCs within 3600 seconds. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1589, level: 5" node_number="1589">[148] arXiv:2112.04947 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1590, level: 5" node_number="1590"> <div class="valid" valid="valid" title="valid: True, node: 1591, level: 6" node_number="1591"> <div class="valid" valid="valid" title="valid: True, node: 1592, level: 7" node_number="1592"> Title: Automated Side Channel Analysis of Media Software with Manifold Learning </div> <div class="valid" valid="valid" title="valid: True, node: 1593, level: 7" node_number="1593"> Authors: Yuanyuan Yuan, <a class="valid" valid="valid" title="valid: True, node: 1594, level: 8" node_number="1594">Qi Pang</a>, <a class="valid" valid="valid" title="valid: True, node: 1595, level: 8" node_number="1595">Shuai Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1596, level: 7" node_number="1596"> Subjects: Cryptography and Security (cs.CR); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1597, level: 7" node_number="1597">The prosperous development of cloud computing and machine learning as a service has led to the widespread use of media software to process confidential media data. This paper explores an adversary's ability to launch side channel analyses (SCA) against media software to reconstruct confidential media inputs. Recent advances in representation learning and perceptual learning inspired us to consider the reconstruction of media inputs from side channel traces as a cross-modality manifold learning task that can be addressed in a unified manner with an autoencoder framework trained to learn the mapping between media inputs and side channel observations. We further enhance the autoencoder with attention to localize the program points that make the primary contribution to SCA, thus automatically pinpointing information-leakage points in media software. We also propose a novel and highly effective defensive technique called perception blinding that can perturb media inputs with perception masks and mitigate manifold learning-based SCA. Our evaluation exploits three popular media software to reconstruct inputs in image, audio, and text formats. We analyze three common side channels - cache bank, cache line, and page tables - and userspace-only cache set accesses logged by standard Prime+Probe. Our framework successfully reconstructs high-quality confidential inputs from the assessed media software and automatically pinpoint their vulnerable program points, many of which are unknown to the public. We further show that perception blinding can mitigate manifold learning-based SCA with negligible extra cost. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1598, level: 5" node_number="1598">[149] arXiv:2112.04948 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1599, level: 5" node_number="1599"> <div class="valid" valid="valid" title="valid: True, node: 1600, level: 6" node_number="1600"> <div class="valid" valid="valid" title="valid: True, node: 1601, level: 7" node_number="1601"> Title: PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function </div> <div class="valid" valid="valid" title="valid: True, node: 1602, level: 7" node_number="1602"> Authors: Manaar Alam, <a class="valid" valid="valid" title="valid: True, node: 1603, level: 8" node_number="1603">Shubhajit Datta</a>, <a class="valid" valid="valid" title="valid: True, node: 1604, level: 8" node_number="1604">Debdeep Mukhopadhyay</a>, <a class="valid" valid="valid" title="valid: True, node: 1605, level: 8" node_number="1605">Arijit Mondal</a>, <a class="valid" valid="valid" title="valid: True, node: 1606, level: 8" node_number="1606">Partha Pratim Chakrabarti</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1607, level: 7" node_number="1607"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1608, level: 7" node_number="1608">The security of Deep Learning classifiers is a critical field of study because of the existence of adversarial attacks. Such attacks usually rely on the principle of transferability, where an adversarial example crafted on a surrogate classifier tends to mislead the target classifier trained on the same dataset even if both classifiers have quite different architecture. Ensemble methods against adversarial attacks demonstrate that an adversarial example is less likely to mislead multiple classifiers in an ensemble having diverse decision boundaries. However, recent ensemble methods have either been shown to be vulnerable to stronger adversaries or shown to lack an end-to-end evaluation. This paper attempts to develop a new ensemble methodology that constructs multiple diverse classifiers using a Pairwise Adversarially Robust Loss (PARL) function during the training procedure. PARL utilizes gradients of each layer with respect to input in every classifier within the ensemble simultaneously. The proposed training procedure enables PARL to achieve higher robustness against black-box transfer attacks compared to previous ensemble methods without adversely affecting the accuracy of clean examples. We also evaluate the robustness in the presence of white-box attacks, where adversarial examples are crafted using parameters of the target classifier. We present extensive experiments using standard image classification datasets like CIFAR-10 and CIFAR-100 trained using standard ResNet20 classifier against state-of-the-art adversarial attacks to demonstrate the robustness of the proposed ensemble methodology. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1609, level: 5" node_number="1609">[150] arXiv:2112.04953 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1610, level: 5" node_number="1610"> <div class="valid" valid="valid" title="valid: True, node: 1611, level: 6" node_number="1611"> <div class="valid" valid="valid" title="valid: True, node: 1612, level: 7" node_number="1612"> Title: Machine Learning for Utility Prediction in Argument-Based Computational Persuasion </div> <div class="valid" valid="valid" title="valid: True, node: 1613, level: 7" node_number="1613"> Authors: Ivan Donadello, <a class="valid" valid="valid" title="valid: True, node: 1614, level: 8" node_number="1614">Anthony Hunter</a>, <a class="valid" valid="valid" title="valid: True, node: 1615, level: 8" node_number="1615">Stefano Teso</a>, <a class="valid" valid="valid" title="valid: True, node: 1616, level: 8" node_number="1616">Mauro Dragoni</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1617, level: 7" node_number="1617"> Subjects: Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1618, level: 7" node_number="1618">Automated persuasion systems (APS) aim to persuade a user to believe something by entering into a dialogue in which arguments and counterarguments are exchanged. To maximize the probability that an APS is successful in persuading a user, it can identify a global policy that will allow it to select the best arguments it presents at each stage of the dialogue whatever arguments the user presents. However, in real applications, such as for healthcare, it is unlikely the utility of the outcome of the dialogue will be the same, or the exact opposite, for the APS and user. In order to deal with this situation, games in extended form have been harnessed for argumentation in Bi-party Decision Theory. This opens new problems that we address in this paper: (1) How can we use Machine Learning (ML) methods to predict utility functions for different subpopulations of users? and (2) How can we identify for a new user the best utility function from amongst those that we have learned? To this extent, we develop two ML methods, EAI and EDS, that leverage information coming from the users to predict their utilities. EAI is restricted to a fixed amount of information, whereas EDS can choose the information that best detects the subpopulations of a user. We evaluate EAI and EDS in a simulation setting and in a realistic case study concerning healthy eating habits. Results are promising in both cases, but EDS is more effective at predicting useful utility functions. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1619, level: 5" node_number="1619">[151] arXiv:2112.04957 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1620, level: 5" node_number="1620"> <div class="valid" valid="valid" title="valid: True, node: 1621, level: 6" node_number="1621"> <div class="valid" valid="valid" title="valid: True, node: 1622, level: 7" node_number="1622"> Title: Smart Support for Mission Success </div> <div class="valid" valid="valid" title="valid: True, node: 1623, level: 7" node_number="1623"> Authors: Juliette Mattioli, <a class="valid" valid="valid" title="valid: True, node: 1624, level: 8" node_number="1624">Pierre-Olivier Robic</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1625, level: 7" node_number="1625"> Comments: 8 pages, 2 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1626, level: 7" node_number="1626"> Subjects: Other Computer Science (cs.OH); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1627, level: 7" node_number="1627">Today's battlefield environment is complex, dynamic and uncertain, and requires efficient support to ensure mission success. This relies on a proper support strategy to provide supported equipment able to fulfill the mission. In the context of defense where both systems and organization are complex, having a holistic approach is challenging by nature, forces and support agencies need to rely on an efficient decision support system. Logistics, readiness and sustainability are critical factors for asset management, which can benefit from AI to reach "Smart In Service" level relying especially on predictive and prescriptive approaches and on effective management of operational re-sources. Smart Support capacities can be then monitored by appropriate metrics and improved by multi-criteria decision support and knowledge management system. Depending on the operational context in terms of information and the objective, different AI paradigms (data-driven AI, knowledge-based AI) are suitable even a combination through hybrid AI. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1628, level: 5" node_number="1628">[152] arXiv:2112.04960 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1629, level: 5" node_number="1629"> <div class="valid" valid="valid" title="valid: True, node: 1630, level: 6" node_number="1630"> <div class="valid" valid="valid" title="valid: True, node: 1631, level: 7" node_number="1631"> Title: mechanoChemML: A software library for machine learning in computational materials physics </div> <div class="valid" valid="valid" title="valid: True, node: 1632, level: 7" node_number="1632"> Authors: X. Zhang, <a class="valid" valid="valid" title="valid: True, node: 1633, level: 8" node_number="1633">G.H. Teichert</a>, <a class="valid" valid="valid" title="valid: True, node: 1634, level: 8" node_number="1634">Z. Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1635, level: 8" node_number="1635">M. Duschenes</a>, <a class="valid" valid="valid" title="valid: True, node: 1636, level: 8" node_number="1636">S. Srivastava</a>, <a class="valid" valid="valid" title="valid: True, node: 1637, level: 8" node_number="1637">A. Sunderarajan</a>, <a class="valid" valid="valid" title="valid: True, node: 1638, level: 8" node_number="1638">E. Livingston</a>, <a class="valid" valid="valid" title="valid: True, node: 1639, level: 8" node_number="1639">K. Garikipati</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1640, level: 7" node_number="1640"> Subjects: Computational Engineering, Finance, and Science (cs.CE) </div> <p class="valid" valid="valid" title="valid: True, node: 1641, level: 7" node_number="1641">We present mechanoChemML, a machine learning software library for computational materials physics. mechanoChemML is designed to function as an interface between platforms that are widely used for machine learning on one hand, and others for solution of partial differential equations-based models of physics. Of special interest here, and the focus of mechanoChemML, are applications to computational materials physics. These typically feature the coupled solution of material transport, reaction, phase transformation, mechanics, heat transport and electrochemistry. Central to the organization of mechanoChemML are machine learning workflows that arise in the context of data-driven computational materials physics. The mechanoChemML code structure is described, the machine learning workflows are laid out and their application to the solution of several problems in materials physics is outlined. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1642, level: 5" node_number="1642">[153] arXiv:2112.04963 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1643, level: 5" node_number="1643"> <div class="valid" valid="valid" title="valid: True, node: 1644, level: 6" node_number="1644"> <div class="valid" valid="valid" title="valid: True, node: 1645, level: 7" node_number="1645"> Title: Model-Agnostic Hybrid Numerical Weather Prediction and Machine Learning Paradigm for Solar Forecasting in the Tropics </div> <div class="valid" valid="valid" title="valid: True, node: 1646, level: 7" node_number="1646"> Authors: Nigel Yuan Yun Ng, <a class="valid" valid="valid" title="valid: True, node: 1647, level: 8" node_number="1647">Harish Gopalan</a>, <a class="valid" valid="valid" title="valid: True, node: 1648, level: 8" node_number="1648">Venugopalan S.G. Raghavan</a>, <a class="valid" valid="valid" title="valid: True, node: 1649, level: 8" node_number="1649">Chin Chun Ooi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1650, level: 7" node_number="1650"> Subjects: Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph) </div> <p class="valid" valid="valid" title="valid: True, node: 1651, level: 7" node_number="1651">Numerical weather prediction (NWP) and machine learning (ML) methods are popular for solar forecasting. However, NWP models have multiple possible physical parameterizations, which requires site-specific NWP optimization. This is further complicated when regional NWP models are used with global climate models with different possible parameterizations. In this study, an alternative approach is proposed and evaluated for four radiation models. Weather Research and Forecasting (WRF) model is run in both global and regional mode to provide an estimate for solar irradiance. This estimate is then post-processed using ML to provide a final prediction. Normalized root-mean-square error from WRF is reduced by up to 40-50% with this ML error correction model. Results obtained using CAM, GFDL, New Goddard and RRTMG radiation models were comparable after this correction, negating the need for WRF parameterization tuning. Other models incorporating nearby locations and sensor data are also evaluated, with the latter being particularly promising. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1652, level: 5" node_number="1652">[154] arXiv:2112.04966 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1653, level: 5" node_number="1653"> <div class="valid" valid="valid" title="valid: True, node: 1654, level: 6" node_number="1654"> <div class="valid" valid="valid" title="valid: True, node: 1655, level: 7" node_number="1655"> Title: CaSP: Class-agnostic Semi-Supervised Pretraining for Detection and Segmentation </div> <div class="valid" valid="valid" title="valid: True, node: 1656, level: 7" node_number="1656"> Authors: Lu Qi, <a class="valid" valid="valid" title="valid: True, node: 1657, level: 8" node_number="1657">Jason Kuen</a>, <a class="valid" valid="valid" title="valid: True, node: 1658, level: 8" node_number="1658">Zhe Lin</a>, <a class="valid" valid="valid" title="valid: True, node: 1659, level: 8" node_number="1659">Jiuxiang Gu</a>, <a class="valid" valid="valid" title="valid: True, node: 1660, level: 8" node_number="1660">Fengyun Rao</a>, <a class="valid" valid="valid" title="valid: True, node: 1661, level: 8" node_number="1661">Dian Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1662, level: 8" node_number="1662">Weidong Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 1663, level: 8" node_number="1663">Zhen Wen</a>, <a class="valid" valid="valid" title="valid: True, node: 1664, level: 8" node_number="1664">Jiaya Jia</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1665, level: 7" node_number="1665"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1666, level: 7" node_number="1666">To improve instance-level detection/segmentation performance, existing self-supervised and semi-supervised methods extract either very task-unrelated or very task-specific training signals from unlabeled data. We argue that these two approaches, at the two extreme ends of the task-specificity spectrum, are suboptimal for the task performance. Utilizing too little task-specific training signals causes underfitting to the ground-truth labels of downstream tasks, while the opposite causes overfitting to the ground-truth labels. To this end, we propose a novel Class-agnostic Semi-supervised Pretraining (CaSP) framework to achieve a more favorable task-specificity balance in extracting training signals from unlabeled data. Compared to semi-supervised learning, CaSP reduces the task specificity in training signals by ignoring class information in the pseudo labels and having a separate pretraining stage that uses only task-unrelated unlabeled data. On the other hand, CaSP preserves the right amount of task specificity by leveraging box/mask-level pseudo labels. As a result, our pretrained model can better avoid underfitting/overfitting to ground-truth labels when finetuned on the downstream task. Using 3.6M unlabeled data, we achieve a remarkable performance gain of 4.7% over ImageNet-pretrained baseline on object detection. Our pretrained model also demonstrates excellent transferability to other detection and segmentation tasks/frameworks. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1667, level: 5" node_number="1667">[155] arXiv:2112.04968 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1668, level: 5" node_number="1668"> <div class="valid" valid="valid" title="valid: True, node: 1669, level: 6" node_number="1669"> <div class="valid" valid="valid" title="valid: True, node: 1670, level: 7" node_number="1670"> Title: Tradeoff between Diversity and Multiplexing Gains in Block Fading Optical Wireless Channels </div> <div class="valid" valid="valid" title="valid: True, node: 1671, level: 7" node_number="1671"> Authors: Sufang Yang, <a class="valid" valid="valid" title="valid: True, node: 1672, level: 8" node_number="1672">Longguang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 1673, level: 8" node_number="1673">Haoyue Tang</a>, <a class="valid" valid="valid" title="valid: True, node: 1674, level: 8" node_number="1674">Jintao Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1675, level: 7" node_number="1675"> Subjects: Information Theory (cs.IT) </div> <p class="valid" valid="valid" title="valid: True, node: 1676, level: 7" node_number="1676">The diversity-multiplexing tradeoff (DMT) provides a fundamental performance metric for different multiple-input multiple-output (MIMO) schemes in wireless communications. In this paper, we explore the block fading optical wireless communication (OWC) channels and characterize the DMT in the presence of both optical peak- and average-power constraints. Three different fading distributions are considered, which reflect different channel conditions. In each channel condition, we obtain the optimal DMT when the block length is sufficiently large, and we also derive the lower and upper bounds of the DMT curve when the block length is small. These results are dramatically different from the existing DMT results in radio-frequency (RF) channels. These differences may be due to the fact that the optical input signal is real and bounded, while its RF counterpart is usually complex and unbounded. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1677, level: 5" node_number="1677">[156] arXiv:2112.04971 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1678, level: 5" node_number="1678"> <div class="valid" valid="valid" title="valid: True, node: 1679, level: 6" node_number="1679"> <div class="valid" valid="valid" title="valid: True, node: 1680, level: 7" node_number="1680"> Title: How Universal is Genre in Universal Dependencies? </div> <div class="valid" valid="valid" title="valid: True, node: 1681, level: 7" node_number="1681"> Authors: Max M&#252;ller-Eberstein, <a class="valid" valid="valid" title="valid: True, node: 1682, level: 8" node_number="1682">Rob van der Goot</a>, <a class="valid" valid="valid" title="valid: True, node: 1683, level: 8" node_number="1683">Barbara Plank</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1684, level: 7" node_number="1684"> Comments: Accepted at SyntaxFest 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1685, level: 7" node_number="1685"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1686, level: 7" node_number="1686">This work provides the first in-depth analysis of genre in Universal Dependencies (UD). In contrast to prior work on genre identification which uses small sets of well-defined labels in mono-/bilingual setups, UD contains 18 genres with varying degrees of specificity spread across 114 languages. As most treebanks are labeled with multiple genres while lacking annotations about which instances belong to which genre, we propose four methods for predicting instance-level genre using weak supervision from treebank metadata. The proposed methods recover instance-level genre better than competitive baselines as measured on a subset of UD with labeled instances and adhere better to the global expected distribution. Our analysis sheds light on prior work using UD genre metadata for treebank selection, finding that metadata alone are a noisy signal and must be disentangled within treebanks before it can be universally applied. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1687, level: 5" node_number="1687">[157] arXiv:2112.04974 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1688, level: 5" node_number="1688"> <div class="valid" valid="valid" title="valid: True, node: 1689, level: 6" node_number="1689"> <div class="valid" valid="valid" title="valid: True, node: 1690, level: 7" node_number="1690"> Title: AdaStereo: An Efficient Domain-Adaptive Stereo Matching Approach </div> <div class="valid" valid="valid" title="valid: True, node: 1691, level: 7" node_number="1691"> Authors: Xiao Song, <a class="valid" valid="valid" title="valid: True, node: 1692, level: 8" node_number="1692">Guorun Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 1693, level: 8" node_number="1693">Xinge Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 1694, level: 8" node_number="1694">Hui Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 1695, level: 8" node_number="1695">Yuexin Ma</a>, <a class="valid" valid="valid" title="valid: True, node: 1696, level: 8" node_number="1696">Zhe Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 1697, level: 8" node_number="1697">Jianping Shi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1698, level: 7" node_number="1698"> Comments: To be published in International Journal of Computer Vision (IJCV) </div> <div class="valid" valid="valid" title="valid: True, node: 1699, level: 7" node_number="1699"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1700, level: 7" node_number="1700">Recently, records on stereo matching benchmarks are constantly broken by end-to-end disparity networks. However, the domain adaptation ability of these deep models is quite limited. Addressing such problem, we present a novel domain-adaptive approach called AdaStereo that aims to align multi-level representations for deep stereo matching networks. Compared to previous methods, our AdaStereo realizes a more standard, complete and effective domain adaptation pipeline. Firstly, we propose a non-adversarial progressive color transfer algorithm for input image-level alignment. Secondly, we design an efficient parameter-free cost normalization layer for internal feature-level alignment. Lastly, a highly related auxiliary task, self-supervised occlusion-aware reconstruction is presented to narrow the gaps in output space. We perform intensive ablation studies and break-down comparisons to validate the effectiveness of each proposed module. With no extra inference overhead and only a slight increase in training complexity, our AdaStereo models achieve state-of-the-art cross-domain performance on multiple benchmarks, including KITTI, Middlebury, ETH3D and DrivingStereo, even outperforming some state-of-the-art disparity networks finetuned with target-domain ground-truths. Moreover, based on two additional evaluation metrics, the superiority of our domain-adaptive stereo matching pipeline is further uncovered from more perspectives. Finally, we demonstrate that our method is robust to various domain adaptation settings, and can be easily integrated into quick adaptation application scenarios and real-world deployments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1701, level: 5" node_number="1701">[158] arXiv:2112.04975 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1702, level: 5" node_number="1702"> <div class="valid" valid="valid" title="valid: True, node: 1703, level: 6" node_number="1703"> <div class="valid" valid="valid" title="valid: True, node: 1704, level: 7" node_number="1704"> Title: Personalized musically induced emotions of not-so-popular Colombian music </div> <div class="valid" valid="valid" title="valid: True, node: 1705, level: 7" node_number="1705"> Authors: Juan Sebasti&#225;n G&#243;mez-Ca&#241;&#243;n, <a class="valid" valid="valid" title="valid: True, node: 1706, level: 8" node_number="1706">Perfecto Herrera</a>, <a class="valid" valid="valid" title="valid: True, node: 1707, level: 8" node_number="1707">Estefan&#237;a Cano</a>, <a class="valid" valid="valid" title="valid: True, node: 1708, level: 8" node_number="1708">Emilia G&#243;mez</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1709, level: 7" node_number="1709"> Journal-ref: HCAI Human Centered AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div class="valid" valid="valid" title="valid: True, node: 1710, level: 7" node_number="1710"> Subjects: Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 1711, level: 7" node_number="1711">This work presents an initial proof of concept of how Music Emotion Recognition (MER) systems could be intentionally biased with respect to annotations of musically induced emotions in a political context. In specific, we analyze traditional Colombian music containing politically charged lyrics of two types: (1) vallenatos and social songs from the "left-wing" guerrilla Fuerzas Armadas Revolucionarias de Colombia (FARC) and (2) corridos from the "right-wing" paramilitaries Autodefensas Unidas de Colombia (AUC). We train personalized machine learning models to predict induced emotions for three users with diverse political views - we aim at identifying the songs that may induce negative emotions for a particular user, such as anger and fear. To this extent, a user's emotion judgements could be interpreted as problematizing data - subjective emotional judgments could in turn be used to influence the user in a human-centered machine learning environment. In short, highly desired "emotion regulation" applications could potentially deviate to "emotion manipulation" - the recent discredit of emotion recognition technologies might transcend ethical issues of diversity and inclusion. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1712, level: 5" node_number="1712">[159] arXiv:2112.04977 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1713, level: 5" node_number="1713"> <div class="valid" valid="valid" title="valid: True, node: 1714, level: 6" node_number="1714"> <div class="valid" valid="valid" title="valid: True, node: 1715, level: 7" node_number="1715"> Title: Bringing Atomistic Deep Learning to Prime Time </div> <div class="valid" valid="valid" title="valid: True, node: 1716, level: 7" node_number="1716"> Authors: Nathan C. Frey, <a class="valid" valid="valid" title="valid: True, node: 1717, level: 8" node_number="1717">Siddharth Samsi</a>, <a class="valid" valid="valid" title="valid: True, node: 1718, level: 8" node_number="1718">Bharath Ramsundar</a>, <a class="valid" valid="valid" title="valid: True, node: 1719, level: 8" node_number="1719">Connor W. Coley</a>, <a class="valid" valid="valid" title="valid: True, node: 1720, level: 8" node_number="1720">Vijay Gadepally</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1721, level: 7" node_number="1721"> Comments: 6 pages, 1 figure, NeurIPS 2021 AI for Science workshop </div> <div class="valid" valid="valid" title="valid: True, node: 1722, level: 7" node_number="1722"> Subjects: Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Chemical Physics (physics.chem-ph) </div> <p class="valid" valid="valid" title="valid: True, node: 1723, level: 7" node_number="1723">Artificial intelligence has not yet revolutionized the design of materials and molecules. In this perspective, we identify four barriers preventing the integration of atomistic deep learning, molecular science, and high-performance computing. We outline focused research efforts to address the opportunities presented by these challenges. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1724, level: 5" node_number="1724">[160] arXiv:2112.04981 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1725, level: 5" node_number="1725"> <div class="valid" valid="valid" title="valid: True, node: 1726, level: 6" node_number="1726"> <div class="valid" valid="valid" title="valid: True, node: 1727, level: 7" node_number="1727"> Title: PE-former: Pose Estimation Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 1728, level: 7" node_number="1728"> Authors: Paschalis Panteleris, <a class="valid" valid="valid" title="valid: True, node: 1729, level: 8" node_number="1729">Antonis Argyros</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1730, level: 7" node_number="1730"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1731, level: 7" node_number="1731">Vision transformer architectures have been demonstrated to work very effectively for image classification tasks. Efforts to solve more challenging vision tasks with transformers rely on convolutional backbones for feature extraction. In this paper we investigate the use of a pure transformer architecture (i.e., one with no CNN backbone) for the problem of 2D body pose estimation. We evaluate two ViT architectures on the COCO dataset. We demonstrate that using an encoder-decoder transformer architecture yields state of the art results on this estimation problem. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1732, level: 5" node_number="1732">[161] arXiv:2112.04989 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1733, level: 5" node_number="1733"> <div class="valid" valid="valid" title="valid: True, node: 1734, level: 6" node_number="1734"> <div class="valid" valid="valid" title="valid: True, node: 1735, level: 7" node_number="1735"> Title: The geometry of one-weight codes in the sum-rank metric </div> <div class="valid" valid="valid" title="valid: True, node: 1736, level: 7" node_number="1736"> Authors: Alessandro Neri, <a class="valid" valid="valid" title="valid: True, node: 1737, level: 8" node_number="1737">Paolo Santonastaso</a>, <a class="valid" valid="valid" title="valid: True, node: 1738, level: 8" node_number="1738">Ferdinando Zullo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1739, level: 7" node_number="1739"> Subjects: Information Theory (cs.IT); Combinatorics (math.CO) </div> <p class="valid" valid="valid" title="valid: True, node: 1740, level: 7" node_number="1740">We provide a geometric characterization of $k$-dimensional $\mathbb{F}_{q^m}$-linear sum-rank metric codes as tuples of $\mathbb{F}_q$-subspaces of $\mathbb{F}_{q^m}^k$. We then use this characterization to study one-weight codes in the sum-rank metric. This leads us to extend the family of linearized Reed-Solomon codes in order to obtain a doubly-extended version of them. We prove that these codes are still maximum sum-rank distance (MSRD) codes and, when $k=2$, they are one-weight, as in the Hamming-metric case. We then focus on constant rank-profile codes in the sum-rank metric, which are a special family of one weight-codes, and derive constraints on their parameters with the aid of an associated Hamming-metric code. Furthermore, we introduce the $n$-simplex codes in the sum-rank metric, which are obtained as the orbit of a Singer subgroup of $\mathrm{GL}(k,q^m)$. They turn out to be constant rank-profile - and hence one-weight - and generalize the simplex codes in both the Hamming and the rank metric. Finally, we focus on $2$-dimensional one-weight codes, deriving constraints on the parameters of those which are also MSRD, and we find a new construction of one-weight MSRD codes when $q=2$. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1741, level: 5" node_number="1741">[162] arXiv:2112.04999 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1742, level: 5" node_number="1742"> <div class="valid" valid="valid" title="valid: True, node: 1743, level: 6" node_number="1743"> <div class="valid" valid="valid" title="valid: True, node: 1744, level: 7" node_number="1744"> Title: Few-Shot NLU with Vector Projection Distance and Abstract Triangular CRF </div> <div class="valid" valid="valid" title="valid: True, node: 1745, level: 7" node_number="1745"> Authors: Su Zhu, <a class="valid" valid="valid" title="valid: True, node: 1746, level: 8" node_number="1746">Lu Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 1747, level: 8" node_number="1747">Ruisheng Cao</a>, <a class="valid" valid="valid" title="valid: True, node: 1748, level: 8" node_number="1748">Zhi Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 1749, level: 8" node_number="1749">Qingliang Miao</a>, <a class="valid" valid="valid" title="valid: True, node: 1750, level: 8" node_number="1750">Kai Yu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1751, level: 7" node_number="1751"> Comments: Accepted by NLPCC 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1752, level: 7" node_number="1752"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 1753, level: 7" node_number="1753">Data sparsity problem is a key challenge of Natural Language Understanding (NLU), especially for a new target domain. By training an NLU model in source domains and applying the model to an arbitrary target domain directly (even without fine-tuning), few-shot NLU becomes crucial to mitigate the data scarcity issue. In this paper, we propose to improve prototypical networks with vector projection distance and abstract triangular Conditional Random Field (CRF) for the few-shot NLU. The vector projection distance exploits projections of contextual word embeddings on label vectors as word-label similarities, which is equivalent to a normalized linear model. The abstract triangular CRF learns domain-agnostic label transitions for joint intent classification and slot filling tasks. Extensive experiments demonstrate that our proposed methods can significantly surpass strong baselines. Specifically, our approach can achieve a new state-of-the-art on two few-shot NLU benchmarks (Few-Joint and SNIPS) in Chinese and English without fine-tuning on target domains. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1754, level: 5" node_number="1754">[163] arXiv:2112.05000 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1755, level: 5" node_number="1755"> <div class="valid" valid="valid" title="valid: True, node: 1756, level: 6" node_number="1756"> <div class="valid" valid="valid" title="valid: True, node: 1757, level: 7" node_number="1757"> Title: The Peril of Popular Deep Learning Uncertainty Estimation Methods </div> <div class="valid" valid="valid" title="valid: True, node: 1758, level: 7" node_number="1758"> Authors: Yehao Liu, <a class="valid" valid="valid" title="valid: True, node: 1759, level: 8" node_number="1759">Matteo Pagliardini</a>, <a class="valid" valid="valid" title="valid: True, node: 1760, level: 8" node_number="1760">Tatjana Chavdarova</a>, <a class="valid" valid="valid" title="valid: True, node: 1761, level: 8" node_number="1761">Sebastian U. Stich</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1762, level: 7" node_number="1762"> Comments: Presented at the Bayesian Deep Learning Workshop at NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1763, level: 7" node_number="1763"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 1764, level: 7" node_number="1764">Uncertainty estimation (UE) techniques -- such as the Gaussian process (GP), Bayesian neural networks (BNN), Monte Carlo dropout (MCDropout) -- aim to improve the interpretability of machine learning models by assigning an estimated uncertainty value to each of their prediction outputs. However, since too high uncertainty estimates can have fatal consequences in practice, this paper analyzes the above techniques. Firstly, we show that GP methods always yield high uncertainty estimates on out of distribution (OOD) data. Secondly, we show on a 2D toy example that both BNNs and MCDropout do not give high uncertainty estimates on OOD samples. Finally, we show empirically that this pitfall of BNNs and MCDropout holds on real world datasets as well. Our insights (i) raise awareness for the more cautious use of currently popular UE methods in Deep Learning, (ii) encourage the development of UE methods that approximate GP-based methods -- instead of BNNs and MCDropout, and (iii) our empirical setups can be used for verifying the OOD performances of any other UE method. The source code is available at https://github.com/epfml/uncertainity-estimation. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1765, level: 5" node_number="1765">[164] arXiv:2112.05003 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1766, level: 5" node_number="1766"> <div class="valid" valid="valid" title="valid: True, node: 1767, level: 6" node_number="1767"> <div class="valid" valid="valid" title="valid: True, node: 1768, level: 7" node_number="1768"> Title: Wikidated 1.0: An Evolving Knowledge Graph Dataset of Wikidata's Revision History </div> <div class="valid" valid="valid" title="valid: True, node: 1769, level: 7" node_number="1769"> Authors: Lukas Schmelzeisen, <a class="valid" valid="valid" title="valid: True, node: 1770, level: 8" node_number="1770">Corina Dima</a>, <a class="valid" valid="valid" title="valid: True, node: 1771, level: 8" node_number="1771">Steffen Staab</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1772, level: 7" node_number="1772"> Comments: 15 pages, 4 figures. Published at Wikidata@ISWC 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1773, level: 7" node_number="1773"> Journal-ref: Wikidata@ISWC 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 1774, level: 7" node_number="1774"> Subjects: Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1775, level: 7" node_number="1775">Wikidata is the largest general-interest knowledge base that is openly available. It is collaboratively edited by thousands of volunteer editors and has thus evolved considerably since its inception in 2012. In this paper, we present Wikidated 1.0, a dataset of Wikidata's full revision history, which encodes changes between Wikidata revisions as sets of deletions and additions of RDF triples. To the best of our knowledge, it constitutes the first large dataset of an evolving knowledge graph, a recently emerging research subject in the Semantic Web community. We introduce the methodology for generating Wikidated 1.0 from dumps of Wikidata, discuss its implementation and limitations, and present statistical characteristics of the dataset. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1776, level: 5" node_number="1776">[165] arXiv:2112.05005 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1777, level: 5" node_number="1777"> <div class="valid" valid="valid" title="valid: True, node: 1778, level: 6" node_number="1778"> <div class="valid" valid="valid" title="valid: True, node: 1779, level: 7" node_number="1779"> Title: Mutual Adversarial Training: Learning together is better than going alone </div> <div class="valid" valid="valid" title="valid: True, node: 1780, level: 7" node_number="1780"> Authors: Jiang Liu, <a class="valid" valid="valid" title="valid: True, node: 1781, level: 8" node_number="1781">Chun Pong Lau</a>, <a class="valid" valid="valid" title="valid: True, node: 1782, level: 8" node_number="1782">Hossein Souri</a>, <a class="valid" valid="valid" title="valid: True, node: 1783, level: 8" node_number="1783">Soheil Feizi</a>, <a class="valid" valid="valid" title="valid: True, node: 1784, level: 8" node_number="1784">Rama Chellappa</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1785, level: 7" node_number="1785"> Comments: Under submission </div> <div class="valid" valid="valid" title="valid: True, node: 1786, level: 7" node_number="1786"> Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1787, level: 7" node_number="1787">Recent studies have shown that robustness to adversarial attacks can be transferred across networks. In other words, we can make a weak model more robust with the help of a strong teacher model. We ask if instead of learning from a static teacher, can models "learn together" and "teach each other" to achieve better robustness? In this paper, we study how interactions among models affect robustness via knowledge distillation. We propose mutual adversarial training (MAT), in which multiple models are trained together and share the knowledge of adversarial examples to achieve improved robustness. MAT allows robust models to explore a larger space of adversarial samples, and find more robust feature spaces and decision boundaries. Through extensive experiments on CIFAR-10 and CIFAR-100, we demonstrate that MAT can effectively improve model robustness and outperform state-of-the-art methods under white-box attacks, bringing $\sim$8% accuracy gain to vanilla adversarial training (AT) under PGD-100 attacks. In addition, we show that MAT can also mitigate the robustness trade-off among different perturbation types, bringing as much as 13.1% accuracy gain to AT baselines against the union of $l_\infty$, $l_2$ and $l_1$ attacks. These results show the superiority of the proposed method and demonstrate that collaborative learning is an effective strategy for designing robust models. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1788, level: 5" node_number="1788">[166] arXiv:2112.05006 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1789, level: 5" node_number="1789"> <div class="valid" valid="valid" title="valid: True, node: 1790, level: 6" node_number="1790"> <div class="valid" valid="valid" title="valid: True, node: 1791, level: 7" node_number="1791"> Title: Exploring Event-driven Dynamic Context for Accident Scene Segmentation </div> <div class="valid" valid="valid" title="valid: True, node: 1792, level: 7" node_number="1792"> Authors: Jiaming Zhang, <a class="valid" valid="valid" title="valid: True, node: 1793, level: 8" node_number="1793">Kailun Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 1794, level: 8" node_number="1794">Rainer Stiefelhagen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1795, level: 7" node_number="1795"> Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS), extended version of <a class="valid" valid="valid" title="valid: True, node: 1796, level: 8" node_number="1796">arXiv:2008.08974</a>, dataset and code will be made publicly available at <a class="valid" valid="valid" title="valid: True, node: 1797, level: 8" node_number="1797">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1798, level: 7" node_number="1798"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1799, level: 7" node_number="1799">The robustness of semantic segmentation on edge cases of traffic scene is a vital factor for the safety of intelligent transportation. However, most of the critical scenes of traffic accidents are extremely dynamic and previously unseen, which seriously harm the performance of semantic segmentation methods. In addition, the delay of the traditional camera during high-speed driving will further reduce the contextual information in the time dimension. Therefore, we propose to extract dynamic context from event-based data with a higher temporal resolution to enhance static RGB images, even for those from traffic accidents with motion blur, collisions, deformations, overturns, etc. Moreover, in order to evaluate the segmentation performance in traffic accidents, we provide a pixel-wise annotated accident dataset, namely DADA-seg, which contains a variety of critical scenarios from traffic accidents. Our experiments indicate that event-based data can provide complementary information to stabilize semantic segmentation under adverse conditions by preserving fine-grained motion of fast-moving foreground (crash objects) in accidents. Our approach achieves +8.2% performance gain on the proposed accident dataset, exceeding more than 20 state-of-the-art semantic segmentation methods. The proposal has been demonstrated to be consistently effective for models learned on multiple source databases including Cityscapes, KITTI-360, BDD, and ApolloScape. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1800, level: 5" node_number="1800">[167] arXiv:2112.05008 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1801, level: 5" node_number="1801"> <div class="valid" valid="valid" title="valid: True, node: 1802, level: 6" node_number="1802"> <div class="valid" valid="valid" title="valid: True, node: 1803, level: 7" node_number="1803"> Title: Millimeter Wave Localization with Imperfect Training Data using Shallow Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 1804, level: 7" node_number="1804"> Authors: Anish Shastri, <a class="valid" valid="valid" title="valid: True, node: 1805, level: 8" node_number="1805">Joan Palacios</a>, <a class="valid" valid="valid" title="valid: True, node: 1806, level: 8" node_number="1806">Paolo Casari</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1807, level: 7" node_number="1807"> Comments: 6 pages, 9 figures. The paper is submitted to IEEE WCNC 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 1808, level: 7" node_number="1808"> Subjects: Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1809, level: 7" node_number="1809">Millimeter wave (mmWave) localization algorithms exploit the quasi-optical propagation of mmWave signals, which yields sparse angular spectra at the receiver. Geometric approaches to angle-based localization typically require to know the map of the environment and the location of the access points. Thus, several works have resorted to automated learning in order to infer a device's location from the properties of the received mmWave signals. However, collecting training data for such models is a significant burden. In this work, we propose a shallow neural network model to localize mmWave devices indoors. This model requires significantly fewer weights than those proposed in the literature. Therefore, it is amenable for implementation in resource-constrained hardware, and needs fewer training samples to converge. We also propose to relieve training data collection efforts by retrieving (inherently imperfect) location estimates from geometry-based mmWave localization algorithms. Even in this case, our results show that the proposed neural networks perform as good as or better than state-of-the-art algorithms. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1810, level: 5" node_number="1810">[168] arXiv:2112.05019 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1811, level: 5" node_number="1811"> <div class="valid" valid="valid" title="valid: True, node: 1812, level: 6" node_number="1812"> <div class="valid" valid="valid" title="valid: True, node: 1813, level: 7" node_number="1813"> Title: Uncovering the Size of the Illegal Corporate Service Provider Industry in the Netherlands: a Network Approach </div> <div class="valid" valid="valid" title="valid: True, node: 1814, level: 7" node_number="1814"> Authors: Javier Garcia-Bernardo, <a class="valid" valid="valid" title="valid: True, node: 1815, level: 8" node_number="1815">Joost Witteman</a>, <a class="valid" valid="valid" title="valid: True, node: 1816, level: 8" node_number="1816">Marilou Vlaanderen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1817, level: 7" node_number="1817"> Subjects: Social and Information Networks (cs.SI) </div> <p class="valid" valid="valid" title="valid: True, node: 1818, level: 7" node_number="1818">Economic crimes such as money laundering, terrorism financing, tax evasion or corruption almost invariably involve the use of a corporate entity. Such entities are regularly incorporated and managed by corporate services providers (CSPs). Given this potential for enabling economic crime, the CSP industry in the Netherlands is heavily regulated and CSPs require a license to operate. Operating without a licence is illegal. In this paper we develop a classification method to detect potentially illegal CSPs based on their similarity with licensed CSPs. Similarity is computed based on their position within the network of directors, companies and addresses, and the characteristics of such entities. We manually annotate a sample of the potential illegal CSPs and estimate that illegal CSPs constitute 45\% of the total number of CSPs and manage 15--30\% of all companies managed by CSPs.Our analysis provides a tool to regulators to improve detection and prevention of economic crime, and can be extended to the detection of other illegal activities. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1819, level: 5" node_number="1819">[169] arXiv:2112.05023 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1820, level: 5" node_number="1820"> <div class="valid" valid="valid" title="valid: True, node: 1821, level: 6" node_number="1821"> <div class="valid" valid="valid" title="valid: True, node: 1822, level: 7" node_number="1822"> Title: Polynomial XL: A Variant of the XL Algorithm Using Macaulay Matrices over Polynomial Rings </div> <div class="valid" valid="valid" title="valid: True, node: 1823, level: 7" node_number="1823"> Authors: Hiroki Furue, <a class="valid" valid="valid" title="valid: True, node: 1824, level: 8" node_number="1824">Momonari Kudo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1825, level: 7" node_number="1825"> Comments: 28 pages, 1 figure </div> <div class="valid" valid="valid" title="valid: True, node: 1826, level: 7" node_number="1826"> Subjects: Symbolic Computation (cs.SC); Cryptography and Security (cs.CR); Commutative Algebra (math.AC) </div> <p class="valid" valid="valid" title="valid: True, node: 1827, level: 7" node_number="1827">Solving a system of $m$ multivariate quadratic equations in $n$ variables (the $\mathcal MQ$ problem) is one of the main challenges of algebraic cryptanalysis. The XL algorithm (XL for short) is a major approach for solving the $\mathcal MQ$ problem with linearization over a coefficient field. Furthermore, the hybrid approach with XL (h-XL) is a variant of XL guessing some variables beforehand. In this paper, we present a variant of h-XL, which we call the polynomial XL (PXL). In PXL, the whole $n$ variables are divided into $k$ variables to be fixed and the remaining $n-k$ variables as "main variables", and we generate the Macaulay matrix with respect to the $n-k$ main variables over a polynomial ring of the $k$ variables. By eliminating some columns of the Macaulay matrix over the polynomial ring before guessing $k$ variables, the amount of manipulations required for each guessed value can be reduced. Our complexity analysis indicates that PXL is efficient on the system with $n \approx m$. For example, on systems over ${\mathbb F}_{2^8}$ with $n=m=80$, the number of manipulations required by the hybrid approaches with XL and Wiedemann XL and PXL is estimated as $2^{252}$, $2^{234}$, and $2^{220}$, respectively. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1828, level: 5" node_number="1828">[170] arXiv:2112.05025 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1829, level: 5" node_number="1829"> <div class="valid" valid="valid" title="valid: True, node: 1830, level: 6" node_number="1830"> <div class="valid" valid="valid" title="valid: True, node: 1831, level: 7" node_number="1831"> Title: Gradient-matching coresets for continual learning </div> <div class="valid" valid="valid" title="valid: True, node: 1832, level: 7" node_number="1832"> Authors: Lukas Balles, Giovanni Zappella, <a class="valid" valid="valid" title="valid: True, node: 1833, level: 8" node_number="1833">C&#233;dric Archambeau</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1834, level: 7" node_number="1834"> Comments: Accepted at the NeurIPS '21 Workshop on Distribution Shifts </div> <div class="valid" valid="valid" title="valid: True, node: 1835, level: 7" node_number="1835"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1836, level: 7" node_number="1836">We devise a coreset selection method based on the idea of gradient matching: The gradients induced by the coreset should match, as closely as possible, those induced by the original training dataset. We evaluate the method in the context of continual learning, where it can be used to curate a rehearsal memory. Our method performs strong competitors such as reservoir sampling across a range of memory sizes. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1837, level: 5" node_number="1837">[171] arXiv:2112.05028 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1838, level: 5" node_number="1838"> <div class="valid" valid="valid" title="valid: True, node: 1839, level: 6" node_number="1839"> <div class="valid" valid="valid" title="valid: True, node: 1840, level: 7" node_number="1840"> Title: Almost complete analytical integration in Galerkin BEM </div> <div class="valid" valid="valid" title="valid: True, node: 1841, level: 7" node_number="1841"> Authors: Daniel Seibel </div> <div class="valid" valid="valid" title="valid: True, node: 1842, level: 7" node_number="1842"> Comments: 27 pages, 7 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1843, level: 7" node_number="1843"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 1844, level: 7" node_number="1844">In this work, semi-analytical formulae for the numerical evaluation of surface integrals occurring in Galerkin boundary element methods (BEM) in 3D are derived. The integrals appear as the entries of BEM matrices and are formed over pairs of surface triangles. Since the integrands become singular if the triangles have non-empty intersection, the transformation presented by Sauter and Schwab is used to remove the singularities. It is shown that the resulting integrals admit analytical formulae if the triangles are identical or share a common edge. Moreover, the four-dimensional integrals are reduced to one- or two-dimensional integrals for triangle pairs with common vertices or disjoint triangles respectively. The efficiency and accuracy of the formulae is demonstrated in numerical experiments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1845, level: 5" node_number="1845">[172] arXiv:2112.05036 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1846, level: 5" node_number="1846"> <div class="valid" valid="valid" title="valid: True, node: 1847, level: 6" node_number="1847"> <div class="valid" valid="valid" title="valid: True, node: 1848, level: 7" node_number="1848"> Title: Domain Adaptation and Autoencoder Based Unsupervised Speech Enhancement </div> <div class="valid" valid="valid" title="valid: True, node: 1849, level: 7" node_number="1849"> Authors: Yi Li, <a class="valid" valid="valid" title="valid: True, node: 1850, level: 8" node_number="1850">Yang Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 1851, level: 8" node_number="1851">Kirill Horoshenkov</a>, <a class="valid" valid="valid" title="valid: True, node: 1852, level: 8" node_number="1852">Syed Mohsen Naqvi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1853, level: 7" node_number="1853"> Journal-ref: IEEE Transactions on Artificial Intelligence. (2021) </div> <div class="valid" valid="valid" title="valid: True, node: 1854, level: 7" node_number="1854"> Subjects: Sound (cs.SD); Audio and Speech Processing (eess.AS) </div> <p class="valid" valid="valid" title="valid: True, node: 1855, level: 7" node_number="1855">As a category of transfer learning, domain adaptation plays an important role in generalizing the model trained in one task and applying it to other similar tasks or settings. In speech enhancement, a well-trained acoustic model can be exploited to obtain the speech signal in the context of other languages, speakers, and environments. Recent domain adaptation research was developed more effectively with various neural networks and high-level abstract features. However, the related studies are more likely to transfer the well-trained model from a rich and more diverse domain to a limited and similar domain. Therefore, in this study, the domain adaptation method is proposed in unsupervised speech enhancement for the opposite circumstance that transferring to a larger and richer domain. On the one hand, the importance-weighting (IW) approach is exploited with a variance constrained autoencoder to reduce the shift of shared weights between the source and target domains. On the other hand, in order to train the classifier with the worst-case weights and minimize the risk, the minimax method is proposed. Both the proposed IW and minimax methods are evaluated from the VOICE BANK and IEEE datasets to the TIMIT dataset. The experiment results show that the proposed methods outperform the state-of-the-art approaches. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1856, level: 5" node_number="1856">[173] arXiv:2112.05050 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1857, level: 5" node_number="1857"> <div class="valid" valid="valid" title="valid: True, node: 1858, level: 6" node_number="1858"> <div class="valid" valid="valid" title="valid: True, node: 1859, level: 7" node_number="1859"> Title: End-to-End Learning of Joint Geometric and Probabilistic Constellation Shaping </div> <div class="valid" valid="valid" title="valid: True, node: 1860, level: 7" node_number="1860"> Authors: Vahid Aref, <a class="valid" valid="valid" title="valid: True, node: 1861, level: 8" node_number="1861">Mathieu Chagnon</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1862, level: 7" node_number="1862"> Comments: Will be presented at OFC 2022 (invited talk) </div> <div class="valid" valid="valid" title="valid: True, node: 1863, level: 7" node_number="1863"> Subjects: Information Theory (cs.IT); Artificial Intelligence (cs.AI); Signal Processing (eess.SP) </div> <p class="valid" valid="valid" title="valid: True, node: 1864, level: 7" node_number="1864">We present a novel autoencoder-based learning of joint geometric and probabilistic constellation shaping for coded-modulation systems. It can maximize either the mutual information (for symbol-metric decoding) or the generalized mutual information (for bit-metric decoding). </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1865, level: 5" node_number="1865">[174] arXiv:2112.05051 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1866, level: 5" node_number="1866"> <div class="valid" valid="valid" title="valid: True, node: 1867, level: 6" node_number="1867"> <div class="valid" valid="valid" title="valid: True, node: 1868, level: 7" node_number="1868"> Title: Preconditioning Richards Equations: spectral analysis and parallel solution at very large scale </div> <div class="valid" valid="valid" title="valid: True, node: 1869, level: 7" node_number="1869"> Authors: Daniele Bertaccini, <a class="valid" valid="valid" title="valid: True, node: 1870, level: 8" node_number="1870">Pasqua D'Ambra</a>, <a class="valid" valid="valid" title="valid: True, node: 1871, level: 8" node_number="1871">Fabio Durastante</a>, <a class="valid" valid="valid" title="valid: True, node: 1872, level: 8" node_number="1872">Salvatore Filippone</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1873, level: 7" node_number="1873"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 1874, level: 7" node_number="1874">We consider here a cell-centered finite difference approximation of the Richards equation in three dimensions, averaging for interface values the hydraulic conductivity $K=K(p)$, a highly nonlinear function, by arithmetic, upstream, and harmonic means. The nonlinearities in the equation can lead to changes in soil conductivity over several orders of magnitude and discretizations with respect to space variables often produce stiff systems of differential equations. Fully implicit time discretization is provided by backward Euler one-step formula; the resulting nonlinear algebraic system is solved by an inexact Newton Armijo-Goldstein algorithm, requiring the solution of a sequence of linear systems involving Jacobian matrices. We prove some new results concerning the distribution of the Jacobians eigenvalues and the explicit expression of their entries. Moreover, we explore some connections between the saturation of the soil and the ill-conditioning of the Jacobians. The information on eigenvalues justifies the effectiveness of some preconditioner approaches which are widely used in the solution of the Richards equation. We propose a new software framework to experiment with scalable and robust preconditioners suitable for efficient parallel simulations at very large scales. Performance results on a literature test case show that our framework is very promising in the advance towards realistic simulations at extreme scale. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1875, level: 5" node_number="1875">[175] arXiv:2112.05053 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1876, level: 5" node_number="1876"> <div class="valid" valid="valid" title="valid: True, node: 1877, level: 6" node_number="1877"> <div class="valid" valid="valid" title="valid: True, node: 1878, level: 7" node_number="1878"> Title: Illumination and Temperature-Aware Multispectral Networks for Edge-Computing-Enabled Pedestrian Detection </div> <div class="valid" valid="valid" title="valid: True, node: 1879, level: 7" node_number="1879"> Authors: Yifan Zhuang, <a class="valid" valid="valid" title="valid: True, node: 1880, level: 8" node_number="1880">Ziyuan Pu</a>, <a class="valid" valid="valid" title="valid: True, node: 1881, level: 8" node_number="1881">Jia Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 1882, level: 8" node_number="1882">Yinhai Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1883, level: 7" node_number="1883"> Comments: 13 pages, 12 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1884, level: 7" node_number="1884"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 1885, level: 7" node_number="1885">Accurate and efficient pedestrian detection is crucial for the intelligent transportation system regarding pedestrian safety and mobility, e.g., Advanced Driver Assistance Systems, and smart pedestrian crosswalk systems. Among all pedestrian detection methods, vision-based detection method is demonstrated to be the most effective in previous studies. However, the existing vision-based pedestrian detection algorithms still have two limitations that restrict their implementations, those being real-time performance as well as the resistance to the impacts of environmental factors, e.g., low illumination conditions. To address these issues, this study proposes a lightweight Illumination and Temperature-aware Multispectral Network (IT-MN) for accurate and efficient pedestrian detection. The proposed IT-MN is an efficient one-stage detector. For accommodating the impacts of environmental factors and enhancing the sensing accuracy, thermal image data is fused by the proposed IT-MN with visual images to enrich useful information when visual image quality is limited. In addition, an innovative and effective late fusion strategy is also developed to optimize the image fusion performance. To make the proposed model implementable for edge computing, the model quantization is applied to reduce the model size by 75% while shortening the inference time significantly. The proposed algorithm is evaluated by comparing with the selected state-of-the-art algorithms using a public dataset collected by in-vehicle cameras. The results show that the proposed algorithm achieves a low miss rate and inference time at 14.19% and 0.03 seconds per image pair on GPU. Besides, the quantized IT-MN achieves an inference time of 0.21 seconds per image pair on the edge device, which also demonstrates the potentiality of deploying the proposed model on edge devices as a highly efficient pedestrian detection algorithm. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1886, level: 5" node_number="1886">[176] arXiv:2112.05055 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1887, level: 5" node_number="1887"> <div class="valid" valid="valid" title="valid: True, node: 1888, level: 6" node_number="1888"> <div class="valid" valid="valid" title="valid: True, node: 1889, level: 7" node_number="1889"> Title: Multivariate analysis-suitable T-splines of arbitrary degree </div> <div class="valid" valid="valid" title="valid: True, node: 1890, level: 7" node_number="1890"> Authors: Robin G&#246;rmer, <a class="valid" valid="valid" title="valid: True, node: 1891, level: 8" node_number="1891">Philipp Morgenstern</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1892, level: 7" node_number="1892"> Comments: 13 pages, 4 figures </div> <div class="valid" valid="valid" title="valid: True, node: 1893, level: 7" node_number="1893"> Subjects: Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 1894, level: 7" node_number="1894">This paper defines analysis-suitable T-splines for arbitrary degree (including even and mixed degrees) and arbitrary dimension. We generalize the concept of anchor elements known from the two-dimensional setting, extend two existing concepts of analysis-suitability and justify their sufficiency for linear independence of the T-spline basis. Finally, we propose a local refinement scheme for multivariate T-splines that allows anisotropic refinement and preserves weak geometric analysis-suitability. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1895, level: 5" node_number="1895">[177] arXiv:2112.05056 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1896, level: 5" node_number="1896"> <div class="valid" valid="valid" title="valid: True, node: 1897, level: 6" node_number="1897"> <div class="valid" valid="valid" title="valid: True, node: 1898, level: 7" node_number="1898"> Title: Opinion Extraction as A Structured Sentiment Analysis using Transformers </div> <div class="valid" valid="valid" title="valid: True, node: 1899, level: 7" node_number="1899"> Authors: Yucheng Liu, <a class="valid" valid="valid" title="valid: True, node: 1900, level: 8" node_number="1900">Tian Zhu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1901, level: 7" node_number="1901"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1902, level: 7" node_number="1902">Relationship extraction and named entity recognition have always been considered as two distinct tasks that require different input data, labels, and models. However, both are essential for structured sentiment analysis. We believe that both tasks can be combined into a single stacked model with the same input data. We performed different experiments to find the best model to extract multiple opinion tuples from a single sentence. The opinion tuples will consist of holders, targets, and expressions. With the opinion tuples, we will be able to extract the relationship we need. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1903, level: 5" node_number="1903">[178] arXiv:2112.05061 [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1904, level: 5" node_number="1904"> <div class="valid" valid="valid" title="valid: True, node: 1905, level: 6" node_number="1905"> <div class="valid" valid="valid" title="valid: True, node: 1906, level: 7" node_number="1906"> Title: Deep Learning based Differential Distinguisher for Lightweight Block Ciphers </div> <div class="valid" valid="valid" title="valid: True, node: 1907, level: 7" node_number="1907"> Authors: Aayush Jain, <a class="valid" valid="valid" title="valid: True, node: 1908, level: 8" node_number="1908">Varun Kohli</a>, <a class="valid" valid="valid" title="valid: True, node: 1909, level: 8" node_number="1909">Girish Mishra</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1910, level: 7" node_number="1910"> Comments: 12 pages, 6 figures, 3 tables, 1 algorithm </div> <div class="valid" valid="valid" title="valid: True, node: 1911, level: 7" node_number="1911"> Subjects: Cryptography and Security (cs.CR) </div> <p class="valid" valid="valid" title="valid: True, node: 1912, level: 7" node_number="1912">Recent years have seen an increasing involvement of Deep Learning in the cryptanalysis of various ciphers. The present study is inspired by past works on differential distinguishers, to develop a Deep Neural Network-based differential distinguisher for round reduced lightweight block ciphers PRESENT and Simeck. We make improvements in the state-of-the-art approach and extend its use to the two structurally different block ciphers, PRESENT-80 and Simeck64/128. The obtained results suggest the universality of our cryptanalysis method. The proposed method can distinguish random data from the cipher data obtained until 6 rounds of PRESENT and 7 rounds of Simeck encryption with high accuracy. In addition to this, we explore a new approach to select good input differentials, which to the best of our knowledge has not been explored in the past. We also provide a minimum-security requirement for the discussed ciphers against our differential attack. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1913, level: 5" node_number="1913">[179] arXiv:2112.05062 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1914, level: 5" node_number="1914"> <div class="valid" valid="valid" title="valid: True, node: 1915, level: 6" node_number="1915"> <div class="valid" valid="valid" title="valid: True, node: 1916, level: 7" node_number="1916"> Title: Learning Transferable Motor Skills with Hierarchical Latent Mixture Policies </div> <div class="valid" valid="valid" title="valid: True, node: 1917, level: 7" node_number="1917"> Authors: Dushyant Rao, <a class="valid" valid="valid" title="valid: True, node: 1918, level: 8" node_number="1918">Fereshteh Sadeghi</a>, <a class="valid" valid="valid" title="valid: True, node: 1919, level: 8" node_number="1919">Leonard Hasenclever</a>, <a class="valid" valid="valid" title="valid: True, node: 1920, level: 8" node_number="1920">Markus Wulfmeier</a>, <a class="valid" valid="valid" title="valid: True, node: 1921, level: 8" node_number="1921">Martina Zambelli</a>, <a class="valid" valid="valid" title="valid: True, node: 1922, level: 8" node_number="1922">Giulia Vezzani</a>, <a class="valid" valid="valid" title="valid: True, node: 1923, level: 8" node_number="1923">Dhruva Tirumala</a>, <a class="valid" valid="valid" title="valid: True, node: 1924, level: 8" node_number="1924">Yusuf Aytar</a>, <a class="valid" valid="valid" title="valid: True, node: 1925, level: 8" node_number="1925">Josh Merel</a>, <a class="valid" valid="valid" title="valid: True, node: 1926, level: 8" node_number="1926">Nicolas Heess</a>, <a class="valid" valid="valid" title="valid: True, node: 1927, level: 8" node_number="1927">Raia Hadsell</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1928, level: 7" node_number="1928"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 1929, level: 7" node_number="1929">For robots operating in the real world, it is desirable to learn reusable behaviours that can effectively be transferred and adapted to numerous tasks and scenarios. We propose an approach to learn abstract motor skills from data using a hierarchical mixture latent variable model. In contrast to existing work, our method exploits a three-level hierarchy of both discrete and continuous latent variables, to capture a set of high-level behaviours while allowing for variance in how they are executed. We demonstrate in manipulation domains that the method can effectively cluster offline data into distinct, executable behaviours, while retaining the flexibility of a continuous latent variable model. The resulting skills can be transferred and fine-tuned on new tasks, unseen objects, and from state to vision-based policies, yielding better sample efficiency and asymptotic performance compared to existing skill- and imitation-based methods. We further analyse how and when the skills are most beneficial: they encourage directed exploration to cover large regions of the state space relevant to the task, making them most effective in challenging sparse-reward settings. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1930, level: 5" node_number="1930">[180] arXiv:2112.05068 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1931, level: 5" node_number="1931"> <div class="valid" valid="valid" title="valid: True, node: 1932, level: 6" node_number="1932"> <div class="valid" valid="valid" title="valid: True, node: 1933, level: 7" node_number="1933"> Title: A Bayesian Treatment of Real-to-Sim for Deformable Object Manipulation </div> <div class="valid" valid="valid" title="valid: True, node: 1934, level: 7" node_number="1934"> Authors: Rika Antonova, <a class="valid" valid="valid" title="valid: True, node: 1935, level: 8" node_number="1935">Jingyun Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 1936, level: 8" node_number="1936">Priya Sundaresan</a>, <a class="valid" valid="valid" title="valid: True, node: 1937, level: 8" node_number="1937">Dieter Fox</a>, <a class="valid" valid="valid" title="valid: True, node: 1938, level: 8" node_number="1938">Fabio Ramos</a>, <a class="valid" valid="valid" title="valid: True, node: 1939, level: 8" node_number="1939">Jeannette Bohg</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1940, level: 7" node_number="1940"> Subjects: Robotics (cs.RO); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1941, level: 7" node_number="1941">Deformable object manipulation remains a challenging task in robotics research. Conventional techniques for parameter inference and state estimation typically rely on a precise definition of the state space and its dynamics. While this is appropriate for rigid objects and robot states, it is challenging to define the state space of a deformable object and how it evolves in time. In this work, we pose the problem of inferring physical parameters of deformable objects as a probabilistic inference task defined with a simulator. We propose a novel methodology for extracting state information from image sequences via a technique to represent the state of a deformable object as a distribution embedding. This allows to incorporate noisy state observations directly into modern Bayesian simulation-based inference tools in a principled manner. Our experiments confirm that we can estimate posterior distributions of physical properties, such as elasticity, friction and scale of highly deformable objects, such as cloth and ropes. Overall, our method addresses the real-to-sim problem probabilistically and helps to better represent the evolution of the state of deformable objects. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1942, level: 5" node_number="1942">[181] arXiv:2112.05070 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1943, level: 5" node_number="1943"> <div class="valid" valid="valid" title="valid: True, node: 1944, level: 6" node_number="1944"> <div class="valid" valid="valid" title="valid: True, node: 1945, level: 7" node_number="1945"> Title: Unique Assembly Verification in Two-Handed Self-Assembly </div> <div class="valid" valid="valid" title="valid: True, node: 1946, level: 7" node_number="1946"> Authors: David Caballero, <a class="valid" valid="valid" title="valid: True, node: 1947, level: 8" node_number="1947">Timothy Gomez</a>, <a class="valid" valid="valid" title="valid: True, node: 1948, level: 8" node_number="1948">Robert Schweller</a>, <a class="valid" valid="valid" title="valid: True, node: 1949, level: 8" node_number="1949">Tim Wylie</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1950, level: 7" node_number="1950"> Subjects: Computational Geometry (cs.CG); Computational Complexity (cs.CC) </div> <p class="valid" valid="valid" title="valid: True, node: 1951, level: 7" node_number="1951">One of the most fundamental and well-studied problems in Tile Self-Assembly is the Unique Assembly Verification (UAV) problem. This algorithmic problem asks whether a given tile system uniquely assembles a specific assembly. The complexity of this problem in the 2-Handed Assembly Model (2HAM) at a constant temperature is a long-standing open problem since the model was introduced. Previously, only membership in the class coNP was known and that the problem is in P if the temperature is one ($au=1$). The problem is known to be hard for many generalizations of the model, such as allowing one step into the third dimension or allowing the temperature of the system to be a variable, but the most fundamental version has remained open. In this paper, we prove the UAV problem in the 2HAM is hard even with a small constant temperature ($au = 2$), and finally answer the complexity of this problem (open since 2013). Further, this result proves that UAV in the staged self-assembly model is coNP-complete with a single bin and stage (open since 2007), and that UAV in the q-tile model is also coNP-complete (open since 2004). We reduce from Monotone Planar 3-SAT with Neighboring Variable Pairs, a special case of 3SAT recently proven to be NP-hard. We accompany this reduction with a positive result showing that UAV is solvable in polynomial time with the promise that the given target assembly will have a tree-shaped bond graph, i.e., contains no cycles. We provide a $\mathcal{O}(n^5)$ algorithm for UAV on tree-bonded assemblies when the temperature is fixed to $2$, and a $\mathcal{O}(n^5\log au)$ time algorithm when the temperature is part of the input. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1952, level: 5" node_number="1952">[182] arXiv:2112.05071 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1953, level: 5" node_number="1953"> <div class="valid" valid="valid" title="valid: True, node: 1954, level: 6" node_number="1954"> <div class="valid" valid="valid" title="valid: True, node: 1955, level: 7" node_number="1955"> Title: A Novel Tropical Geometry-based Interpretable Machine Learning Method: Application in Prognosis of Advanced Heart Failure </div> <div class="valid" valid="valid" title="valid: True, node: 1956, level: 7" node_number="1956"> Authors: Heming Yao, <a class="valid" valid="valid" title="valid: True, node: 1957, level: 8" node_number="1957">Harm Derksen</a>, <a class="valid" valid="valid" title="valid: True, node: 1958, level: 8" node_number="1958">Jessica R. Golbus</a>, <a class="valid" valid="valid" title="valid: True, node: 1959, level: 8" node_number="1959">Justin Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 1960, level: 8" node_number="1960">Keith D. Aaronson</a>, <a class="valid" valid="valid" title="valid: True, node: 1961, level: 8" node_number="1961">Jonathan Gryak</a>, <a class="valid" valid="valid" title="valid: True, node: 1962, level: 8" node_number="1962">Kayvan Najarian</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1963, level: 7" node_number="1963"> Subjects: Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 1964, level: 7" node_number="1964">A model's interpretability is essential to many practical applications such as clinical decision support systems. In this paper, a novel interpretable machine learning method is presented, which can model the relationship between input variables and responses in humanly understandable rules. The method is built by applying tropical geometry to fuzzy inference systems, wherein variable encoding functions and salient rules can be discovered by supervised learning. Experiments using synthetic datasets were conducted to investigate the performance and capacity of the proposed algorithm in classification and rule discovery. Furthermore, the proposed method was applied to a clinical application that identified heart failure patients that would benefit from advanced therapies such as heart transplant or durable mechanical circulatory support. Experimental results show that the proposed network achieved great performance on the classification tasks. In addition to learning humanly understandable rules from the dataset, existing fuzzy domain knowledge can be easily transferred into the network and used to facilitate model training. From our results, the proposed model and the ability of learning existing domain knowledge can significantly improve the model generalizability. The characteristics of the proposed network make it promising in applications requiring model reliability and justification. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1965, level: 5" node_number="1965">[183] arXiv:2112.05077 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1966, level: 5" node_number="1966"> <div class="valid" valid="valid" title="valid: True, node: 1967, level: 6" node_number="1967"> <div class="valid" valid="valid" title="valid: True, node: 1968, level: 7" node_number="1968"> Title: Generating Useful Accident-Prone Driving Scenarios via a Learned Traffic Prior </div> <div class="valid" valid="valid" title="valid: True, node: 1969, level: 7" node_number="1969"> Authors: Davis Rempe, <a class="valid" valid="valid" title="valid: True, node: 1970, level: 8" node_number="1970">Jonah Philion</a>, <a class="valid" valid="valid" title="valid: True, node: 1971, level: 8" node_number="1971">Leonidas J. Guibas</a>, <a class="valid" valid="valid" title="valid: True, node: 1972, level: 8" node_number="1972">Sanja Fidler</a>, <a class="valid" valid="valid" title="valid: True, node: 1973, level: 8" node_number="1973">Or Litany</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1974, level: 7" node_number="1974"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 1975, level: 7" node_number="1975">Evaluating and improving planning for autonomous vehicles requires scalable generation of long-tail traffic scenarios. To be useful, these scenarios must be realistic and challenging, but not impossible to drive through safely. In this work, we introduce STRIVE, a method to automatically generate challenging scenarios that cause a given planner to produce undesirable behavior, like collisions. To maintain scenario plausibility, the key idea is to leverage a learned model of traffic motion in the form of a graph-based conditional VAE. Scenario generation is formulated as an optimization in the latent space of this traffic model, effected by perturbing an initial real-world scene to produce trajectories that collide with a given planner. A subsequent optimization is used to find a "solution" to the scenario, ensuring it is useful to improve the given planner. Further analysis clusters generated scenarios based on collision type. We attack two planners and show that STRIVE successfully generates realistic, challenging scenarios in both cases. We additionally "close the loop" and use these scenarios to optimize hyperparameters of a rule-based planner. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1976, level: 5" node_number="1976">[184] arXiv:2112.05080 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1977, level: 5" node_number="1977"> <div class="valid" valid="valid" title="valid: True, node: 1978, level: 6" node_number="1978"> <div class="valid" valid="valid" title="valid: True, node: 1979, level: 7" node_number="1979"> Title: Locally Shifted Attention With Early Global Integration </div> <div class="valid" valid="valid" title="valid: True, node: 1980, level: 7" node_number="1980"> Authors: Shelly Sheynin, <a class="valid" valid="valid" title="valid: True, node: 1981, level: 8" node_number="1981">Sagie Benaim</a>, <a class="valid" valid="valid" title="valid: True, node: 1982, level: 8" node_number="1982">Adam Polyak</a>, <a class="valid" valid="valid" title="valid: True, node: 1983, level: 8" node_number="1983">Lior Wolf</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1984, level: 7" node_number="1984"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> <p class="valid" valid="valid" title="valid: True, node: 1985, level: 7" node_number="1985">Recent work has shown the potential of transformers for computer vision applications. An image is first partitioned into patches, which are then used as input tokens for the attention mechanism. Due to the expensive quadratic cost of the attention mechanism, either a large patch size is used, resulting in coarse-grained global interactions, or alternatively, attention is applied only on a local region of the image, at the expense of long-range interactions. In this work, we propose an approach that allows for both coarse global interactions and fine-grained local interactions already at early layers of a vision transformer. At the core of our method is the application of local and global attention layers. In the local attention layer, we apply attention to each patch and its local shifts, resulting in virtually located local patches, which are not bound to a single, specific location. These virtually located patches are then used in a global attention layer. The separation of the attention layer into local and global counterparts allows for a low computational cost in the number of patches, while still supporting data-dependent localization already at the first layer, as opposed to the static positioning in other visual transformers. Our method is shown to be superior to both convolutional and transformer-based methods for image classification on CIFAR10, CIFAR100, and ImageNet. Code is available at: https://github.com/shellysheynin/Locally-SAG-Transformer. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1986, level: 5" node_number="1986">[185] arXiv:2112.05083 [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1987, level: 5" node_number="1987"> <div class="valid" valid="valid" title="valid: True, node: 1988, level: 6" node_number="1988"> <div class="valid" valid="valid" title="valid: True, node: 1989, level: 7" node_number="1989"> Title: Improved approximation algorithms for two Euclidean k-Center variants </div> <div class="valid" valid="valid" title="valid: True, node: 1990, level: 7" node_number="1990"> Authors: Haris Angelidakis, <a class="valid" valid="valid" title="valid: True, node: 1991, level: 8" node_number="1991">Ivan Sergeev</a>, <a class="valid" valid="valid" title="valid: True, node: 1992, level: 8" node_number="1992">Pontus Westermark</a> </div> <div class="valid" valid="valid" title="valid: True, node: 1993, level: 7" node_number="1993"> Comments: An approximation algorithm with the same factor for Robust Euclidean k-Supplier also recently appeared in an independent work of Lee, Nagarajan and Wang (<a class="valid" valid="valid" title="valid: True, node: 1994, level: 8" node_number="1994">arXiv:2112.01700</a>) </div> <div class="valid" valid="valid" title="valid: True, node: 1995, level: 7" node_number="1995"> Subjects: Data Structures and Algorithms (cs.DS); Computational Geometry (cs.CG) </div> <p class="valid" valid="valid" title="valid: True, node: 1996, level: 7" node_number="1996">The $k$-Center problem is one of the most popular clustering problems. After decades of work, the complexity of most of its variants on general metrics is now well understood. Surprisingly, this is not the case for a natural setting that often arises in practice, namely the Euclidean setting, in which the input points are points in $\mathbb{R}^d$, and the distance between them is the standard $\ell_2$ Euclidean distance. In this work, we study two Euclidean $k$-Center variants, the Matroid Center problem on the real line and the Robust Euclidean $k$-Supplier problem, and provide algorithms that improve upon the best approximation guarantees known for these problems. In particular, we present a simple $2.5$-approximation algorithm for the Matroid Center problem on the real line, thus improving upon the $3$-approximation factor algorithm of Chen, Li, Liang, and Wang (2016) that works for general metrics. Moreover, we present a $(1 + \sqrt{3})$-approximation algorithm for the Robust Euclidean $k$-Supplier problem, thus improving upon the state-of-the-art $3$-approximation algorithm for Robust $k$-Supplier on general metrics and matching the best approximation factor known for the non-robust setting by Nagarajan, Schieber and Shachnai (2020). </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 1997, level: 5" node_number="1997">[186] arXiv:2112.05084 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 1998, level: 5" node_number="1998"> <div class="valid" valid="valid" title="valid: True, node: 1999, level: 6" node_number="1999"> <div class="valid" valid="valid" title="valid: True, node: 2000, level: 7" node_number="2000"> Title: A Survey on Echo Chambers on Social Media: Description, Detection and Mitigation </div> <div class="valid" valid="valid" title="valid: True, node: 2001, level: 7" node_number="2001"> Authors: Faisal Alatawi, <a class="valid" valid="valid" title="valid: True, node: 2002, level: 8" node_number="2002">Lu Cheng</a>, <a class="valid" valid="valid" title="valid: True, node: 2003, level: 8" node_number="2003">Anique Tahir</a>, <a class="valid" valid="valid" title="valid: True, node: 2004, level: 8" node_number="2004">Mansooreh Karami</a>, <a class="valid" valid="valid" title="valid: True, node: 2005, level: 8" node_number="2005">Bohan Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 2006, level: 8" node_number="2006">Tyler Black</a>, <a class="valid" valid="valid" title="valid: True, node: 2007, level: 8" node_number="2007">Huan Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2008, level: 7" node_number="2008"> Comments: 21 pages, 5 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2009, level: 7" node_number="2009"> Subjects: Social and Information Networks (cs.SI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2010, level: 7" node_number="2010">Echo chambers on social media are a significant problem that can elicit a number of negative consequences, most recently affecting the response to COVID-19. Echo chambers promote conspiracy theories about the virus and are found to be linked to vaccine hesitancy, less compliance with mask mandates, and the practice of social distancing. Moreover, the problem of echo chambers is connected to other pertinent issues like political polarization and the spread of misinformation. An echo chamber is defined as a network of users in which users only interact with opinions that support their pre-existing beliefs and opinions, and they exclude and discredit other viewpoints. This survey aims to examine the echo chamber phenomenon on social media from a social computing perspective and provide a blueprint for possible solutions. We survey the related literature to understand the attributes of echo chambers and how they affect the individual and society at large. Additionally, we show the mechanisms, both algorithmic and psychological, that lead to the formation of echo chambers. These mechanisms could be manifested in two forms: (1) the bias of social media's recommender systems and (2) internal biases such as confirmation bias and homophily. While it is immensely challenging to mitigate internal biases, there has been great efforts seeking to mitigate the bias of recommender systems. These recommender systems take advantage of our own biases to personalize content recommendations to keep us engaged in order to watch more ads. Therefore, we further investigate different computational approaches for echo chamber detection and prevention, mainly based around recommender systems. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2011, level: 5" node_number="2011">[187] arXiv:2112.05090 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2012, level: 5" node_number="2012"> <div class="valid" valid="valid" title="valid: True, node: 2013, level: 6" node_number="2013"> <div class="valid" valid="valid" title="valid: True, node: 2014, level: 7" node_number="2014"> Title: Extending the WILDS Benchmark for Unsupervised Adaptation </div> <div class="valid" valid="valid" title="valid: True, node: 2015, level: 7" node_number="2015"> Authors: Shiori Sagawa, <a class="valid" valid="valid" title="valid: True, node: 2016, level: 8" node_number="2016">Pang Wei Koh</a>, <a class="valid" valid="valid" title="valid: True, node: 2017, level: 8" node_number="2017">Tony Lee</a>, <a class="valid" valid="valid" title="valid: True, node: 2018, level: 8" node_number="2018">Irena Gao</a>, <a class="valid" valid="valid" title="valid: True, node: 2019, level: 8" node_number="2019">Sang Michael Xie</a>, <a class="valid" valid="valid" title="valid: True, node: 2020, level: 8" node_number="2020">Kendrick Shen</a>, <a class="valid" valid="valid" title="valid: True, node: 2021, level: 8" node_number="2021">Ananya Kumar</a>, <a class="valid" valid="valid" title="valid: True, node: 2022, level: 8" node_number="2022">Weihua Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 2023, level: 8" node_number="2023">Michihiro Yasunaga</a>, <a class="valid" valid="valid" title="valid: True, node: 2024, level: 8" node_number="2024">Henrik Marklund</a>, <a class="valid" valid="valid" title="valid: True, node: 2025, level: 8" node_number="2025">Sara Beery</a>, <a class="valid" valid="valid" title="valid: True, node: 2026, level: 8" node_number="2026">Etienne David</a>, <a class="valid" valid="valid" title="valid: True, node: 2027, level: 8" node_number="2027">Ian Stavness</a>, <a class="valid" valid="valid" title="valid: True, node: 2028, level: 8" node_number="2028">Wei Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 2029, level: 8" node_number="2029">Jure Leskovec</a>, <a class="valid" valid="valid" title="valid: True, node: 2030, level: 8" node_number="2030">Kate Saenko</a>, <a class="valid" valid="valid" title="valid: True, node: 2031, level: 8" node_number="2031">Tatsunori Hashimoto</a>, <a class="valid" valid="valid" title="valid: True, node: 2032, level: 8" node_number="2032">Sergey Levine</a>, <a class="valid" valid="valid" title="valid: True, node: 2033, level: 8" node_number="2033">Chelsea Finn</a>, <a class="valid" valid="valid" title="valid: True, node: 2034, level: 8" node_number="2034">Percy Liang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2035, level: 7" node_number="2035"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 2036, level: 7" node_number="2036">Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data. However, existing distribution shift benchmarks for unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. To maintain consistency, the labeled training, validation, and test sets, as well as the evaluation metrics, are exactly the same as in the original WILDS benchmark. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). We systematically benchmark state-of-the-art methods that leverage unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS 2.0 is limited. To facilitate method development and evaluation, we provide an open-source package that automates data loading and contains all of the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2037, level: 5" node_number="2037">[188] arXiv:2112.05106 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2038, level: 5" node_number="2038"> <div class="valid" valid="valid" title="valid: True, node: 2039, level: 6" node_number="2039"> <div class="valid" valid="valid" title="valid: True, node: 2040, level: 7" node_number="2040"> Title: Estimating the Longest Increasing Subsequence in Nearly Optimal Time </div> <div class="valid" valid="valid" title="valid: True, node: 2041, level: 7" node_number="2041"> Authors: Alexandr Andoni, <a class="valid" valid="valid" title="valid: True, node: 2042, level: 8" node_number="2042">Negev Shekel Nosatzki</a>, <a class="valid" valid="valid" title="valid: True, node: 2043, level: 8" node_number="2043">Sandip Sinha</a>, <a class="valid" valid="valid" title="valid: True, node: 2044, level: 8" node_number="2044">Clifford Stein</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2045, level: 7" node_number="2045"> Subjects: Data Structures and Algorithms (cs.DS) </div> <p class="valid" valid="valid" title="valid: True, node: 2046, level: 7" node_number="2046">Longest Increasing Subsequence (LIS) is a fundamental statistic of a sequence, and has been studied for decades. While the LIS of a sequence of length $n$ can be computed exactly in time $O(n\log n)$, the complexity of estimating the (length of the) LIS in sublinear time, especially when LIS $\ll n$, is still open. We show that for any integer $n$ and any $\lambda = o(1)$, there exists a (randomized) non-adaptive algorithm that, given a sequence of length $n$ with LIS $\ge \lambda n$, approximates the LIS up to a factor of $1/\lambda^{o(1)}$ in $n^{o(1)} / \lambda$ time. Our algorithm improves upon prior work substantially in terms of both approximation and run-time: (i) we provide the first sub-polynomial approximation for LIS in sub-linear time; and (ii) our run-time complexity essentially matches the trivial sample complexity lower bound of $\Omega(1/\lambda)$, which is required to obtain any non-trivial approximation of the LIS. As part of our solution, we develop two novel ideas which may be of independent interest: First, we define a new Genuine-LIS problem, where each sequence element may either be genuine or corrupted. In this model, the user receives unrestricted access to actual sequence, but does not know apriori which elements are genuine. The goal is to estimate the LIS using genuine elements only, with the minimal number of "genuiness tests". The second idea, Precision Forest, enables accurate estimations for composition of general functions from "coarse" (sub-)estimates. Precision Forest essentially generalizes classical precision sampling, which works only for summations. As a central tool, the Precision Forest is initially pre-processed on a set of samples, which thereafter is repeatedly reused by multiple sub-parts of the algorithm, improving their amortized complexity. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2047, level: 5" node_number="2047">[189] arXiv:2112.05112 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2048, level: 5" node_number="2048"> <div class="valid" valid="valid" title="valid: True, node: 2049, level: 6" node_number="2049"> <div class="valid" valid="valid" title="valid: True, node: 2050, level: 7" node_number="2050"> Title: BLT: Bidirectional Layout Transformer for Controllable Layout Generation </div> <div class="valid" valid="valid" title="valid: True, node: 2051, level: 7" node_number="2051"> Authors: Xiang Kong, <a class="valid" valid="valid" title="valid: True, node: 2052, level: 8" node_number="2052">Lu Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 2053, level: 8" node_number="2053">Huiwen Chang</a>, <a class="valid" valid="valid" title="valid: True, node: 2054, level: 8" node_number="2054">Han Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2055, level: 8" node_number="2055">Yuan Hao</a>, <a class="valid" valid="valid" title="valid: True, node: 2056, level: 8" node_number="2056">Haifeng Gong</a>, <a class="valid" valid="valid" title="valid: True, node: 2057, level: 8" node_number="2057">Irfan Essa</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2058, level: 7" node_number="2058"> Comments: 14 pages, under review </div> <div class="valid" valid="valid" title="valid: True, node: 2059, level: 7" node_number="2059"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2060, level: 7" node_number="2060">Creating visual layouts is an important step in graphic design. Automatic generation of such layouts is important as we seek scale-able and diverse visual designs. Prior works on automatic layout generation focus on unconditional generation, in which the models generate layouts while neglecting user needs for specific problems. To advance conditional layout generation, we introduce BLT, a bidirectional layout transformer. BLT differs from autoregressive decoding as it first generates a draft layout that satisfies the user inputs and then refines the layout iteratively. We verify the proposed model on multiple benchmarks with various fidelity metrics. Our results demonstrate two key advances to the state-of-the-art layout transformer models. First, our model empowers layout transformers to fulfill controllable layout generation. Second, our model slashes the linear inference time in autoregressive decoding into a constant complexity, thereby achieving 4x-10x speedups in generating a layout at inference time. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2061, level: 5" node_number="2061">[190] arXiv:2112.05118 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2062, level: 5" node_number="2062"> <div class="valid" valid="valid" title="valid: True, node: 2063, level: 6" node_number="2063"> <div class="valid" valid="valid" title="valid: True, node: 2064, level: 7" node_number="2064"> Title: Web Platform for Visualisation of Kinematic Data captured from a Motor Tele-rehabilitation System </div> <div class="valid" valid="valid" title="valid: True, node: 2065, level: 7" node_number="2065"> Authors: Praveena Satkunarajah, <a class="valid" valid="valid" title="valid: True, node: 2066, level: 8" node_number="2066">Kat Agres</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2067, level: 7" node_number="2067"> Subjects: Human-Computer Interaction (cs.HC) </div> <p class="valid" valid="valid" title="valid: True, node: 2068, level: 7" node_number="2068">Stroke can have a severe impact on an individual's quality of life, leading to consequences such as motor loss and communication problems, especially among the elderly. Studies have shown that early and easy access to stroke rehabilitation can improve an elderly individual's quality of life, and that telerehabilitation is a solution that facilitates this improvement. In this work, we visualize movement to music during rehabilitation exercises captured by the Kinect motion sensor, using a dedicated Serious Game called `Move to the Music'(MoMu). Our system provides a quantitative view of progress made by patients during a motor rehabilitation regime for healthcare professionals to track remotely (tele-rehab). </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2069, level: 5" node_number="2069">[191] arXiv:2112.05121 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2070, level: 5" node_number="2070"> <div class="valid" valid="valid" title="valid: True, node: 2071, level: 6" node_number="2071"> <div class="valid" valid="valid" title="valid: True, node: 2072, level: 7" node_number="2072"> Title: Self-Supervised Keypoint Discovery in Behavioral Videos </div> <div class="valid" valid="valid" title="valid: True, node: 2073, level: 7" node_number="2073"> Authors: Jennifer J. Sun, Serim Ryou, <a class="valid" valid="valid" title="valid: True, node: 2074, level: 8" node_number="2074">Roni Goldshmid</a>, <a class="valid" valid="valid" title="valid: True, node: 2075, level: 8" node_number="2075">Brandon Weissbourd</a>, <a class="valid" valid="valid" title="valid: True, node: 2076, level: 8" node_number="2076">John Dabiri</a>, <a class="valid" valid="valid" title="valid: True, node: 2077, level: 8" node_number="2077">David J. Anderson</a>, <a class="valid" valid="valid" title="valid: True, node: 2078, level: 8" node_number="2078">Ann Kennedy</a>, <a class="valid" valid="valid" title="valid: True, node: 2079, level: 8" node_number="2079">Yisong Yue</a>, <a class="valid" valid="valid" title="valid: True, node: 2080, level: 8" node_number="2080">Pietro Perona</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2081, level: 7" node_number="2081"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2082, level: 7" node_number="2082">We propose a method for learning the posture and structure of agents from unlabelled behavioral videos. Starting from the observation that behaving agents are generally the main sources of movement in behavioral videos, our method uses an encoder-decoder architecture with a geometric bottleneck to reconstruct the difference between video frames. By focusing only on regions of movement, our approach works directly on input videos without requiring manual annotations, such as keypoints or bounding boxes. Experiments on a variety of agent types (mouse, fly, human, jellyfish, and trees) demonstrate the generality of our approach and reveal that our discovered keypoints represent semantically meaningful body parts, which achieve state-of-the-art performance on keypoint regression among self-supervised methods. Additionally, our discovered keypoints achieve comparable performance to supervised keypoints on downstream tasks, such as behavior classification, suggesting that our method can dramatically reduce the cost of model training vis-a-vis supervised methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2083, level: 5" node_number="2083">[192] arXiv:2112.05124 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2084, level: 5" node_number="2084"> <div class="valid" valid="valid" title="valid: True, node: 2085, level: 6" node_number="2085"> <div class="valid" valid="valid" title="valid: True, node: 2086, level: 7" node_number="2086"> Title: Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation </div> <div class="valid" valid="valid" title="valid: True, node: 2087, level: 7" node_number="2087"> Authors: Anthony Simeonov, <a class="valid" valid="valid" title="valid: True, node: 2088, level: 8" node_number="2088">Yilun Du</a>, <a class="valid" valid="valid" title="valid: True, node: 2089, level: 8" node_number="2089">Andrea Tagliasacchi</a>, <a class="valid" valid="valid" title="valid: True, node: 2090, level: 8" node_number="2090">Joshua B. Tenenbaum</a>, <a class="valid" valid="valid" title="valid: True, node: 2091, level: 8" node_number="2091">Alberto Rodriguez</a>, <a class="valid" valid="valid" title="valid: True, node: 2092, level: 8" node_number="2092">Pulkit Agrawal</a>, <a class="valid" valid="valid" title="valid: True, node: 2093, level: 8" node_number="2093">Vincent Sitzmann</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2094, level: 7" node_number="2094"> Comments: Website: <a class="valid" valid="valid" title="valid: True, node: 2095, level: 8" node_number="2095">this https URL</a> First two authors contributed equally (order determined by coin flip), last two authors equal advising </div> <div class="valid" valid="valid" title="valid: True, node: 2096, level: 7" node_number="2096"> Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2097, level: 7" node_number="2097">We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (5-10) demonstrations both in simulation and on a real robot. Our performance generalizes across both object instances and 6-DoF object poses, and significantly outperforms a recent baseline that relies on 2D descriptors. Project website: https://yilundu.github.io/ndf/. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2098, level: 5" node_number="2098">[193] arXiv:2112.05125 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2099, level: 5" node_number="2099"> <div class="valid" valid="valid" title="valid: True, node: 2100, level: 6" node_number="2100"> <div class="valid" valid="valid" title="valid: True, node: 2101, level: 7" node_number="2101"> Title: Transferring BERT-like Transformers' Knowledge for Authorship Verification </div> <div class="valid" valid="valid" title="valid: True, node: 2102, level: 7" node_number="2102"> Authors: Andrei Manolache, <a class="valid" valid="valid" title="valid: True, node: 2103, level: 8" node_number="2103">Florin Brad</a>, <a class="valid" valid="valid" title="valid: True, node: 2104, level: 8" node_number="2104">Elena Burceanu</a>, <a class="valid" valid="valid" title="valid: True, node: 2105, level: 8" node_number="2105">Antonio Barbalau</a>, <a class="valid" valid="valid" title="valid: True, node: 2106, level: 8" node_number="2106">Radu Ionescu</a>, <a class="valid" valid="valid" title="valid: True, node: 2107, level: 8" node_number="2107">Marius Popescu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2108, level: 7" node_number="2108"> Comments: 16 pages, 3 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2109, level: 7" node_number="2109"> Subjects: Computation and Language (cs.CL) </div> <p class="valid" valid="valid" title="valid: True, node: 2110, level: 7" node_number="2110">The task of identifying the author of a text spans several decades and was tackled using linguistics, statistics, and, more recently, machine learning. Inspired by the impressive performance gains across a broad range of natural language processing tasks and by the recent availability of the PAN large-scale authorship dataset, we first study the effectiveness of several BERT-like transformers for the task of authorship verification. Such models prove to achieve very high scores consistently. Next, we empirically show that they focus on topical clues rather than on author writing style characteristics, taking advantage of existing biases in the dataset. To address this problem, we provide new splits for PAN-2020, where training and test data are sampled from disjoint topics or authors. Finally, we introduce DarkReddit, a dataset with a different input data distribution. We further use it to analyze the domain generalization performance of models in a low-data regime and how performance varies when using the proposed PAN-2020 splits for fine-tuning. We show that those splits can enhance the models' capability to transfer knowledge over a new, significantly different dataset. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2111, level: 5" node_number="2111">[194] arXiv:2112.05126 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2112, level: 5" node_number="2112"> <div class="valid" valid="valid" title="valid: True, node: 2113, level: 6" node_number="2113"> <div class="valid" valid="valid" title="valid: True, node: 2114, level: 7" node_number="2114"> Title: IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo </div> <div class="valid" valid="valid" title="valid: True, node: 2115, level: 7" node_number="2115"> Authors: Fangjinhua Wang, <a class="valid" valid="valid" title="valid: True, node: 2116, level: 8" node_number="2116">Silvano Galliani</a>, <a class="valid" valid="valid" title="valid: True, node: 2117, level: 8" node_number="2117">Christoph Vogel</a>, <a class="valid" valid="valid" title="valid: True, node: 2118, level: 8" node_number="2118">Marc Pollefeys</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2119, level: 7" node_number="2119"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2120, level: 7" node_number="2120">We present IterMVS, a new data-driven method for high-resolution multi-view stereo. We propose a novel GRU-based estimator that encodes pixel-wise probability distributions of depth in its hidden state. Ingesting multi-scale matching information, our model refines these distributions over multiple iterations and infers depth and confidence. To extract the depth maps, we combine traditional classification and regression in a novel manner. We verify the efficiency and effectiveness of our method on DTU, TanksTemples and ETH3D. While being the most efficient method in both memory and run-time, our model achieves competitive performance on DTU and better generalization ability on TanksTemples as well as ETH3D than most state-of-the-art methods. Code is available at https://github.com/FangjinhuaWang/IterMVS. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2121, level: 5" node_number="2121">[195] arXiv:2112.05129 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2122, level: 5" node_number="2122"> <div class="valid" valid="valid" title="valid: True, node: 2123, level: 6" node_number="2123"> <div class="valid" valid="valid" title="valid: True, node: 2124, level: 7" node_number="2124"> Title: Assistive Tele-op: Leveraging Transformers to Collect Robotic Task Demonstrations </div> <div class="valid" valid="valid" title="valid: True, node: 2125, level: 7" node_number="2125"> Authors: Henry M. Clever, <a class="valid" valid="valid" title="valid: True, node: 2126, level: 8" node_number="2126">Ankur Handa</a>, <a class="valid" valid="valid" title="valid: True, node: 2127, level: 8" node_number="2127">Hammad Mazhar</a>, <a class="valid" valid="valid" title="valid: True, node: 2128, level: 8" node_number="2128">Kevin Parker</a>, <a class="valid" valid="valid" title="valid: True, node: 2129, level: 8" node_number="2129">Omer Shapira</a>, <a class="valid" valid="valid" title="valid: True, node: 2130, level: 8" node_number="2130">Qian Wan</a>, <a class="valid" valid="valid" title="valid: True, node: 2131, level: 8" node_number="2131">Yashraj Narang</a>, <a class="valid" valid="valid" title="valid: True, node: 2132, level: 8" node_number="2132">Iretiayo Akinola</a>, <a class="valid" valid="valid" title="valid: True, node: 2133, level: 8" node_number="2133">Maya Cakmak</a>, <a class="valid" valid="valid" title="valid: True, node: 2134, level: 8" node_number="2134">Dieter Fox</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2135, level: 7" node_number="2135"> Comments: 9 pages, 4 figures, 1 table. NeurIPS 2021 Workshop on Robot Learning: Self-Supervised and Lifelong Learning, Virtual, Virtual </div> <div class="valid" valid="valid" title="valid: True, node: 2136, level: 7" node_number="2136"> Subjects: Robotics (cs.RO) </div> <p class="valid" valid="valid" title="valid: True, node: 2137, level: 7" node_number="2137">Sharing autonomy between robots and human operators could facilitate data collection of robotic task demonstrations to continuously improve learned models. Yet, the means to communicate intent and reason about the future are disparate between humans and robots. We present Assistive Tele-op, a virtual reality (VR) system for collecting robot task demonstrations that displays an autonomous trajectory forecast to communicate the robot's intent. As the robot moves, the user can switch between autonomous and manual control when desired. This allows users to collect task demonstrations with both a high success rate and with greater ease than manual teleoperation systems. Our system is powered by transformers, which can provide a window of potential states and actions far into the future -- with almost no added computation time. A key insight is that human intent can be injected at any location within the transformer sequence if the user decides that the model-predicted actions are inappropriate. At every time step, the user can (1) do nothing and allow autonomous operation to continue while observing the robot's future plan sequence, or (2) take over and momentarily prescribe a different set of actions to nudge the model back on track. We host the videos and other supplementary material at https://sites.google.com/view/assistive-teleop. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2138, level: 5" node_number="2138">[196] arXiv:2112.05130 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2139, level: 5" node_number="2139"> <div class="valid" valid="valid" title="valid: True, node: 2140, level: 6" node_number="2140"> <div class="valid" valid="valid" title="valid: True, node: 2141, level: 7" node_number="2141"> Title: Multimodal Conditional Image Synthesis with Product-of-Experts GANs </div> <div class="valid" valid="valid" title="valid: True, node: 2142, level: 7" node_number="2142"> Authors: Xun Huang, <a class="valid" valid="valid" title="valid: True, node: 2143, level: 8" node_number="2143">Arun Mallya</a>, <a class="valid" valid="valid" title="valid: True, node: 2144, level: 8" node_number="2144">Ting-Chun Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2145, level: 8" node_number="2145">Ming-Yu Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2146, level: 7" node_number="2146"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2147, level: 7" node_number="2147">Existing conditional image synthesis frameworks generate images based on user inputs in a single modality, such as text, segmentation, sketch, or style reference. They are often unable to leverage multimodal user inputs when available, which reduces their practicality. To address this limitation, we propose the Product-of-Experts Generative Adversarial Networks (PoE-GAN) framework, which can synthesize images conditioned on multiple input modalities or any subset of them, even the empty set. PoE-GAN consists of a product-of-experts generator and a multimodal multiscale projection discriminator. Through our carefully designed training scheme, PoE-GAN learns to synthesize images with high quality and diversity. Besides advancing the state of the art in multimodal conditional image synthesis, PoE-GAN also outperforms the best existing unimodal conditional image synthesis approaches when tested in the unimodal setting. The project website is available at https://deepimagination.github.io/PoE-GAN . </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2148, level: 5" node_number="2148">[197] arXiv:2112.05131 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2149, level: 5" node_number="2149"> <div class="valid" valid="valid" title="valid: True, node: 2150, level: 6" node_number="2150"> <div class="valid" valid="valid" title="valid: True, node: 2151, level: 7" node_number="2151"> Title: Plenoxels: Radiance Fields without Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 2152, level: 7" node_number="2152"> Authors: Alex Yu, <a class="valid" valid="valid" title="valid: True, node: 2153, level: 8" node_number="2153">Sara Fridovich-Keil</a>, <a class="valid" valid="valid" title="valid: True, node: 2154, level: 8" node_number="2154">Matthew Tancik</a>, <a class="valid" valid="valid" title="valid: True, node: 2155, level: 8" node_number="2155">Qinhong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2156, level: 8" node_number="2156">Benjamin Recht</a>, <a class="valid" valid="valid" title="valid: True, node: 2157, level: 8" node_number="2157">Angjoo Kanazawa</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2158, level: 7" node_number="2158"> Comments: For video and code, please see <a class="valid" valid="valid" title="valid: True, node: 2159, level: 8" node_number="2159">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2160, level: 7" node_number="2160"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p class="valid" valid="valid" title="valid: True, node: 2161, level: 7" node_number="2161">We introduce Plenoxels (plenoptic voxels), a system for photorealistic view synthesis. Plenoxels represent a scene as a sparse 3D grid with spherical harmonics. This representation can be optimized from calibrated images via gradient methods and regularization without any neural components. On standard, benchmark tasks, Plenoxels are optimized two orders of magnitude faster than Neural Radiance Fields with no loss in visual quality. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2162, level: 5" node_number="2162">[198] arXiv:2112.05132 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2163, level: 5" node_number="2163"> <div class="valid" valid="valid" title="valid: True, node: 2164, level: 6" node_number="2164"> <div class="valid" valid="valid" title="valid: True, node: 2165, level: 7" node_number="2165"> Title: Spatio-temporal Relation Modeling for Few-shot Action Recognition </div> <div class="valid" valid="valid" title="valid: True, node: 2166, level: 7" node_number="2166"> Authors: Anirudh Thatipelli, <a class="valid" valid="valid" title="valid: True, node: 2167, level: 8" node_number="2167">Sanath Narayan</a>, <a class="valid" valid="valid" title="valid: True, node: 2168, level: 8" node_number="2168">Salman Khan</a>, <a class="valid" valid="valid" title="valid: True, node: 2169, level: 8" node_number="2169">Rao Muhammad Anwer</a>, <a class="valid" valid="valid" title="valid: True, node: 2170, level: 8" node_number="2170">Fahad Shahbaz Khan</a>, <a class="valid" valid="valid" title="valid: True, node: 2171, level: 8" node_number="2171">Bernard Ghanem</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2172, level: 7" node_number="2172"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2173, level: 7" node_number="2173">We propose a novel few-shot action recognition framework, STRM, which enhances class-specific feature discriminability while simultaneously learning higher-order temporal representations. The focus of our approach is a novel spatio-temporal enrichment module that aggregates spatial and temporal contexts with dedicated local patch-level and global frame-level feature enrichment sub-modules. Local patch-level enrichment captures the appearance-based characteristics of actions. On the other hand, global frame-level enrichment explicitly encodes the broad temporal context, thereby capturing the relevant object features over time. The resulting spatio-temporally enriched representations are then utilized to learn the relational matching between query and support action sub-sequences. We further introduce a query-class similarity classifier on the patch-level enriched features to enhance class-specific feature discriminability by reinforcing the feature learning at different stages in the proposed framework. Experiments are performed on four few-shot action recognition benchmarks: Kinetics, SSv2, HMDB51 and UCF101. Our extensive ablation study reveals the benefits of the proposed contributions. Furthermore, our approach sets a new state-of-the-art on all four benchmarks. On the challenging SSv2 benchmark, our approach achieves an absolute gain of 3.5% in classification accuracy, as compared to the best existing method in the literature. Our code and models will be publicly released. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2174, level: 5" node_number="2174">[199] arXiv:2112.05134 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2175, level: 5" node_number="2175"> <div class="valid" valid="valid" title="valid: True, node: 2176, level: 6" node_number="2176"> <div class="valid" valid="valid" title="valid: True, node: 2177, level: 7" node_number="2177"> Title: A Shared Representation for Photorealistic Driving Simulators </div> <div class="valid" valid="valid" title="valid: True, node: 2178, level: 7" node_number="2178"> Authors: Saeed Saadatnejad, <a class="valid" valid="valid" title="valid: True, node: 2179, level: 8" node_number="2179">Siyuan Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2180, level: 8" node_number="2180">Taylor Mordan</a>, <a class="valid" valid="valid" title="valid: True, node: 2181, level: 8" node_number="2181">Alexandre Alahi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2182, level: 7" node_number="2182"> Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS) </div> <div class="valid" valid="valid" title="valid: True, node: 2183, level: 7" node_number="2183"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2184, level: 7" node_number="2184">A powerful simulator highly decreases the need for real-world tests when training and evaluating autonomous vehicles. Data-driven simulators flourished with the recent advancement of conditional Generative Adversarial Networks (cGANs), providing high-fidelity images. The main challenge is synthesizing photorealistic images while following given constraints. In this work, we propose to improve the quality of generated images by rethinking the discriminator architecture. The focus is on the class of problems where images are generated given semantic inputs, such as scene segmentation maps or human body poses. We build on successful cGAN models to propose a new semantically-aware discriminator that better guides the generator. We aim to learn a shared latent representation that encodes enough information to jointly do semantic segmentation, content reconstruction, along with a coarse-to-fine grained adversarial reasoning. The achieved improvements are generic and simple enough to be applied to any architecture of conditional image synthesis. We demonstrate the strength of our method on the scene, building, and human synthesis tasks across three different datasets. The code is available at https://github.com/vita-epfl/SemDisc. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2185, level: 5" node_number="2185">[200] arXiv:2112.05135 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2186, level: 5" node_number="2186"> <div class="valid" valid="valid" title="valid: True, node: 2187, level: 6" node_number="2187"> <div class="valid" valid="valid" title="valid: True, node: 2188, level: 7" node_number="2188"> Title: PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures </div> <div class="valid" valid="valid" title="valid: True, node: 2189, level: 7" node_number="2189"> Authors: Dan Hendrycks, <a class="valid" valid="valid" title="valid: True, node: 2190, level: 8" node_number="2190">Andy Zou</a>, <a class="valid" valid="valid" title="valid: True, node: 2191, level: 8" node_number="2191">Mantas Mazeika</a>, <a class="valid" valid="valid" title="valid: True, node: 2192, level: 8" node_number="2192">Leonard Tang</a>, <a class="valid" valid="valid" title="valid: True, node: 2193, level: 8" node_number="2193">Dawn Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2194, level: 8" node_number="2194">Jacob Steinhardt</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2195, level: 7" node_number="2195"> Comments: Code and models are available at <a class="valid" valid="valid" title="valid: True, node: 2196, level: 8" node_number="2196">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2197, level: 7" node_number="2197"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2198, level: 7" node_number="2198">In real-world applications of machine learning, reliable and safe systems must consider measures of performance beyond standard test set accuracy. These other goals include out-of-distribution (OOD) robustness, prediction consistency, resilience to adversaries, calibrated uncertainty estimates, and the ability to detect anomalous inputs. However, improving performance towards these goals is often a balancing act that today's methods cannot achieve without sacrificing performance on other safety axes. For instance, adversarial training improves adversarial robustness but sharply degrades other classifier performance metrics. Similarly, strong data augmentation and regularization techniques often improve OOD robustness but harm anomaly detection, raising the question of whether a Pareto improvement on all existing safety measures is possible. To meet this challenge, we design a new data augmentation strategy utilizing the natural structural complexity of pictures such as fractals, which outperforms numerous baselines, is near Pareto-optimal, and roundly improves safety measures. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2199, level: 5" node_number="2199">[201] arXiv:2112.05136 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2200, level: 5" node_number="2200"> <div class="valid" valid="valid" title="valid: True, node: 2201, level: 6" node_number="2201"> <div class="valid" valid="valid" title="valid: True, node: 2202, level: 7" node_number="2202"> Title: PTR: A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning </div> <div class="valid" valid="valid" title="valid: True, node: 2203, level: 7" node_number="2203"> Authors: Yining Hong, <a class="valid" valid="valid" title="valid: True, node: 2204, level: 8" node_number="2204">Li Yi</a>, <a class="valid" valid="valid" title="valid: True, node: 2205, level: 8" node_number="2205">Joshua B. Tenenbaum</a>, <a class="valid" valid="valid" title="valid: True, node: 2206, level: 8" node_number="2206">Antonio Torralba</a>, <a class="valid" valid="valid" title="valid: True, node: 2207, level: 8" node_number="2207">Chuang Gan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2208, level: 7" node_number="2208"> Comments: NeurIPS 2021. Project page: <a class="valid" valid="valid" title="valid: True, node: 2209, level: 8" node_number="2209">this http URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2210, level: 7" node_number="2210"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2211, level: 7" node_number="2211">A critical aspect of human visual perception is the ability to parse visual scenes into individual objects and further into object parts, forming part-whole hierarchies. Such composite structures could induce a rich set of semantic concepts and relations, thus playing an important role in the interpretation and organization of visual signals as well as for the generalization of visual perception and reasoning. However, existing visual reasoning benchmarks mostly focus on objects rather than parts. Visual reasoning based on the full part-whole hierarchy is much more challenging than object-centric reasoning due to finer-grained concepts, richer geometry relations, and more complex physics. Therefore, to better serve for part-based conceptual, relational and physical reasoning, we introduce a new large-scale diagnostic visual reasoning dataset named PTR. PTR contains around 70k RGBD synthetic images with ground truth object and part level annotations regarding semantic instance segmentation, color attributes, spatial and geometric relationships, and certain physical properties such as stability. These images are paired with 700k machine-generated questions covering various types of reasoning types, making them a good testbed for visual reasoning models. We examine several state-of-the-art visual reasoning models on this dataset and observe that they still make many surprising mistakes in situations where humans can easily infer the correct answer. We believe this dataset will open up new opportunities for part-based reasoning. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2212, level: 5" node_number="2212">[202] arXiv:2112.05138 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2213, level: 5" node_number="2213"> <div class="valid" valid="valid" title="valid: True, node: 2214, level: 6" node_number="2214"> <div class="valid" valid="valid" title="valid: True, node: 2215, level: 7" node_number="2215"> Title: Searching Parameterized AP Loss for Object Detection </div> <div class="valid" valid="valid" title="valid: True, node: 2216, level: 7" node_number="2216"> Authors: Chenxin Tao, <a class="valid" valid="valid" title="valid: True, node: 2217, level: 8" node_number="2217">Zizhang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2218, level: 8" node_number="2218">Xizhou Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 2219, level: 8" node_number="2219">Gao Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 2220, level: 8" node_number="2220">Yong Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 2221, level: 8" node_number="2221">Jifeng Dai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2222, level: 7" node_number="2222"> Comments: Accepted by NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 2223, level: 7" node_number="2223"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2224, level: 7" node_number="2224">Loss functions play an important role in training deep-network-based object detectors. The most widely used evaluation metric for object detection is Average Precision (AP), which captures the performance of localization and classification sub-tasks simultaneously. However, due to the non-differentiable nature of the AP metric, traditional object detectors adopt separate differentiable losses for the two sub-tasks. Such a mis-alignment issue may well lead to performance degradation. To address this, existing works seek to design surrogate losses for the AP metric manually, which requires expertise and may still be sub-optimal. In this paper, we propose Parameterized AP Loss, where parameterized functions are introduced to substitute the non-differentiable components in the AP calculation. Different AP approximations are thus represented by a family of parameterized functions in a unified formula. Automatic parameter search algorithm is then employed to search for the optimal parameters. Extensive experiments on the COCO benchmark with three different object detectors (i.e., RetinaNet, Faster R-CNN, and Deformable DETR) demonstrate that the proposed Parameterized AP Loss consistently outperforms existing handcrafted losses. Code is released at https://github.com/fundamentalvision/Parameterized-AP-Loss. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2225, level: 5" node_number="2225">[203] arXiv:2112.05139 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2226, level: 5" node_number="2226"> <div class="valid" valid="valid" title="valid: True, node: 2227, level: 6" node_number="2227"> <div class="valid" valid="valid" title="valid: True, node: 2228, level: 7" node_number="2228"> Title: CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields </div> <div class="valid" valid="valid" title="valid: True, node: 2229, level: 7" node_number="2229"> Authors: Can Wang, <a class="valid" valid="valid" title="valid: True, node: 2230, level: 8" node_number="2230">Menglei Chai</a>, <a class="valid" valid="valid" title="valid: True, node: 2231, level: 8" node_number="2231">Mingming He</a>, <a class="valid" valid="valid" title="valid: True, node: 2232, level: 8" node_number="2232">Dongdong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2233, level: 8" node_number="2233">Jing Liao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2234, level: 7" node_number="2234"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p class="valid" valid="valid" title="valid: True, node: 2235, level: 7" node_number="2235">We present CLIP-NeRF, a multi-modal 3D object manipulation method for neural radiance fields (NeRF). By leveraging the joint language-image embedding space of the recent Contrastive Language-Image Pre-Training (CLIP) model, we propose a unified framework that allows manipulating NeRF in a user-friendly way, using either a short text prompt or an exemplar image. Specifically, to combine the novel view synthesis capability of NeRF and the controllable manipulation ability of latent representations from generative models, we introduce a disentangled conditional NeRF architecture that allows individual control over both shape and appearance. This is achieved by performing the shape conditioning via applying a learned deformation field to the positional encoding and deferring color conditioning to the volumetric rendering stage. To bridge this disentangled latent representation to the CLIP embedding, we design two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing. The mappers are trained with a CLIP-based matching loss to ensure the manipulation accuracy. Furthermore, we propose an inverse optimization method that accurately projects an input image to the latent codes for manipulation to enable editing on real images. We evaluate our approach by extensive experiments on a variety of text prompts and exemplar images and also provide an intuitive interface for interactive editing. Our implementation is available at https://cassiepython.github.io/clipnerf/ </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2236, level: 5" node_number="2236">[204] arXiv:2112.05140 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2237, level: 5" node_number="2237"> <div class="valid" valid="valid" title="valid: True, node: 2238, level: 6" node_number="2238"> <div class="valid" valid="valid" title="valid: True, node: 2239, level: 7" node_number="2239"> Title: Neural Radiance Fields for Outdoor Scene Relighting </div> <div class="valid" valid="valid" title="valid: True, node: 2240, level: 7" node_number="2240"> Authors: Viktor Rudnev, <a class="valid" valid="valid" title="valid: True, node: 2241, level: 8" node_number="2241">Mohamed Elgharib</a>, <a class="valid" valid="valid" title="valid: True, node: 2242, level: 8" node_number="2242">William Smith</a>, <a class="valid" valid="valid" title="valid: True, node: 2243, level: 8" node_number="2243">Lingjie Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 2244, level: 8" node_number="2244">Vladislav Golyanik</a>, <a class="valid" valid="valid" title="valid: True, node: 2245, level: 8" node_number="2245">Christian Theobalt</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2246, level: 7" node_number="2246"> Comments: 13 pages, 8 figures, 2 tables; project web page: <a class="valid" valid="valid" title="valid: True, node: 2247, level: 8" node_number="2247">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2248, level: 7" node_number="2248"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p class="valid" valid="valid" title="valid: True, node: 2249, level: 7" node_number="2249">Photorealistic editing of outdoor scenes from photographs requires a profound understanding of the image formation process and an accurate estimation of the scene geometry, reflectance and illumination. A delicate manipulation of the lighting can then be performed while keeping the scene albedo and geometry unaltered. We present NeRF-OSR, i.e., the first approach for outdoor scene relighting based on neural radiance fields. In contrast to the prior art, our technique allows simultaneous editing of both scene illumination and camera viewpoint using only a collection of outdoor photos shot in uncontrolled settings. Moreover, it enables direct control over the scene illumination, as defined through a spherical harmonics model. It also includes a dedicated network for shadow reproduction, which is crucial for high-quality outdoor scene relighting. To evaluate the proposed method, we collect a new benchmark dataset of several outdoor sites, where each site is photographed from multiple viewpoints and at different timings. For each timing, a 360 degrees environment map is captured together with a colour-calibration chequerboard to allow accurate numerical evaluations on real data against ground truth. Comparisons against state of the art show that NeRF-OSR enables controllable lighting and viewpoint editing at higher quality and with realistic self-shadowing reproduction. Our method and the dataset will be made publicly available at https://4dqv.mpi-inf.mpg.de/NeRF-OSR/. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2250, level: 5" node_number="2250">[205] arXiv:2112.05141 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2251, level: 5" node_number="2251"> <div class="valid" valid="valid" title="valid: True, node: 2252, level: 6" node_number="2252"> <div class="valid" valid="valid" title="valid: True, node: 2253, level: 7" node_number="2253"> Title: Exploring the Equivalence of Siamese Self-Supervised Learning via A Unified Gradient Framework </div> <div class="valid" valid="valid" title="valid: True, node: 2254, level: 7" node_number="2254"> Authors: Chenxin Tao, <a class="valid" valid="valid" title="valid: True, node: 2255, level: 8" node_number="2255">Honghui Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2256, level: 8" node_number="2256">Xizhou Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 2257, level: 8" node_number="2257">Jiahua Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 2258, level: 8" node_number="2258">Shiji Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2259, level: 8" node_number="2259">Gao Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 2260, level: 8" node_number="2260">Jifeng Dai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2261, level: 7" node_number="2261"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2262, level: 7" node_number="2262">Self-supervised learning has shown its great potential to extract powerful visual representations without human annotations. Various works are proposed to deal with self-supervised learning from different perspectives: (1) contrastive learning methods (e.g., MoCo, SimCLR) utilize both positive and negative samples to guide the training direction; (2) asymmetric network methods (e.g., BYOL, SimSiam) get rid of negative samples via the introduction of a predictor network and the stop-gradient operation; (3) feature decorrelation methods (e.g., Barlow Twins, VICReg) instead aim to reduce the redundancy between feature dimensions. These methods appear to be quite different in the designed loss functions from various motivations. The final accuracy numbers also vary, where different networks and tricks are utilized in different works. In this work, we demonstrate that these methods can be unified into the same form. Instead of comparing their loss functions, we derive a unified formula through gradient analysis. Furthermore, we conduct fair and detailed experiments to compare their performances. It turns out that there is little gap between these methods, and the use of momentum encoder is the key factor to boost performance. From this unified framework, we propose UniGrad, a simple but effective gradient form for self-supervised learning. It does not require a memory bank or a predictor network, but can still achieve state-of-the-art performance and easily adopt other training strategies. Extensive experiments on linear evaluation and many downstream tasks also show its effectiveness. Code shall be released. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2263, level: 5" node_number="2263">[206] arXiv:2112.05142 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2264, level: 5" node_number="2264"> <div class="valid" valid="valid" title="valid: True, node: 2265, level: 6" node_number="2265"> <div class="valid" valid="valid" title="valid: True, node: 2266, level: 7" node_number="2266"> Title: HairCLIP: Design Your Hair by Text and Reference Image </div> <div class="valid" valid="valid" title="valid: True, node: 2267, level: 7" node_number="2267"> Authors: Tianyi Wei, <a class="valid" valid="valid" title="valid: True, node: 2268, level: 8" node_number="2268">Dongdong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2269, level: 8" node_number="2269">Wenbo Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 2270, level: 8" node_number="2270">Jing Liao</a>, <a class="valid" valid="valid" title="valid: True, node: 2271, level: 8" node_number="2271">Zhentao Tan</a>, <a class="valid" valid="valid" title="valid: True, node: 2272, level: 8" node_number="2272">Lu Yuan</a>, <a class="valid" valid="valid" title="valid: True, node: 2273, level: 8" node_number="2273">Weiming Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2274, level: 8" node_number="2274">Nenghai Yu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2275, level: 7" node_number="2275"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> <p class="valid" valid="valid" title="valid: True, node: 2276, level: 7" node_number="2276">Hair editing is an interesting and challenging problem in computer vision and graphics. Many existing methods require well-drawn sketches or masks as conditional inputs for editing, however these interactions are neither straightforward nor efficient. In order to free users from the tedious interaction process, this paper proposes a new hair editing interaction mode, which enables manipulating hair attributes individually or jointly based on the texts or reference images provided by users. For this purpose, we encode the image and text conditions in a shared embedding space and propose a unified hair editing framework by leveraging the powerful image text representation capability of the Contrastive Language-Image Pre-Training (CLIP) model. With the carefully designed network structures and loss functions, our framework can perform high-quality hair editing in a disentangled manner. Extensive experiments demonstrate the superiority of our approach in terms of manipulation accuracy, visual realism of editing results, and irrelevant attribute preservation. Project repo is https://github.com/wty-ustc/HairCLIP. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2277, level: 5" node_number="2277">[207] arXiv:2112.05143 [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2278, level: 5" node_number="2278"> <div class="valid" valid="valid" title="valid: True, node: 2279, level: 6" node_number="2279"> <div class="valid" valid="valid" title="valid: True, node: 2280, level: 7" node_number="2280"> Title: GAN-Supervised Dense Visual Alignment </div> <div class="valid" valid="valid" title="valid: True, node: 2281, level: 7" node_number="2281"> Authors: William Peebles, <a class="valid" valid="valid" title="valid: True, node: 2282, level: 8" node_number="2282">Jun-Yan Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 2283, level: 8" node_number="2283">Richard Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2284, level: 8" node_number="2284">Antonio Torralba</a>, <a class="valid" valid="valid" title="valid: True, node: 2285, level: 8" node_number="2285">Alexei Efros</a>, <a class="valid" valid="valid" title="valid: True, node: 2286, level: 8" node_number="2286">Eli Shechtman</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2287, level: 7" node_number="2287"> Comments: Code available at <a class="valid" valid="valid" title="valid: True, node: 2288, level: 8" node_number="2288">this https URL</a> . Project page and videos available at <a class="valid" valid="valid" title="valid: True, node: 2289, level: 8" node_number="2289">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2290, level: 7" node_number="2290"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2291, level: 7" node_number="2291">We propose GAN-Supervised Learning, a framework for learning discriminative models and their GAN-generated training data jointly end-to-end. We apply our framework to the dense visual alignment problem. Inspired by the classic Congealing method, our GANgealing algorithm trains a Spatial Transformer to map random samples from a GAN trained on unaligned data to a common, jointly-learned target mode. We show results on eight datasets, all of which demonstrate our method successfully aligns complex data and discovers dense correspondences. GANgealing significantly outperforms past self-supervised correspondence algorithms and performs on-par with (and sometimes exceeds) state-of-the-art supervised correspondence algorithms on several datasets -- without making use of any correspondence supervision or data augmentation and despite being trained exclusively on GAN-generated data. For precise correspondence, we improve upon state-of-the-art supervised methods by as much as $3imes$. We show applications of our method for augmented reality, image editing and automated pre-processing of image datasets for downstream GAN training. </p> </div> </dd> </dl> <h3 class="valid" valid="valid" title="valid: True, node: 2292, level: 4" node_number="2292">Cross-lists for Fri, 10 Dec 21</h3> <dl class="valid" valid="valid" title="valid: True, node: 2293, level: 4" node_number="2293"> <dt class="valid" valid="valid" title="valid: True, node: 2294, level: 5" node_number="2294">[208] arXiv:2112.04489 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2295, level: 5" node_number="2295"> <div class="valid" valid="valid" title="valid: True, node: 2296, level: 6" node_number="2296"> <div class="valid" valid="valid" title="valid: True, node: 2297, level: 7" node_number="2297"> Title: Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning </div> <div class="valid" valid="valid" title="valid: True, node: 2298, level: 7" node_number="2298"> Authors: Alessa Hering, <a class="valid" valid="valid" title="valid: True, node: 2299, level: 8" node_number="2299">Lasse Hansen</a>, <a class="valid" valid="valid" title="valid: True, node: 2300, level: 8" node_number="2300">Tony C. W. Mok</a>, <a class="valid" valid="valid" title="valid: True, node: 2301, level: 8" node_number="2301">Albert C. S. Chung</a>, <a class="valid" valid="valid" title="valid: True, node: 2302, level: 8" node_number="2302">Hanna Siebert</a>, <a class="valid" valid="valid" title="valid: True, node: 2303, level: 8" node_number="2303">Stephanie H&#228;ger</a>, <a class="valid" valid="valid" title="valid: True, node: 2304, level: 8" node_number="2304">Annkristin Lange</a>, <a class="valid" valid="valid" title="valid: True, node: 2305, level: 8" node_number="2305">Sven Kuckertz</a>, <a class="valid" valid="valid" title="valid: True, node: 2306, level: 8" node_number="2306">Stefan Heldmann</a>, <a class="valid" valid="valid" title="valid: True, node: 2307, level: 8" node_number="2307">Wei Shao</a>, <a class="valid" valid="valid" title="valid: True, node: 2308, level: 8" node_number="2308">Sulaiman Vesal</a>, <a class="valid" valid="valid" title="valid: True, node: 2309, level: 8" node_number="2309">Mirabela Rusu</a>, <a class="valid" valid="valid" title="valid: True, node: 2310, level: 8" node_number="2310">Geoffrey Sonn</a>, <a class="valid" valid="valid" title="valid: True, node: 2311, level: 8" node_number="2311">Th&#233;o Estienne</a>, <a class="valid" valid="valid" title="valid: True, node: 2312, level: 8" node_number="2312">Maria Vakalopoulou</a>, <a class="valid" valid="valid" title="valid: True, node: 2313, level: 8" node_number="2313">Luyi Han</a>, <a class="valid" valid="valid" title="valid: True, node: 2314, level: 8" node_number="2314">Yunzhi Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 2315, level: 8" node_number="2315">Mikael Brudfors</a>, <a class="valid" valid="valid" title="valid: True, node: 2316, level: 8" node_number="2316">Ya&#235;l Balbastre</a>, <a class="valid" valid="valid" title="valid: True, node: 2317, level: 8" node_number="2317">Samuel Joutard</a>, <a class="valid" valid="valid" title="valid: True, node: 2318, level: 8" node_number="2318">Marc Modat</a>, <a class="valid" valid="valid" title="valid: True, node: 2319, level: 8" node_number="2319">Gal Lifshitz</a>, <a class="valid" valid="valid" title="valid: True, node: 2320, level: 8" node_number="2320">Dan Raviv</a>, <a class="valid" valid="valid" title="valid: True, node: 2321, level: 8" node_number="2321">Jinxin Lv</a>, <a class="valid" valid="valid" title="valid: True, node: 2322, level: 8" node_number="2322">Qiang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2323, level: 8" node_number="2323">Vincent Jaouen</a>, <a class="valid" valid="valid" title="valid: True, node: 2324, level: 8" node_number="2324">Dimitris Visvikis</a>, <a class="valid" valid="valid" title="valid: True, node: 2325, level: 8" node_number="2325">Constance Fourcade</a>, <a class="valid" valid="valid" title="valid: True, node: 2326, level: 8" node_number="2326">Mathieu Rubeaux</a>, <a class="valid" valid="valid" title="valid: True, node: 2327, level: 8" node_number="2327">Wentao Pan</a>, <a class="valid" valid="valid" title="valid: True, node: 2328, level: 8" node_number="2328">Zhe Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 2329, level: 8" node_number="2329">Bailiang Jian</a>, <a class="valid" valid="valid" title="valid: True, node: 2330, level: 8" node_number="2330">Francesca De Benetti</a>, <a class="valid" valid="valid" title="valid: True, node: 2331, level: 8" node_number="2331">Marek Wodzinski</a>, <a class="valid" valid="valid" title="valid: True, node: 2332, level: 8" node_number="2332">Niklas Gunnarsson</a>, <a class="valid" valid="valid" title="valid: True, node: 2333, level: 8" node_number="2333">Huaqi Qiu</a>, <a class="valid" valid="valid" title="valid: True, node: 2334, level: 8" node_number="2334">Zeju Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2335, level: 8" node_number="2335">Christoph Gro&#223;br&#246;hmer</a>, <a class="valid" valid="valid" title="valid: True, node: 2336, level: 8" node_number="2336">Andrew Hoopes</a>, <a class="valid" valid="valid" title="valid: True, node: 2337, level: 8" node_number="2337">Ingerid Reinertsen</a>, <a class="valid" valid="valid" title="valid: True, node: 2338, level: 8" node_number="2338">Yiming Xiao</a>, <a class="valid" valid="valid" title="valid: True, node: 2339, level: 8" node_number="2339">Bennett Landman</a>, <a class="valid" valid="valid" title="valid: True, node: 2340, level: 8" node_number="2340">Yuankai Huo</a>, <a class="valid" valid="valid" title="valid: True, node: 2341, level: 8" node_number="2341">Keelin Murphy</a>, <a class="valid" valid="valid" title="valid: True, node: 2342, level: 8" node_number="2342">Bram van Ginneken</a>, <a class="valid" valid="valid" title="valid: True, node: 2343, level: 8" node_number="2343">Adrian Dalca</a>, <a class="valid" valid="valid" title="valid: True, node: 2344, level: 8" node_number="2344">Mattias P. Heinrich</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2345, level: 7" node_number="2345"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2346, level: 7" node_number="2346">To date few studies have comprehensively compared medical image registration approaches on a wide-range of complementary clinically relevant tasks. This limits the adoption of advances in research into practice and prevents fair benchmarks across competing approaches. Many newer learning-based methods have been explored within the last five years, but the question which optimisation, architectural or metric strategy is ideally suited remains open. Learn2Reg covers a wide range of anatomies: brain, abdomen and thorax, modalities: ultrasound, CT, MRI, populations: intra- and inter-patient and levels of supervision. We established a lower entry barrier for training and validation of 3D registration, which helped us compile results of over 65 individual method submissions from more than 20 unique teams. Our complementary set of metrics, including robustness, accuracy, plausibility and speed enables unique insight into the current-state-of-the-art of medical image registration. Further analyses into transferability, bias and importance of supervision question the superiority of primarily deep learning based approaches and open exiting new research directions into hybrid methods that leverage GPU-accelerated conventional optimisation. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2347, level: 5" node_number="2347">[209] arXiv:2112.04490 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2348, level: 5" node_number="2348"> <div class="valid" valid="valid" title="valid: True, node: 2349, level: 6" node_number="2349"> <div class="valid" valid="valid" title="valid: True, node: 2350, level: 7" node_number="2350"> Title: A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms </div> <div class="valid" valid="valid" title="valid: True, node: 2351, level: 7" node_number="2351"> Authors: Huyen T. X. Nguyen, <a class="valid" valid="valid" title="valid: True, node: 2352, level: 8" node_number="2352">Sam B. Tran</a>, <a class="valid" valid="valid" title="valid: True, node: 2353, level: 8" node_number="2353">Dung B. Nguyen</a>, <a class="valid" valid="valid" title="valid: True, node: 2354, level: 8" node_number="2354">Hieu H. Pham</a>, <a class="valid" valid="valid" title="valid: True, node: 2355, level: 8" node_number="2355">Ha Q. Nguyen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2356, level: 7" node_number="2356"> Comments: Under review by IEEE EMBC </div> <div class="valid" valid="valid" title="valid: True, node: 2357, level: 7" node_number="2357"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2358, level: 7" node_number="2358">Advanced deep learning (DL) algorithms may predict the patient's risk of developing breast cancer based on the Breast Imaging Reporting and Data System (BI-RADS) and density standards. Recent studies have suggested that the combination of multi-view analysis improved the overall breast exam classification. In this paper, we propose a novel multi-view DL approach for BI-RADS and density assessment of mammograms. The proposed approach first deploys deep convolutional networks for feature extraction on each view separately. The extracted features are then stacked and fed into a Light Gradient Boosting Machine (LightGBM) classifier to predict BI-RADS and density scores. We conduct extensive experiments on both the internal mammography dataset and the public dataset Digital Database for Screening Mammography (DDSM). The experimental results demonstrate that the proposed approach outperforms the single-view classification approach on two benchmark datasets by huge margins (5% on the internal dataset and 10% on the DDSM dataset). These results highlight the vital role of combining multi-view information to improve the performance of breast cancer risk prediction. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2359, level: 5" node_number="2359">[210] arXiv:2112.04491 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2360, level: 5" node_number="2360"> <div class="valid" valid="valid" title="valid: True, node: 2361, level: 6" node_number="2361"> <div class="valid" valid="valid" title="valid: True, node: 2362, level: 7" node_number="2362"> Title: Revisiting Global Statistics Aggregation for Improving Image Restoration </div> <div class="valid" valid="valid" title="valid: True, node: 2363, level: 7" node_number="2363"> Authors: Xiaojie Chu, <a class="valid" valid="valid" title="valid: True, node: 2364, level: 8" node_number="2364">Liangyu Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2365, level: 8" node_number="2365">Chengpeng Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2366, level: 8" node_number="2366">Xin Lu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2367, level: 7" node_number="2367"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2368, level: 7" node_number="2368">Global spatial statistics, which are aggregated along entire spatial dimensions, are widely used in top-performance image restorers. For example, mean, variance in Instance Normalization (IN) which is adopted by HINet, and global average pooling (i.e. mean) in Squeeze and Excitation (SE) which is applied to MPRNet. This paper first shows that statistics aggregated on the patches-based/entire-image-based feature in the training/testing phase respectively may distribute very differently and lead to performance degradation in image restorers. It has been widely overlooked by previous works. To solve this issue, we propose a simple approach, Test-time Local Statistics Converter (TLSC), that replaces the region of statistics aggregation operation from global to local, only in the test time. Without retraining or finetuning, our approach significantly improves the image restorer's performance. In particular, by extending SE with TLSC to the state-of-the-art models, MPRNet boost by 0.65 dB in PSNR on GoPro dataset, achieves 33.31 dB, exceeds the previous best result 0.6 dB. In addition, we simply apply TLSC to the high-level vision task, i.e. semantic segmentation, and achieves competitive results. Extensive quantity and quality experiments are conducted to demonstrate TLSC solves the issue with marginal costs while significant gain. The code is available at https://github.com/megvii-research/tlsc. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2369, level: 5" node_number="2369">[211] arXiv:2112.04493 (cross-list from eess.IV) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2370, level: 5" node_number="2370"> <div class="valid" valid="valid" title="valid: True, node: 2371, level: 6" node_number="2371"> <div class="valid" valid="valid" title="valid: True, node: 2372, level: 7" node_number="2372"> Title: Binary Change Guided Hyperspectral Multiclass Change Detection </div> <div class="valid" valid="valid" title="valid: True, node: 2373, level: 7" node_number="2373"> Authors: Meiqi Hu, <a class="valid" valid="valid" title="valid: True, node: 2374, level: 8" node_number="2374">Chen Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 2375, level: 8" node_number="2375">Bo Du</a>, <a class="valid" valid="valid" title="valid: True, node: 2376, level: 8" node_number="2376">Liangpei Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2377, level: 7" node_number="2377"> Comments: 14 pages,17 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2378, level: 7" node_number="2378"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2379, level: 7" node_number="2379">Characterized by tremendous spectral information, hyperspectral image is able to detect subtle changes and discriminate various change classes for change detection. The recent research works dominated by hyperspectral binary change detection, however, cannot provide fine change classes information. And most methods incorporating spectral unmixing for hyperspectral multiclass change detection (HMCD), yet suffer from the neglection of temporal correlation and error accumulation. In this study, we proposed an unsupervised Binary Change Guided hyperspectral multiclass change detection Network (BCG-Net) for HMCD, which aims at boosting the multiclass change detection result and unmixing result with the mature binary change detection approaches. In BCG-Net, a novel partial-siamese united-unmixing module is designed for multi-temporal spectral unmixing, and a groundbreaking temporal correlation constraint directed by the pseudo-labels of binary change detection result is developed to guide the unmixing process from the perspective of change detection, encouraging the abundance of the unchanged pixels more coherent and that of the changed pixels more accurate. Moreover, an innovative binary change detection rule is put forward to deal with the problem that traditional rule is susceptible to numerical values. The iterative optimization of the spectral unmixing process and the change detection process is proposed to eliminate the accumulated errors and bias from unmixing result to change detection result. The experimental results demonstrate that our proposed BCG-Net could achieve comparative or even outstanding performance of multiclass change detection among the state-of-the-art approaches and gain better spectral unmixing results at the same time. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2380, level: 5" node_number="2380">[212] arXiv:2112.04495 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2381, level: 5" node_number="2381"> <div class="valid" valid="valid" title="valid: True, node: 2382, level: 6" node_number="2382"> <div class="valid" valid="valid" title="valid: True, node: 2383, level: 7" node_number="2383"> Title: Dynamic multi feature-class Gaussian process models </div> <div class="valid" valid="valid" title="valid: True, node: 2384, level: 7" node_number="2384"> Authors: Jean-Rassaire Fouefack, <a class="valid" valid="valid" title="valid: True, node: 2385, level: 8" node_number="2385">Bhushan Borotikar</a>, <a class="valid" valid="valid" title="valid: True, node: 2386, level: 8" node_number="2386">Marcel L&#252;thi</a>, <a class="valid" valid="valid" title="valid: True, node: 2387, level: 8" node_number="2387">Tania S. Douglas</a>, <a class="valid" valid="valid" title="valid: True, node: 2388, level: 8" node_number="2388">Val&#233;rie Burdin</a>, <a class="valid" valid="valid" title="valid: True, node: 2389, level: 8" node_number="2389">Tinashe E.M. Mutsvangwa</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2390, level: 7" node_number="2390"> Comments: 16 </div> <div class="valid" valid="valid" title="valid: True, node: 2391, level: 7" node_number="2391"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2392, level: 7" node_number="2392">In model-based medical image analysis, three features of interest are the shape of structures of interest, their relative pose, and image intensity profiles representative of some physical property. Often, these are modelled separately through statistical models by decomposing the object's features into a set of basis functions through principal geodesic analysis or principal component analysis. This study presents a statistical modelling method for automatic learning of shape, pose and intensity features in medical images which we call the Dynamic multi feature-class Gaussian process models (DMFC-GPM). A DMFC-GPM is a Gaussian process (GP)-based model with a shared latent space that encodes linear and non-linear variation. Our method is defined in a continuous domain with a principled way to represent shape, pose and intensity feature classes in a linear space, based on deformation fields. A deformation field-based metric is adapted in the method for modelling shape and intensity feature variation as well as for comparing rigid transformations (pose). Moreover, DMFC-GPMs inherit properties intrinsic to GPs including marginalisation and regression. Furthermore, they allow for adding additional pose feature variability on top of those obtained from the image acquisition process; what we term as permutation modelling. For image analysis tasks using DMFC-GPMs, we adapt Metropolis-Hastings algorithms making the prediction of features fully probabilistic. We validate the method using controlled synthetic data and we perform experiments on bone structures from CT images of the shoulder to illustrate the efficacy of the model for pose and shape feature prediction. The model performance results suggest that this new modelling paradigm is robust, accurate, accessible, and has potential applications including the management of musculoskeletal disorders and clinical decision making </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2393, level: 5" node_number="2393">[213] arXiv:2112.04499 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2394, level: 5" node_number="2394"> <div class="valid" valid="valid" title="valid: True, node: 2395, level: 6" node_number="2395"> <div class="valid" valid="valid" title="valid: True, node: 2396, level: 7" node_number="2396"> Title: Multiscale Softmax Cross Entropy for Fovea Localization on Color Fundus Photography </div> <div class="valid" valid="valid" title="valid: True, node: 2397, level: 7" node_number="2397"> Authors: Yuli Wu, <a class="valid" valid="valid" title="valid: True, node: 2398, level: 8" node_number="2398">Peter Walter</a>, <a class="valid" valid="valid" title="valid: True, node: 2399, level: 8" node_number="2399">Dorit Merhof</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2400, level: 7" node_number="2400"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2401, level: 7" node_number="2401">Fovea localization is one of the most popular tasks in ophthalmic medical image analysis, where the coordinates of the center point of the macula lutea, i.e. fovea centralis, should be calculated based on color fundus images. In this work, we treat the localization problem as a classification task, where the coordinates of the x- and y-axis are considered as the target classes. Moreover, the combination of the softmax activation function and the cross entropy loss function is modified to its multiscale variation to encourage the predicted coordinates to be located closely to the ground-truths. Based on color fundus photography images, we empirically show that the proposed multiscale softmax cross entropy yields better performance than the vanilla version and than the mean squared error loss with sigmoid activation, which provides a novel approach for coordinate regression. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2402, level: 5" node_number="2402">[214] arXiv:2112.04527 (cross-list from hep-th) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2403, level: 5" node_number="2403"> <div class="valid" valid="valid" title="valid: True, node: 2404, level: 6" node_number="2404"> <div class="valid" valid="valid" title="valid: True, node: 2405, level: 7" node_number="2405"> Title: Building Quantum Field Theories Out of Neurons </div> <div class="valid" valid="valid" title="valid: True, node: 2406, level: 7" node_number="2406"> Authors: James Halverson </div> <div class="valid" valid="valid" title="valid: True, node: 2407, level: 7" node_number="2407"> Subjects: High Energy Physics - Theory (hep-th); Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph) </div> <p class="valid" valid="valid" title="valid: True, node: 2408, level: 7" node_number="2408">An approach to field theory is studied in which fields are comprised of $N$ constituent random neurons. Gaussian theories arise in the infinite-$N$ limit when neurons are independently distributed, via the Central Limit Theorem, while interactions arise due to finite-$N$ effects or non-independently distributed neurons. Euclidean-invariant ensembles of neurons are engineered, with tunable two-point function, yielding families of Euclidean-invariant field theories. Some Gaussian, Euclidean invariant theories are reflection positive, which allows for analytic continuation to a Lorentz-invariant quantum field theory. Examples are presented that yield dual theories at infinite-$N$, but have different symmetries at finite-$N$. Landscapes of classical field configurations are determined by local maxima of parameter distributions. Predictions arise from mixed field-neuron correlators. Near-Gaussianity is exhibited at large-$N$, potentially explaining a feature of field theories in Nature. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2409, level: 5" node_number="2409">[215] arXiv:2112.04553 (cross-list from q-fin.MF) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2410, level: 5" node_number="2410"> <div class="valid" valid="valid" title="valid: True, node: 2411, level: 6" node_number="2411"> <div class="valid" valid="valid" title="valid: True, node: 2412, level: 7" node_number="2412"> Title: Recent Advances in Reinforcement Learning in Finance </div> <div class="valid" valid="valid" title="valid: True, node: 2413, level: 7" node_number="2413"> Authors: Ben Hambly, <a class="valid" valid="valid" title="valid: True, node: 2414, level: 8" node_number="2414">Renyuan Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 2415, level: 8" node_number="2415">Huining Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2416, level: 7" node_number="2416"> Comments: 60 pages, 1 figure </div> <div class="valid" valid="valid" title="valid: True, node: 2417, level: 7" node_number="2417"> Subjects: Mathematical Finance (q-fin.MF); Machine Learning (cs.LG); Computational Finance (q-fin.CP); Trading and Market Microstructure (q-fin.TR) </div> <p class="valid" valid="valid" title="valid: True, node: 2418, level: 7" node_number="2418">The rapid changes in the finance industry due to the increasing amount of data have revolutionized the techniques on data processing and data analysis and brought new theoretical and computational challenges. In contrast to classical stochastic control theory and other analytical approaches for solving financial decision-making problems that heavily reply on model assumptions, new developments from reinforcement learning (RL) are able to make full use of the large amount of financial data with fewer model assumptions and to improve decisions in complex financial environments. This survey paper aims to review the recent developments and use of RL approaches in finance. We give an introduction to Markov decision processes, which is the setting for many of the commonly used RL approaches. Various algorithms are then introduced with a focus on value and policy based methods that do not require any model assumptions. Connections are made with neural networks to extend the framework to encompass deep RL algorithms. Our survey concludes by discussing the application of these RL algorithms in a variety of decision-making problems in finance, including optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2419, level: 5" node_number="2419">[216] arXiv:2112.04586 (cross-list from quant-ph) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2420, level: 5" node_number="2420"> <div class="valid" valid="valid" title="valid: True, node: 2421, level: 6" node_number="2421"> <div class="valid" valid="valid" title="valid: True, node: 2422, level: 7" node_number="2422"> Title: Monolithic Integration of Quantum Resonant Tunneling Gate on a 22nm FD-SOI CMOS Process </div> <div class="valid" valid="valid" title="valid: True, node: 2423, level: 7" node_number="2423"> Authors: Imran Bashir, <a class="valid" valid="valid" title="valid: True, node: 2424, level: 8" node_number="2424">Dirk Leipold</a>, <a class="valid" valid="valid" title="valid: True, node: 2425, level: 8" node_number="2425">Elena Blokhina</a>, <a class="valid" valid="valid" title="valid: True, node: 2426, level: 8" node_number="2426">Mike Asker</a>, <a class="valid" valid="valid" title="valid: True, node: 2427, level: 8" node_number="2427">David Redmond</a>, <a class="valid" valid="valid" title="valid: True, node: 2428, level: 8" node_number="2428">Ali Esmailiyan</a>, <a class="valid" valid="valid" title="valid: True, node: 2429, level: 8" node_number="2429">Panagiotis Giounanlis</a>, <a class="valid" valid="valid" title="valid: True, node: 2430, level: 8" node_number="2430">Hans Haenlein</a>, <a class="valid" valid="valid" title="valid: True, node: 2431, level: 8" node_number="2431">Xuton Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 2432, level: 8" node_number="2432">Andrii Sokolov</a>, <a class="valid" valid="valid" title="valid: True, node: 2433, level: 8" node_number="2433">Dennis Andrade-Miceli</a>, <a class="valid" valid="valid" title="valid: True, node: 2434, level: 8" node_number="2434">Robert Bogdan Staszewski</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2435, level: 7" node_number="2435"> Subjects: Quantum Physics (quant-ph); Systems and Control (eess.SY) </div> <p class="valid" valid="valid" title="valid: True, node: 2436, level: 7" node_number="2436">The proliferation of quantum computing technologies has fueled the race to build a practical quantum computer. The spectrum of the innovation is wide and encompasses many aspects of this technology, such as the qubit, control and detection mechanism, cryogenic electronics, and system integration. A few of those emerging technologies are poised for successful monolithic integration of cryogenic electronics with the quantum structure where the qubits reside. In this work, we present a fully integrated Quantum Processor Unit in which the quantum core is co-located with control and detection circuits on the same die in a commercial 22-nm FD-SOI process from GlobalFoundries. The system described in this work comprises a two dimensional (2D) 240 qubits array integrated with 8 detectors and 32 injectors operating at 3K and inside a two-stage Gifford-McMahon cryo-cooler. The power consumption of each detector and injector is 1mW and 0.27mW, respectively. The control sequence is programmed into an on-chip pattern generator that acts as a command and control block for all hardware in the Quantum Processor Unit. Using the aforementioned apparatus, we performed a quantum resonant tunneling experiment on two qubits inside the 2D qubit array. With supporting lab measurements, we demonstrate the feasibility of the proposed architecture in scaling-up the existing quantum core to thousands of qubits. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2437, level: 5" node_number="2437">[217] arXiv:2112.04599 (cross-list from math.CT) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2438, level: 5" node_number="2438"> <div class="valid" valid="valid" title="valid: True, node: 2439, level: 6" node_number="2439"> <div class="valid" valid="valid" title="valid: True, node: 2440, level: 7" node_number="2440"> Title: Quotients of span categories that are allegories and the representation of regular categories </div> <div class="valid" valid="valid" title="valid: True, node: 2441, level: 7" node_number="2441"> Authors: S. Naser Hosseini, <a class="valid" valid="valid" title="valid: True, node: 2442, level: 8" node_number="2442">Amir R. Shir Ali Nasab</a>, <a class="valid" valid="valid" title="valid: True, node: 2443, level: 8" node_number="2443">Walter Tholen</a>, <a class="valid" valid="valid" title="valid: True, node: 2444, level: 8" node_number="2444">Leila Yeganeh</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2445, level: 7" node_number="2445"> Subjects: Category Theory (math.CT); Logic in Computer Science (cs.LO) </div> <p class="valid" valid="valid" title="valid: True, node: 2446, level: 7" node_number="2446">We consider the ordinary category Span(C) of (isomorphism classes of) spans of morphisms in a category C with finite limits as needed, composed horizontally via pullback, and give a general criterion for a quotient of Span(C) to be an allegory. In particular, when C carries a pullback-stable, but not necessarily proper, (E, M)-factorization system, we establish a quotient category Span_E(C) that is isomorphic to the category Rel_M(C) of M-relations in C, and show that it is a (unitary and tabular) allegory precisely when M is a class of monomorphisms in C. Without this restriction, one can still find a least pullback-stable and composition-closed class E. containing E such that Span_E.(C) is a unitary and tabular allegory. In this way one obtains a left adjoint to the 2-functor that assigns to every unitary and tabular allegory the regular category of its Lawverian maps. With the Freyd-Scedrov Representation Theorem for regular categories, we conclude that every finitely complete category with a stable factorization system has a reflection into the huge 2-category of all regular categories. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2447, level: 5" node_number="2447">[218] arXiv:2112.04624 (cross-list from q-bio.QM) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2448, level: 5" node_number="2448"> <div class="valid" valid="valid" title="valid: True, node: 2449, level: 6" node_number="2449"> <div class="valid" valid="valid" title="valid: True, node: 2450, level: 7" node_number="2450"> Title: Deep Molecular Representation Learning via Fusing Physical and Chemical Information </div> <div class="valid" valid="valid" title="valid: True, node: 2451, level: 7" node_number="2451"> Authors: Shuwen Yang, <a class="valid" valid="valid" title="valid: True, node: 2452, level: 8" node_number="2452">Ziyao Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2453, level: 8" node_number="2453">Guojie Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2454, level: 8" node_number="2454">Lingsheng Cai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2455, level: 7" node_number="2455"> Comments: In NeurIPS-2021, 18 pages, 5 figures, appendix included </div> <div class="valid" valid="valid" title="valid: True, node: 2456, level: 7" node_number="2456"> Subjects: Quantitative Methods (q-bio.QM); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2457, level: 7" node_number="2457">Molecular representation learning is the first yet vital step in combining deep learning and molecular science. To push the boundaries of molecular representation learning, we present PhysChem, a novel neural architecture that learns molecular representations via fusing physical and chemical information of molecules. PhysChem is composed of a physicist network (PhysNet) and a chemist network (ChemNet). PhysNet is a neural physical engine that learns molecular conformations through simulating molecular dynamics with parameterized forces; ChemNet implements geometry-aware deep message-passing to learn chemical / biomedical properties of molecules. Two networks specialize in their own tasks and cooperate by providing expertise to each other. By fusing physical and chemical information, PhysChem achieved state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark. The effectiveness of PhysChem was further corroborated on cutting-edge datasets of SARS-CoV-2. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2458, level: 5" node_number="2458">[219] arXiv:2112.04653 (cross-list from eess.IV) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2459, level: 5" node_number="2459"> <div class="valid" valid="valid" title="valid: True, node: 2460, level: 6" node_number="2460"> <div class="valid" valid="valid" title="valid: True, node: 2461, level: 7" node_number="2461"> Title: Extending nn-UNet for brain tumor segmentation </div> <div class="valid" valid="valid" title="valid: True, node: 2462, level: 7" node_number="2462"> Authors: Huan Minh Luu, <a class="valid" valid="valid" title="valid: True, node: 2463, level: 8" node_number="2463">Sung-Hong Park</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2464, level: 7" node_number="2464"> Comments: 12 pages, 4 figures, BraTS competition paper </div> <div class="valid" valid="valid" title="valid: True, node: 2465, level: 7" node_number="2465"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2466, level: 7" node_number="2466">Brain tumor segmentation is essential for the diagnosis and prognosis of patients with gliomas. The brain tumor segmentation challenge has continued to provide a great source of data to develop automatic algorithms to perform the task. This paper describes our contribution to the 2021 competition. We developed our methods based on nn-UNet, the winning entry of last year competition. We experimented with several modifications, including using a larger network, replacing batch normalization with group normalization, and utilizing axial attention in the decoder. Internal 5-fold cross validation as well as online evaluation from the organizers showed the effectiveness of our approach, with minor improvement in quantitative metrics when compared to the baseline. The proposed models won first place in the final ranking on unseen test data. The codes, pretrained weights, and docker image for the winning submission are publicly available at https://github.com/rixez/Brats21_KAIST_MRI_Lab </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2467, level: 5" node_number="2467">[220] arXiv:2112.04677 (cross-list from stat.ML) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2468, level: 5" node_number="2468"> <div class="valid" valid="valid" title="valid: True, node: 2469, level: 6" node_number="2469"> <div class="valid" valid="valid" title="valid: True, node: 2470, level: 7" node_number="2470"> Title: A Note on Comparison of F-measures </div> <div class="valid" valid="valid" title="valid: True, node: 2471, level: 7" node_number="2471"> Authors: Wei Ju, <a class="valid" valid="valid" title="valid: True, node: 2472, level: 8" node_number="2472">Wenxin Jiang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2473, level: 7" node_number="2473"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2474, level: 7" node_number="2474">We comment on a recent TKDE paper "Linear Approximation of F-measure for the Performance Evaluation of Classification Algorithms on Imbalanced Data Sets", and make two improvements related to comparison of F-measures for two prediction rules. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2475, level: 5" node_number="2475">[221] arXiv:2112.04721 (cross-list from eess.IV) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2476, level: 5" node_number="2476"> <div class="valid" valid="valid" title="valid: True, node: 2477, level: 6" node_number="2477"> <div class="valid" valid="valid" title="valid: True, node: 2478, level: 7" node_number="2478"> Title: One-dimensional Deep Low-rank and Sparse Network for Accelerated MRI </div> <div class="valid" valid="valid" title="valid: True, node: 2479, level: 7" node_number="2479"> Authors: Zi Wang, <a class="valid" valid="valid" title="valid: True, node: 2480, level: 8" node_number="2480">Chen Qian</a>, <a class="valid" valid="valid" title="valid: True, node: 2481, level: 8" node_number="2481">Di Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 2482, level: 8" node_number="2482">Hongwei Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 2483, level: 8" node_number="2483">Rushuai Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2484, level: 8" node_number="2484">Bo Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 2485, level: 8" node_number="2485">Xiaobo Qu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2486, level: 7" node_number="2486"> Comments: 16 pages </div> <div class="valid" valid="valid" title="valid: True, node: 2487, level: 7" node_number="2487"> Subjects: Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph) </div> <p class="valid" valid="valid" title="valid: True, node: 2488, level: 7" node_number="2488">Deep learning has shown astonishing performance in accelerated magnetic resonance imaging (MRI). Most state-of-the-art deep learning reconstructions adopt the powerful convolutional neural network and perform 2D convolution since many magnetic resonance images or their corresponding k-space are in 2D. In this work, we present a new approach that explores the 1D convolution, making the deep network much easier to be trained and generalized. We further integrate the 1D convolution into the proposed deep network, named as One-dimensional Deep Low-rank and Sparse network (ODLS), which unrolls the iteration procedure of a low-rank and sparse reconstruction model. Extensive results on in vivo knee and brain datasets demonstrate that, the proposed ODLS is very suitable for the case of limited training subjects and provides improved reconstruction performance than state-of-the-art methods both visually and quantitatively. Additionally, ODLS also shows nice robustness to different undersampling scenarios and some mismatches between the training and test data. In summary, our work demonstrates that the 1D deep learning scheme is memory-efficient and robust in fast MRI. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2489, level: 5" node_number="2489">[222] arXiv:2112.04755 (cross-list from q-fin.PM) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2490, level: 5" node_number="2490"> <div class="valid" valid="valid" title="valid: True, node: 2491, level: 6" node_number="2491"> <div class="valid" valid="valid" title="valid: True, node: 2492, level: 7" node_number="2492"> Title: High-Dimensional Stock Portfolio Trading with Deep Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 2493, level: 7" node_number="2493"> Authors: Uta Pigorsch, <a class="valid" valid="valid" title="valid: True, node: 2494, level: 8" node_number="2494">Sebastian Sch&#228;fer</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2495, level: 7" node_number="2495"> Comments: 14 pages, 5 figures, 2 tables </div> <div class="valid" valid="valid" title="valid: True, node: 2496, level: 7" node_number="2496"> Subjects: Portfolio Management (q-fin.PM); Machine Learning (cs.LG); Computational Finance (q-fin.CP) </div> <p class="valid" valid="valid" title="valid: True, node: 2497, level: 7" node_number="2497">This paper proposes a Deep Reinforcement Learning algorithm for financial portfolio trading based on Deep Q-learning. The algorithm is capable of trading high-dimensional portfolios from cross-sectional datasets of any size which may include data gaps and non-unique history lengths in the assets. We sequentially set up environments by sampling one asset for each environment while rewarding investments with the resulting asset's return and cash reservation with the average return of the set of assets. This enforces the agent to strategically assign capital to assets that it predicts to perform above-average. We apply our methodology in an out-of-sample analysis to 48 US stock portfolio setups, varying in the number of stocks from ten up to 500 stocks, in the selection criteria and in the level of transaction costs. The algorithm on average outperforms all considered passive and active benchmark investment strategies by a large margin using only one hyperparameter setup for all portfolios. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2498, level: 5" node_number="2498">[223] arXiv:2112.04768 (cross-list from quant-ph) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2499, level: 5" node_number="2499"> <div class="valid" valid="valid" title="valid: True, node: 2500, level: 6" node_number="2500"> <div class="valid" valid="valid" title="valid: True, node: 2501, level: 7" node_number="2501"> Title: Quantum Link Prediction in Complex Networks </div> <div class="valid" valid="valid" title="valid: True, node: 2502, level: 7" node_number="2502"> Authors: Jo&#227;o P. Moutinho, <a class="valid" valid="valid" title="valid: True, node: 2503, level: 8" node_number="2503">Andr&#233; Melo</a>, <a class="valid" valid="valid" title="valid: True, node: 2504, level: 8" node_number="2504">Bruno Coutinho</a>, <a class="valid" valid="valid" title="valid: True, node: 2505, level: 8" node_number="2505">Istv&#225;n A. Kov&#225;cs</a>, <a class="valid" valid="valid" title="valid: True, node: 2506, level: 8" node_number="2506">Yasser Omar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2507, level: 7" node_number="2507"> Comments: Keywords: Complex Networks, Quantum Algorithms, Link Prediction, Social Networks, Protein-Protein Interaction Networks </div> <div class="valid" valid="valid" title="valid: True, node: 2508, level: 7" node_number="2508"> Subjects: Quantum Physics (quant-ph); Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI); Biological Physics (physics.bio-ph) </div> <p class="valid" valid="valid" title="valid: True, node: 2509, level: 7" node_number="2509">Predicting new links in physical, biological, social, or technological networks has a significant scientific and societal impact. Network-based link prediction methods utilize topological patterns in a network to infer new or unobserved links. Here, we propose a quantum algorithm for link prediction, QLP, which uses quantum walks to infer unknown links based on even and odd length paths. By sampling new links from quantum measurements, QLP avoids the need to explicitly calculate all pairwise scores in the network. We study the complexity of QLP and discuss in which cases one may achieve a polynomial speedup over classical link prediction methods. Furthermore, tests with real-world datasets show that QLP is at least as precise as state-of-the-art classical link prediction methods, both in cross-validation tests and in the prediction of experimentally verified protein-protein interactions. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2510, level: 5" node_number="2510">[224] arXiv:2112.04779 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2511, level: 5" node_number="2511"> <div class="valid" valid="valid" title="valid: True, node: 2512, level: 6" node_number="2512"> <div class="valid" valid="valid" title="valid: True, node: 2513, level: 7" node_number="2513"> Title: Regularized Modal Regression on Markov-dependent Observations: A Theoretical Assessment </div> <div class="valid" valid="valid" title="valid: True, node: 2514, level: 7" node_number="2514"> Authors: Tielang Gong, <a class="valid" valid="valid" title="valid: True, node: 2515, level: 8" node_number="2515">Yuxin Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 2516, level: 8" node_number="2516">Hong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2517, level: 8" node_number="2517">Bo Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 2518, level: 8" node_number="2518">Wei Feng</a>, <a class="valid" valid="valid" title="valid: True, node: 2519, level: 8" node_number="2519">Chen Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2520, level: 7" node_number="2520"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2521, level: 7" node_number="2521">Modal regression, a widely used regression protocol, has been extensively investigated in statistical and machine learning communities due to its robustness to outliers and heavy-tailed noises. Understanding modal regression's theoretical behavior can be fundamental in learning theory. Despite significant progress in characterizing its statistical property, the majority of the results are based on the assumption that samples are independent and identical distributed (i.i.d.), which is too restrictive for real-world applications. This paper concerns the statistical property of regularized modal regression (RMR) within an important dependence structure - Markov dependent. Specifically, we establish the upper bound for RMR estimator under moderate conditions and give an explicit learning rate. Our results show that the Markov dependence impacts on the generalization error in the way that sample size would be discounted by a multiplicative factor depending on the spectral gap of underlying Markov chain. This result shed a new light on characterizing the theoretical underpinning for robust regression. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2522, level: 5" node_number="2522">[225] arXiv:2112.04814 (cross-list from q-bio.BM) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2523, level: 5" node_number="2523"> <div class="valid" valid="valid" title="valid: True, node: 2524, level: 6" node_number="2524"> <div class="valid" valid="valid" title="valid: True, node: 2525, level: 7" node_number="2525"> Title: Multimodal Pre-Training Model for Sequence-based Prediction of Protein-Protein Interaction </div> <div class="valid" valid="valid" title="valid: True, node: 2526, level: 7" node_number="2526"> Authors: Yang Xue, <a class="valid" valid="valid" title="valid: True, node: 2527, level: 8" node_number="2527">Zijing Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 2528, level: 8" node_number="2528">Xiaomin Fang</a>, <a class="valid" valid="valid" title="valid: True, node: 2529, level: 8" node_number="2529">Fan Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2530, level: 7" node_number="2530"> Comments: MLCB 2021 Spotlight </div> <div class="valid" valid="valid" title="valid: True, node: 2531, level: 7" node_number="2531"> Subjects: Biomolecules (q-bio.BM); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2532, level: 7" node_number="2532">Protein-protein interactions (PPIs) are essentials for many biological processes where two or more proteins physically bind together to achieve their functions. Modeling PPIs is useful for many biomedical applications, such as vaccine design, antibody therapeutics, and peptide drug discovery. Pre-training a protein model to learn effective representation is critical for PPIs. Most pre-training models for PPIs are sequence-based, which naively adopt the language models used in natural language processing to amino acid sequences. More advanced works utilize the structure-aware pre-training technique, taking advantage of the contact maps of known protein structures. However, neither sequences nor contact maps can fully characterize structures and functions of the proteins, which are closely related to the PPI problem. Inspired by this insight, we propose a multimodal protein pre-training model with three modalities: sequence, structure, and function (S2F). Notably, instead of using contact maps to learn the amino acid-level rigid structures, we encode the structure feature with the topology complex of point clouds of heavy atoms. It allows our model to learn structural information about not only the backbones but also the side chains. Moreover, our model incorporates the knowledge from the functional description of proteins extracted from literature or manual annotations. Our experiments show that the S2F learns protein embeddings that achieve good performances on a variety of PPIs tasks, including cross-species PPI, antibody-antigen affinity prediction, antibody neutralization prediction for SARS-CoV-2, and mutation-driven binding affinity change prediction. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2533, level: 5" node_number="2533">[226] arXiv:2112.04828 (cross-list from stat.ML) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2534, level: 5" node_number="2534"> <div class="valid" valid="valid" title="valid: True, node: 2535, level: 6" node_number="2535"> <div class="valid" valid="valid" title="valid: True, node: 2536, level: 7" node_number="2536"> Title: Evaluation of survival distribution predictions with discrimination measures </div> <div class="valid" valid="valid" title="valid: True, node: 2537, level: 7" node_number="2537"> Authors: Raphael Sonabend, <a class="valid" valid="valid" title="valid: True, node: 2538, level: 8" node_number="2538">Andreas Bender</a>, <a class="valid" valid="valid" title="valid: True, node: 2539, level: 8" node_number="2539">Sebastian Vollmer</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2540, level: 7" node_number="2540"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME) </div> <p class="valid" valid="valid" title="valid: True, node: 2541, level: 7" node_number="2541">In this paper we consider how to evaluate survival distribution predictions with measures of discrimination. This is a non-trivial problem as discrimination measures are the most commonly used in survival analysis and yet there is no clear method to derive a risk prediction from a distribution prediction. We survey methods proposed in literature and software and consider their respective advantages and disadvantages. Whilst distributions are frequently evaluated by discrimination measures, we find that the method for doing so is rarely described in the literature and often leads to unfair comparisons. We find that the most robust method of reducing a distribution to a risk is to sum over the predicted cumulative hazard. We recommend that machine learning survival analysis software implements clear transformations between distribution and risk predictions in order to allow more transparent and accessible model evaluation. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2542, level: 5" node_number="2542">[227] arXiv:2112.04841 (cross-list from eess.AS) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2543, level: 5" node_number="2543"> <div class="valid" valid="valid" title="valid: True, node: 2544, level: 6" node_number="2544"> <div class="valid" valid="valid" title="valid: True, node: 2545, level: 7" node_number="2545"> Title: On The Effect Of Coding Artifacts On Acoustic Scene Classification </div> <div class="valid" valid="valid" title="valid: True, node: 2546, level: 7" node_number="2546"> Authors: Nagashree K. S. Rao, <a class="valid" valid="valid" title="valid: True, node: 2547, level: 8" node_number="2547">Nils Peters</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2548, level: 7" node_number="2548"> Comments: paper presented at the 2021 Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE) </div> <div class="valid" valid="valid" title="valid: True, node: 2549, level: 7" node_number="2549"> Subjects: Audio and Speech Processing (eess.AS); Multimedia (cs.MM); Sound (cs.SD); Signal Processing (eess.SP) </div> <p class="valid" valid="valid" title="valid: True, node: 2550, level: 7" node_number="2550">Previous DCASE challenges contributed to an increase in the performance of acoustic scene classification systems. State-of-the-art classifiers demand significant processing capabilities and memory which is challenging for resource-constrained mobile or IoT edge devices. Thus, it is more likely to deploy these models on more powerful hardware and classify audio recordings previously uploaded (or streamed) from low-power edge devices. In such scenario, the edge device may apply perceptual audio coding to reduce the transmission data rate. This paper explores the effect of perceptual audio coding on the classification performance using a DCASE 2020 challenge contribution [1]. We found that classification accuracy can degrade by up to 57% compared to classifying original (uncompressed) audio. We further demonstrate how lossy audio compression techniques during model training can improve classification accuracy of compressed audio signals even for audio codecs and codec bitrates not included in the training process. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2551, level: 5" node_number="2551">[228] arXiv:2112.04863 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2552, level: 5" node_number="2552"> <div class="valid" valid="valid" title="valid: True, node: 2553, level: 6" node_number="2553"> <div class="valid" valid="valid" title="valid: True, node: 2554, level: 7" node_number="2554"> Title: 3D Medical Point Transformer: Introducing Convolution to Attention Networks for Medical Point Cloud Analysis </div> <div class="valid" valid="valid" title="valid: True, node: 2555, level: 7" node_number="2555"> Authors: Jianhui Yu, <a class="valid" valid="valid" title="valid: True, node: 2556, level: 8" node_number="2556">Chaoyi Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2557, level: 8" node_number="2557">Heng Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2558, level: 8" node_number="2558">Dingxin Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2559, level: 8" node_number="2559">Yang Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2560, level: 8" node_number="2560">Tiange Xiang</a>, <a class="valid" valid="valid" title="valid: True, node: 2561, level: 8" node_number="2561">Dongnan Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 2562, level: 8" node_number="2562">Weidong Cai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2563, level: 7" node_number="2563"> Comments: technical report </div> <div class="valid" valid="valid" title="valid: True, node: 2564, level: 7" node_number="2564"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2565, level: 7" node_number="2565">General point clouds have been increasingly investigated for different tasks, and recently Transformer-based networks are proposed for point cloud analysis. However, there are barely related works for medical point clouds, which are important for disease detection and treatment. In this work, we propose an attention-based model specifically for medical point clouds, namely 3D medical point Transformer (3DMedPT), to examine the complex biological structures. By augmenting contextual information and summarizing local responses at query, our attention module can capture both local context and global content feature interactions. However, the insufficient training samples of medical data may lead to poor feature learning, so we apply position embeddings to learn accurate local geometry and Multi-Graph Reasoning (MGR) to examine global knowledge propagation over channel graphs to enrich feature representations. Experiments conducted on IntrA dataset proves the superiority of 3DMedPT, where we achieve the best classification and segmentation results. Furthermore, the promising generalization ability of our method is validated on general 3D point cloud benchmarks: ModelNet40 and ShapeNetPart. Code will be released soon. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2566, level: 5" node_number="2566">[229] arXiv:2112.04882 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2567, level: 5" node_number="2567"> <div class="valid" valid="valid" title="valid: True, node: 2568, level: 6" node_number="2568"> <div class="valid" valid="valid" title="valid: True, node: 2569, level: 7" node_number="2569"> Title: Evaluating saliency methods on artificial data with different background types </div> <div class="valid" valid="valid" title="valid: True, node: 2570, level: 7" node_number="2570"> Authors: C&#233;line Budding, <a class="valid" valid="valid" title="valid: True, node: 2571, level: 8" node_number="2571">Fabian Eitel</a>, <a class="valid" valid="valid" title="valid: True, node: 2572, level: 8" node_number="2572">Kerstin Ritter</a>, <a class="valid" valid="valid" title="valid: True, node: 2573, level: 8" node_number="2573">Stefan Haufe</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2574, level: 7" node_number="2574"> Comments: 6 pages, 2 figures. Presented at Medical Imaging meets NeurIPS 2021 (poster presentation) </div> <div class="valid" valid="valid" title="valid: True, node: 2575, level: 7" node_number="2575"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> <p class="valid" valid="valid" title="valid: True, node: 2576, level: 7" node_number="2576">Over the last years, many 'explainable artificial intelligence' (xAI) approaches have been developed, but these have not always been objectively evaluated. To evaluate the quality of heatmaps generated by various saliency methods, we developed a framework to generate artificial data with synthetic lesions and a known ground truth map. Using this framework, we evaluated two data sets with different backgrounds, Perlin noise and 2D brain MRI slices, and found that the heatmaps vary strongly between saliency methods and backgrounds. We strongly encourage further evaluation of saliency maps and xAI methods using this framework before applying these in clinical or other safety-critical settings. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2577, level: 5" node_number="2577">[230] arXiv:2112.04887 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2578, level: 5" node_number="2578"> <div class="valid" valid="valid" title="valid: True, node: 2579, level: 6" node_number="2579"> <div class="valid" valid="valid" title="valid: True, node: 2580, level: 7" node_number="2580"> Title: Forecast Evaluation in Large Cross-Sections of Realized Volatility </div> <div class="valid" valid="valid" title="valid: True, node: 2581, level: 7" node_number="2581"> Authors: Christis Katsouris </div> <div class="valid" valid="valid" title="valid: True, node: 2582, level: 7" node_number="2582"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2583, level: 7" node_number="2583">In this paper, we consider the forecast evaluation of realized volatility measures under cross-section dependence using equal predictive accuracy testing procedures. We evaluate the predictive accuracy of the model based on the augmented cross-section when forecasting Realized Volatility. Under the null hypothesis of equal predictive accuracy the benchmark model employed is a standard HAR model while under the alternative of non-equal predictive accuracy the forecast model is an augmented HAR model estimated via the LASSO shrinkage. We study the sensitivity of forecasts to the model specification by incorporating a measurement error correction as well as cross-sectional jump component measures. The out-of-sample forecast evaluation of the models is assessed with numerical implementations. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2584, level: 5" node_number="2584">[231] arXiv:2112.04894 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2585, level: 5" node_number="2585"> <div class="valid" valid="valid" title="valid: True, node: 2586, level: 6" node_number="2586"> <div class="valid" valid="valid" title="valid: True, node: 2587, level: 7" node_number="2587"> Title: Semi-Supervised Medical Image Segmentation via Cross Teaching between CNN and Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 2588, level: 7" node_number="2588"> Authors: Xiangde Luo, <a class="valid" valid="valid" title="valid: True, node: 2589, level: 8" node_number="2589">Minhao Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 2590, level: 8" node_number="2590">Tao Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2591, level: 8" node_number="2591">Guotai Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2592, level: 8" node_number="2592">Shaoting Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2593, level: 7" node_number="2593"> Comments: A technical report about SSL4MIS:<a class="valid" valid="valid" title="valid: True, node: 2594, level: 8" node_number="2594">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2595, level: 7" node_number="2595"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2596, level: 7" node_number="2596">Recently, deep learning with Convolutional Neural Networks (CNNs) and Transformers has shown encouraging results in fully supervised medical image segmentation. However, it is still challenging for them to achieve good performance with limited annotations for training. In this work, we present a very simple yet efficient framework for semi-supervised medical image segmentation by introducing the cross teaching between CNN and Transformer. Specifically, we simplify the classical deep co-training from consistency regularization to cross teaching, where the prediction of a network is used as the pseudo label to supervise the other network directly end-to-end. Considering the difference in learning paradigm between CNN and Transformer, we introduce the Cross Teaching between CNN and Transformer rather than just using CNNs. Experiments on a public benchmark show that our method outperforms eight existing semi-supervised learning methods just with a simpler framework. Notably, this work may be the first attempt to combine CNN and transformer for semi-supervised medical image segmentation and achieve promising results on a public benchmark. The code will be released at: https://github.com/HiLab-git/SSL4MIS. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2597, level: 5" node_number="2597">[232] arXiv:2112.04906 (cross-list from math.OC) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2598, level: 5" node_number="2598"> <div class="valid" valid="valid" title="valid: True, node: 2599, level: 6" node_number="2599"> <div class="valid" valid="valid" title="valid: True, node: 2600, level: 7" node_number="2600"> Title: Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring </div> <div class="valid" valid="valid" title="valid: True, node: 2601, level: 7" node_number="2601"> Authors: Yunzhuang Shen, <a class="valid" valid="valid" title="valid: True, node: 2602, level: 8" node_number="2602">Yuan Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 2603, level: 8" node_number="2603">Xiaodong Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2604, level: 8" node_number="2604">Andrew Eberhard</a>, <a class="valid" valid="valid" title="valid: True, node: 2605, level: 8" node_number="2605">Andreas Ernst</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2606, level: 7" node_number="2606"> Comments: Machine learning for column generation and branch-and-price; accepted to AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 2607, level: 7" node_number="2607"> Subjects: Optimization and Control (math.OC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2608, level: 7" node_number="2608">Column Generation (CG) is an effective method for solving large-scale optimization problems. CG starts by solving a sub-problem with a subset of columns (i.e., variables) and gradually includes new columns that can improve the solution of the current subproblem. The new columns are generated as needed by repeatedly solving a pricing problem, which is often NP-hard and is a bottleneck of the CG approach. To tackle this, we propose a Machine-Learning-based Pricing Heuristic (MLPH)that can generate many high-quality columns efficiently. In each iteration of CG, our MLPH leverages an ML model to predict the optimal solution of the pricing problem, which is then used to guide a sampling method to efficiently generate multiple high-quality columns. Using the graph coloring problem, we empirically show that MLPH significantly enhancesCG as compared to six state-of-the-art methods, and the improvement in CG can lead to substantially better performance of the branch-and-price exact method. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2609, level: 5" node_number="2609">[233] arXiv:2112.04914 (cross-list from eess.AS) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2610, level: 5" node_number="2610"> <div class="valid" valid="valid" title="valid: True, node: 2611, level: 6" node_number="2611"> <div class="valid" valid="valid" title="valid: True, node: 2612, level: 7" node_number="2612"> Title: End-to-end Alexa Device Arbitration </div> <div class="valid" valid="valid" title="valid: True, node: 2613, level: 7" node_number="2613"> Authors: Jarred Barber, <a class="valid" valid="valid" title="valid: True, node: 2614, level: 8" node_number="2614">Yifeng Fan</a>, <a class="valid" valid="valid" title="valid: True, node: 2615, level: 8" node_number="2615">Tao Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2616, level: 7" node_number="2616"> Comments: Submitted to ICASSP 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 2617, level: 7" node_number="2617"> Subjects: Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD) </div> <p class="valid" valid="valid" title="valid: True, node: 2618, level: 7" node_number="2618">We introduce a variant of the speaker localization problem, which we call device arbitration. In the device arbitration problem, a user utters a keyword that is detected by multiple distributed microphone arrays (smart home devices), and we want to determine which device was closest to the user. Rather than solving the full localization problem, we propose an end-to-end machine learning system. This system learns a feature embedding that is computed independently on each device. The embeddings from each device are then aggregated together to produce the final arbitration decision. We use a large-scale room simulation to generate training and evaluation data, and compare our system against a signal processing baseline. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2619, level: 5" node_number="2619">[234] arXiv:2112.04922 (cross-list from math.OC) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2620, level: 5" node_number="2620"> <div class="valid" valid="valid" title="valid: True, node: 2621, level: 6" node_number="2621"> <div class="valid" valid="valid" title="valid: True, node: 2622, level: 7" node_number="2622"> Title: A More Stable Accelerated Gradient Method Inspired by Continuous-Time Perspective </div> <div class="valid" valid="valid" title="valid: True, node: 2623, level: 7" node_number="2623"> Authors: Yasong Feng, <a class="valid" valid="valid" title="valid: True, node: 2624, level: 8" node_number="2624">Weiguo Gao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2625, level: 7" node_number="2625"> Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computation (stat.CO) </div> <p class="valid" valid="valid" title="valid: True, node: 2626, level: 7" node_number="2626">Nesterov's accelerated gradient method (NAG) is widely used in problems with machine learning background including deep learning, and is corresponding to a continuous-time differential equation. From this connection, the property of the differential equation and its numerical approximation can be investigated to improve the accelerated gradient method. In this work we present a new improvement of NAG in terms of stability inspired by numerical analysis. We give the precise order of NAG as a numerical approximation of its continuous-time limit and then present a new method with higher order. We show theoretically that our new method is more stable than NAG for large step size. Experiments of matrix completion and handwriting digit recognition demonstrate that the stability of our new method is better. Furthermore, better stability leads to higher computational speed in experiments. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2627, level: 5" node_number="2627">[235] arXiv:2112.04933 (cross-list from stat.AP) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2628, level: 5" node_number="2628"> <div class="valid" valid="valid" title="valid: True, node: 2629, level: 6" node_number="2629"> <div class="valid" valid="valid" title="valid: True, node: 2630, level: 7" node_number="2630"> Title: Measuring Wind Turbine Health Using Drifting Concepts </div> <div class="valid" valid="valid" title="valid: True, node: 2631, level: 7" node_number="2631"> Authors: Agnieszka Jastrzebska, <a class="valid" valid="valid" title="valid: True, node: 2632, level: 8" node_number="2632">Alejandro Morales-Hern&#225;ndez</a>, <a class="valid" valid="valid" title="valid: True, node: 2633, level: 8" node_number="2633">Gonzalo N&#225;poles</a>, <a class="valid" valid="valid" title="valid: True, node: 2634, level: 8" node_number="2634">Yamisleydi Salgueiro</a>, <a class="valid" valid="valid" title="valid: True, node: 2635, level: 8" node_number="2635">Koen Vanhoof</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2636, level: 7" node_number="2636"> Subjects: Applications (stat.AP); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2637, level: 7" node_number="2637">Time series processing is an essential aspect of wind turbine health monitoring. Despite the progress in this field, there is still room for new methods to improve modeling quality. In this paper, we propose two new approaches for the analysis of wind turbine health. Both approaches are based on abstract concepts, implemented using fuzzy sets, which summarize and aggregate the underlying raw data. By observing the change in concepts, we infer about the change in the turbine's health. Analyzes are carried out separately for different external conditions (wind speed and temperature). We extract concepts that represent relative low, moderate, and high power production. The first method aims at evaluating the decrease or increase in relatively high and low power production. This task is performed using a regression-like model. The second method evaluates the overall drift of the extracted concepts. Large drift indicates that the power production process undergoes fluctuations in time. Concepts are labeled using linguistic labels, thus equipping our model with improved interpretability features. We applied the proposed approach to process publicly available data describing four wind turbines. The simulation results have shown that the aging process is not homogeneous in all wind turbines. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2638, level: 5" node_number="2638">[236] arXiv:2112.04939 (cross-list from eess.AS) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2639, level: 5" node_number="2639"> <div class="valid" valid="valid" title="valid: True, node: 2640, level: 6" node_number="2640"> <div class="valid" valid="valid" title="valid: True, node: 2641, level: 7" node_number="2641"> Title: A Training Framework for Stereo-Aware Speech Enhancement using Deep Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 2642, level: 7" node_number="2642"> Authors: Bahareh Tolooshams, <a class="valid" valid="valid" title="valid: True, node: 2643, level: 8" node_number="2643">Kazuhito Koishida</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2644, level: 7" node_number="2644"> Comments: Submitted to ICASSP 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 2645, level: 7" node_number="2645"> Subjects: Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD) </div> <p class="valid" valid="valid" title="valid: True, node: 2646, level: 7" node_number="2646">Deep learning-based speech enhancement has shown unprecedented performance in recent years. The most popular mono speech enhancement frameworks are end-to-end networks mapping the noisy mixture into an estimate of the clean speech. With growing computational power and availability of multichannel microphone recordings, prior works have aimed to incorporate spatial statistics along with spectral information to boost up performance. Despite an improvement in enhancement performance of mono output, the spatial image preservation and subjective evaluations have not gained much attention in the literature. This paper proposes a novel stereo-aware framework for speech enhancement, i.e., a training loss for deep learning-based speech enhancement to preserve the spatial image while enhancing the stereo mixture. The proposed framework is model independent, hence it can be applied to any deep learning based architecture. We provide an extensive objective and subjective evaluation of the trained models through a listening test. We show that by regularizing for an image preservation loss, the overall performance is improved, and the stereo aspect of the speech is better preserved. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2647, level: 5" node_number="2647">[237] arXiv:2112.04949 (cross-list from eess.AS) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2648, level: 5" node_number="2648"> <div class="valid" valid="valid" title="valid: True, node: 2649, level: 6" node_number="2649"> <div class="valid" valid="valid" title="valid: True, node: 2650, level: 7" node_number="2650"> Title: Harmonic and non-Harmonic Based Noisy Reverberant Speech Enhancement in Time Domain </div> <div class="valid" valid="valid" title="valid: True, node: 2651, level: 7" node_number="2651"> Authors: G. Zucatelli, <a class="valid" valid="valid" title="valid: True, node: 2652, level: 8" node_number="2652">R. Coelho</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2653, level: 7" node_number="2653"> Comments: 9 pages </div> <div class="valid" valid="valid" title="valid: True, node: 2654, level: 7" node_number="2654"> Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> <p class="valid" valid="valid" title="valid: True, node: 2655, level: 7" node_number="2655">This paper introduces the single step time domain method named HnH-NRSE, whihc is designed for simultaneous speech intelligibility and quality improvement under noisy-reverberant conditions. In this solution, harmonic and non-harmonic elements of speech are separated by applying zero-crossing and energy criteria. An objective evaluation of the its non-stationarity degree is further used for an adaptive gain to treat masking components. No prior knowledge of speech statistics or room information is required for this technique. Additionally, two combined solutions, IRMO and IRMN, are proposed as composite methods for improvement on noisy-reverberant speech signals. The proposed and baseline methods are evaluated considering two intelligibility and three quality measures, applied for the objective prediction. The results show that the proposed scheme leads to a higher intelligibility and quality improvement when compared to competing methods in most scenarios. Additionally, a perceptual intelligibility listening test is performed, which corroborates with these results. Furthermore, the proposed HnH-NRSE solution attains SRMR quality measure with similar results when compared to the composed IRMO and IRMN techniques. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2656, level: 5" node_number="2656">[238] arXiv:2112.04979 (cross-list from physics.flu-dyn) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2657, level: 5" node_number="2657"> <div class="valid" valid="valid" title="valid: True, node: 2658, level: 6" node_number="2658"> <div class="valid" valid="valid" title="valid: True, node: 2659, level: 7" node_number="2659"> Title: A fully-differentiable compressible high-order computational fluid dynamics solver </div> <div class="valid" valid="valid" title="valid: True, node: 2660, level: 7" node_number="2660"> Authors: Deniz A. Bezgin, <a class="valid" valid="valid" title="valid: True, node: 2661, level: 8" node_number="2661">Aaron B. Buhendwa</a>, <a class="valid" valid="valid" title="valid: True, node: 2662, level: 8" node_number="2662">Nikolaus A. Adams</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2663, level: 7" node_number="2663"> Subjects: Fluid Dynamics (physics.flu-dyn); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2664, level: 7" node_number="2664">Fluid flows are omnipresent in nature and engineering disciplines. The reliable computation of fluids has been a long-lasting challenge due to nonlinear interactions over multiple spatio-temporal scales. The compressible Navier-Stokes equations govern compressible flows and allow for complex phenomena like turbulence and shocks. Despite tremendous progress in hardware and software, capturing the smallest length-scales in fluid flows still introduces prohibitive computational cost for real-life applications. We are currently witnessing a paradigm shift towards machine learning supported design of numerical schemes as a means to tackle aforementioned problem. While prior work has explored differentiable algorithms for one- or two-dimensional incompressible fluid flows, we present a fully-differentiable three-dimensional framework for the computation of compressible fluid flows using high-order state-of-the-art numerical methods. Firstly, we demonstrate the efficiency of our solver by computing classical two- and three-dimensional test cases, including strong shocks and transition to turbulence. Secondly, and more importantly, our framework allows for end-to-end optimization to improve existing numerical schemes inside computational fluid dynamics algorithms. In particular, we are using neural networks to substitute a conventional numerical flux function. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2665, level: 5" node_number="2665">[239] arXiv:2112.04984 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2666, level: 5" node_number="2666"> <div class="valid" valid="valid" title="valid: True, node: 2667, level: 6" node_number="2667"> <div class="valid" valid="valid" title="valid: True, node: 2668, level: 7" node_number="2668"> Title: Robust Weakly Supervised Learning for COVID-19 Recognition Using Multi-Center CT Images </div> <div class="valid" valid="valid" title="valid: True, node: 2669, level: 7" node_number="2669"> Authors: Qinghao Ye, <a class="valid" valid="valid" title="valid: True, node: 2670, level: 8" node_number="2670">Yuan Gao</a>, <a class="valid" valid="valid" title="valid: True, node: 2671, level: 8" node_number="2671">Weiping Ding</a>, <a class="valid" valid="valid" title="valid: True, node: 2672, level: 8" node_number="2672">Zhangming Niu</a>, <a class="valid" valid="valid" title="valid: True, node: 2673, level: 8" node_number="2673">Chengjia Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2674, level: 8" node_number="2674">Yinghui Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 2675, level: 8" node_number="2675">Minhao Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2676, level: 8" node_number="2676">Evandro Fei Fang</a>, <a class="valid" valid="valid" title="valid: True, node: 2677, level: 8" node_number="2677">Wade Menpes-Smith</a>, <a class="valid" valid="valid" title="valid: True, node: 2678, level: 8" node_number="2678">Jun Xia</a>, <a class="valid" valid="valid" title="valid: True, node: 2679, level: 8" node_number="2679">Guang Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2680, level: 7" node_number="2680"> Comments: 32 pages, 8 figures, Applied Soft Computing </div> <div class="valid" valid="valid" title="valid: True, node: 2681, level: 7" node_number="2681"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2682, level: 7" node_number="2682">The world is currently experiencing an ongoing pandemic of an infectious disease named coronavirus disease 2019 (i.e., COVID-19), which is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Computed Tomography (CT) plays an important role in assessing the severity of the infection and can also be used to identify those symptomatic and asymptomatic COVID-19 carriers. With a surge of the cumulative number of COVID-19 patients, radiologists are increasingly stressed to examine the CT scans manually. Therefore, an automated 3D CT scan recognition tool is highly in demand since the manual analysis is time-consuming for radiologists and their fatigue can cause possible misjudgment. However, due to various technical specifications of CT scanners located in different hospitals, the appearance of CT images can be significantly different leading to the failure of many automated image recognition approaches. The multi-domain shift problem for the multi-center and multi-scanner studies is therefore nontrivial that is also crucial for a dependable recognition and critical for reproducible and objective diagnosis and prognosis. In this paper, we proposed a COVID-19 CT scan recognition model namely coronavirus information fusion and diagnosis network (CIFD-Net) that can efficiently handle the multi-domain shift problem via a new robust weakly supervised learning paradigm. Our model can resolve the problem of different appearance in CT scan images reliably and efficiently while attaining higher accuracy compared to other state-of-the-art methods. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2683, level: 5" node_number="2683">[240] arXiv:2112.04998 (cross-list from eess.IV) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2684, level: 5" node_number="2684"> <div class="valid" valid="valid" title="valid: True, node: 2685, level: 6" node_number="2685"> <div class="valid" valid="valid" title="valid: True, node: 2686, level: 7" node_number="2686"> Title: Sparse-View CT Reconstruction using Recurrent Stacked Back Projection </div> <div class="valid" valid="valid" title="valid: True, node: 2687, level: 7" node_number="2687"> Authors: Wenrui Li, <a class="valid" valid="valid" title="valid: True, node: 2688, level: 8" node_number="2688">Gregery T. Buzzard</a>, <a class="valid" valid="valid" title="valid: True, node: 2689, level: 8" node_number="2689">Charles A. Bouman</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2690, level: 7" node_number="2690"> Comments: 5 pages, 5 pages, 2021 Asilomar Conference on Signals, Systems, and Computers </div> <div class="valid" valid="valid" title="valid: True, node: 2691, level: 7" node_number="2691"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2692, level: 7" node_number="2692">Sparse-view CT reconstruction is important in a wide range of applications due to limitations on cost, acquisition time, or dosage. However, traditional direct reconstruction methods such as filtered back-projection (FBP) lead to low-quality reconstructions in the sub-Nyquist regime. In contrast, deep neural networks (DNNs) can produce high-quality reconstructions from sparse and noisy data, e.g. through post-processing of FBP reconstructions, as can model-based iterative reconstruction (MBIR), albeit at a higher computational cost. In this paper, we introduce a direct-reconstruction DNN method called Recurrent Stacked Back Projection (RSBP) that uses sequentially-acquired backprojections of individual views as input to a recurrent convolutional LSTM network. The SBP structure maintains all information in the sinogram, while the recurrent processing exploits the correlations between adjacent views and produces an updated reconstruction after each new view. We train our network on simulated data and test on both simulated and real data and demonstrate that RSBP outperforms both DNN post-processing of FBP images and basic MBIR, with a lower computational cost than MBIR. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2693, level: 5" node_number="2693">[241] arXiv:2112.05004 (cross-list from math.NT) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2694, level: 5" node_number="2694"> <div class="valid" valid="valid" title="valid: True, node: 2695, level: 6" node_number="2695"> <div class="valid" valid="valid" title="valid: True, node: 2696, level: 7" node_number="2696"> Title: Explicit Bounds for Linear Forms in the Exponentials of Algebraic Numbers </div> <div class="valid" valid="valid" title="valid: True, node: 2697, level: 7" node_number="2697"> Authors: Cheng-Chao Huang </div> <div class="valid" valid="valid" title="valid: True, node: 2698, level: 7" node_number="2698"> Subjects: Number Theory (math.NT); Computational Complexity (cs.CC); Symbolic Computation (cs.SC) </div> <p class="valid" valid="valid" title="valid: True, node: 2699, level: 7" node_number="2699">In this paper, we study linear forms $\lambda = \beta_1{\mathrm{e}}^{\alpha_1}+\cdots+\beta_m{\mathrm{e}}^{\alpha_m}$, where $\alpha_i$ and $\beta_i$ are algebraic numbers. An explicit lower bound for $|\lambda|$ is proved, which is derived from "th\'eor\`eme de Lindemann--Weierstrass effectif" via constructive methods in algebraic computation. Besides, an explicit upper bound for the minimal $|\lambda|$ is established on systematic results of counting algebraic numbers. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2700, level: 5" node_number="2700">[242] arXiv:2112.05016 (cross-list from eess.AS) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2701, level: 5" node_number="2701"> <div class="valid" valid="valid" title="valid: True, node: 2702, level: 6" node_number="2702"> <div class="valid" valid="valid" title="valid: True, node: 2703, level: 7" node_number="2703"> Title: X-Vector based voice activity detection for multi-genre broadcast speech-to-text </div> <div class="valid" valid="valid" title="valid: True, node: 2704, level: 7" node_number="2704"> Authors: Misa Ogura, <a class="valid" valid="valid" title="valid: True, node: 2705, level: 8" node_number="2705">Matt Haynes</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2706, level: 7" node_number="2706"> Comments: 7 pages, 3 figures, 4 tables </div> <div class="valid" valid="valid" title="valid: True, node: 2707, level: 7" node_number="2707"> Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> <p class="valid" valid="valid" title="valid: True, node: 2708, level: 7" node_number="2708">Voice Activity Detection (VAD) is a fundamental preprocessing step in automatic speech recognition. This is especially true within the broadcast industry where a wide variety of audio materials and recording conditions are encountered. Based on previous studies which indicate that xvector embeddings can be applied to a diverse set of audio classification tasks, we investigate the suitability of x-vectors in discriminating speech from noise. We find that the proposed x-vector based VAD system achieves the best reported score in detecting clean speech on AVA-Speech, whilst retaining robust VAD performance in the presence of noise and music. Furthermore, we integrate the x-vector based VAD system into an existing STT pipeline and compare its performance on multiple broadcast datasets against a baseline system with WebRTC VAD. Crucially, our proposed x-vector based VAD improves the accuracy of STT transcription on real-world broadcast audio </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2709, level: 5" node_number="2709">[243] arXiv:2112.05020 (cross-list from math.OC) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2710, level: 5" node_number="2710"> <div class="valid" valid="valid" title="valid: True, node: 2711, level: 6" node_number="2711"> <div class="valid" valid="valid" title="valid: True, node: 2712, level: 7" node_number="2712"> Title: A Preconditioned Inexact Active-Set Method for Large-Scale Nonlinear Optimal Control Problems </div> <div class="valid" valid="valid" title="valid: True, node: 2713, level: 7" node_number="2713"> Authors: John W. Pearson, <a class="valid" valid="valid" title="valid: True, node: 2714, level: 8" node_number="2714">Andreas Potschka</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2715, level: 7" node_number="2715"> Comments: 26 pages </div> <div class="valid" valid="valid" title="valid: True, node: 2716, level: 7" node_number="2716"> Subjects: Optimization and Control (math.OC); Numerical Analysis (math.NA) </div> <p class="valid" valid="valid" title="valid: True, node: 2717, level: 7" node_number="2717">We provide a global convergence proof of the recently proposed sequential homotopy method with an inexact Krylov--semismooth-Newton method employed as a local solver. The resulting method constitutes an active-set method in function space. After discretization, it allows for efficient application of Krylov-subspace methods. For a certain class of optimal control problems with PDE constraints, in which the control enters the Lagrangian only linearly, we propose and analyze an efficient, parallelizable, symmetric positive definite preconditioner based on a double Schur complement approach. We conclude with numerical results for a badly conditioned and highly nonlinear benchmark optimization problem with elliptic partial differential equations and control bounds. The resulting method is faster than using direct linear algebra for the 2D benchmark and allows for the parallel solution of large 3D problems. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2718, level: 5" node_number="2718">[244] arXiv:2112.05042 (cross-list from math.CO) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2719, level: 5" node_number="2719"> <div class="valid" valid="valid" title="valid: True, node: 2720, level: 6" node_number="2720"> <div class="valid" valid="valid" title="valid: True, node: 2721, level: 7" node_number="2721"> Title: A solution to Ringel's circle problem </div> <div class="valid" valid="valid" title="valid: True, node: 2722, level: 7" node_number="2722"> Authors: James Davies, Chaya Keller, <a class="valid" valid="valid" title="valid: True, node: 2723, level: 8" node_number="2723">Linda Kleist</a>, <a class="valid" valid="valid" title="valid: True, node: 2724, level: 8" node_number="2724">Shakhar Smorodinsky</a>, <a class="valid" valid="valid" title="valid: True, node: 2725, level: 8" node_number="2725">Bartosz Walczak</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2726, level: 7" node_number="2726"> Comments: 14 pages, 5 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2727, level: 7" node_number="2727"> Subjects: Combinatorics (math.CO); Discrete Mathematics (cs.DM) </div> <p class="valid" valid="valid" title="valid: True, node: 2728, level: 7" node_number="2728">We construct families of circles in the plane such that their tangency graphs have arbitrarily large girth and chromatic number. This provides a strong negative answer to Ringel's circle problem (1959). The proof relies on a (multidimensional) version of Gallai's theorem with polynomial constraints, which we derive from the Hales-Jewett theorem and which may be of independent interest. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2729, level: 5" node_number="2729">[245] arXiv:2112.05074 (cross-list from math.AG) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2730, level: 5" node_number="2730"> <div class="valid" valid="valid" title="valid: True, node: 2731, level: 6" node_number="2731"> <div class="valid" valid="valid" title="valid: True, node: 2732, level: 7" node_number="2732"> Title: Critical configurations for two projective views, a new approach </div> <div class="valid" valid="valid" title="valid: True, node: 2733, level: 7" node_number="2733"> Authors: Martin Br&#229;telund </div> <div class="valid" valid="valid" title="valid: True, node: 2734, level: 7" node_number="2734"> Comments: 22 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2735, level: 7" node_number="2735"> Subjects: Algebraic Geometry (math.AG); Computer Vision and Pattern Recognition (cs.CV) </div> <p class="valid" valid="valid" title="valid: True, node: 2736, level: 7" node_number="2736">The problem of structure from motion is concerned with recovering 3-dimensional structure of an object from a set of 2-dimensional images. Generally, all information can be uniquely recovered if enough images and image points are provided, but there are certain cases where unique recovery is impossible; these are called critical configurations. In this paper we use an algebraic approach to study the critical configurations for two projective cameras. We show that all critical configurations lie on quadric surfaces, and classify exactly which quadrics constitute a critical configuration. The paper also describes the relation between the different reconstructions when unique reconstruction is impossible. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2737, level: 5" node_number="2737">[246] arXiv:2112.05082 (cross-list from eess.SP) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2738, level: 5" node_number="2738"> <div class="valid" valid="valid" title="valid: True, node: 2739, level: 6" node_number="2739"> <div class="valid" valid="valid" title="valid: True, node: 2740, level: 7" node_number="2740"> Title: Fast Electromagnetic Validations of Large-Scale Digital Coding Metasurfaces Accelerated by Recurrence Rebuild and Retrieval Method </div> <div class="valid" valid="valid" title="valid: True, node: 2741, level: 7" node_number="2741"> Authors: Yu Zhao, <a class="valid" valid="valid" title="valid: True, node: 2742, level: 8" node_number="2742">Shang Xiang</a>, <a class="valid" valid="valid" title="valid: True, node: 2743, level: 8" node_number="2743">Long Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2744, level: 7" node_number="2744"> Subjects: Signal Processing (eess.SP); Computational Engineering, Finance, and Science (cs.CE) </div> <p class="valid" valid="valid" title="valid: True, node: 2745, level: 7" node_number="2745">The recurrence rebuild and retrieval method (R3M) is proposed in this paper to accelerate the electromagnetic (EM) validations of large-scale digital coding metasurfaces (DCMs). R3M aims to accelerate the EM validations of DCMs with varied codebooks, which involves the analysis of a group of similar but distinct coding patterns. The method transforms general DCMs to rigorously periodic arrays by replacing each coding unit with the macro unit, which comprises all possible coding states. The system matrix corresponding to the rigorously periodic array is globally shared for DCMs with arbitrary codebooks via implicit retrieval. The discrepancy of the interactions for edge and corner units are precluded by the basis extension of periodic boundaries. Moreover, the hierarchical pattern exploitation algorithm is leveraged to efficiently assemble the system matrix for further acceleration. Due to the fully utilization of the rigid periodicity, the computational complexity of R3M is theoretically lower than that of $\mathcal{H}$-matrix within the same paradigm. Numerical results for two types of DCMs indicate that R3M is accurate in comparison with commercial software. Besides, R3M is also compatible with the preconditioning for efficient iterative solutions. The efficiency of R3M for DCMs outperforms the conventional fast algorithms by a large margin in both the storage and CPU time cost. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2746, level: 5" node_number="2746">[247] arXiv:2112.05095 (cross-list from stat.ML) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2747, level: 5" node_number="2747"> <div class="valid" valid="valid" title="valid: True, node: 2748, level: 6" node_number="2748"> <div class="valid" valid="valid" title="valid: True, node: 2749, level: 7" node_number="2749"> Title: Provable Continual Learning via Sketched Jacobian Approximations </div> <div class="valid" valid="valid" title="valid: True, node: 2750, level: 7" node_number="2750"> Authors: Reinhard Heckel </div> <div class="valid" valid="valid" title="valid: True, node: 2751, level: 7" node_number="2751"> Subjects: Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2752, level: 7" node_number="2752">An important problem in machine learning is the ability to learn tasks in a sequential manner. If trained with standard first-order methods most models forget previously learned tasks when trained on a new task, which is often referred to as catastrophic forgetting. A popular approach to overcome forgetting is to regularize the loss function by penalizing models that perform poorly on previous tasks. For example, elastic weight consolidation (EWC) regularizes with a quadratic form involving a diagonal matrix build based on past data. While EWC works very well for some setups, we show that, even under otherwise ideal conditions, it can provably suffer catastrophic forgetting if the diagonal matrix is a poor approximation of the Hessian matrix of previous tasks. We propose a simple approach to overcome this: Regularizing training of a new task with sketches of the Jacobian matrix of past data. This provably enables overcoming catastrophic forgetting for linear models and for wide neural networks, at the cost of memory. The overarching goal of this paper is to provided insights on when regularization-based continual learning algorithms work and under what memory costs. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2753, level: 5" node_number="2753">[248] arXiv:2112.05104 (cross-list from math.OC) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2754, level: 5" node_number="2754"> <div class="valid" valid="valid" title="valid: True, node: 2755, level: 6" node_number="2755"> <div class="valid" valid="valid" title="valid: True, node: 2756, level: 7" node_number="2756"> Title: Continuation Path with Linear Convergence Rate </div> <div class="valid" valid="valid" title="valid: True, node: 2757, level: 7" node_number="2757"> Authors: Eugene Ndiaye, <a class="valid" valid="valid" title="valid: True, node: 2758, level: 8" node_number="2758">Ichiro Takeuchi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2759, level: 7" node_number="2759"> Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2760, level: 7" node_number="2760">Path-following algorithms are frequently used in composite optimization problems where a series of subproblems, with varying regularization hyperparameters, are solved sequentially. By reusing the previous solutions as initialization, better convergence speeds have been observed numerically. This makes it a rather useful heuristic to speed up the execution of optimization algorithms in machine learning. We present a primal dual analysis of the path-following algorithm and explore how to design its hyperparameters as well as determining how accurately each subproblem should be solved to guarantee a linear convergence rate on a target problem. Furthermore, considering optimization with a sparsity-inducing penalty, we analyze the change of the active sets with respect to the regularization parameter. The latter can then be adaptively calibrated to finely determine the number of features that will be selected along the solution path. This leads to simple heuristics for calibrating hyperparameters of active set approaches to reduce their complexity and improve their execution time. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2761, level: 5" node_number="2761">[249] arXiv:2112.05120 (cross-list from stat.ML) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2762, level: 5" node_number="2762"> <div class="valid" valid="valid" title="valid: True, node: 2763, level: 6" node_number="2763"> <div class="valid" valid="valid" title="valid: True, node: 2764, level: 7" node_number="2764"> Title: On Convergence of Federated Averaging Langevin Dynamics </div> <div class="valid" valid="valid" title="valid: True, node: 2765, level: 7" node_number="2765"> Authors: Wei Deng, <a class="valid" valid="valid" title="valid: True, node: 2766, level: 8" node_number="2766">Yi-An Ma</a>, <a class="valid" valid="valid" title="valid: True, node: 2767, level: 8" node_number="2767">Zhao Song</a>, <a class="valid" valid="valid" title="valid: True, node: 2768, level: 8" node_number="2768">Qian Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2769, level: 8" node_number="2769">Guang Lin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2770, level: 7" node_number="2770"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2771, level: 7" node_number="2771">We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions with distributed clients. In particular, we generalize beyond normal posterior distributions and consider a general class of models. We develop theoretical guarantees for FA-LD for strongly log-concave distributions with non-i.i.d data and study how the injected noise and the stochastic-gradient noise, the heterogeneity of data, and the varying learning rates affect the convergence. Such an analysis sheds light on the optimal choice of local updates to minimize communication costs. Important to our approach is that the communication efficiency does not deteriorate with the injected noise in the Langevin algorithms. In addition, we examine in our FA-LD algorithm both independent and correlated noise used over different clients. We observe that there is also a trade-off between federation and communication cost there. As local devices may become inactive in the federated network, we also show convergence results based on different averaging schemes where only partial device updates are available. </p> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2772, level: 5" node_number="2772">[250] arXiv:2112.05128 (cross-list from stat.ML) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2773, level: 5" node_number="2773"> <div class="valid" valid="valid" title="valid: True, node: 2774, level: 6" node_number="2774"> <div class="valid" valid="valid" title="valid: True, node: 2775, level: 7" node_number="2775"> Title: Fair Structure Learning in Heterogeneous Graphical Models </div> <div class="valid" valid="valid" title="valid: True, node: 2776, level: 7" node_number="2776"> Authors: Davoud Ataee Tarzanagh, <a class="valid" valid="valid" title="valid: True, node: 2777, level: 8" node_number="2777">Laura Balzano</a>, <a class="valid" valid="valid" title="valid: True, node: 2778, level: 8" node_number="2778">Alfred O. Hero</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2779, level: 7" node_number="2779"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> <p class="valid" valid="valid" title="valid: True, node: 2780, level: 7" node_number="2780">Inference of community structure in probabilistic graphical models may not be consistent with fairness constraints when nodes have demographic attributes. Certain demographics may be over-represented in some detected communities and under-represented in others. This paper defines a novel $\ell_1$-regularized pseudo-likelihood approach for fair graphical model selection. In particular, we assume there is some community or clustering structure in the true underlying graph, and we seek to learn a sparse undirected graph and its communities from the data such that demographic groups are fairly represented within the communities. Our optimization approach uses the demographic parity definition of fairness, but the framework is easily extended to other definitions of fairness. We establish statistical consistency of the proposed method for both a Gaussian graphical model and an Ising model for, respectively, continuous and binary data, proving that our method can recover the graphs and their fair communities with high probability. </p> </div> </dd> </dl> <h3 class="valid" valid="valid" title="valid: True, node: 2781, level: 4" node_number="2781">Replacements for Fri, 10 Dec 21</h3> <dl class="valid" valid="valid" title="valid: True, node: 2782, level: 4" node_number="2782"> <dt class="valid" valid="valid" title="valid: True, node: 2783, level: 5" node_number="2783">[251] arXiv:1411.2785 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2784, level: 5" node_number="2784"> <div class="valid" valid="valid" title="valid: True, node: 2785, level: 6" node_number="2785"> <div class="valid" valid="valid" title="valid: True, node: 2786, level: 7" node_number="2786"> Title: Faster Compressed Quadtrees </div> <div class="valid" valid="valid" title="valid: True, node: 2787, level: 7" node_number="2787"> Authors: Guillermo de Bernardo, <a class="valid" valid="valid" title="valid: True, node: 2788, level: 8" node_number="2788">Travis Gagie</a>, <a class="valid" valid="valid" title="valid: True, node: 2789, level: 8" node_number="2789">Susana Ladra</a>, <a class="valid" valid="valid" title="valid: True, node: 2790, level: 8" node_number="2790">Gonzalo Navarro</a>, <a class="valid" valid="valid" title="valid: True, node: 2791, level: 8" node_number="2791">Diego Seco</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2792, level: 7" node_number="2792"> Comments: Journal version of DCC '15 paper </div> <div class="valid" valid="valid" title="valid: True, node: 2793, level: 7" node_number="2793"> Subjects: Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2794, level: 5" node_number="2794">[252] arXiv:1805.07984 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2795, level: 5" node_number="2795"> <div class="valid" valid="valid" title="valid: True, node: 2796, level: 6" node_number="2796"> <div class="valid" valid="valid" title="valid: True, node: 2797, level: 7" node_number="2797"> Title: Adversarial Attacks on Neural Networks for Graph Data </div> <div class="valid" valid="valid" title="valid: True, node: 2798, level: 7" node_number="2798"> Authors: Daniel Z&#252;gner, <a class="valid" valid="valid" title="valid: True, node: 2799, level: 8" node_number="2799">Amir Akbarnejad</a>, <a class="valid" valid="valid" title="valid: True, node: 2800, level: 8" node_number="2800">Stephan G&#252;nnemann</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2801, level: 7" node_number="2801"> Comments: Accepted as a full paper at KDD 2018 on May 6, 2018 </div> <div class="valid" valid="valid" title="valid: True, node: 2802, level: 7" node_number="2802"> Journal-ref: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery Data Mining, KDD 2018, pp. 2847-2856 </div> <div class="valid" valid="valid" title="valid: True, node: 2803, level: 7" node_number="2803"> Subjects: Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2804, level: 5" node_number="2804">[253] arXiv:1901.06234 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2805, level: 5" node_number="2805"> <div class="valid" valid="valid" title="valid: True, node: 2806, level: 6" node_number="2806"> <div class="valid" valid="valid" title="valid: True, node: 2807, level: 7" node_number="2807"> Title: SPARCs for Unsourced Random Access </div> <div class="valid" valid="valid" title="valid: True, node: 2808, level: 7" node_number="2808"> Authors: Alexander Fengler, <a class="valid" valid="valid" title="valid: True, node: 2809, level: 8" node_number="2809">Peter Jung</a>, <a class="valid" valid="valid" title="valid: True, node: 2810, level: 8" node_number="2810">Giuseppe Caire</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2811, level: 7" node_number="2811"> Comments: v3: Corrected some errors in Thm 2 and 4, v2: Major revision; Parts of this work have been presented at ISIT 2019 and ISIT 2020 </div> <div class="valid" valid="valid" title="valid: True, node: 2812, level: 7" node_number="2812"> Journal-ref: IEEE Transactions on Information Theory, vol. 67, no. 10, pp. 6894-6915, Oct. 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 2813, level: 7" node_number="2813"> Subjects: Information Theory (cs.IT) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2814, level: 5" node_number="2814">[254] arXiv:1902.10905 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2815, level: 5" node_number="2815"> <div class="valid" valid="valid" title="valid: True, node: 2816, level: 6" node_number="2816"> <div class="valid" valid="valid" title="valid: True, node: 2817, level: 7" node_number="2817"> Title: PixelSteganalysis: Pixel-wise Hidden Information Removal with Low Visual Degradation </div> <div class="valid" valid="valid" title="valid: True, node: 2818, level: 7" node_number="2818"> Authors: Dahuin Jung, <a class="valid" valid="valid" title="valid: True, node: 2819, level: 8" node_number="2819">Ho Bae</a>, <a class="valid" valid="valid" title="valid: True, node: 2820, level: 8" node_number="2820">Hyun-Soo Choi</a>, <a class="valid" valid="valid" title="valid: True, node: 2821, level: 8" node_number="2821">Sungroh Yoon</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2822, level: 7" node_number="2822"> Comments: IEEE TDSC </div> <div class="valid" valid="valid" title="valid: True, node: 2823, level: 7" node_number="2823"> Subjects: Multimedia (cs.MM); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2824, level: 5" node_number="2824">[255] arXiv:1905.07718 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2825, level: 5" node_number="2825"> <div class="valid" valid="valid" title="valid: True, node: 2826, level: 6" node_number="2826"> <div class="valid" valid="valid" title="valid: True, node: 2827, level: 7" node_number="2827"> Title: Geometric Pose Affordance: 3D Human Pose with Scene Constraints </div> <div class="valid" valid="valid" title="valid: True, node: 2828, level: 7" node_number="2828"> Authors: Zhe Wang, <a class="valid" valid="valid" title="valid: True, node: 2829, level: 8" node_number="2829">Liyan Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2830, level: 8" node_number="2830">Shaurya Rathore</a>, <a class="valid" valid="valid" title="valid: True, node: 2831, level: 8" node_number="2831">Daeyun Shin</a>, <a class="valid" valid="valid" title="valid: True, node: 2832, level: 8" node_number="2832">Charless Fowlkes</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2833, level: 7" node_number="2833"> Comments: $\href{<a class="valid" valid="valid" title="valid: True, node: 2834, level: 8" node_number="2834">this https URL</a>}{Project Page}$, in submission to CVIU </div> <div class="valid" valid="valid" title="valid: True, node: 2835, level: 7" node_number="2835"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2836, level: 5" node_number="2836">[256] arXiv:1905.10711 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2837, level: 5" node_number="2837"> <div class="valid" valid="valid" title="valid: True, node: 2838, level: 6" node_number="2838"> <div class="valid" valid="valid" title="valid: True, node: 2839, level: 7" node_number="2839"> Title: DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction </div> <div class="valid" valid="valid" title="valid: True, node: 2840, level: 7" node_number="2840"> Authors: Qiangeng Xu, <a class="valid" valid="valid" title="valid: True, node: 2841, level: 8" node_number="2841">Weiyue Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 2842, level: 8" node_number="2842">Duygu Ceylan</a>, <a class="valid" valid="valid" title="valid: True, node: 2843, level: 8" node_number="2843">Radomir Mech</a>, <a class="valid" valid="valid" title="valid: True, node: 2844, level: 8" node_number="2844">Ulrich Neumann</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2845, level: 7" node_number="2845"> Journal-ref: 33rd Annual Conference on Neural Information Processing Systems (NeurIPS 2019) </div> <div class="valid" valid="valid" title="valid: True, node: 2846, level: 7" node_number="2846"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2847, level: 5" node_number="2847">[257] arXiv:1905.12346 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2848, level: 5" node_number="2848"> <div class="valid" valid="valid" title="valid: True, node: 2849, level: 6" node_number="2849"> <div class="valid" valid="valid" title="valid: True, node: 2850, level: 7" node_number="2850"> Title: Nystr&#246;m landmark sampling and regularized Christoffel functions </div> <div class="valid" valid="valid" title="valid: True, node: 2851, level: 7" node_number="2851"> Authors: Micha&#235;l Fanuel, <a class="valid" valid="valid" title="valid: True, node: 2852, level: 8" node_number="2852">Joachim Schreurs</a>, <a class="valid" valid="valid" title="valid: True, node: 2853, level: 8" node_number="2853">Johan A.K. Suykens</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2854, level: 7" node_number="2854"> Comments: More details in the proofs. Typos corrected </div> <div class="valid" valid="valid" title="valid: True, node: 2855, level: 7" node_number="2855"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2856, level: 5" node_number="2856">[258] arXiv:1906.06397 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2857, level: 5" node_number="2857"> <div class="valid" valid="valid" title="valid: True, node: 2858, level: 6" node_number="2858"> <div class="valid" valid="valid" title="valid: True, node: 2859, level: 7" node_number="2859"> Title: Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations </div> <div class="valid" valid="valid" title="valid: True, node: 2860, level: 7" node_number="2860"> Authors: Rohan Paleja, <a class="valid" valid="valid" title="valid: True, node: 2861, level: 8" node_number="2861">Andrew Silva</a>, <a class="valid" valid="valid" title="valid: True, node: 2862, level: 8" node_number="2862">Letian Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2863, level: 8" node_number="2863">Matthew Gombolay</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2864, level: 7" node_number="2864"> Journal-ref: Proceedings of the 34th International Conference on Neural Information Processing Systems 2020, 6417-6428 </div> <div class="valid" valid="valid" title="valid: True, node: 2865, level: 7" node_number="2865"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2866, level: 5" node_number="2866">[259] arXiv:1906.10462 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2867, level: 5" node_number="2867"> <div class="valid" valid="valid" title="valid: True, node: 2868, level: 6" node_number="2868"> <div class="valid" valid="valid" title="valid: True, node: 2869, level: 7" node_number="2869"> Title: Policy Optimization with Stochastic Mirror Descent </div> <div class="valid" valid="valid" title="valid: True, node: 2870, level: 7" node_number="2870"> Authors: Long Yang, <a class="valid" valid="valid" title="valid: True, node: 2871, level: 8" node_number="2871">Yu Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 2872, level: 8" node_number="2872">Gang Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 2873, level: 8" node_number="2873">Qian Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 2874, level: 8" node_number="2874">Pengfei Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2875, level: 8" node_number="2875">Jun Wen</a>, <a class="valid" valid="valid" title="valid: True, node: 2876, level: 8" node_number="2876">Gang Pan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2877, level: 7" node_number="2877"> Journal-ref: AAAI2022 </div> <div class="valid" valid="valid" title="valid: True, node: 2878, level: 7" node_number="2878"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2879, level: 5" node_number="2879">[260] arXiv:1912.10784 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2880, level: 5" node_number="2880"> <div class="valid" valid="valid" title="valid: True, node: 2881, level: 6" node_number="2881"> <div class="valid" valid="valid" title="valid: True, node: 2882, level: 7" node_number="2882"> Title: An improper estimator with optimal excess risk in misspecified density estimation and logistic regression </div> <div class="valid" valid="valid" title="valid: True, node: 2883, level: 7" node_number="2883"> Authors: Jaouad Mourtada, <a class="valid" valid="valid" title="valid: True, node: 2884, level: 8" node_number="2884">St&#233;phane Ga&#239;ffas</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2885, level: 7" node_number="2885"> Comments: 43 pages, minor revision </div> <div class="valid" valid="valid" title="valid: True, node: 2886, level: 7" node_number="2886"> Subjects: Statistics Theory (math.ST); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2887, level: 5" node_number="2887">[261] arXiv:2003.03710 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2888, level: 5" node_number="2888"> <div class="valid" valid="valid" title="valid: True, node: 2889, level: 6" node_number="2889"> <div class="valid" valid="valid" title="valid: True, node: 2890, level: 7" node_number="2890"> Title: Trajectory Grouping with Curvature Regularization for Tubular Structure Tracking </div> <div class="valid" valid="valid" title="valid: True, node: 2891, level: 7" node_number="2891"> Authors: Li Liu, <a class="valid" valid="valid" title="valid: True, node: 2892, level: 8" node_number="2892">Da Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 2893, level: 8" node_number="2893">Minglei Shu</a>, <a class="valid" valid="valid" title="valid: True, node: 2894, level: 8" node_number="2894">Baosheng Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2895, level: 8" node_number="2895">Huazhong Shu</a>, <a class="valid" valid="valid" title="valid: True, node: 2896, level: 8" node_number="2896">Michel Paques</a>, <a class="valid" valid="valid" title="valid: True, node: 2897, level: 8" node_number="2897">Laurent D. Cohen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2898, level: 7" node_number="2898"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2899, level: 5" node_number="2899">[262] arXiv:2003.07695 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2900, level: 5" node_number="2900"> <div class="valid" valid="valid" title="valid: True, node: 2901, level: 6" node_number="2901"> <div class="valid" valid="valid" title="valid: True, node: 2902, level: 7" node_number="2902"> Title: Online Assortment and Market Segmentation under Bertrand Competition with Set-Dependent Revenues </div> <div class="valid" valid="valid" title="valid: True, node: 2903, level: 7" node_number="2903"> Authors: S. Rasoul Etesami </div> <div class="valid" valid="valid" title="valid: True, node: 2904, level: 7" node_number="2904"> Subjects: Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2905, level: 5" node_number="2905">[263] arXiv:2003.12112 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2906, level: 5" node_number="2906"> <div class="valid" valid="valid" title="valid: True, node: 2907, level: 6" node_number="2907"> <div class="valid" valid="valid" title="valid: True, node: 2908, level: 7" node_number="2908"> Title: The Network Dynamics of Social and Technological Conventions </div> <div class="valid" valid="valid" title="valid: True, node: 2909, level: 7" node_number="2909"> Authors: Joshua Becker </div> <div class="valid" valid="valid" title="valid: True, node: 2910, level: 7" node_number="2910"> Comments: 21 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2911, level: 7" node_number="2911"> Subjects: Physics and Society (physics.soc-ph); Social and Information Networks (cs.SI); General Economics (econ.GN) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2912, level: 5" node_number="2912">[264] arXiv:2004.07861 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2913, level: 5" node_number="2913"> <div class="valid" valid="valid" title="valid: True, node: 2914, level: 6" node_number="2914"> <div class="valid" valid="valid" title="valid: True, node: 2915, level: 7" node_number="2915"> Title: The Co-Production of Service: Modeling Service Times in Contact Centers Using Hawkes Processes </div> <div class="valid" valid="valid" title="valid: True, node: 2916, level: 7" node_number="2916"> Authors: Andrew Daw, Antonio Castellanos, <a class="valid" valid="valid" title="valid: True, node: 2917, level: 8" node_number="2917">Galit B. Yom-Tov</a>, <a class="valid" valid="valid" title="valid: True, node: 2918, level: 8" node_number="2918">Jamol Pender</a>, <a class="valid" valid="valid" title="valid: True, node: 2919, level: 8" node_number="2919">Leor Gruendlinger</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2920, level: 7" node_number="2920"> Subjects: Social and Information Networks (cs.SI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2921, level: 5" node_number="2921">[265] arXiv:2005.08551 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2922, level: 5" node_number="2922"> <div class="valid" valid="valid" title="valid: True, node: 2923, level: 6" node_number="2923"> <div class="valid" valid="valid" title="valid: True, node: 2924, level: 7" node_number="2924"> Title: Omni-supervised Facial Expression Recognition via Distilled Data </div> <div class="valid" valid="valid" title="valid: True, node: 2925, level: 7" node_number="2925"> Authors: Ping Liu, <a class="valid" valid="valid" title="valid: True, node: 2926, level: 8" node_number="2926">Yunchao Wei</a>, <a class="valid" valid="valid" title="valid: True, node: 2927, level: 8" node_number="2927">Zibo Meng</a>, <a class="valid" valid="valid" title="valid: True, node: 2928, level: 8" node_number="2928">Weihong Deng</a>, <a class="valid" valid="valid" title="valid: True, node: 2929, level: 8" node_number="2929">Joey Tianyi Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 2930, level: 8" node_number="2930">Yi Yang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2931, level: 7" node_number="2931"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2932, level: 5" node_number="2932">[266] arXiv:2006.00808 (replaced) [src]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2933, level: 5" node_number="2933"> <div class="valid" valid="valid" title="valid: True, node: 2934, level: 6" node_number="2934"> <div class="valid" valid="valid" title="valid: True, node: 2935, level: 7" node_number="2935"> Title: Note to "An efficient Data Structure for Lattice Operation" </div> <div class="valid" valid="valid" title="valid: True, node: 2936, level: 7" node_number="2936"> Authors: Maurizio Talamo, <a class="valid" valid="valid" title="valid: True, node: 2937, level: 8" node_number="2937">Paola Vocca</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2938, level: 7" node_number="2938"> Comments: There is one error that I have to ammend </div> <div class="valid" valid="valid" title="valid: True, node: 2939, level: 7" node_number="2939"> Subjects: Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2940, level: 5" node_number="2940">[267] arXiv:2006.01578 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2941, level: 5" node_number="2941"> <div class="valid" valid="valid" title="valid: True, node: 2942, level: 6" node_number="2942"> <div class="valid" valid="valid" title="valid: True, node: 2943, level: 7" node_number="2943"> Title: Deep Learning in Target Space </div> <div class="valid" valid="valid" title="valid: True, node: 2944, level: 7" node_number="2944"> Authors: Michael Fairbank, <a class="valid" valid="valid" title="valid: True, node: 2945, level: 8" node_number="2945">Spyridon Samothrakis</a>, <a class="valid" valid="valid" title="valid: True, node: 2946, level: 8" node_number="2946">Luca Citi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2947, level: 7" node_number="2947"> Subjects: Neural and Evolutionary Computing (cs.NE) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2948, level: 5" node_number="2948">[268] arXiv:2007.13437 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2949, level: 5" node_number="2949"> <div class="valid" valid="valid" title="valid: True, node: 2950, level: 6" node_number="2950"> <div class="valid" valid="valid" title="valid: True, node: 2951, level: 7" node_number="2951"> Title: Energy-based View of Retrosynthesis </div> <div class="valid" valid="valid" title="valid: True, node: 2952, level: 7" node_number="2952"> Authors: Ruoxi Sun, <a class="valid" valid="valid" title="valid: True, node: 2953, level: 8" node_number="2953">Hanjun Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 2954, level: 8" node_number="2954">Li Li</a>, <a class="valid" valid="valid" title="valid: True, node: 2955, level: 8" node_number="2955">Steven Kearnes</a>, <a class="valid" valid="valid" title="valid: True, node: 2956, level: 8" node_number="2956">Bo Dai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2957, level: 7" node_number="2957"> Subjects: Chemical Physics (physics.chem-ph); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2958, level: 5" node_number="2958">[269] arXiv:2007.14769 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2959, level: 5" node_number="2959"> <div class="valid" valid="valid" title="valid: True, node: 2960, level: 6" node_number="2960"> <div class="valid" valid="valid" title="valid: True, node: 2961, level: 7" node_number="2961"> Title: A convergence analysis of the price of anarchy in atomic congestion games </div> <div class="valid" valid="valid" title="valid: True, node: 2962, level: 7" node_number="2962"> Authors: Zijun Wu, <a class="valid" valid="valid" title="valid: True, node: 2963, level: 8" node_number="2963">Rolf H. Moehring</a>, <a class="valid" valid="valid" title="valid: True, node: 2964, level: 8" node_number="2964">Chunying Ren</a>, <a class="valid" valid="valid" title="valid: True, node: 2965, level: 8" node_number="2965">Dachuan Xu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2966, level: 7" node_number="2966"> Comments: 57 pages </div> <div class="valid" valid="valid" title="valid: True, node: 2967, level: 7" node_number="2967"> Subjects: Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2968, level: 5" node_number="2968">[270] arXiv:2008.04088 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2969, level: 5" node_number="2969"> <div class="valid" valid="valid" title="valid: True, node: 2970, level: 6" node_number="2970"> <div class="valid" valid="valid" title="valid: True, node: 2971, level: 7" node_number="2971"> Title: mpNet: variable depth unfolded neural network for massive MIMO channel estimation </div> <div class="valid" valid="valid" title="valid: True, node: 2972, level: 7" node_number="2972"> Authors: Taha Yassine (IRT b-com, Hypermedia), <a class="valid" valid="valid" title="valid: True, node: 2973, level: 8" node_number="2973">Luc Le Magoarou</a> (IRT b-com, Hypermedia) </div> <div class="valid" valid="valid" title="valid: True, node: 2974, level: 7" node_number="2974"> Subjects: Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2975, level: 5" node_number="2975">[271] arXiv:2008.08974 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2976, level: 5" node_number="2976"> <div class="valid" valid="valid" title="valid: True, node: 2977, level: 6" node_number="2977"> <div class="valid" valid="valid" title="valid: True, node: 2978, level: 7" node_number="2978"> Title: ISSAFE: Improving Semantic Segmentation in Accidents by Fusing Event-based Data </div> <div class="valid" valid="valid" title="valid: True, node: 2979, level: 7" node_number="2979"> Authors: Jiaming Zhang, <a class="valid" valid="valid" title="valid: True, node: 2980, level: 8" node_number="2980">Kailun Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 2981, level: 8" node_number="2981">Rainer Stiefelhagen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2982, level: 7" node_number="2982"> Comments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 2983, level: 7" node_number="2983"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2984, level: 5" node_number="2984">[272] arXiv:2008.12552 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2985, level: 5" node_number="2985"> <div class="valid" valid="valid" title="valid: True, node: 2986, level: 6" node_number="2986"> <div class="valid" valid="valid" title="valid: True, node: 2987, level: 7" node_number="2987"> Title: Probabilistic Random Indexing for Continuous Event Detection </div> <div class="valid" valid="valid" title="valid: True, node: 2988, level: 7" node_number="2988"> Authors: Yashank Singh, <a class="valid" valid="valid" title="valid: True, node: 2989, level: 8" node_number="2989">Niladri Chatterjee</a> </div> <div class="valid" valid="valid" title="valid: True, node: 2990, level: 7" node_number="2990"> Comments: 8 pages, 12 figures </div> <div class="valid" valid="valid" title="valid: True, node: 2991, level: 7" node_number="2991"> Subjects: Machine Learning (cs.LG); Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 2992, level: 5" node_number="2992">[273] arXiv:2009.01845 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 2993, level: 5" node_number="2993"> <div class="valid" valid="valid" title="valid: True, node: 2994, level: 6" node_number="2994"> <div class="valid" valid="valid" title="valid: True, node: 2995, level: 7" node_number="2995"> Title: Qibo: a framework for quantum simulation with hardware acceleration </div> <div class="valid" valid="valid" title="valid: True, node: 2996, level: 7" node_number="2996"> Authors: Stavros Efthymiou, Sergi Ramos-Calderer, <a class="valid" valid="valid" title="valid: True, node: 2997, level: 8" node_number="2997">Carlos Bravo-Prieto</a>, <a class="valid" valid="valid" title="valid: True, node: 2998, level: 8" node_number="2998">Adri&#225;n P&#233;rez-Salinas</a>, <a class="valid" valid="valid" title="valid: True, node: 2999, level: 8" node_number="2999">Diego Garc&#237;a-Mart&#237;n</a>, <a class="valid" valid="valid" title="valid: True, node: 3000, level: 8" node_number="3000">Artur Garcia-Saez</a>, <a class="valid" valid="valid" title="valid: True, node: 3001, level: 8" node_number="3001">Jos&#233; Ignacio Latorre</a>, <a class="valid" valid="valid" title="valid: True, node: 3002, level: 8" node_number="3002">Stefano Carrazza</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3003, level: 7" node_number="3003"> Comments: 15 pages, 12 figures, 5 tables,code available at <a class="valid" valid="valid" title="valid: True, node: 3004, level: 8" node_number="3004">this https URL</a>, final version published in QST </div> <div class="valid" valid="valid" title="valid: True, node: 3005, level: 7" node_number="3005"> Subjects: Quantum Physics (quant-ph); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3006, level: 5" node_number="3006">[274] arXiv:2009.08687 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3007, level: 5" node_number="3007"> <div class="valid" valid="valid" title="valid: True, node: 3008, level: 6" node_number="3008"> <div class="valid" valid="valid" title="valid: True, node: 3009, level: 7" node_number="3009"> Title: Chemical Property Prediction Under Experimental Biases </div> <div class="valid" valid="valid" title="valid: True, node: 3010, level: 7" node_number="3010"> Authors: Yang Liu, <a class="valid" valid="valid" title="valid: True, node: 3011, level: 8" node_number="3011">Hisashi Kashima</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3012, level: 7" node_number="3012"> Subjects: Quantitative Methods (q-bio.QM); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3013, level: 5" node_number="3013">[275] arXiv:2009.10007 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3014, level: 5" node_number="3014"> <div class="valid" valid="valid" title="valid: True, node: 3015, level: 6" node_number="3015"> <div class="valid" valid="valid" title="valid: True, node: 3016, level: 7" node_number="3016"> Title: Learning Realistic Patterns from Unrealistic Stimuli: Generalization and Data Anonymization </div> <div class="valid" valid="valid" title="valid: True, node: 3017, level: 7" node_number="3017"> Authors: Konstantinos Nikolaidis, <a class="valid" valid="valid" title="valid: True, node: 3018, level: 8" node_number="3018">Stein Kristiansen</a>, <a class="valid" valid="valid" title="valid: True, node: 3019, level: 8" node_number="3019">Thomas Plagemann</a>, <a class="valid" valid="valid" title="valid: True, node: 3020, level: 8" node_number="3020">Vera Goebel</a>, <a class="valid" valid="valid" title="valid: True, node: 3021, level: 8" node_number="3021">Knut Liest&#248;l</a>, <a class="valid" valid="valid" title="valid: True, node: 3022, level: 8" node_number="3022">Mohan Kankanhalli</a>, <a class="valid" valid="valid" title="valid: True, node: 3023, level: 8" node_number="3023">Gunn Marit Traaen</a>, <a class="valid" valid="valid" title="valid: True, node: 3024, level: 8" node_number="3024">Britt &#216;verland</a>, <a class="valid" valid="valid" title="valid: True, node: 3025, level: 8" node_number="3025">Harriet Akre</a>, <a class="valid" valid="valid" title="valid: True, node: 3026, level: 8" node_number="3026">Lars Aaker&#248;y</a>, <a class="valid" valid="valid" title="valid: True, node: 3027, level: 8" node_number="3027">Sigurd Steinshamn</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3028, level: 7" node_number="3028"> Journal-ref: Journal of Artificial Intelligence Research 72 (2021): 1163-1214 </div> <div class="valid" valid="valid" title="valid: True, node: 3029, level: 7" node_number="3029"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3030, level: 5" node_number="3030">[276] arXiv:2010.00145 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3031, level: 5" node_number="3031"> <div class="valid" valid="valid" title="valid: True, node: 3032, level: 6" node_number="3032"> <div class="valid" valid="valid" title="valid: True, node: 3033, level: 7" node_number="3033"> Title: Entropy Regularization for Mean Field Games with Learning </div> <div class="valid" valid="valid" title="valid: True, node: 3034, level: 7" node_number="3034"> Authors: Xin Guo, <a class="valid" valid="valid" title="valid: True, node: 3035, level: 8" node_number="3035">Renyuan Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 3036, level: 8" node_number="3036">Thaleia Zariphopoulou</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3037, level: 7" node_number="3037"> Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3038, level: 5" node_number="3038">[277] arXiv:2010.05998 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3039, level: 5" node_number="3039"> <div class="valid" valid="valid" title="valid: True, node: 3040, level: 6" node_number="3040"> <div class="valid" valid="valid" title="valid: True, node: 3041, level: 7" node_number="3041"> Title: Counting Subgraphs in Degenerate Graphs </div> <div class="valid" valid="valid" title="valid: True, node: 3042, level: 7" node_number="3042"> Authors: Suman K. Bera, <a class="valid" valid="valid" title="valid: True, node: 3043, level: 8" node_number="3043">Lior Gishboliner</a>, <a class="valid" valid="valid" title="valid: True, node: 3044, level: 8" node_number="3044">Yevgeny Levanzov</a>, <a class="valid" valid="valid" title="valid: True, node: 3045, level: 8" node_number="3045">C. Seshadhri</a>, <a class="valid" valid="valid" title="valid: True, node: 3046, level: 8" node_number="3046">Asaf Shapira</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3047, level: 7" node_number="3047"> Subjects: Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3048, level: 5" node_number="3048">[278] arXiv:2011.00628 (replaced) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3049, level: 5" node_number="3049"> <div class="valid" valid="valid" title="valid: True, node: 3050, level: 6" node_number="3050"> <div class="valid" valid="valid" title="valid: True, node: 3051, level: 7" node_number="3051"> Title: Brain Tumor Classification Using Medial Residual Encoder Layers </div> <div class="valid" valid="valid" title="valid: True, node: 3052, level: 7" node_number="3052"> Authors: Zahra SobhaniNia, <a class="valid" valid="valid" title="valid: True, node: 3053, level: 8" node_number="3053">Nader Karimi</a>, <a class="valid" valid="valid" title="valid: True, node: 3054, level: 8" node_number="3054">Pejman Khadivi</a>, <a class="valid" valid="valid" title="valid: True, node: 3055, level: 8" node_number="3055">Roshank Roshandel</a>, <a class="valid" valid="valid" title="valid: True, node: 3056, level: 8" node_number="3056">Shadrokh Samavi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3057, level: 7" node_number="3057"> Comments: 4 pages, 4 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3058, level: 7" node_number="3058"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3059, level: 5" node_number="3059">[279] arXiv:2011.04843 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3060, level: 5" node_number="3060"> <div class="valid" valid="valid" title="valid: True, node: 3061, level: 6" node_number="3061"> <div class="valid" valid="valid" title="valid: True, node: 3062, level: 7" node_number="3062"> Title: Multi-document Summarization via Deep Learning Techniques: A Survey </div> <div class="valid" valid="valid" title="valid: True, node: 3063, level: 7" node_number="3063"> Authors: Congbo Ma, <a class="valid" valid="valid" title="valid: True, node: 3064, level: 8" node_number="3064">Wei Emma Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3065, level: 8" node_number="3065">Mingyu Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 3066, level: 8" node_number="3066">Hu Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 3067, level: 8" node_number="3067">Quan Z. Sheng</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3068, level: 7" node_number="3068"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3069, level: 5" node_number="3069">[280] arXiv:2011.09168 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3070, level: 5" node_number="3070"> <div class="valid" valid="valid" title="valid: True, node: 3071, level: 6" node_number="3071"> <div class="valid" valid="valid" title="valid: True, node: 3072, level: 7" node_number="3072"> Title: Multiscale Scattering in Nonlinear Kerr-Type Media </div> <div class="valid" valid="valid" title="valid: True, node: 3073, level: 7" node_number="3073"> Authors: Roland Maier, <a class="valid" valid="valid" title="valid: True, node: 3074, level: 8" node_number="3074">Barbara Verf&#252;rth</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3075, level: 7" node_number="3075"> Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3076, level: 5" node_number="3076">[281] arXiv:2011.09588 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3077, level: 5" node_number="3077"> <div class="valid" valid="valid" title="valid: True, node: 3078, level: 6" node_number="3078"> <div class="valid" valid="valid" title="valid: True, node: 3079, level: 7" node_number="3079"> Title: Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification </div> <div class="valid" valid="valid" title="valid: True, node: 3080, level: 7" node_number="3080"> Authors: Youngseog Chung, Willie Neiswanger, <a class="valid" valid="valid" title="valid: True, node: 3081, level: 8" node_number="3081">Ian Char</a>, <a class="valid" valid="valid" title="valid: True, node: 3082, level: 8" node_number="3082">Jeff Schneider</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3083, level: 7" node_number="3083"> Comments: Appears in Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div class="valid" valid="valid" title="valid: True, node: 3084, level: 7" node_number="3084"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3085, level: 5" node_number="3085">[282] arXiv:2011.12984 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3086, level: 5" node_number="3086"> <div class="valid" valid="valid" title="valid: True, node: 3087, level: 6" node_number="3087"> <div class="valid" valid="valid" title="valid: True, node: 3088, level: 7" node_number="3088"> Title: Enabling GPU Accelerated Computing in the SUNDIALS Time Integration Library </div> <div class="valid" valid="valid" title="valid: True, node: 3089, level: 7" node_number="3089"> Authors: Cody J. Balos, <a class="valid" valid="valid" title="valid: True, node: 3090, level: 8" node_number="3090">David J. Gardner</a>, <a class="valid" valid="valid" title="valid: True, node: 3091, level: 8" node_number="3091">Carol S. Woodward</a>, <a class="valid" valid="valid" title="valid: True, node: 3092, level: 8" node_number="3092">Daniel R. Reynolds</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3093, level: 7" node_number="3093"> Journal-ref: Parallel Computing, Volume 108, 2021, 102836, ISSN 0167-8191 </div> <div class="valid" valid="valid" title="valid: True, node: 3094, level: 7" node_number="3094"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3095, level: 5" node_number="3095">[283] arXiv:2011.14473 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3096, level: 5" node_number="3096"> <div class="valid" valid="valid" title="valid: True, node: 3097, level: 6" node_number="3097"> <div class="valid" valid="valid" title="valid: True, node: 3098, level: 7" node_number="3098"> Title: Kinetics-Informed Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 3099, level: 7" node_number="3099"> Authors: Gabriel S. Gusm&#227;o, <a class="valid" valid="valid" title="valid: True, node: 3100, level: 8" node_number="3100">Adhika P. Retnanto</a>, <a class="valid" valid="valid" title="valid: True, node: 3101, level: 8" node_number="3101">Shashwati C. da Cunha</a>, <a class="valid" valid="valid" title="valid: True, node: 3102, level: 8" node_number="3102">Andrew J. Medford</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3103, level: 7" node_number="3103"> Comments: Pre-print for first submission </div> <div class="valid" valid="valid" title="valid: True, node: 3104, level: 7" node_number="3104"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3105, level: 5" node_number="3105">[284] arXiv:2012.04567 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3106, level: 5" node_number="3106"> <div class="valid" valid="valid" title="valid: True, node: 3107, level: 6" node_number="3107"> <div class="valid" valid="valid" title="valid: True, node: 3108, level: 7" node_number="3108"> Title: Bayesian Image Reconstruction using Deep Generative Models </div> <div class="valid" valid="valid" title="valid: True, node: 3109, level: 7" node_number="3109"> Authors: Razvan V Marinescu, <a class="valid" valid="valid" title="valid: True, node: 3110, level: 8" node_number="3110">Daniel Moyer</a>, <a class="valid" valid="valid" title="valid: True, node: 3111, level: 8" node_number="3111">Polina Golland</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3112, level: 7" node_number="3112"> Comments: 27 pages, 17 figures, 5 tables </div> <div class="valid" valid="valid" title="valid: True, node: 3113, level: 7" node_number="3113"> Journal-ref: NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications </div> <div class="valid" valid="valid" title="valid: True, node: 3114, level: 7" node_number="3114"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Image and Video Processing (eess.IV); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3115, level: 5" node_number="3115">[285] arXiv:2012.05062 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3116, level: 5" node_number="3116"> <div class="valid" valid="valid" title="valid: True, node: 3117, level: 6" node_number="3117"> <div class="valid" valid="valid" title="valid: True, node: 3118, level: 7" node_number="3118"> Title: Finite-dimensional observer-based PI regulation control of a reaction-diffusion equation </div> <div class="valid" valid="valid" title="valid: True, node: 3119, level: 7" node_number="3119"> Authors: Hugo Lhachemi, <a class="valid" valid="valid" title="valid: True, node: 3120, level: 8" node_number="3120">Christophe Prieur</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3121, level: 7" node_number="3121"> Subjects: Optimization and Control (math.OC); Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3122, level: 5" node_number="3122">[286] arXiv:2012.12868 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3123, level: 5" node_number="3123"> <div class="valid" valid="valid" title="valid: True, node: 3124, level: 6" node_number="3124"> <div class="valid" valid="valid" title="valid: True, node: 3125, level: 7" node_number="3125"> Title: Flat-Combining-Based Persistent Data Structures for Non-Volatile Memory </div> <div class="valid" valid="valid" title="valid: True, node: 3126, level: 7" node_number="3126"> Authors: Matan Rusanovsky, <a class="valid" valid="valid" title="valid: True, node: 3127, level: 8" node_number="3127">Hagit Attiya</a>, <a class="valid" valid="valid" title="valid: True, node: 3128, level: 8" node_number="3128">Ohad Ben-Baruch</a>, <a class="valid" valid="valid" title="valid: True, node: 3129, level: 8" node_number="3129">Tom Gerby</a>, <a class="valid" valid="valid" title="valid: True, node: 3130, level: 8" node_number="3130">Danny Hendler</a>, <a class="valid" valid="valid" title="valid: True, node: 3131, level: 8" node_number="3131">Pedro Ramalhete</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3132, level: 7" node_number="3132"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Operating Systems (cs.OS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3133, level: 5" node_number="3133">[287] arXiv:2012.13577 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3134, level: 5" node_number="3134"> <div class="valid" valid="valid" title="valid: True, node: 3135, level: 6" node_number="3135"> <div class="valid" valid="valid" title="valid: True, node: 3136, level: 7" node_number="3136"> Title: LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification </div> <div class="valid" valid="valid" title="valid: True, node: 3137, level: 7" node_number="3137"> Authors: Jiangjie Chen, <a class="valid" valid="valid" title="valid: True, node: 3138, level: 8" node_number="3138">Qiaoben Bao</a>, <a class="valid" valid="valid" title="valid: True, node: 3139, level: 8" node_number="3139">Changzhi Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 3140, level: 8" node_number="3140">Xinbo Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3141, level: 8" node_number="3141">Jiaze Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3142, level: 8" node_number="3142">Hao Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 3143, level: 8" node_number="3143">Yanghua Xiao</a>, <a class="valid" valid="valid" title="valid: True, node: 3144, level: 8" node_number="3144">Lei Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3145, level: 7" node_number="3145"> Comments: Accepted to AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 3146, level: 7" node_number="3146"> Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3147, level: 5" node_number="3147">[288] arXiv:2101.07009 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3148, level: 5" node_number="3148"> <div class="valid" valid="valid" title="valid: True, node: 3149, level: 6" node_number="3149"> <div class="valid" valid="valid" title="valid: True, node: 3150, level: 7" node_number="3150"> Title: Separating Polarization from Noise: Comparison and Normalization of Structural Polarization Measures </div> <div class="valid" valid="valid" title="valid: True, node: 3151, level: 7" node_number="3151"> Authors: Ali Salloum, <a class="valid" valid="valid" title="valid: True, node: 3152, level: 8" node_number="3152">Ted Hsuan Yun Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3153, level: 8" node_number="3153">Mikko Kivel&#228;</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3154, level: 7" node_number="3154"> Subjects: Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph); Applications (stat.AP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3155, level: 5" node_number="3155">[289] arXiv:2102.00487 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3156, level: 5" node_number="3156"> <div class="valid" valid="valid" title="valid: True, node: 3157, level: 6" node_number="3157"> <div class="valid" valid="valid" title="valid: True, node: 3158, level: 7" node_number="3158"> Title: Nonlinear Evolutionary PDE-Based Refinement of Optical Flow </div> <div class="valid" valid="valid" title="valid: True, node: 3159, level: 7" node_number="3159"> Authors: Hirak Doshi, <a class="valid" valid="valid" title="valid: True, node: 3160, level: 8" node_number="3160">N. Uday Kiran</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3161, level: 7" node_number="3161"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Analysis of PDEs (math.AP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3162, level: 5" node_number="3162">[290] arXiv:2102.01606 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3163, level: 5" node_number="3163"> <div class="valid" valid="valid" title="valid: True, node: 3164, level: 6" node_number="3164"> <div class="valid" valid="valid" title="valid: True, node: 3165, level: 7" node_number="3165"> Title: Structure-preserving Gaussian Process Dynamics </div> <div class="valid" valid="valid" title="valid: True, node: 3166, level: 7" node_number="3166"> Authors: Katharina Ensinger, <a class="valid" valid="valid" title="valid: True, node: 3167, level: 8" node_number="3167">Friedrich Solowjow</a>, <a class="valid" valid="valid" title="valid: True, node: 3168, level: 8" node_number="3168">Sebastian Ziesche</a>, <a class="valid" valid="valid" title="valid: True, node: 3169, level: 8" node_number="3169">Michael Tiemann</a>, <a class="valid" valid="valid" title="valid: True, node: 3170, level: 8" node_number="3170">Sebastian Trimpe</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3171, level: 7" node_number="3171"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3172, level: 5" node_number="3172">[291] arXiv:2102.04738 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3173, level: 5" node_number="3173"> <div class="valid" valid="valid" title="valid: True, node: 3174, level: 6" node_number="3174"> <div class="valid" valid="valid" title="valid: True, node: 3175, level: 7" node_number="3175"> Title: End-to-End Deep Learning of Lane Detection and Path Prediction for Real-Time Autonomous Driving </div> <div class="valid" valid="valid" title="valid: True, node: 3176, level: 7" node_number="3176"> Authors: Der-Hau Lee, <a class="valid" valid="valid" title="valid: True, node: 3177, level: 8" node_number="3177">Jinn-Liang Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3178, level: 7" node_number="3178"> Comments: 6 pages, 4 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3179, level: 7" node_number="3179"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3180, level: 5" node_number="3180">[292] arXiv:2102.07074 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3181, level: 5" node_number="3181"> <div class="valid" valid="valid" title="valid: True, node: 3182, level: 6" node_number="3182"> <div class="valid" valid="valid" title="valid: True, node: 3183, level: 7" node_number="3183"> Title: TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up </div> <div class="valid" valid="valid" title="valid: True, node: 3184, level: 7" node_number="3184"> Authors: Yifan Jiang, <a class="valid" valid="valid" title="valid: True, node: 3185, level: 8" node_number="3185">Shiyu Chang</a>, <a class="valid" valid="valid" title="valid: True, node: 3186, level: 8" node_number="3186">Zhangyang Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3187, level: 7" node_number="3187"> Comments: Accepted to NeruIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3188, level: 7" node_number="3188"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3189, level: 5" node_number="3189">[293] arXiv:2102.07148 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3190, level: 5" node_number="3190"> <div class="valid" valid="valid" title="valid: True, node: 3191, level: 6" node_number="3191"> <div class="valid" valid="valid" title="valid: True, node: 3192, level: 7" node_number="3192"> Title: A New Look and Convergence Rate of Federated Multi-Task Learning with Laplacian Regularization </div> <div class="valid" valid="valid" title="valid: True, node: 3193, level: 7" node_number="3193"> Authors: Canh T. Dinh, <a class="valid" valid="valid" title="valid: True, node: 3194, level: 8" node_number="3194">Tung T. Vu</a>, <a class="valid" valid="valid" title="valid: True, node: 3195, level: 8" node_number="3195">Nguyen H. Tran</a>, <a class="valid" valid="valid" title="valid: True, node: 3196, level: 8" node_number="3196">Minh N. Dao</a>, <a class="valid" valid="valid" title="valid: True, node: 3197, level: 8" node_number="3197">Hongyu Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3198, level: 7" node_number="3198"> Subjects: Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3199, level: 5" node_number="3199">[294] arXiv:2102.08138 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3200, level: 5" node_number="3200"> <div class="valid" valid="valid" title="valid: True, node: 3201, level: 6" node_number="3201"> <div class="valid" valid="valid" title="valid: True, node: 3202, level: 7" node_number="3202"> Title: IronMan: GNN-assisted Design Space Exploration in High-Level Synthesis via Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 3203, level: 7" node_number="3203"> Authors: Nan Wu, <a class="valid" valid="valid" title="valid: True, node: 3204, level: 8" node_number="3204">Yuan Xie</a>, <a class="valid" valid="valid" title="valid: True, node: 3205, level: 8" node_number="3205">Cong Hao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3206, level: 7" node_number="3206"> Journal-ref: GLSVLSI 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3207, level: 7" node_number="3207"> Subjects: Hardware Architecture (cs.AR); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3208, level: 5" node_number="3208">[295] arXiv:2102.09277 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3209, level: 5" node_number="3209"> <div class="valid" valid="valid" title="valid: True, node: 3210, level: 6" node_number="3210"> <div class="valid" valid="valid" title="valid: True, node: 3211, level: 7" node_number="3211"> Title: Locally Checkable Problems in Rooted Trees </div> <div class="valid" valid="valid" title="valid: True, node: 3212, level: 7" node_number="3212"> Authors: Alkida Balliu, <a class="valid" valid="valid" title="valid: True, node: 3213, level: 8" node_number="3213">Sebastian Brandt</a>, <a class="valid" valid="valid" title="valid: True, node: 3214, level: 8" node_number="3214">Yi-Jun Chang</a>, <a class="valid" valid="valid" title="valid: True, node: 3215, level: 8" node_number="3215">Dennis Olivetti</a>, <a class="valid" valid="valid" title="valid: True, node: 3216, level: 8" node_number="3216">Jan Studen&#253;</a>, <a class="valid" valid="valid" title="valid: True, node: 3217, level: 8" node_number="3217">Jukka Suomela</a>, <a class="valid" valid="valid" title="valid: True, node: 3218, level: 8" node_number="3218">Aleksandr Tereshchenko</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3219, level: 7" node_number="3219"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3220, level: 5" node_number="3220">[296] arXiv:2103.00167 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3221, level: 5" node_number="3221"> <div class="valid" valid="valid" title="valid: True, node: 3222, level: 6" node_number="3222"> <div class="valid" valid="valid" title="valid: True, node: 3223, level: 7" node_number="3223"> Title: Inferring Unobserved Events in Systems With Shared Resources and Queues </div> <div class="valid" valid="valid" title="valid: True, node: 3224, level: 7" node_number="3224"> Authors: Dirk Fahland, <a class="valid" valid="valid" title="valid: True, node: 3225, level: 8" node_number="3225">Vadim Denisov</a>, <a class="valid" valid="valid" title="valid: True, node: 3226, level: 8" node_number="3226">Wil. M.P. van der Aalst</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3227, level: 7" node_number="3227"> Comments: Final formatted version at Fundamenta Informatica </div> <div class="valid" valid="valid" title="valid: True, node: 3228, level: 7" node_number="3228"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Performance (cs.PF) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3229, level: 5" node_number="3229">[297] arXiv:2103.02313 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3230, level: 5" node_number="3230"> <div class="valid" valid="valid" title="valid: True, node: 3231, level: 6" node_number="3231"> <div class="valid" valid="valid" title="valid: True, node: 3232, level: 7" node_number="3232"> Title: Open community platform for hearing aid algorithm research: open Master Hearing Aid (openMHA) </div> <div class="valid" valid="valid" title="valid: True, node: 3233, level: 7" node_number="3233"> Authors: Hendrik Kayser, <a class="valid" valid="valid" title="valid: True, node: 3234, level: 8" node_number="3234">Tobias Herzke</a>, <a class="valid" valid="valid" title="valid: True, node: 3235, level: 8" node_number="3235">Paul Maanen</a>, <a class="valid" valid="valid" title="valid: True, node: 3236, level: 8" node_number="3236">Max Zimmermann</a>, <a class="valid" valid="valid" title="valid: True, node: 3237, level: 8" node_number="3237">Giso Grimm</a>, <a class="valid" valid="valid" title="valid: True, node: 3238, level: 8" node_number="3238">Volker Hohmann</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3239, level: 7" node_number="3239"> Comments: 29 pages, 5 figures, resubmitted to SoftwareX after revision </div> <div class="valid" valid="valid" title="valid: True, node: 3240, level: 7" node_number="3240"> Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3241, level: 5" node_number="3241">[298] arXiv:2103.02895 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3242, level: 5" node_number="3242"> <div class="valid" valid="valid" title="valid: True, node: 3243, level: 6" node_number="3243"> <div class="valid" valid="valid" title="valid: True, node: 3244, level: 7" node_number="3244"> Title: On the privacy-utility trade-off in differentially private hierarchical text classification </div> <div class="valid" valid="valid" title="valid: True, node: 3245, level: 7" node_number="3245"> Authors: Dominik Wunderlich, <a class="valid" valid="valid" title="valid: True, node: 3246, level: 8" node_number="3246">Daniel Bernau</a>, <a class="valid" valid="valid" title="valid: True, node: 3247, level: 8" node_number="3247">Francesco Ald&#224;</a>, <a class="valid" valid="valid" title="valid: True, node: 3248, level: 8" node_number="3248">Javier Parra-Arnau</a>, <a class="valid" valid="valid" title="valid: True, node: 3249, level: 8" node_number="3249">Thorsten Strufe</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3250, level: 7" node_number="3250"> Subjects: Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3251, level: 5" node_number="3251">[299] arXiv:2103.05577 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3252, level: 5" node_number="3252"> <div class="valid" valid="valid" title="valid: True, node: 3253, level: 6" node_number="3253"> <div class="valid" valid="valid" title="valid: True, node: 3254, level: 7" node_number="3254"> Title: Parametrized quantum policies for reinforcement learning </div> <div class="valid" valid="valid" title="valid: True, node: 3255, level: 7" node_number="3255"> Authors: Sofiene Jerbi, <a class="valid" valid="valid" title="valid: True, node: 3256, level: 8" node_number="3256">Casper Gyurik</a>, <a class="valid" valid="valid" title="valid: True, node: 3257, level: 8" node_number="3257">Simon C. Marshall</a>, <a class="valid" valid="valid" title="valid: True, node: 3258, level: 8" node_number="3258">Hans J. Briegel</a>, <a class="valid" valid="valid" title="valid: True, node: 3259, level: 8" node_number="3259">Vedran Dunjko</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3260, level: 7" node_number="3260"> Comments: NeurIPS 2021 camera-ready version </div> <div class="valid" valid="valid" title="valid: True, node: 3261, level: 7" node_number="3261"> Subjects: Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3262, level: 5" node_number="3262">[300] arXiv:2103.07454 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3263, level: 5" node_number="3263"> <div class="valid" valid="valid" title="valid: True, node: 3264, level: 6" node_number="3264"> <div class="valid" valid="valid" title="valid: True, node: 3265, level: 7" node_number="3265"> Title: EventGraD: Event-Triggered Communication in Parallel Machine Learning </div> <div class="valid" valid="valid" title="valid: True, node: 3266, level: 7" node_number="3266"> Authors: Soumyadip Ghosh, <a class="valid" valid="valid" title="valid: True, node: 3267, level: 8" node_number="3267">Bernardo Aquino</a>, <a class="valid" valid="valid" title="valid: True, node: 3268, level: 8" node_number="3268">Vijay Gupta</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3269, level: 7" node_number="3269"> Comments: Published in Neurocomputing, Nov 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3270, level: 7" node_number="3270"> Subjects: Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3271, level: 5" node_number="3271">[301] arXiv:2103.10994 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3272, level: 5" node_number="3272"> <div class="valid" valid="valid" title="valid: True, node: 3273, level: 6" node_number="3273"> <div class="valid" valid="valid" title="valid: True, node: 3274, level: 7" node_number="3274"> Title: Self-Supervised Classification Network </div> <div class="valid" valid="valid" title="valid: True, node: 3275, level: 7" node_number="3275"> Authors: Elad Amrani, <a class="valid" valid="valid" title="valid: True, node: 3276, level: 8" node_number="3276">Leonid Karlinsky</a>, <a class="valid" valid="valid" title="valid: True, node: 3277, level: 8" node_number="3277">Alex Bronstein</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3278, level: 7" node_number="3278"> Comments: Update method and add experiments </div> <div class="valid" valid="valid" title="valid: True, node: 3279, level: 7" node_number="3279"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3280, level: 5" node_number="3280">[302] arXiv:2103.13056 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3281, level: 5" node_number="3281"> <div class="valid" valid="valid" title="valid: True, node: 3282, level: 6" node_number="3282"> <div class="valid" valid="valid" title="valid: True, node: 3283, level: 7" node_number="3283"> Title: Minimax Regret for Stochastic Shortest Path </div> <div class="valid" valid="valid" title="valid: True, node: 3284, level: 7" node_number="3284"> Authors: Alon Cohen, <a class="valid" valid="valid" title="valid: True, node: 3285, level: 8" node_number="3285">Yonathan Efroni</a>, <a class="valid" valid="valid" title="valid: True, node: 3286, level: 8" node_number="3286">Yishay Mansour</a>, <a class="valid" valid="valid" title="valid: True, node: 3287, level: 8" node_number="3287">Aviv Rosenberg</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3288, level: 7" node_number="3288"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3289, level: 5" node_number="3289">[303] arXiv:2103.15924 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3290, level: 5" node_number="3290"> <div class="valid" valid="valid" title="valid: True, node: 3291, level: 6" node_number="3291"> <div class="valid" valid="valid" title="valid: True, node: 3292, level: 7" node_number="3292"> Title: How Far Can We Go in Compute-less Networking: Computation Correctness and Accuracy </div> <div class="valid" valid="valid" title="valid: True, node: 3293, level: 7" node_number="3293"> Authors: Boubakr Nour, <a class="valid" valid="valid" title="valid: True, node: 3294, level: 8" node_number="3294">Soumaya Cherkaoui</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3295, level: 7" node_number="3295"> Comments: Accepted for publication by the IEEE Network Magazine </div> <div class="valid" valid="valid" title="valid: True, node: 3296, level: 7" node_number="3296"> Subjects: Networking and Internet Architecture (cs.NI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3297, level: 5" node_number="3297">[304] arXiv:2103.16634 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3298, level: 5" node_number="3298"> <div class="valid" valid="valid" title="valid: True, node: 3299, level: 6" node_number="3299"> <div class="valid" valid="valid" title="valid: True, node: 3300, level: 7" node_number="3300"> Title: Exploiting Invariance in Training Deep Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 3301, level: 7" node_number="3301"> Authors: Chengxi Ye, <a class="valid" valid="valid" title="valid: True, node: 3302, level: 8" node_number="3302">Xiong Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 3303, level: 8" node_number="3303">Tristan McKinney</a>, <a class="valid" valid="valid" title="valid: True, node: 3304, level: 8" node_number="3304">Yanfeng Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 3305, level: 8" node_number="3305">Qinggang Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 3306, level: 8" node_number="3306">Fedor Zhdanov</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3307, level: 7" node_number="3307"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3308, level: 5" node_number="3308">[305] arXiv:2104.02446 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3309, level: 5" node_number="3309"> <div class="valid" valid="valid" title="valid: True, node: 3310, level: 6" node_number="3310"> <div class="valid" valid="valid" title="valid: True, node: 3311, level: 7" node_number="3311"> Title: Upper paired domination versus upper domination </div> <div class="valid" valid="valid" title="valid: True, node: 3312, level: 7" node_number="3312"> Authors: Hadi Alizadeh, <a class="valid" valid="valid" title="valid: True, node: 3313, level: 8" node_number="3313">Didem G&#246;z&#252;pek</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3314, level: 7" node_number="3314"> Subjects: Combinatorics (math.CO); Discrete Mathematics (cs.DM) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3315, level: 5" node_number="3315">[306] arXiv:2104.04258 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3316, level: 5" node_number="3316"> <div class="valid" valid="valid" title="valid: True, node: 3317, level: 6" node_number="3317"> <div class="valid" valid="valid" title="valid: True, node: 3318, level: 7" node_number="3318"> Title: Counter-Strike Deathmatch with Large-Scale Behavioural Cloning </div> <div class="valid" valid="valid" title="valid: True, node: 3319, level: 7" node_number="3319"> Authors: Tim Pearce, <a class="valid" valid="valid" title="valid: True, node: 3320, level: 8" node_number="3320">Jun Zhu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3321, level: 7" node_number="3321"> Comments: Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3322, level: 7" node_number="3322"> Subjects: Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3323, level: 5" node_number="3323">[307] arXiv:2104.04896 (replaced) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3324, level: 5" node_number="3324"> <div class="valid" valid="valid" title="valid: True, node: 3325, level: 6" node_number="3325"> <div class="valid" valid="valid" title="valid: True, node: 3326, level: 7" node_number="3326"> Title: A Toolbox for Construction and Analysis of Speech Datasets </div> <div class="valid" valid="valid" title="valid: True, node: 3327, level: 7" node_number="3327"> Authors: Evelina Bakhturina, <a class="valid" valid="valid" title="valid: True, node: 3328, level: 8" node_number="3328">Vitaly Lavrukhin</a>, <a class="valid" valid="valid" title="valid: True, node: 3329, level: 8" node_number="3329">Boris Ginsburg</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3330, level: 7" node_number="3330"> Subjects: Audio and Speech Processing (eess.AS); Computation and Language (cs.CL); Sound (cs.SD) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3331, level: 5" node_number="3331">[308] arXiv:2104.05002 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3332, level: 5" node_number="3332"> <div class="valid" valid="valid" title="valid: True, node: 3333, level: 6" node_number="3333"> <div class="valid" valid="valid" title="valid: True, node: 3334, level: 7" node_number="3334"> Title: Learning the CSI Denoising and Feedback Without Supervision </div> <div class="valid" valid="valid" title="valid: True, node: 3335, level: 7" node_number="3335"> Authors: Valentina Rizzello, <a class="valid" valid="valid" title="valid: True, node: 3336, level: 8" node_number="3336">Wolfgang Utschick</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3337, level: 7" node_number="3337"> Comments: Final version </div> <div class="valid" valid="valid" title="valid: True, node: 3338, level: 7" node_number="3338"> Subjects: Information Theory (cs.IT); Signal Processing (eess.SP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3339, level: 5" node_number="3339">[309] arXiv:2104.05256 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3340, level: 5" node_number="3340"> <div class="valid" valid="valid" title="valid: True, node: 3341, level: 6" node_number="3341"> <div class="valid" valid="valid" title="valid: True, node: 3342, level: 7" node_number="3342"> Title: A Coq Formalization of Lebesgue Integration of Nonnegative Functions </div> <div class="valid" valid="valid" title="valid: True, node: 3343, level: 7" node_number="3343"> Authors: Sylvie Boldo (TOCCATA), <a class="valid" valid="valid" title="valid: True, node: 3344, level: 8" node_number="3344">Fran&#231;ois Cl&#233;ment</a> (SERENA, CERMICS), <a class="valid" valid="valid" title="valid: True, node: 3345, level: 8" node_number="3345">Florian Faissole</a> (TOCCATA), <a class="valid" valid="valid" title="valid: True, node: 3346, level: 8" node_number="3346">Vincent Martin</a> (LMAC), <a class="valid" valid="valid" title="valid: True, node: 3347, level: 8" node_number="3347">Micaela Mayero</a> (LIPN) </div> <div class="valid" valid="valid" title="valid: True, node: 3348, level: 7" node_number="3348"> Subjects: Logic in Computer Science (cs.LO); Functional Analysis (math.FA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3349, level: 5" node_number="3349">[310] arXiv:2104.05463 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3350, level: 5" node_number="3350"> <div class="valid" valid="valid" title="valid: True, node: 3351, level: 6" node_number="3351"> <div class="valid" valid="valid" title="valid: True, node: 3352, level: 7" node_number="3352"> Title: Scalable Power Control/Beamforming in Heterogeneous Wireless Networks with Graph Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 3353, level: 7" node_number="3353"> Authors: Xiaochen Zhang, <a class="valid" valid="valid" title="valid: True, node: 3354, level: 8" node_number="3354">Haitao Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 3355, level: 8" node_number="3355">Jun Xiong</a>, <a class="valid" valid="valid" title="valid: True, node: 3356, level: 8" node_number="3356">Li Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 3357, level: 8" node_number="3357">Jibo Wei</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3358, level: 7" node_number="3358"> Comments: 6 pages, 6 figures, accepted by IEEE GLOBECOM 2021. Copyright may be transferred without notice, after which this version may no longer be accessible </div> <div class="valid" valid="valid" title="valid: True, node: 3359, level: 7" node_number="3359"> Subjects: Machine Learning (cs.LG); Signal Processing (eess.SP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3360, level: 5" node_number="3360">[311] arXiv:2104.10029 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3361, level: 5" node_number="3361"> <div class="valid" valid="valid" title="valid: True, node: 3362, level: 6" node_number="3362"> <div class="valid" valid="valid" title="valid: True, node: 3363, level: 7" node_number="3363"> Title: Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images: Techniques and Clinical Applications </div> <div class="valid" valid="valid" title="valid: True, node: 3364, level: 7" node_number="3364"> Authors: Yang Ma, <a class="valid" valid="valid" title="valid: True, node: 3365, level: 8" node_number="3365">Chaoyi Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3366, level: 8" node_number="3366">Mariano Cabezas</a>, <a class="valid" valid="valid" title="valid: True, node: 3367, level: 8" node_number="3367">Yang Song</a>, <a class="valid" valid="valid" title="valid: True, node: 3368, level: 8" node_number="3368">Zihao Tang</a>, <a class="valid" valid="valid" title="valid: True, node: 3369, level: 8" node_number="3369">Dongnan Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 3370, level: 8" node_number="3370">Weidong Cai</a>, <a class="valid" valid="valid" title="valid: True, node: 3371, level: 8" node_number="3371">Michael Barnett</a>, <a class="valid" valid="valid" title="valid: True, node: 3372, level: 8" node_number="3372">Chenyu Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3373, level: 7" node_number="3373"> Comments: 14 pages, 3 Figures </div> <div class="valid" valid="valid" title="valid: True, node: 3374, level: 7" node_number="3374"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Applications (stat.AP) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3375, level: 5" node_number="3375">[312] arXiv:2104.12138 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3376, level: 5" node_number="3376"> <div class="valid" valid="valid" title="valid: True, node: 3377, level: 6" node_number="3377"> <div class="valid" valid="valid" title="valid: True, node: 3378, level: 7" node_number="3378"> Title: Learning to Address Intra-segment Misclassification in Retinal Imaging </div> <div class="valid" valid="valid" title="valid: True, node: 3379, level: 7" node_number="3379"> Authors: Yukun Zhou, <a class="valid" valid="valid" title="valid: True, node: 3380, level: 8" node_number="3380">Moucheng Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 3381, level: 8" node_number="3381">Yipeng Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 3382, level: 8" node_number="3382">Hongxiang Lin</a>, <a class="valid" valid="valid" title="valid: True, node: 3383, level: 8" node_number="3383">Joseph Jacob</a>, <a class="valid" valid="valid" title="valid: True, node: 3384, level: 8" node_number="3384">Pearse A. Keane</a>, <a class="valid" valid="valid" title="valid: True, node: 3385, level: 8" node_number="3385">Daniel C. Alexander</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3386, level: 7" node_number="3386"> Comments: 13 pages, 9 figures, and 2 tables </div> <div class="valid" valid="valid" title="valid: True, node: 3387, level: 7" node_number="3387"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3388, level: 5" node_number="3388">[313] arXiv:2104.13020 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3389, level: 5" node_number="3389"> <div class="valid" valid="valid" title="valid: True, node: 3390, level: 6" node_number="3390"> <div class="valid" valid="valid" title="valid: True, node: 3391, level: 7" node_number="3391"> Title: Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding </div> <div class="valid" valid="valid" title="valid: True, node: 3392, level: 7" node_number="3392"> Authors: Jose M. Pe&#241;a </div> <div class="valid" valid="valid" title="valid: True, node: 3393, level: 7" node_number="3393"> Subjects: Methodology (stat.ME); Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3394, level: 5" node_number="3394">[314] arXiv:2104.13247 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3395, level: 5" node_number="3395"> <div class="valid" valid="valid" title="valid: True, node: 3396, level: 6" node_number="3396"> <div class="valid" valid="valid" title="valid: True, node: 3397, level: 7" node_number="3397"> Title: IATos: AI-powered pre-screening tool for COVID-19 from cough audio samples </div> <div class="valid" valid="valid" title="valid: True, node: 3398, level: 7" node_number="3398"> Authors: D. Trejo Pizzo, <a class="valid" valid="valid" title="valid: True, node: 3399, level: 8" node_number="3399">S. Esteban</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3400, level: 7" node_number="3400"> Subjects: Audio and Speech Processing (eess.AS); Sound (cs.SD) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3401, level: 5" node_number="3401">[315] arXiv:2104.14118 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3402, level: 5" node_number="3402"> <div class="valid" valid="valid" title="valid: True, node: 3403, level: 6" node_number="3403"> <div class="valid" valid="valid" title="valid: True, node: 3404, level: 7" node_number="3404"> Title: REGRAD: A Large-Scale Relational Grasp Dataset for Safe and Object-Specific Robotic Grasping in Clutter </div> <div class="valid" valid="valid" title="valid: True, node: 3405, level: 7" node_number="3405"> Authors: Hanbo Zhang, Deyu Yang, <a class="valid" valid="valid" title="valid: True, node: 3406, level: 8" node_number="3406">Han Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 3407, level: 8" node_number="3407">Binglei Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 3408, level: 8" node_number="3408">Xuguang Lan</a>, <a class="valid" valid="valid" title="valid: True, node: 3409, level: 8" node_number="3409">Jishiyu Ding</a>, <a class="valid" valid="valid" title="valid: True, node: 3410, level: 8" node_number="3410">Nanning Zheng</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3411, level: 7" node_number="3411"> Subjects: Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3412, level: 5" node_number="3412">[316] arXiv:2105.04504 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3413, level: 5" node_number="3413"> <div class="valid" valid="valid" title="valid: True, node: 3414, level: 6" node_number="3414"> <div class="valid" valid="valid" title="valid: True, node: 3415, level: 7" node_number="3415"> Title: Deep Neural Networks as Point Estimates for Deep Gaussian Processes </div> <div class="valid" valid="valid" title="valid: True, node: 3416, level: 7" node_number="3416"> Authors: Vincent Dutordoir, <a class="valid" valid="valid" title="valid: True, node: 3417, level: 8" node_number="3417">James Hensman</a>, <a class="valid" valid="valid" title="valid: True, node: 3418, level: 8" node_number="3418">Mark van der Wilk</a>, <a class="valid" valid="valid" title="valid: True, node: 3419, level: 8" node_number="3419">Carl Henrik Ek</a>, <a class="valid" valid="valid" title="valid: True, node: 3420, level: 8" node_number="3420">Zoubin Ghahramani</a>, <a class="valid" valid="valid" title="valid: True, node: 3421, level: 8" node_number="3421">Nicolas Durrande</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3422, level: 7" node_number="3422"> Comments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021) </div> <div class="valid" valid="valid" title="valid: True, node: 3423, level: 7" node_number="3423"> Subjects: Machine Learning (stat.ML); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3424, level: 5" node_number="3424">[317] arXiv:2105.07324 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3425, level: 5" node_number="3425"> <div class="valid" valid="valid" title="valid: True, node: 3426, level: 6" node_number="3426"> <div class="valid" valid="valid" title="valid: True, node: 3427, level: 7" node_number="3427"> Title: Data-driven Algorithms for signal processing with trigonometric rational functions </div> <div class="valid" valid="valid" title="valid: True, node: 3428, level: 7" node_number="3428"> Authors: Heather Wilber, <a class="valid" valid="valid" title="valid: True, node: 3429, level: 8" node_number="3429">Anil Damle</a>, <a class="valid" valid="valid" title="valid: True, node: 3430, level: 8" node_number="3430">Alex Townsend</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3431, level: 7" node_number="3431"> Comments: 25 pages, 7 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3432, level: 7" node_number="3432"> Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3433, level: 5" node_number="3433">[318] arXiv:2105.13647 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3434, level: 5" node_number="3434"> <div class="valid" valid="valid" title="valid: True, node: 3435, level: 6" node_number="3435"> <div class="valid" valid="valid" title="valid: True, node: 3436, level: 7" node_number="3436"> Title: Hybrid Beamforming for Intelligent Reflecting Surface Aided Millimeter Wave MIMO Systems </div> <div class="valid" valid="valid" title="valid: True, node: 3437, level: 7" node_number="3437"> Authors: Sung Hyuck Hong, <a class="valid" valid="valid" title="valid: True, node: 3438, level: 8" node_number="3438">Jaeyong Park</a>, <a class="valid" valid="valid" title="valid: True, node: 3439, level: 8" node_number="3439">Sung-Jin Kim</a>, <a class="valid" valid="valid" title="valid: True, node: 3440, level: 8" node_number="3440">Junil Choi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3441, level: 7" node_number="3441"> Comments: 13 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3442, level: 7" node_number="3442"> Subjects: Signal Processing (eess.SP); Information Theory (cs.IT) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3443, level: 5" node_number="3443">[319] arXiv:2106.00214 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3444, level: 5" node_number="3444"> <div class="valid" valid="valid" title="valid: True, node: 3445, level: 6" node_number="3445"> <div class="valid" valid="valid" title="valid: True, node: 3446, level: 7" node_number="3446"> Title: Game-Theoretic Frameworks for Epidemic Spreading and Human Decision Making: A Review </div> <div class="valid" valid="valid" title="valid: True, node: 3447, level: 7" node_number="3447"> Authors: Yunhan Huang, <a class="valid" valid="valid" title="valid: True, node: 3448, level: 8" node_number="3448">Quanyan Zhu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3449, level: 7" node_number="3449"> Subjects: Systems and Control (eess.SY); Computer Science and Game Theory (cs.GT) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3450, level: 5" node_number="3450">[320] arXiv:2106.01040 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3451, level: 5" node_number="3451"> <div class="valid" valid="valid" title="valid: True, node: 3452, level: 6" node_number="3452"> <div class="valid" valid="valid" title="valid: True, node: 3453, level: 7" node_number="3453"> Title: Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling </div> <div class="valid" valid="valid" title="valid: True, node: 3454, level: 7" node_number="3454"> Authors: Chuhan Wu, <a class="valid" valid="valid" title="valid: True, node: 3455, level: 8" node_number="3455">Fangzhao Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 3456, level: 8" node_number="3456">Tao Qi</a>, <a class="valid" valid="valid" title="valid: True, node: 3457, level: 8" node_number="3457">Yongfeng Huang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3458, level: 7" node_number="3458"> Comments: ACL 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3459, level: 7" node_number="3459"> Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3460, level: 5" node_number="3460">[321] arXiv:2106.02249 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3461, level: 5" node_number="3461"> <div class="valid" valid="valid" title="valid: True, node: 3462, level: 6" node_number="3462"> <div class="valid" valid="valid" title="valid: True, node: 3463, level: 7" node_number="3463"> Title: Robustifying Reinforcement Learning Policies with $\mathcal{L}_1$ Adaptive Control </div> <div class="valid" valid="valid" title="valid: True, node: 3464, level: 7" node_number="3464"> Authors: Yikun Cheng, <a class="valid" valid="valid" title="valid: True, node: 3465, level: 8" node_number="3465">Pan Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 3466, level: 8" node_number="3466">Manan Gandhi</a>, <a class="valid" valid="valid" title="valid: True, node: 3467, level: 8" node_number="3467">Bo Li</a>, <a class="valid" valid="valid" title="valid: True, node: 3468, level: 8" node_number="3468">Evangelos Theodorou</a>, <a class="valid" valid="valid" title="valid: True, node: 3469, level: 8" node_number="3469">Naira Hovakimyan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3470, level: 7" node_number="3470"> Comments: A significantly extended version of this paper has been uploaded to arXiv. <a class="valid" valid="valid" title="valid: True, node: 3471, level: 8" node_number="3471">arXiv:2112.01953</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3472, level: 7" node_number="3472"> Subjects: Machine Learning (cs.LG); Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3473, level: 5" node_number="3473">[322] arXiv:2106.03027 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3474, level: 5" node_number="3474"> <div class="valid" valid="valid" title="valid: True, node: 3475, level: 6" node_number="3475"> <div class="valid" valid="valid" title="valid: True, node: 3476, level: 7" node_number="3476"> Title: Model Zoo: A Growing "Brain" That Learns Continually </div> <div class="valid" valid="valid" title="valid: True, node: 3477, level: 7" node_number="3477"> Authors: Rahul Ramesh, <a class="valid" valid="valid" title="valid: True, node: 3478, level: 8" node_number="3478">Pratik Chaudhari</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3479, level: 7" node_number="3479"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3480, level: 5" node_number="3480">[323] arXiv:2106.04906 (replaced) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3481, level: 5" node_number="3481"> <div class="valid" valid="valid" title="valid: True, node: 3482, level: 6" node_number="3482"> <div class="valid" valid="valid" title="valid: True, node: 3483, level: 7" node_number="3483"> Title: Engineering-Economic Evaluation of Diffractive Non-Line-Of-Sight Backhaul (e3nb): A Techno-economic Model for 3D Wireless Backhaul Assessment </div> <div class="valid" valid="valid" title="valid: True, node: 3484, level: 7" node_number="3484"> Authors: Edward J. Oughton, <a class="valid" valid="valid" title="valid: True, node: 3485, level: 8" node_number="3485">Erik Boch</a>, <a class="valid" valid="valid" title="valid: True, node: 3486, level: 8" node_number="3486">Julius Kusuma</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3487, level: 7" node_number="3487"> Subjects: Networking and Internet Architecture (cs.NI); Computers and Society (cs.CY); Emerging Technologies (cs.ET); General Economics (econ.GN) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3488, level: 5" node_number="3488">[324] arXiv:2106.05206 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3489, level: 5" node_number="3489"> <div class="valid" valid="valid" title="valid: True, node: 3490, level: 6" node_number="3490"> <div class="valid" valid="valid" title="valid: True, node: 3491, level: 7" node_number="3491"> Title: Avoiding Traps in Nonconvex Problems </div> <div class="valid" valid="valid" title="valid: True, node: 3492, level: 7" node_number="3492"> Authors: Sean Deyo, <a class="valid" valid="valid" title="valid: True, node: 3493, level: 8" node_number="3493">Veit Elser</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3494, level: 7" node_number="3494"> Subjects: Optimization and Control (math.OC); Machine Learning (cs.LG); Dynamical Systems (math.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3495, level: 5" node_number="3495">[325] arXiv:2106.06168 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3496, level: 5" node_number="3496"> <div class="valid" valid="valid" title="valid: True, node: 3497, level: 6" node_number="3497"> <div class="valid" valid="valid" title="valid: True, node: 3498, level: 7" node_number="3498"> Title: Generate, Annotate, and Learn: NLP with Synthetic Text </div> <div class="valid" valid="valid" title="valid: True, node: 3499, level: 7" node_number="3499"> Authors: Xuanli He, <a class="valid" valid="valid" title="valid: True, node: 3500, level: 8" node_number="3500">Islam Nassar</a>, <a class="valid" valid="valid" title="valid: True, node: 3501, level: 8" node_number="3501">Jamie Kiros</a>, <a class="valid" valid="valid" title="valid: True, node: 3502, level: 8" node_number="3502">Gholamreza Haffari</a>, <a class="valid" valid="valid" title="valid: True, node: 3503, level: 8" node_number="3503">Mohammad Norouzi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3504, level: 7" node_number="3504"> Comments: 28 pages, 3 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3505, level: 7" node_number="3505"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3506, level: 5" node_number="3506">[326] arXiv:2106.07153 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3507, level: 5" node_number="3507"> <div class="valid" valid="valid" title="valid: True, node: 3508, level: 6" node_number="3508"> <div class="valid" valid="valid" title="valid: True, node: 3509, level: 7" node_number="3509"> Title: Iterative Methods for Private Synthetic Data: Unifying Framework and New Methods </div> <div class="valid" valid="valid" title="valid: True, node: 3510, level: 7" node_number="3510"> Authors: Terrance Liu, <a class="valid" valid="valid" title="valid: True, node: 3511, level: 8" node_number="3511">Giuseppe Vietri</a>, <a class="valid" valid="valid" title="valid: True, node: 3512, level: 8" node_number="3512">Zhiwei Steven Wu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3513, level: 7" node_number="3513"> Comments: NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3514, level: 7" node_number="3514"> Subjects: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3515, level: 5" node_number="3515">[327] arXiv:2106.07464 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3516, level: 5" node_number="3516"> <div class="valid" valid="valid" title="valid: True, node: 3517, level: 6" node_number="3517"> <div class="valid" valid="valid" title="valid: True, node: 3518, level: 7" node_number="3518"> Title: Meta-Interpretive Learning as Metarule Specialisation </div> <div class="valid" valid="valid" title="valid: True, node: 3519, level: 7" node_number="3519"> Authors: Stassa Patsantzis, <a class="valid" valid="valid" title="valid: True, node: 3520, level: 8" node_number="3520">Stephen H. Muggleton</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3521, level: 7" node_number="3521"> Comments: 29 pages. Submitted to the Machine Learning Journal Special Issue on Learning and Reasoning on June 1st, 2021. Revised and resubmitted on 16/09/21. Revised again and resubmitted on 09/12/2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3522, level: 7" node_number="3522"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3523, level: 5" node_number="3523">[328] arXiv:2106.11808 (replaced) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3524, level: 5" node_number="3524"> <div class="valid" valid="valid" title="valid: True, node: 3525, level: 6" node_number="3525"> <div class="valid" valid="valid" title="valid: True, node: 3526, level: 7" node_number="3526"> Title: Fully CMOS-compatible passive TiO2-based memristor crossbars for in-memory computing </div> <div class="valid" valid="valid" title="valid: True, node: 3527, level: 7" node_number="3527"> Authors: Abdelouadoud El Mesoudy, <a class="valid" valid="valid" title="valid: True, node: 3528, level: 8" node_number="3528">Gw&#233;na&#235;lle Lamri</a>, <a class="valid" valid="valid" title="valid: True, node: 3529, level: 8" node_number="3529">Rapha&#235;l Dawant</a>, <a class="valid" valid="valid" title="valid: True, node: 3530, level: 8" node_number="3530">Javier Arias-Zapata</a>, <a class="valid" valid="valid" title="valid: True, node: 3531, level: 8" node_number="3531">Pierre Gliech</a>, <a class="valid" valid="valid" title="valid: True, node: 3532, level: 8" node_number="3532">Yann Beilliard</a>, <a class="valid" valid="valid" title="valid: True, node: 3533, level: 8" node_number="3533">Serge Ecoffey</a>, <a class="valid" valid="valid" title="valid: True, node: 3534, level: 8" node_number="3534">Andreas Ruediger</a>, <a class="valid" valid="valid" title="valid: True, node: 3535, level: 8" node_number="3535">Fabien Alibart</a>, <a class="valid" valid="valid" title="valid: True, node: 3536, level: 8" node_number="3536">Dominique Drouin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3537, level: 7" node_number="3537"> Comments: 18 pages, 4 figures in main text, 5 figures in SI </div> <div class="valid" valid="valid" title="valid: True, node: 3538, level: 7" node_number="3538"> Subjects: Emerging Technologies (cs.ET); Applied Physics (physics.app-ph) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3539, level: 5" node_number="3539">[329] arXiv:2106.15256 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3540, level: 5" node_number="3540"> <div class="valid" valid="valid" title="valid: True, node: 3541, level: 6" node_number="3541"> <div class="valid" valid="valid" title="valid: True, node: 3542, level: 7" node_number="3542"> Title: The Complexity of Synthesis of $b$-Bounded Petri Nets </div> <div class="valid" valid="valid" title="valid: True, node: 3543, level: 7" node_number="3543"> Authors: Ronny Tredup </div> <div class="valid" valid="valid" title="valid: True, node: 3544, level: 7" node_number="3544"> Subjects: Computational Complexity (cs.CC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3545, level: 5" node_number="3545">[330] arXiv:2106.15278 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3546, level: 5" node_number="3546"> <div class="valid" valid="valid" title="valid: True, node: 3547, level: 6" node_number="3547"> <div class="valid" valid="valid" title="valid: True, node: 3548, level: 7" node_number="3548"> Title: Open-Set Representation Learning through Combinatorial Embedding </div> <div class="valid" valid="valid" title="valid: True, node: 3549, level: 7" node_number="3549"> Authors: Geeho Kim, <a class="valid" valid="valid" title="valid: True, node: 3550, level: 8" node_number="3550">Junoh Kang</a>, <a class="valid" valid="valid" title="valid: True, node: 3551, level: 8" node_number="3551">Bohyung Han</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3552, level: 7" node_number="3552"> Comments: 11 pages, 6 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3553, level: 7" node_number="3553"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3554, level: 5" node_number="3554">[331] arXiv:2107.00644 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3555, level: 5" node_number="3555"> <div class="valid" valid="valid" title="valid: True, node: 3556, level: 6" node_number="3556"> <div class="valid" valid="valid" title="valid: True, node: 3557, level: 7" node_number="3557"> Title: Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation </div> <div class="valid" valid="valid" title="valid: True, node: 3558, level: 7" node_number="3558"> Authors: Nicklas Hansen, <a class="valid" valid="valid" title="valid: True, node: 3559, level: 8" node_number="3559">Hao Su</a>, <a class="valid" valid="valid" title="valid: True, node: 3560, level: 8" node_number="3560">Xiaolong Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3561, level: 7" node_number="3561"> Comments: Code and videos are available at <a class="valid" valid="valid" title="valid: True, node: 3562, level: 8" node_number="3562">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3563, level: 7" node_number="3563"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3564, level: 5" node_number="3564">[332] arXiv:2107.05775 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3565, level: 5" node_number="3565"> <div class="valid" valid="valid" title="valid: True, node: 3566, level: 6" node_number="3566"> <div class="valid" valid="valid" title="valid: True, node: 3567, level: 7" node_number="3567"> Title: Fast and Explicit Neural View Synthesis </div> <div class="valid" valid="valid" title="valid: True, node: 3568, level: 7" node_number="3568"> Authors: Pengsheng Guo, <a class="valid" valid="valid" title="valid: True, node: 3569, level: 8" node_number="3569">Miguel Angel Bautista</a>, <a class="valid" valid="valid" title="valid: True, node: 3570, level: 8" node_number="3570">Alex Colburn</a>, <a class="valid" valid="valid" title="valid: True, node: 3571, level: 8" node_number="3571">Liang Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 3572, level: 8" node_number="3572">Daniel Ulbricht</a>, <a class="valid" valid="valid" title="valid: True, node: 3573, level: 8" node_number="3573">Joshua M. Susskind</a>, <a class="valid" valid="valid" title="valid: True, node: 3574, level: 8" node_number="3574">Qi Shan</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3575, level: 7" node_number="3575"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3576, level: 5" node_number="3576">[333] arXiv:2107.06253 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3577, level: 5" node_number="3577"> <div class="valid" valid="valid" title="valid: True, node: 3578, level: 6" node_number="3578"> <div class="valid" valid="valid" title="valid: True, node: 3579, level: 7" node_number="3579"> Title: Bottom-up Synthesis of Recursive Functional Programs using Angelic Execution </div> <div class="valid" valid="valid" title="valid: True, node: 3580, level: 7" node_number="3580"> Authors: Anders Miltner, <a class="valid" valid="valid" title="valid: True, node: 3581, level: 8" node_number="3581">Adrian Trejo Nu&#241;ez</a>, <a class="valid" valid="valid" title="valid: True, node: 3582, level: 8" node_number="3582">Ana Brendel</a>, <a class="valid" valid="valid" title="valid: True, node: 3583, level: 8" node_number="3583">Swarat Chaudhuri</a>, <a class="valid" valid="valid" title="valid: True, node: 3584, level: 8" node_number="3584">Isil Dillig</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3585, level: 7" node_number="3585"> Subjects: Programming Languages (cs.PL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3586, level: 5" node_number="3586">[334] arXiv:2107.09274 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3587, level: 5" node_number="3587"> <div class="valid" valid="valid" title="valid: True, node: 3588, level: 6" node_number="3588"> <div class="valid" valid="valid" title="valid: True, node: 3589, level: 7" node_number="3589"> Title: Paraphrasing via Ranking Many Candidates </div> <div class="valid" valid="valid" title="valid: True, node: 3590, level: 7" node_number="3590"> Authors: Joosung Lee </div> <div class="valid" valid="valid" title="valid: True, node: 3591, level: 7" node_number="3591"> Comments: 4 pages </div> <div class="valid" valid="valid" title="valid: True, node: 3592, level: 7" node_number="3592"> Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3593, level: 5" node_number="3593">[335] arXiv:2107.14735 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3594, level: 5" node_number="3594"> <div class="valid" valid="valid" title="valid: True, node: 3595, level: 6" node_number="3595"> <div class="valid" valid="valid" title="valid: True, node: 3596, level: 7" node_number="3596"> Title: Neural Relighting and Expression Transfer On Video Portraits </div> <div class="valid" valid="valid" title="valid: True, node: 3597, level: 7" node_number="3597"> Authors: Youjia Wang, Taotao Zhou, <a class="valid" valid="valid" title="valid: True, node: 3598, level: 8" node_number="3598">Minzhang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 3599, level: 8" node_number="3599">Teng Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 3600, level: 8" node_number="3600">Minye Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 3601, level: 8" node_number="3601">Lan Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 3602, level: 8" node_number="3602">Jingyi Yu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3603, level: 7" node_number="3603"> Comments: Project Page <a class="valid" valid="valid" title="valid: True, node: 3604, level: 8" node_number="3604">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3605, level: 7" node_number="3605"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3606, level: 5" node_number="3606">[336] arXiv:2108.01204 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3607, level: 5" node_number="3607"> <div class="valid" valid="valid" title="valid: True, node: 3608, level: 6" node_number="3608"> <div class="valid" valid="valid" title="valid: True, node: 3609, level: 7" node_number="3609"> Title: The RareDis corpus: a corpus annotated with rare diseases, their signs and symptoms </div> <div class="valid" valid="valid" title="valid: True, node: 3610, level: 7" node_number="3610"> Authors: Claudia Mart&#237;nez-deMiguel, <a class="valid" valid="valid" title="valid: True, node: 3611, level: 8" node_number="3611">Isabel Segura-Bedmar</a>, <a class="valid" valid="valid" title="valid: True, node: 3612, level: 8" node_number="3612">Esteban Chac&#243;n-Solano</a>, <a class="valid" valid="valid" title="valid: True, node: 3613, level: 8" node_number="3613">Sara Guerrero-Aspizua</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3614, level: 7" node_number="3614"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3615, level: 5" node_number="3615">[337] arXiv:2108.01483 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3616, level: 5" node_number="3616"> <div class="valid" valid="valid" title="valid: True, node: 3617, level: 6" node_number="3617"> <div class="valid" valid="valid" title="valid: True, node: 3618, level: 7" node_number="3618"> Title: Research Challenges and Progress in Robotic Grasping and Manipulation Competitions </div> <div class="valid" valid="valid" title="valid: True, node: 3619, level: 7" node_number="3619"> Authors: Yu Sun, <a class="valid" valid="valid" title="valid: True, node: 3620, level: 8" node_number="3620">Joe Falco</a>, <a class="valid" valid="valid" title="valid: True, node: 3621, level: 8" node_number="3621">Maximo A. Roa</a>, <a class="valid" valid="valid" title="valid: True, node: 3622, level: 8" node_number="3622">Berk Calli</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3623, level: 7" node_number="3623"> Comments: Accepted for publication by IEEE Robotics and Automation Letters </div> <div class="valid" valid="valid" title="valid: True, node: 3624, level: 7" node_number="3624"> Subjects: Robotics (cs.RO); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3625, level: 5" node_number="3625">[338] arXiv:2108.03603 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3626, level: 5" node_number="3626"> <div class="valid" valid="valid" title="valid: True, node: 3627, level: 6" node_number="3627"> <div class="valid" valid="valid" title="valid: True, node: 3628, level: 7" node_number="3628"> Title: Understanding the computational demands underlying visual reasoning </div> <div class="valid" valid="valid" title="valid: True, node: 3629, level: 7" node_number="3629"> Authors: Mohit Vaishnav, <a class="valid" valid="valid" title="valid: True, node: 3630, level: 8" node_number="3630">Remi Cadene</a>, <a class="valid" valid="valid" title="valid: True, node: 3631, level: 8" node_number="3631">Andrea Alamia</a>, <a class="valid" valid="valid" title="valid: True, node: 3632, level: 8" node_number="3632">Drew Linsley</a>, <a class="valid" valid="valid" title="valid: True, node: 3633, level: 8" node_number="3633">Rufin VanRullen</a>, <a class="valid" valid="valid" title="valid: True, node: 3634, level: 8" node_number="3634">Thomas Serre</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3635, level: 7" node_number="3635"> Comments: 26 pages, 16 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3636, level: 7" node_number="3636"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3637, level: 5" node_number="3637">[339] arXiv:2108.05895 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3638, level: 5" node_number="3638"> <div class="valid" valid="valid" title="valid: True, node: 3639, level: 6" node_number="3639"> <div class="valid" valid="valid" title="valid: True, node: 3640, level: 7" node_number="3640"> Title: Mobile-Former: Bridging MobileNet and Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 3641, level: 7" node_number="3641"> Authors: Yinpeng Chen, <a class="valid" valid="valid" title="valid: True, node: 3642, level: 8" node_number="3642">Xiyang Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 3643, level: 8" node_number="3643">Dongdong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3644, level: 8" node_number="3644">Mengchen Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 3645, level: 8" node_number="3645">Xiaoyi Dong</a>, <a class="valid" valid="valid" title="valid: True, node: 3646, level: 8" node_number="3646">Lu Yuan</a>, <a class="valid" valid="valid" title="valid: True, node: 3647, level: 8" node_number="3647">Zicheng Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3648, level: 7" node_number="3648"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3649, level: 5" node_number="3649">[340] arXiv:2108.10555 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3650, level: 5" node_number="3650"> <div class="valid" valid="valid" title="valid: True, node: 3651, level: 6" node_number="3651"> <div class="valid" valid="valid" title="valid: True, node: 3652, level: 7" node_number="3652"> Title: MIMO OFDM Dual-Function Radar-Communication Under Error Rate and Beampattern Constraints </div> <div class="valid" valid="valid" title="valid: True, node: 3653, level: 7" node_number="3653"> Authors: Jeremy Johnston, <a class="valid" valid="valid" title="valid: True, node: 3654, level: 8" node_number="3654">Luca Venturino</a>, <a class="valid" valid="valid" title="valid: True, node: 3655, level: 8" node_number="3655">Emanuele Grossi</a>, <a class="valid" valid="valid" title="valid: True, node: 3656, level: 8" node_number="3656">Marco Lops</a>, <a class="valid" valid="valid" title="valid: True, node: 3657, level: 8" node_number="3657">Xiaodong Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3658, level: 7" node_number="3658"> Comments: This work has been submitted to the IEEE Journal on Selected Areas in Communications for possible publication </div> <div class="valid" valid="valid" title="valid: True, node: 3659, level: 7" node_number="3659"> Subjects: Signal Processing (eess.SP); Information Theory (cs.IT) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3660, level: 5" node_number="3660">[341] arXiv:2109.02351 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3661, level: 5" node_number="3661"> <div class="valid" valid="valid" title="valid: True, node: 3662, level: 6" node_number="3662"> <div class="valid" valid="valid" title="valid: True, node: 3663, level: 7" node_number="3663"> Title: Fair Federated Learning for Heterogeneous Face Data </div> <div class="valid" valid="valid" title="valid: True, node: 3664, level: 7" node_number="3664"> Authors: Samhita Kanaparthy, <a class="valid" valid="valid" title="valid: True, node: 3665, level: 8" node_number="3665">Manisha Padala</a>, <a class="valid" valid="valid" title="valid: True, node: 3666, level: 8" node_number="3666">Sankarshan Damle</a>, <a class="valid" valid="valid" title="valid: True, node: 3667, level: 8" node_number="3667">Ravi Kiran Sarvadevabhatla</a>, <a class="valid" valid="valid" title="valid: True, node: 3668, level: 8" node_number="3668">Sujit Gujar</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3669, level: 7" node_number="3669"> Subjects: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3670, level: 5" node_number="3670">[342] arXiv:2109.03188 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3671, level: 5" node_number="3671"> <div class="valid" valid="valid" title="valid: True, node: 3672, level: 6" node_number="3672"> <div class="valid" valid="valid" title="valid: True, node: 3673, level: 7" node_number="3673"> Title: Optimizing Quantum Variational Circuits with Deep Reinforcement Learning </div> <div class="valid" valid="valid" title="valid: True, node: 3674, level: 7" node_number="3674"> Authors: Owen Lockwood </div> <div class="valid" valid="valid" title="valid: True, node: 3675, level: 7" node_number="3675"> Subjects: Machine Learning (cs.LG); Quantum Physics (quant-ph) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3676, level: 5" node_number="3676">[343] arXiv:2109.04330 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3677, level: 5" node_number="3677"> <div class="valid" valid="valid" title="valid: True, node: 3678, level: 6" node_number="3678"> <div class="valid" valid="valid" title="valid: True, node: 3679, level: 7" node_number="3679"> Title: On iterated interpolation </div> <div class="valid" valid="valid" title="valid: True, node: 3680, level: 7" node_number="3680"> Authors: Steffen B&#246;rm </div> <div class="valid" valid="valid" title="valid: True, node: 3681, level: 7" node_number="3681"> Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3682, level: 5" node_number="3682">[344] arXiv:2109.04355 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3683, level: 5" node_number="3683"> <div class="valid" valid="valid" title="valid: True, node: 3684, level: 6" node_number="3684"> <div class="valid" valid="valid" title="valid: True, node: 3685, level: 7" node_number="3685"> Title: Multi-sensor Joint Adaptive Birth Sampler for Labeled Random Finite Set Tracking </div> <div class="valid" valid="valid" title="valid: True, node: 3686, level: 7" node_number="3686"> Authors: Anthony Trezza, <a class="valid" valid="valid" title="valid: True, node: 3687, level: 8" node_number="3687">Donald J. Bucci Jr.</a>, <a class="valid" valid="valid" title="valid: True, node: 3688, level: 8" node_number="3688">Pramod K. Varshney</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3689, level: 7" node_number="3689"> Comments: Submitted to IEEE Transactions on Signal Processing </div> <div class="valid" valid="valid" title="valid: True, node: 3690, level: 7" node_number="3690"> Subjects: Signal Processing (eess.SP); Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3691, level: 5" node_number="3691">[345] arXiv:2109.05573 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3692, level: 5" node_number="3692"> <div class="valid" valid="valid" title="valid: True, node: 3693, level: 6" node_number="3693"> <div class="valid" valid="valid" title="valid: True, node: 3694, level: 7" node_number="3694"> Title: A Priority-Aware Replanning and Resequencing Framework for Coordination of Connected and Automated Vehicles </div> <div class="valid" valid="valid" title="valid: True, node: 3695, level: 7" node_number="3695"> Authors: Behdad Chalaki, <a class="valid" valid="valid" title="valid: True, node: 3696, level: 8" node_number="3696">Andreas A. Malikopoulos</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3697, level: 7" node_number="3697"> Comments: 6 pages, 4 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3698, level: 7" node_number="3698"> Journal-ref: IEEE Control Systems Letters (2021) 1-6 </div> <div class="valid" valid="valid" title="valid: True, node: 3699, level: 7" node_number="3699"> Subjects: Systems and Control (eess.SY); Optimization and Control (math.OC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3700, level: 5" node_number="3700">[346] arXiv:2109.06250 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3701, level: 5" node_number="3701"> <div class="valid" valid="valid" title="valid: True, node: 3702, level: 6" node_number="3702"> <div class="valid" valid="valid" title="valid: True, node: 3703, level: 7" node_number="3703"> Title: TTM: Terrain Traversability Mapping for Autonomous Excavators </div> <div class="valid" valid="valid" title="valid: True, node: 3704, level: 7" node_number="3704"> Authors: Tianrui Guan, <a class="valid" valid="valid" title="valid: True, node: 3705, level: 8" node_number="3705">Zhenpeng He</a>, <a class="valid" valid="valid" title="valid: True, node: 3706, level: 8" node_number="3706">Dinesh Manocha</a>, <a class="valid" valid="valid" title="valid: True, node: 3707, level: 8" node_number="3707">Liangjun Zhang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3708, level: 7" node_number="3708"> Subjects: Robotics (cs.RO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3709, level: 5" node_number="3709">[347] arXiv:2109.07193 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3710, level: 5" node_number="3710"> <div class="valid" valid="valid" title="valid: True, node: 3711, level: 6" node_number="3711"> <div class="valid" valid="valid" title="valid: True, node: 3712, level: 7" node_number="3712"> Title: FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view Physical Adversarial Attack </div> <div class="valid" valid="valid" title="valid: True, node: 3713, level: 7" node_number="3713"> Authors: Donghua Wang, <a class="valid" valid="valid" title="valid: True, node: 3714, level: 8" node_number="3714">Tingsong Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 3715, level: 8" node_number="3715">Jialiang Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 3716, level: 8" node_number="3716">Weien Zhou</a>, <a class="valid" valid="valid" title="valid: True, node: 3717, level: 8" node_number="3717">Xiaoya Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3718, level: 8" node_number="3718">Zhiqiang Gong</a>, <a class="valid" valid="valid" title="valid: True, node: 3719, level: 8" node_number="3719">Wen Yao</a>, <a class="valid" valid="valid" title="valid: True, node: 3720, level: 8" node_number="3720">Xiaoqian Chen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3721, level: 7" node_number="3721"> Comments: 9 pages, 5 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3722, level: 7" node_number="3722"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3723, level: 5" node_number="3723">[348] arXiv:2109.08796 (replaced) [src]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3724, level: 5" node_number="3724"> <div class="valid" valid="valid" title="valid: True, node: 3725, level: 6" node_number="3725"> <div class="valid" valid="valid" title="valid: True, node: 3726, level: 7" node_number="3726"> Title: Solar cell patent classification method based on keyword extraction and deep neural network </div> <div class="valid" valid="valid" title="valid: True, node: 3727, level: 7" node_number="3727"> Authors: Yongmin Yoo, <a class="valid" valid="valid" title="valid: True, node: 3728, level: 8" node_number="3728">Dongjin Lim</a>, <a class="valid" valid="valid" title="valid: True, node: 3729, level: 8" node_number="3729">Tak-Sung Heo</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3730, level: 7" node_number="3730"> Comments: The content and quality of the thesis is too low, and the title and content have been changed and will be uploaded </div> <div class="valid" valid="valid" title="valid: True, node: 3731, level: 7" node_number="3731"> Subjects: Information Retrieval (cs.IR); Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3732, level: 5" node_number="3732">[349] arXiv:2109.12265 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3733, level: 5" node_number="3733"> <div class="valid" valid="valid" title="valid: True, node: 3734, level: 6" node_number="3734"> <div class="valid" valid="valid" title="valid: True, node: 3735, level: 7" node_number="3735"> Title: Data-Assemble: Leveraging Multiple Datasets with Partial Labels </div> <div class="valid" valid="valid" title="valid: True, node: 3736, level: 7" node_number="3736"> Authors: Mintong Kang, <a class="valid" valid="valid" title="valid: True, node: 3737, level: 8" node_number="3737">Yongyi Lu</a>, <a class="valid" valid="valid" title="valid: True, node: 3738, level: 8" node_number="3738">Alan L. Yuille</a>, <a class="valid" valid="valid" title="valid: True, node: 3739, level: 8" node_number="3739">Zongwei Zhou</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3740, level: 7" node_number="3740"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3741, level: 5" node_number="3741">[350] arXiv:2109.14142 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3742, level: 5" node_number="3742"> <div class="valid" valid="valid" title="valid: True, node: 3743, level: 6" node_number="3743"> <div class="valid" valid="valid" title="valid: True, node: 3744, level: 7" node_number="3744"> Title: On the Provable Generalization of Recurrent Neural Networks </div> <div class="valid" valid="valid" title="valid: True, node: 3745, level: 7" node_number="3745"> Authors: Lifu Wang, <a class="valid" valid="valid" title="valid: True, node: 3746, level: 8" node_number="3746">Bo Shen</a>, <a class="valid" valid="valid" title="valid: True, node: 3747, level: 8" node_number="3747">Bo Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 3748, level: 8" node_number="3748">Xing Cao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3749, level: 7" node_number="3749"> Comments: Accepted to Neurips 2021, 29 pages. Some small typos have been fixed </div> <div class="valid" valid="valid" title="valid: True, node: 3750, level: 7" node_number="3750"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3751, level: 5" node_number="3751">[351] arXiv:2110.03753 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3752, level: 5" node_number="3752"> <div class="valid" valid="valid" title="valid: True, node: 3753, level: 6" node_number="3753"> <div class="valid" valid="valid" title="valid: True, node: 3754, level: 7" node_number="3754"> Title: From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness </div> <div class="valid" valid="valid" title="valid: True, node: 3755, level: 7" node_number="3755"> Authors: Lingxiao Zhao, <a class="valid" valid="valid" title="valid: True, node: 3756, level: 8" node_number="3756">Wei Jin</a>, <a class="valid" valid="valid" title="valid: True, node: 3757, level: 8" node_number="3757">Leman Akoglu</a>, <a class="valid" valid="valid" title="valid: True, node: 3758, level: 8" node_number="3758">Neil Shah</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3759, level: 7" node_number="3759"> Comments: Code is published! The version is updated extensively based on the reviewers' suggestions. Expressive GNN framework </div> <div class="valid" valid="valid" title="valid: True, node: 3760, level: 7" node_number="3760"> Subjects: Machine Learning (cs.LG); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3761, level: 5" node_number="3761">[352] arXiv:2110.04227 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3762, level: 5" node_number="3762"> <div class="valid" valid="valid" title="valid: True, node: 3763, level: 6" node_number="3763"> <div class="valid" valid="valid" title="valid: True, node: 3764, level: 7" node_number="3764"> Title: Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows </div> <div class="valid" valid="valid" title="valid: True, node: 3765, level: 7" node_number="3765"> Authors: Michael Puthawala, <a class="valid" valid="valid" title="valid: True, node: 3766, level: 8" node_number="3766">Matti Lassas</a>, <a class="valid" valid="valid" title="valid: True, node: 3767, level: 8" node_number="3767">Ivan Dokmani&#263;</a>, <a class="valid" valid="valid" title="valid: True, node: 3768, level: 8" node_number="3768">Maarten de Hoop</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3769, level: 7" node_number="3769"> Comments: 22 pages, 3 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3770, level: 7" node_number="3770"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3771, level: 5" node_number="3771">[353] arXiv:2110.07993 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3772, level: 5" node_number="3772"> <div class="valid" valid="valid" title="valid: True, node: 3773, level: 6" node_number="3773"> <div class="valid" valid="valid" title="valid: True, node: 3774, level: 7" node_number="3774"> Title: Pose-guided Generative Adversarial Net for Novel View Action Synthesis </div> <div class="valid" valid="valid" title="valid: True, node: 3775, level: 7" node_number="3775"> Authors: Xianhang Li, <a class="valid" valid="valid" title="valid: True, node: 3776, level: 8" node_number="3776">Junhao Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3777, level: 8" node_number="3777">Kunchang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 3778, level: 8" node_number="3778">Shruti Vyas</a>, <a class="valid" valid="valid" title="valid: True, node: 3779, level: 8" node_number="3779">Yogesh S Rawat</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3780, level: 7" node_number="3780"> Comments: Accepted by WACV2022 </div> <div class="valid" valid="valid" title="valid: True, node: 3781, level: 7" node_number="3781"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3782, level: 5" node_number="3782">[354] arXiv:2110.09396 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3783, level: 5" node_number="3783"> <div class="valid" valid="valid" title="valid: True, node: 3784, level: 6" node_number="3784"> <div class="valid" valid="valid" title="valid: True, node: 3785, level: 7" node_number="3785"> Title: Streaming Machine Learning and Online Active Learning for Automated Visual Inspection </div> <div class="valid" valid="valid" title="valid: True, node: 3786, level: 7" node_number="3786"> Authors: Jo&#382;e M. Ro&#382;anec, <a class="valid" valid="valid" title="valid: True, node: 3787, level: 8" node_number="3787">Elena Trajkova</a>, <a class="valid" valid="valid" title="valid: True, node: 3788, level: 8" node_number="3788">Paulien Dam</a>, <a class="valid" valid="valid" title="valid: True, node: 3789, level: 8" node_number="3789">Bla&#382; Fortuna</a>, <a class="valid" valid="valid" title="valid: True, node: 3790, level: 8" node_number="3790">Dunja Mladeni&#263;</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3791, level: 7" node_number="3791"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3792, level: 5" node_number="3792">[355] arXiv:2110.09554 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3793, level: 5" node_number="3793"> <div class="valid" valid="valid" title="valid: True, node: 3794, level: 6" node_number="3794"> <div class="valid" valid="valid" title="valid: True, node: 3795, level: 7" node_number="3795"> Title: TransFusion: Cross-view Fusion with Transformer for 3D Human Pose Estimation </div> <div class="valid" valid="valid" title="valid: True, node: 3796, level: 7" node_number="3796"> Authors: Haoyu Ma, <a class="valid" valid="valid" title="valid: True, node: 3797, level: 8" node_number="3797">Liangjian Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3798, level: 8" node_number="3798">Deying Kong</a>, <a class="valid" valid="valid" title="valid: True, node: 3799, level: 8" node_number="3799">Zhe Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 3800, level: 8" node_number="3800">Xingwei Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 3801, level: 8" node_number="3801">Hao Tang</a>, <a class="valid" valid="valid" title="valid: True, node: 3802, level: 8" node_number="3802">Xiangyi Yan</a>, <a class="valid" valid="valid" title="valid: True, node: 3803, level: 8" node_number="3803">Yusheng Xie</a>, <a class="valid" valid="valid" title="valid: True, node: 3804, level: 8" node_number="3804">Shih-Yao Lin</a>, <a class="valid" valid="valid" title="valid: True, node: 3805, level: 8" node_number="3805">Xiaohui Xie</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3806, level: 7" node_number="3806"> Comments: BMVC 2021. Code is available at: <a class="valid" valid="valid" title="valid: True, node: 3807, level: 8" node_number="3807">this https URL</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3808, level: 7" node_number="3808"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3809, level: 5" node_number="3809">[356] arXiv:2110.13632 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3810, level: 5" node_number="3810"> <div class="valid" valid="valid" title="valid: True, node: 3811, level: 6" node_number="3811"> <div class="valid" valid="valid" title="valid: True, node: 3812, level: 7" node_number="3812"> Title: Generative Networks for Precision Enthusiasts </div> <div class="valid" valid="valid" title="valid: True, node: 3813, level: 7" node_number="3813"> Authors: Anja Butter, <a class="valid" valid="valid" title="valid: True, node: 3814, level: 8" node_number="3814">Theo Heimel</a>, <a class="valid" valid="valid" title="valid: True, node: 3815, level: 8" node_number="3815">Sander Hummerich</a>, <a class="valid" valid="valid" title="valid: True, node: 3816, level: 8" node_number="3816">Tobias Krebs</a>, <a class="valid" valid="valid" title="valid: True, node: 3817, level: 8" node_number="3817">Tilman Plehn</a>, <a class="valid" valid="valid" title="valid: True, node: 3818, level: 8" node_number="3818">Armand Rousselot</a>, <a class="valid" valid="valid" title="valid: True, node: 3819, level: 8" node_number="3819">Sophia Vent</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3820, level: 7" node_number="3820"> Comments: 27 pages, 14 figures </div> <div class="valid" valid="valid" title="valid: True, node: 3821, level: 7" node_number="3821"> Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3822, level: 5" node_number="3822">[357] arXiv:2110.15678 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3823, level: 5" node_number="3823"> <div class="valid" valid="valid" title="valid: True, node: 3824, level: 6" node_number="3824"> <div class="valid" valid="valid" title="valid: True, node: 3825, level: 7" node_number="3825"> Title: A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis </div> <div class="valid" valid="valid" title="valid: True, node: 3826, level: 7" node_number="3826"> Authors: Xingang Pan, <a class="valid" valid="valid" title="valid: True, node: 3827, level: 8" node_number="3827">Xudong Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 3828, level: 8" node_number="3828">Chen Change Loy</a>, <a class="valid" valid="valid" title="valid: True, node: 3829, level: 8" node_number="3829">Christian Theobalt</a>, <a class="valid" valid="valid" title="valid: True, node: 3830, level: 8" node_number="3830">Bo Dai</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3831, level: 7" node_number="3831"> Comments: Accepted to NeurIPS2021. We proposed ShadeGAN, which could perform shape-accurate 3D-aware image synthesis by modeling shading in generative implicit models </div> <div class="valid" valid="valid" title="valid: True, node: 3832, level: 7" node_number="3832"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3833, level: 5" node_number="3833">[358] arXiv:2111.00674 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3834, level: 5" node_number="3834"> <div class="valid" valid="valid" title="valid: True, node: 3835, level: 6" node_number="3835"> <div class="valid" valid="valid" title="valid: True, node: 3836, level: 7" node_number="3836"> Title: Distilling Object Detectors with Feature Richness </div> <div class="valid" valid="valid" title="valid: True, node: 3837, level: 7" node_number="3837"> Authors: Zhixing Du, <a class="valid" valid="valid" title="valid: True, node: 3838, level: 8" node_number="3838">Rui Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3839, level: 8" node_number="3839">Ming Chang</a>, <a class="valid" valid="valid" title="valid: True, node: 3840, level: 8" node_number="3840">Xishan Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 3841, level: 8" node_number="3841">Shaoli Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 3842, level: 8" node_number="3842">Tianshi Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3843, level: 8" node_number="3843">Yunji Chen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3844, level: 7" node_number="3844"> Comments: Accepted in NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3845, level: 7" node_number="3845"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3846, level: 5" node_number="3846">[359] arXiv:2111.00788 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3847, level: 5" node_number="3847"> <div class="valid" valid="valid" title="valid: True, node: 3848, level: 6" node_number="3848"> <div class="valid" valid="valid" title="valid: True, node: 3849, level: 7" node_number="3849"> Title: Hierarchical Adaptable and Transferable Networks (HATN) for Driving Behavior Prediction </div> <div class="valid" valid="valid" title="valid: True, node: 3850, level: 7" node_number="3850"> Authors: Letian Wang, <a class="valid" valid="valid" title="valid: True, node: 3851, level: 8" node_number="3851">Yeping Hu</a>, <a class="valid" valid="valid" title="valid: True, node: 3852, level: 8" node_number="3852">Liting Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 3853, level: 8" node_number="3853">Wei Zhan</a>, <a class="valid" valid="valid" title="valid: True, node: 3854, level: 8" node_number="3854">Masayoshi Tomizuka</a>, <a class="valid" valid="valid" title="valid: True, node: 3855, level: 8" node_number="3855">Changliu Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3856, level: 7" node_number="3856"> Comments: 8 pages, 6 figures. Typo fixed. Accepted by Advances in Neural Information Processing Systems (NeurIPS 2021) Machine Learning for Autonomous Driving Workshop (ML4AD). October 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3857, level: 7" node_number="3857"> Subjects: Robotics (cs.RO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3858, level: 5" node_number="3858">[360] arXiv:2111.01004 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3859, level: 5" node_number="3859"> <div class="valid" valid="valid" title="valid: True, node: 3860, level: 6" node_number="3860"> <div class="valid" valid="valid" title="valid: True, node: 3861, level: 7" node_number="3861"> Title: Improving Contrastive Learning on Imbalanced Seed Data via Open-World Sampling </div> <div class="valid" valid="valid" title="valid: True, node: 3862, level: 7" node_number="3862"> Authors: Ziyu Jiang, <a class="valid" valid="valid" title="valid: True, node: 3863, level: 8" node_number="3863">Tianlong Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3864, level: 8" node_number="3864">Ting Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 3865, level: 8" node_number="3865">Zhangyang Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3866, level: 7" node_number="3866"> Comments: Neurips 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 3867, level: 7" node_number="3867"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3868, level: 5" node_number="3868">[361] arXiv:2111.01884 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3869, level: 5" node_number="3869"> <div class="valid" valid="valid" title="valid: True, node: 3870, level: 6" node_number="3870"> <div class="valid" valid="valid" title="valid: True, node: 3871, level: 7" node_number="3871"> Title: Body Size and Depth Disambiguation in Multi-Person Reconstruction from Single Images </div> <div class="valid" valid="valid" title="valid: True, node: 3872, level: 7" node_number="3872"> Authors: Nicolas Ugrinovic, <a class="valid" valid="valid" title="valid: True, node: 3873, level: 8" node_number="3873">Adria Ruiz</a>, <a class="valid" valid="valid" title="valid: True, node: 3874, level: 8" node_number="3874">Antonio Agudo</a>, <a class="valid" valid="valid" title="valid: True, node: 3875, level: 8" node_number="3875">Alberto Sanfeliu</a>, <a class="valid" valid="valid" title="valid: True, node: 3876, level: 8" node_number="3876">Francesc Moreno-Noguer</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3877, level: 7" node_number="3877"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3878, level: 5" node_number="3878">[362] arXiv:2111.04941 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3879, level: 5" node_number="3879"> <div class="valid" valid="valid" title="valid: True, node: 3880, level: 6" node_number="3880"> <div class="valid" valid="valid" title="valid: True, node: 3881, level: 7" node_number="3881"> Title: Solving PDE-constrained Control Problems using Operator Learning </div> <div class="valid" valid="valid" title="valid: True, node: 3882, level: 7" node_number="3882"> Authors: Rakhoon Hwang, <a class="valid" valid="valid" title="valid: True, node: 3883, level: 8" node_number="3883">Jae Yong Lee</a>, <a class="valid" valid="valid" title="valid: True, node: 3884, level: 8" node_number="3884">Jin Young Shin</a>, <a class="valid" valid="valid" title="valid: True, node: 3885, level: 8" node_number="3885">Hyung Ju Hwang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3886, level: 7" node_number="3886"> Comments: 15 pages, 12 figures. This paper is accepted to the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22) </div> <div class="valid" valid="valid" title="valid: True, node: 3887, level: 7" node_number="3887"> Subjects: Optimization and Control (math.OC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3888, level: 5" node_number="3888">[363] arXiv:2111.05874 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3889, level: 5" node_number="3889"> <div class="valid" valid="valid" title="valid: True, node: 3890, level: 6" node_number="3890"> <div class="valid" valid="valid" title="valid: True, node: 3891, level: 7" node_number="3891"> Title: A Hierarchy for Replica Quantum Advantage </div> <div class="valid" valid="valid" title="valid: True, node: 3892, level: 7" node_number="3892"> Authors: Sitan Chen, <a class="valid" valid="valid" title="valid: True, node: 3893, level: 8" node_number="3893">Jordan Cotler</a>, <a class="valid" valid="valid" title="valid: True, node: 3894, level: 8" node_number="3894">Hsin-Yuan Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 3895, level: 8" node_number="3895">Jerry Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3896, level: 7" node_number="3896"> Comments: 3+17 pages, 2 figures; v2: typos fixed </div> <div class="valid" valid="valid" title="valid: True, node: 3897, level: 7" node_number="3897"> Subjects: Quantum Physics (quant-ph); Computational Complexity (cs.CC); Information Theory (cs.IT); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3898, level: 5" node_number="3898">[364] arXiv:2111.06483 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3899, level: 5" node_number="3899"> <div class="valid" valid="valid" title="valid: True, node: 3900, level: 6" node_number="3900"> <div class="valid" valid="valid" title="valid: True, node: 3901, level: 7" node_number="3901"> Title: Sequential Aggregation and Rematerialization: Distributed Full-batch Training of Graph Neural Networks on Large Graphs </div> <div class="valid" valid="valid" title="valid: True, node: 3902, level: 7" node_number="3902"> Authors: Hesham Mostafa </div> <div class="valid" valid="valid" title="valid: True, node: 3903, level: 7" node_number="3903"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3904, level: 5" node_number="3904">[365] arXiv:2111.06741 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3905, level: 5" node_number="3905"> <div class="valid" valid="valid" title="valid: True, node: 3906, level: 6" node_number="3906"> <div class="valid" valid="valid" title="valid: True, node: 3907, level: 7" node_number="3907"> Title: A Quantum Natural Language Processing Approach to Musical Intelligence </div> <div class="valid" valid="valid" title="valid: True, node: 3908, level: 7" node_number="3908"> Authors: Eduardo Reck Miranda, <a class="valid" valid="valid" title="valid: True, node: 3909, level: 8" node_number="3909">Richie Yeung</a>, <a class="valid" valid="valid" title="valid: True, node: 3910, level: 8" node_number="3910">Anna Pearson</a>, <a class="valid" valid="valid" title="valid: True, node: 3911, level: 8" node_number="3911">Konstantinos Meichanetzidis</a>, <a class="valid" valid="valid" title="valid: True, node: 3912, level: 8" node_number="3912">Bob Coecke</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3913, level: 7" node_number="3913"> Comments: Pre-publication draft of a chapter to appear in Quantum Computer Music, E. R. Miranda (Ed.) </div> <div class="valid" valid="valid" title="valid: True, node: 3914, level: 7" node_number="3914"> Subjects: Quantum Physics (quant-ph); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3915, level: 5" node_number="3915">[366] arXiv:2111.06931 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3916, level: 5" node_number="3916"> <div class="valid" valid="valid" title="valid: True, node: 3917, level: 6" node_number="3917"> <div class="valid" valid="valid" title="valid: True, node: 3918, level: 7" node_number="3918"> Title: Solving A System Of Linear Equations By Randomized Orthogonal Projections </div> <div class="valid" valid="valid" title="valid: True, node: 3919, level: 7" node_number="3919"> Authors: Alireza Entezari, <a class="valid" valid="valid" title="valid: True, node: 3920, level: 8" node_number="3920">Arunava Banerjee</a>, <a class="valid" valid="valid" title="valid: True, node: 3921, level: 8" node_number="3921">Leila Kalantari</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3922, level: 7" node_number="3922"> Subjects: Numerical Analysis (math.NA); Optimization and Control (math.OC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3923, level: 5" node_number="3923">[367] arXiv:2111.07832 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3924, level: 5" node_number="3924"> <div class="valid" valid="valid" title="valid: True, node: 3925, level: 6" node_number="3925"> <div class="valid" valid="valid" title="valid: True, node: 3926, level: 7" node_number="3926"> Title: iBOT: Image BERT Pre-Training with Online Tokenizer </div> <div class="valid" valid="valid" title="valid: True, node: 3927, level: 7" node_number="3927"> Authors: Jinghao Zhou, <a class="valid" valid="valid" title="valid: True, node: 3928, level: 8" node_number="3928">Chen Wei</a>, <a class="valid" valid="valid" title="valid: True, node: 3929, level: 8" node_number="3929">Huiyu Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 3930, level: 8" node_number="3930">Wei Shen</a>, <a class="valid" valid="valid" title="valid: True, node: 3931, level: 8" node_number="3931">Cihang Xie</a>, <a class="valid" valid="valid" title="valid: True, node: 3932, level: 8" node_number="3932">Alan Yuille</a>, <a class="valid" valid="valid" title="valid: True, node: 3933, level: 8" node_number="3933">Tao Kong</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3934, level: 7" node_number="3934"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3935, level: 5" node_number="3935">[368] arXiv:2111.08162 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3936, level: 5" node_number="3936"> <div class="valid" valid="valid" title="valid: True, node: 3937, level: 6" node_number="3937"> <div class="valid" valid="valid" title="valid: True, node: 3938, level: 7" node_number="3938"> Title: On Bock's Conjecture Regarding the Adam Optimizer </div> <div class="valid" valid="valid" title="valid: True, node: 3939, level: 7" node_number="3939"> Authors: Mohamed Akrout, <a class="valid" valid="valid" title="valid: True, node: 3940, level: 8" node_number="3940">Douglas Tweed</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3941, level: 7" node_number="3941"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3942, level: 5" node_number="3942">[369] arXiv:2111.09434 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3943, level: 5" node_number="3943"> <div class="valid" valid="valid" title="valid: True, node: 3944, level: 6" node_number="3944"> <div class="valid" valid="valid" title="valid: True, node: 3945, level: 7" node_number="3945"> Title: On the Effectiveness of Iterative Learning Control </div> <div class="valid" valid="valid" title="valid: True, node: 3946, level: 7" node_number="3946"> Authors: Anirudh Vemula, <a class="valid" valid="valid" title="valid: True, node: 3947, level: 8" node_number="3947">Wen Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 3948, level: 8" node_number="3948">Maxim Likhachev</a>, <a class="valid" valid="valid" title="valid: True, node: 3949, level: 8" node_number="3949">J. Andrew Bagnell</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3950, level: 7" node_number="3950"> Comments: Submitted to L4DC 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 3951, level: 7" node_number="3951"> Subjects: Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3952, level: 5" node_number="3952">[370] arXiv:2111.09543 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3953, level: 5" node_number="3953"> <div class="valid" valid="valid" title="valid: True, node: 3954, level: 6" node_number="3954"> <div class="valid" valid="valid" title="valid: True, node: 3955, level: 7" node_number="3955"> Title: DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing </div> <div class="valid" valid="valid" title="valid: True, node: 3956, level: 7" node_number="3956"> Authors: Pengcheng He, <a class="valid" valid="valid" title="valid: True, node: 3957, level: 8" node_number="3957">Jianfeng Gao</a>, <a class="valid" valid="valid" title="valid: True, node: 3958, level: 8" node_number="3958">Weizhu Chen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3959, level: 7" node_number="3959"> Comments: 16 pages, 10 tables, 2 Figures. The DeBERTaV3 model significantly improves performance of the downstream NLU tasks over models with a similar structure, e.g. DeBERTaV3 large achieves 91.37% average GLUE score which is 1.37% over DeBERTa large. XSmall has only 22M backbone parameters, but significantly outperforms RoBERTa/XLNet-base </div> <div class="valid" valid="valid" title="valid: True, node: 3960, level: 7" node_number="3960"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3961, level: 5" node_number="3961">[371] arXiv:2111.10326 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3962, level: 5" node_number="3962"> <div class="valid" valid="valid" title="valid: True, node: 3963, level: 6" node_number="3963"> <div class="valid" valid="valid" title="valid: True, node: 3964, level: 7" node_number="3964"> Title: Factorisation-based Image Labelling </div> <div class="valid" valid="valid" title="valid: True, node: 3965, level: 7" node_number="3965"> Authors: Yu Yan, <a class="valid" valid="valid" title="valid: True, node: 3966, level: 8" node_number="3966">Yael Balbastre</a>, <a class="valid" valid="valid" title="valid: True, node: 3967, level: 8" node_number="3967">Mikael Brudfors</a>, <a class="valid" valid="valid" title="valid: True, node: 3968, level: 8" node_number="3968">John Ashburner</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3969, level: 7" node_number="3969"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3970, level: 5" node_number="3970">[372] arXiv:2111.11510 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3971, level: 5" node_number="3971"> <div class="valid" valid="valid" title="valid: True, node: 3972, level: 6" node_number="3972"> <div class="valid" valid="valid" title="valid: True, node: 3973, level: 7" node_number="3973"> Title: Bootstrap Your Flow </div> <div class="valid" valid="valid" title="valid: True, node: 3974, level: 7" node_number="3974"> Authors: Laurence Illing Midgley, <a class="valid" valid="valid" title="valid: True, node: 3975, level: 8" node_number="3975">Vincent Stimper</a>, <a class="valid" valid="valid" title="valid: True, node: 3976, level: 8" node_number="3976">Gregor N. C. Simm</a>, <a class="valid" valid="valid" title="valid: True, node: 3977, level: 8" node_number="3977">Jos&#233; Miguel Hern&#225;ndez-Lobato</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3978, level: 7" node_number="3978"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3979, level: 5" node_number="3979">[373] arXiv:2111.12243 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3980, level: 5" node_number="3980"> <div class="valid" valid="valid" title="valid: True, node: 3981, level: 6" node_number="3981"> <div class="valid" valid="valid" title="valid: True, node: 3982, level: 7" node_number="3982"> Title: Vectorizing Sparse Matrix Codes with Dependency Driven Trace Analysis </div> <div class="valid" valid="valid" title="valid: True, node: 3983, level: 7" node_number="3983"> Authors: Zachary Cetinic, <a class="valid" valid="valid" title="valid: True, node: 3984, level: 8" node_number="3984">Kazem Cheshmi</a>, <a class="valid" valid="valid" title="valid: True, node: 3985, level: 8" node_number="3985">Maryam Mehri Dehnavi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3986, level: 7" node_number="3986"> Subjects: Programming Languages (cs.PL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3987, level: 5" node_number="3987">[374] arXiv:2111.12555 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3988, level: 5" node_number="3988"> <div class="valid" valid="valid" title="valid: True, node: 3989, level: 6" node_number="3989"> <div class="valid" valid="valid" title="valid: True, node: 3990, level: 7" node_number="3990"> Title: Serpens: A High Bandwidth Memory Based Accelerator for General-Purpose Sparse Matrix-Vector Multiplication </div> <div class="valid" valid="valid" title="valid: True, node: 3991, level: 7" node_number="3991"> Authors: Linghao Song, <a class="valid" valid="valid" title="valid: True, node: 3992, level: 8" node_number="3992">Yuze Chi</a>, <a class="valid" valid="valid" title="valid: True, node: 3993, level: 8" node_number="3993">Licheng Guo</a>, <a class="valid" valid="valid" title="valid: True, node: 3994, level: 8" node_number="3994">Jason Cong</a> </div> <div class="valid" valid="valid" title="valid: True, node: 3995, level: 7" node_number="3995"> Subjects: Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 3996, level: 5" node_number="3996">[375] arXiv:2111.13436 (replaced) [pdf]</dt> <dd class="valid" valid="valid" title="valid: True, node: 3997, level: 5" node_number="3997"> <div class="valid" valid="valid" title="valid: True, node: 3998, level: 6" node_number="3998"> <div class="valid" valid="valid" title="valid: True, node: 3999, level: 7" node_number="3999"> Title: Towards a Secure and Reliable IT-Ecosystem in Seaports </div> <div class="valid" valid="valid" title="valid: True, node: 4000, level: 7" node_number="4000"> Authors: Tobias Brandt, <a class="valid" valid="valid" title="valid: True, node: 4001, level: 8" node_number="4001">Dieter Hutter</a>, <a class="valid" valid="valid" title="valid: True, node: 4002, level: 8" node_number="4002">Christian Maeder</a>, <a class="valid" valid="valid" title="valid: True, node: 4003, level: 8" node_number="4003">Rainer M&#252;ller</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4004, level: 7" node_number="4004"> Comments: Presented at the 29th Conference of the International Association of Maritime Economists, Rotterdam, November 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 4005, level: 7" node_number="4005"> Subjects: Cryptography and Security (cs.CR) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4006, level: 5" node_number="4006">[376] arXiv:2111.13579 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4007, level: 5" node_number="4007"> <div class="valid" valid="valid" title="valid: True, node: 4008, level: 6" node_number="4008"> <div class="valid" valid="valid" title="valid: True, node: 4009, level: 7" node_number="4009"> Title: VL-LTR: Learning Class-wise Visual-Linguistic Representation for Long-Tailed Visual Recognition </div> <div class="valid" valid="valid" title="valid: True, node: 4010, level: 7" node_number="4010"> Authors: Changyao Tian, <a class="valid" valid="valid" title="valid: True, node: 4011, level: 8" node_number="4011">Wenhai Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4012, level: 8" node_number="4012">Xizhou Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 4013, level: 8" node_number="4013">Xiaogang Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4014, level: 8" node_number="4014">Jifeng Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 4015, level: 8" node_number="4015">Yu Qiao</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4016, level: 7" node_number="4016"> Comments: Technical report; 14 pages, 9 figures </div> <div class="valid" valid="valid" title="valid: True, node: 4017, level: 7" node_number="4017"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4018, level: 5" node_number="4018">[377] arXiv:2111.13755 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4019, level: 5" node_number="4019"> <div class="valid" valid="valid" title="valid: True, node: 4020, level: 6" node_number="4020"> <div class="valid" valid="valid" title="valid: True, node: 4021, level: 7" node_number="4021"> Title: A survey on multi-objective hyperparameter optimization algorithms for Machine Learning </div> <div class="valid" valid="valid" title="valid: True, node: 4022, level: 7" node_number="4022"> Authors: Alejandro Morales-Hern&#225;ndez, <a class="valid" valid="valid" title="valid: True, node: 4023, level: 8" node_number="4023">Inneke Van Nieuwenhuyse</a>, <a class="valid" valid="valid" title="valid: True, node: 4024, level: 8" node_number="4024">Sebastian Rojas Gonzalez</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4025, level: 7" node_number="4025"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4026, level: 5" node_number="4026">[378] arXiv:2111.14259 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4027, level: 5" node_number="4027"> <div class="valid" valid="valid" title="valid: True, node: 4028, level: 6" node_number="4028"> <div class="valid" valid="valid" title="valid: True, node: 4029, level: 7" node_number="4029"> Title: 3D High-Quality Magnetic Resonance Image Restoration in Clinics Using Deep Learning </div> <div class="valid" valid="valid" title="valid: True, node: 4030, level: 7" node_number="4030"> Authors: Hao Li, <a class="valid" valid="valid" title="valid: True, node: 4031, level: 8" node_number="4031">Jianan Liu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4032, level: 7" node_number="4032"> Comments: 14 pages, 8 figures </div> <div class="valid" valid="valid" title="valid: True, node: 4033, level: 7" node_number="4033"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4034, level: 5" node_number="4034">[379] arXiv:2111.14301 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4035, level: 5" node_number="4035"> <div class="valid" valid="valid" title="valid: True, node: 4036, level: 6" node_number="4036"> <div class="valid" valid="valid" title="valid: True, node: 4037, level: 7" node_number="4037"> Title: PSG: Prompt-based Sequence Generation for Acronym Extraction </div> <div class="valid" valid="valid" title="valid: True, node: 4038, level: 7" node_number="4038"> Authors: Bin Li, <a class="valid" valid="valid" title="valid: True, node: 4039, level: 8" node_number="4039">Fei Xia</a>, <a class="valid" valid="valid" title="valid: True, node: 4040, level: 8" node_number="4040">Yixuan Weng</a>, <a class="valid" valid="valid" title="valid: True, node: 4041, level: 8" node_number="4041">Xiusheng Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 4042, level: 8" node_number="4042">Bin Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 4043, level: 8" node_number="4043">Shutao Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4044, level: 7" node_number="4044"> Comments: Accepted for Artificial Intelligence on Scientific Document Understanding (SDU) workshop at AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4045, level: 7" node_number="4045"> Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4046, level: 5" node_number="4046">[380] arXiv:2111.14306 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4047, level: 5" node_number="4047"> <div class="valid" valid="valid" title="valid: True, node: 4048, level: 6" node_number="4048"> <div class="valid" valid="valid" title="valid: True, node: 4049, level: 7" node_number="4049"> Title: SimCLAD: A Simple Framework for Contrastive Learning of Acronym Disambiguation </div> <div class="valid" valid="valid" title="valid: True, node: 4050, level: 7" node_number="4050"> Authors: Bin Li, <a class="valid" valid="valid" title="valid: True, node: 4051, level: 8" node_number="4051">Fei Xia</a>, <a class="valid" valid="valid" title="valid: True, node: 4052, level: 8" node_number="4052">Yixuan Weng</a>, <a class="valid" valid="valid" title="valid: True, node: 4053, level: 8" node_number="4053">Xiusheng Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 4054, level: 8" node_number="4054">Bin Sun</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4055, level: 7" node_number="4055"> Comments: Accepted for Artificial Intelligence on Scientific Document Understanding (SDU) workshop at AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4056, level: 7" node_number="4056"> Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4057, level: 5" node_number="4057">[381] arXiv:2111.14385 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4058, level: 5" node_number="4058"> <div class="valid" valid="valid" title="valid: True, node: 4059, level: 6" node_number="4059"> <div class="valid" valid="valid" title="valid: True, node: 4060, level: 7" node_number="4060"> Title: A theory of meta-factorization </div> <div class="valid" valid="valid" title="valid: True, node: 4061, level: 7" node_number="4061"> Authors: Micha&#322; P. Karpowicz </div> <div class="valid" valid="valid" title="valid: True, node: 4062, level: 7" node_number="4062"> Comments: Added references in section Related work </div> <div class="valid" valid="valid" title="valid: True, node: 4063, level: 7" node_number="4063"> Subjects: Numerical Analysis (math.NA) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4064, level: 5" node_number="4064">[382] arXiv:2111.14592 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4065, level: 5" node_number="4065"> <div class="valid" valid="valid" title="valid: True, node: 4066, level: 6" node_number="4066"> <div class="valid" valid="valid" title="valid: True, node: 4067, level: 7" node_number="4067"> Title: GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection </div> <div class="valid" valid="valid" title="valid: True, node: 4068, level: 7" node_number="4068"> Authors: Wanwei He, <a class="valid" valid="valid" title="valid: True, node: 4069, level: 8" node_number="4069">Yinpei Dai</a>, <a class="valid" valid="valid" title="valid: True, node: 4070, level: 8" node_number="4070">Yinhe Zheng</a>, <a class="valid" valid="valid" title="valid: True, node: 4071, level: 8" node_number="4071">Yuchuan Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 4072, level: 8" node_number="4072">Zheng Cao</a>, <a class="valid" valid="valid" title="valid: True, node: 4073, level: 8" node_number="4073">Dermot Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4074, level: 8" node_number="4074">Peng Jiang</a>, <a class="valid" valid="valid" title="valid: True, node: 4075, level: 8" node_number="4075">Min Yang</a>, <a class="valid" valid="valid" title="valid: True, node: 4076, level: 8" node_number="4076">Fei Huang</a>, <a class="valid" valid="valid" title="valid: True, node: 4077, level: 8" node_number="4077">Luo Si</a>, <a class="valid" valid="valid" title="valid: True, node: 4078, level: 8" node_number="4078">Jian Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 4079, level: 8" node_number="4079">Yongbin Li</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4080, level: 7" node_number="4080"> Comments: 7 pages, 5 figures. Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4081, level: 7" node_number="4081"> Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4082, level: 5" node_number="4082">[383] arXiv:2111.14788 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4083, level: 5" node_number="4083"> <div class="valid" valid="valid" title="valid: True, node: 4084, level: 6" node_number="4084"> <div class="valid" valid="valid" title="valid: True, node: 4085, level: 7" node_number="4085"> Title: Function Approximation for High-Energy Physics: Comparing Machine Learning and Interpolation Methods </div> <div class="valid" valid="valid" title="valid: True, node: 4086, level: 7" node_number="4086"> Authors: Ibrahim Chahrour, <a class="valid" valid="valid" title="valid: True, node: 4087, level: 8" node_number="4087">James D. Wells</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4088, level: 7" node_number="4088"> Comments: 30 pages, 17 figures, added a few references </div> <div class="valid" valid="valid" title="valid: True, node: 4089, level: 7" node_number="4089"> Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4090, level: 5" node_number="4090">[384] arXiv:2111.15438 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4091, level: 5" node_number="4091"> <div class="valid" valid="valid" title="valid: True, node: 4092, level: 6" node_number="4092"> <div class="valid" valid="valid" title="valid: True, node: 4093, level: 7" node_number="4093"> Title: FMD-cGAN: Fast Motion Deblurring using Conditional Generative Adversarial Networks </div> <div class="valid" valid="valid" title="valid: True, node: 4094, level: 7" node_number="4094"> Authors: Jatin Kumar, <a class="valid" valid="valid" title="valid: True, node: 4095, level: 8" node_number="4095">Indra Deep Mastan</a>, <a class="valid" valid="valid" title="valid: True, node: 4096, level: 8" node_number="4096">Shanmuganathan Raman</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4097, level: 7" node_number="4097"> Comments: International Conference on Computer Vision and Image Processing 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 4098, level: 7" node_number="4098"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4099, level: 5" node_number="4099">[385] arXiv:2111.15518 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4100, level: 5" node_number="4100"> <div class="valid" valid="valid" title="valid: True, node: 4101, level: 6" node_number="4101"> <div class="valid" valid="valid" title="valid: True, node: 4102, level: 7" node_number="4102"> Title: Detecting Adversaries, yet Faltering to Noise? Leveraging Conditional Variational AutoEncoders for Adversary Detection in the Presence of Noisy Images </div> <div class="valid" valid="valid" title="valid: True, node: 4103, level: 7" node_number="4103"> Authors: Dvij Kalaria, <a class="valid" valid="valid" title="valid: True, node: 4104, level: 8" node_number="4104">Aritra Hazra</a>, <a class="valid" valid="valid" title="valid: True, node: 4105, level: 8" node_number="4105">Partha Pratim Chakrabarti</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4106, level: 7" node_number="4106"> Comments: Accepted at Adversarial Machine Learning (AdvML) workshop, AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4107, level: 7" node_number="4107"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4108, level: 5" node_number="4108">[386] arXiv:2112.00503 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4109, level: 5" node_number="4109"> <div class="valid" valid="valid" title="valid: True, node: 4110, level: 6" node_number="4110"> <div class="valid" valid="valid" title="valid: True, node: 4111, level: 7" node_number="4111"> Title: Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence Dependency Graph </div> <div class="valid" valid="valid" title="valid: True, node: 4112, level: 7" node_number="4112"> Authors: Liyan Xu, <a class="valid" valid="valid" title="valid: True, node: 4113, level: 8" node_number="4113">Xuchao Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 4114, level: 8" node_number="4114">Bo Zong</a>, <a class="valid" valid="valid" title="valid: True, node: 4115, level: 8" node_number="4115">Yanchi Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4116, level: 8" node_number="4116">Wei Cheng</a>, <a class="valid" valid="valid" title="valid: True, node: 4117, level: 8" node_number="4117">Jingchao Ni</a>, <a class="valid" valid="valid" title="valid: True, node: 4118, level: 8" node_number="4118">Haifeng Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 4119, level: 8" node_number="4119">Liang Zhao</a>, <a class="valid" valid="valid" title="valid: True, node: 4120, level: 8" node_number="4120">Jinho D. Choi</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4121, level: 7" node_number="4121"> Comments: Accepted to AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4122, level: 7" node_number="4122"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4123, level: 5" node_number="4123">[387] arXiv:2112.00702 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4124, level: 5" node_number="4124"> <div class="valid" valid="valid" title="valid: True, node: 4125, level: 6" node_number="4125"> <div class="valid" valid="valid" title="valid: True, node: 4126, level: 7" node_number="4126"> Title: Semi-supervised music emotion recognition using noisy student training and harmonic pitch class profiles </div> <div class="valid" valid="valid" title="valid: True, node: 4127, level: 7" node_number="4127"> Authors: Hao Hao Tan </div> <div class="valid" valid="valid" title="valid: True, node: 4128, level: 7" node_number="4128"> Comments: MediaEval 2021 submission for Emotion and Themes in Music </div> <div class="valid" valid="valid" title="valid: True, node: 4129, level: 7" node_number="4129"> Subjects: Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4130, level: 5" node_number="4130">[388] arXiv:2112.00828 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4131, level: 5" node_number="4131"> <div class="valid" valid="valid" title="valid: True, node: 4132, level: 6" node_number="4132"> <div class="valid" valid="valid" title="valid: True, node: 4133, level: 7" node_number="4133"> Title: The Price of Differential Privacy under Continual Observation </div> <div class="valid" valid="valid" title="valid: True, node: 4134, level: 7" node_number="4134"> Authors: Palak Jain, Sofya Raskhodnikova, <a class="valid" valid="valid" title="valid: True, node: 4135, level: 8" node_number="4135">Satchit Sivakumar</a>, <a class="valid" valid="valid" title="valid: True, node: 4136, level: 8" node_number="4136">Adam Smith</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4137, level: 7" node_number="4137"> Comments: 28 pages </div> <div class="valid" valid="valid" title="valid: True, node: 4138, level: 7" node_number="4138"> Subjects: Data Structures and Algorithms (cs.DS); Cryptography and Security (cs.CR) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4139, level: 5" node_number="4139">[389] arXiv:2112.01030 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4140, level: 5" node_number="4140"> <div class="valid" valid="valid" title="valid: True, node: 4141, level: 6" node_number="4141"> <div class="valid" valid="valid" title="valid: True, node: 4142, level: 7" node_number="4142"> Title: TransMEF: A Transformer-Based Multi-Exposure Image Fusion Framework using Self-Supervised Multi-Task Learning </div> <div class="valid" valid="valid" title="valid: True, node: 4143, level: 7" node_number="4143"> Authors: Linhao Qu, <a class="valid" valid="valid" title="valid: True, node: 4144, level: 8" node_number="4144">Shaolei Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4145, level: 8" node_number="4145">Manning Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4146, level: 8" node_number="4146">Zhijian Song</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4147, level: 7" node_number="4147"> Comments: Accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI2022) </div> <div class="valid" valid="valid" title="valid: True, node: 4148, level: 7" node_number="4148"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4149, level: 5" node_number="4149">[390] arXiv:2112.01332 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4150, level: 5" node_number="4150"> <div class="valid" valid="valid" title="valid: True, node: 4151, level: 6" node_number="4151"> <div class="valid" valid="valid" title="valid: True, node: 4152, level: 7" node_number="4152"> Title: Towards Generating Citation Sentences for Multiple References with Intent Control </div> <div class="valid" valid="valid" title="valid: True, node: 4153, level: 7" node_number="4153"> Authors: Jia-Yan Wu, <a class="valid" valid="valid" title="valid: True, node: 4154, level: 8" node_number="4154">Alexander Te-Wei Shieh</a>, <a class="valid" valid="valid" title="valid: True, node: 4155, level: 8" node_number="4155">Shih-Ju Hsu</a>, <a class="valid" valid="valid" title="valid: True, node: 4156, level: 8" node_number="4156">Yun-Nung Chen</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4157, level: 7" node_number="4157"> Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4158, level: 5" node_number="4158">[391] arXiv:2112.01476 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4159, level: 5" node_number="4159"> <div class="valid" valid="valid" title="valid: True, node: 4160, level: 6" node_number="4160"> <div class="valid" valid="valid" title="valid: True, node: 4161, level: 7" node_number="4161"> Title: KPDrop: An Approach to Improving Absent Keyphrase Generation </div> <div class="valid" valid="valid" title="valid: True, node: 4162, level: 7" node_number="4162"> Authors: Seoyeon Park, <a class="valid" valid="valid" title="valid: True, node: 4163, level: 8" node_number="4163">Jishnu Ray Chowdhury</a>, <a class="valid" valid="valid" title="valid: True, node: 4164, level: 8" node_number="4164">Tuhin Kundu</a>, <a class="valid" valid="valid" title="valid: True, node: 4165, level: 8" node_number="4165">Cornelia Caragea</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4166, level: 7" node_number="4166"> Comments: 4 pages, 1 Figure </div> <div class="valid" valid="valid" title="valid: True, node: 4167, level: 7" node_number="4167"> Subjects: Computation and Language (cs.CL) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4168, level: 5" node_number="4168">[392] arXiv:2112.01513 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4169, level: 5" node_number="4169"> <div class="valid" valid="valid" title="valid: True, node: 4170, level: 6" node_number="4170"> <div class="valid" valid="valid" title="valid: True, node: 4171, level: 7" node_number="4171"> Title: OW-DETR: Open-world Detection Transformer </div> <div class="valid" valid="valid" title="valid: True, node: 4172, level: 7" node_number="4172"> Authors: Akshita Gupta, <a class="valid" valid="valid" title="valid: True, node: 4173, level: 8" node_number="4173">Sanath Narayan</a>, <a class="valid" valid="valid" title="valid: True, node: 4174, level: 8" node_number="4174">K J Joseph</a>, <a class="valid" valid="valid" title="valid: True, node: 4175, level: 8" node_number="4175">Salman Khan</a>, <a class="valid" valid="valid" title="valid: True, node: 4176, level: 8" node_number="4176">Fahad Shahbaz Khan</a>, <a class="valid" valid="valid" title="valid: True, node: 4177, level: 8" node_number="4177">Mubarak Shah</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4178, level: 7" node_number="4178"> Comments: 15 pages </div> <div class="valid" valid="valid" title="valid: True, node: 4179, level: 7" node_number="4179"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4180, level: 5" node_number="4180">[393] arXiv:2112.02646 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4181, level: 5" node_number="4181"> <div class="valid" valid="valid" title="valid: True, node: 4182, level: 6" node_number="4182"> <div class="valid" valid="valid" title="valid: True, node: 4183, level: 7" node_number="4183"> Title: Diverse, Global and Amortised Counterfactual Explanations for Uncertainty Estimates </div> <div class="valid" valid="valid" title="valid: True, node: 4184, level: 7" node_number="4184"> Authors: Dan Ley, <a class="valid" valid="valid" title="valid: True, node: 4185, level: 8" node_number="4185">Umang Bhatt</a>, <a class="valid" valid="valid" title="valid: True, node: 4186, level: 8" node_number="4186">Adrian Weller</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4187, level: 7" node_number="4187"> Comments: Accepted as a conference paper to AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4188, level: 7" node_number="4188"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4189, level: 5" node_number="4189">[394] arXiv:2112.02864 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4190, level: 5" node_number="4190"> <div class="valid" valid="valid" title="valid: True, node: 4191, level: 6" node_number="4191"> <div class="valid" valid="valid" title="valid: True, node: 4192, level: 7" node_number="4192"> Title: Autoencoders for Semivisible Jet Detection </div> <div class="valid" valid="valid" title="valid: True, node: 4193, level: 7" node_number="4193"> Authors: Florencia Canelli, <a class="valid" valid="valid" title="valid: True, node: 4194, level: 8" node_number="4194">Annapaola de Cosa</a>, <a class="valid" valid="valid" title="valid: True, node: 4195, level: 8" node_number="4195">Luc Le Pottier</a>, <a class="valid" valid="valid" title="valid: True, node: 4196, level: 8" node_number="4196">Jeremi Niedziela</a>, <a class="valid" valid="valid" title="valid: True, node: 4197, level: 8" node_number="4197">Kevin Pedro</a>, <a class="valid" valid="valid" title="valid: True, node: 4198, level: 8" node_number="4198">Maurizio Pierini</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4199, level: 7" node_number="4199"> Comments: 16 pages, 10 figures </div> <div class="valid" valid="valid" title="valid: True, node: 4200, level: 7" node_number="4200"> Subjects: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4201, level: 5" node_number="4201">[395] arXiv:2112.03378 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4202, level: 5" node_number="4202"> <div class="valid" valid="valid" title="valid: True, node: 4203, level: 6" node_number="4203"> <div class="valid" valid="valid" title="valid: True, node: 4204, level: 7" node_number="4204"> Title: Differentiable Generalised Predictive Coding </div> <div class="valid" valid="valid" title="valid: True, node: 4205, level: 7" node_number="4205"> Authors: Andr&#233; Ofner, <a class="valid" valid="valid" title="valid: True, node: 4206, level: 8" node_number="4206">Sebastian Stober</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4207, level: 7" node_number="4207"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4208, level: 5" node_number="4208">[396] arXiv:2112.03462 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4209, level: 5" node_number="4209"> <div class="valid" valid="valid" title="valid: True, node: 4210, level: 6" node_number="4210"> <div class="valid" valid="valid" title="valid: True, node: 4211, level: 7" node_number="4211"> Title: SpaceSaving$^\pm$: An Optimal Algorithm for Frequency Estimation and Frequent items in the Bounded Deletion Model </div> <div class="valid" valid="valid" title="valid: True, node: 4212, level: 7" node_number="4212"> Authors: Fuheng Zhao, <a class="valid" valid="valid" title="valid: True, node: 4213, level: 8" node_number="4213">Divyakant Agrawal</a>, <a class="valid" valid="valid" title="valid: True, node: 4214, level: 8" node_number="4214">Amr El Abbadi</a>, <a class="valid" valid="valid" title="valid: True, node: 4215, level: 8" node_number="4215">Ahmed Metwally</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4216, level: 7" node_number="4216"> Subjects: Databases (cs.DB); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4217, level: 5" node_number="4217">[397] arXiv:2112.03552 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4218, level: 5" node_number="4218"> <div class="valid" valid="valid" title="valid: True, node: 4219, level: 6" node_number="4219"> <div class="valid" valid="valid" title="valid: True, node: 4220, level: 7" node_number="4220"> Title: Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training </div> <div class="valid" valid="valid" title="valid: True, node: 4221, level: 7" node_number="4221"> Authors: Haofei Zhang, <a class="valid" valid="valid" title="valid: True, node: 4222, level: 8" node_number="4222">Jiarui Duan</a>, <a class="valid" valid="valid" title="valid: True, node: 4223, level: 8" node_number="4223">Mengqi Xue</a>, <a class="valid" valid="valid" title="valid: True, node: 4224, level: 8" node_number="4224">Jie Song</a>, <a class="valid" valid="valid" title="valid: True, node: 4225, level: 8" node_number="4225">Li Sun</a>, <a class="valid" valid="valid" title="valid: True, node: 4226, level: 8" node_number="4226">Mingli Song</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4227, level: 7" node_number="4227"> Comments: 10 Pages </div> <div class="valid" valid="valid" title="valid: True, node: 4228, level: 7" node_number="4228"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4229, level: 5" node_number="4229">[398] arXiv:2112.03562 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4230, level: 5" node_number="4230"> <div class="valid" valid="valid" title="valid: True, node: 4231, level: 6" node_number="4231"> <div class="valid" valid="valid" title="valid: True, node: 4232, level: 7" node_number="4232"> Title: CMA-CLIP: Cross-Modality Attention CLIP for Image-Text Classification </div> <div class="valid" valid="valid" title="valid: True, node: 4233, level: 7" node_number="4233"> Authors: Huidong Liu, <a class="valid" valid="valid" title="valid: True, node: 4234, level: 8" node_number="4234">Shaoyuan Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 4235, level: 8" node_number="4235">Jinmiao Fu</a>, <a class="valid" valid="valid" title="valid: True, node: 4236, level: 8" node_number="4236">Yang Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4237, level: 8" node_number="4237">Ning Xie</a>, <a class="valid" valid="valid" title="valid: True, node: 4238, level: 8" node_number="4238">Chien-Chih Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4239, level: 8" node_number="4239">Bryan Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4240, level: 8" node_number="4240">Yi Sun</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4241, level: 7" node_number="4241"> Comments: 9 pages, 2 figures, 6 tables, 1 algorithm </div> <div class="valid" valid="valid" title="valid: True, node: 4242, level: 7" node_number="4242"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4243, level: 5" node_number="4243">[399] arXiv:2112.03665 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4244, level: 5" node_number="4244"> <div class="valid" valid="valid" title="valid: True, node: 4245, level: 6" node_number="4245"> <div class="valid" valid="valid" title="valid: True, node: 4246, level: 7" node_number="4246"> Title: Data-Driven Controllability Analysis and Stabilization for Linear Descriptor Systems </div> <div class="valid" valid="valid" title="valid: True, node: 4247, level: 7" node_number="4247"> Authors: Jiabao He, <a class="valid" valid="valid" title="valid: True, node: 4248, level: 8" node_number="4248">Xuan Zhang</a>, <a class="valid" valid="valid" title="valid: True, node: 4249, level: 8" node_number="4249">Feng Xu</a>, <a class="valid" valid="valid" title="valid: True, node: 4250, level: 8" node_number="4250">Xueqian Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4251, level: 7" node_number="4251"> Subjects: Systems and Control (eess.SY) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4252, level: 5" node_number="4252">[400] arXiv:2112.03807 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4253, level: 5" node_number="4253"> <div class="valid" valid="valid" title="valid: True, node: 4254, level: 6" node_number="4254"> <div class="valid" valid="valid" title="valid: True, node: 4255, level: 7" node_number="4255"> Title: raceBERT -- A Transformer-based Model for Predicting Race and Ethnicity from Names </div> <div class="valid" valid="valid" title="valid: True, node: 4256, level: 7" node_number="4256"> Authors: Prasanna Parasurama </div> <div class="valid" valid="valid" title="valid: True, node: 4257, level: 7" node_number="4257"> Comments: See this http URL </div> <div class="valid" valid="valid" title="valid: True, node: 4258, level: 7" node_number="4258"> Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4259, level: 5" node_number="4259">[401] arXiv:2112.04046 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4260, level: 5" node_number="4260"> <div class="valid" valid="valid" title="valid: True, node: 4261, level: 6" node_number="4261"> <div class="valid" valid="valid" title="valid: True, node: 4262, level: 7" node_number="4262"> Title: Asymptotic MIMO Channel Model for Diffusive MC with Fully-absorbing Receivers </div> <div class="valid" valid="valid" title="valid: True, node: 4263, level: 7" node_number="4263"> Authors: Fardad Vakilipoor, <a class="valid" valid="valid" title="valid: True, node: 4264, level: 8" node_number="4264">Marco Ferrari</a>, <a class="valid" valid="valid" title="valid: True, node: 4265, level: 8" node_number="4265">Maurizio Magarini</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4266, level: 7" node_number="4266"> Subjects: Information Theory (cs.IT) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4267, level: 5" node_number="4267">[402] arXiv:2112.04137 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4268, level: 5" node_number="4268"> <div class="valid" valid="valid" title="valid: True, node: 4269, level: 6" node_number="4269"> <div class="valid" valid="valid" title="valid: True, node: 4270, level: 7" node_number="4270"> Title: Pareto Domain Adaptation </div> <div class="valid" valid="valid" title="valid: True, node: 4271, level: 7" node_number="4271"> Authors: Fangrui Lv, <a class="valid" valid="valid" title="valid: True, node: 4272, level: 8" node_number="4272">Jian Liang</a>, <a class="valid" valid="valid" title="valid: True, node: 4273, level: 8" node_number="4273">Kaixiong Gong</a>, <a class="valid" valid="valid" title="valid: True, node: 4274, level: 8" node_number="4274">Shuang Li</a>, <a class="valid" valid="valid" title="valid: True, node: 4275, level: 8" node_number="4275">Chi Harold Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4276, level: 8" node_number="4276">Han Li</a>, <a class="valid" valid="valid" title="valid: True, node: 4277, level: 8" node_number="4277">Di Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4278, level: 8" node_number="4278">Guoren Wang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4279, level: 7" node_number="4279"> Comments: Accepted in NeurIPS 2021 </div> <div class="valid" valid="valid" title="valid: True, node: 4280, level: 7" node_number="4280"> Subjects: Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4281, level: 5" node_number="4281">[403] arXiv:2112.04138 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4282, level: 5" node_number="4282"> <div class="valid" valid="valid" title="valid: True, node: 4283, level: 6" node_number="4283"> <div class="valid" valid="valid" title="valid: True, node: 4284, level: 7" node_number="4284"> Title: Contrastive Instruction-Trajectory Learning for Vision-Language Navigation </div> <div class="valid" valid="valid" title="valid: True, node: 4285, level: 7" node_number="4285"> Authors: Xiwen Liang, <a class="valid" valid="valid" title="valid: True, node: 4286, level: 8" node_number="4286">Fengda Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 4287, level: 8" node_number="4287">Yi Zhu</a>, <a class="valid" valid="valid" title="valid: True, node: 4288, level: 8" node_number="4288">Bingqian Lin</a>, <a class="valid" valid="valid" title="valid: True, node: 4289, level: 8" node_number="4289">Bing Wang</a>, <a class="valid" valid="valid" title="valid: True, node: 4290, level: 8" node_number="4290">Xiaodan Liang</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4291, level: 7" node_number="4291"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4292, level: 7" node_number="4292"> Subjects: Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4293, level: 5" node_number="4293">[404] arXiv:2112.04169 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4294, level: 5" node_number="4294"> <div class="valid" valid="valid" title="valid: True, node: 4295, level: 6" node_number="4295"> <div class="valid" valid="valid" title="valid: True, node: 4296, level: 7" node_number="4296"> Title: Equity Promotion in Online Resource Allocation </div> <div class="valid" valid="valid" title="valid: True, node: 4297, level: 7" node_number="4297"> Authors: Pan Xu, <a class="valid" valid="valid" title="valid: True, node: 4298, level: 8" node_number="4298">Yifan Xu</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4299, level: 7" node_number="4299"> Comments: A preliminary version will appear in the 36th AAAI Conference on Artificial Intelligence (AAAI 22) </div> <div class="valid" valid="valid" title="valid: True, node: 4300, level: 7" node_number="4300"> Subjects: Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4301, level: 5" node_number="4301">[405] arXiv:2112.04178 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4302, level: 5" node_number="4302"> <div class="valid" valid="valid" title="valid: True, node: 4303, level: 6" node_number="4303"> <div class="valid" valid="valid" title="valid: True, node: 4304, level: 7" node_number="4304"> Title: Topology-aware Convolutional Neural Network for Efficient Skeleton-based Action Recognition </div> <div class="valid" valid="valid" title="valid: True, node: 4305, level: 7" node_number="4305"> Authors: Kailin Xu, <a class="valid" valid="valid" title="valid: True, node: 4306, level: 8" node_number="4306">Fanfan Ye</a>, <a class="valid" valid="valid" title="valid: True, node: 4307, level: 8" node_number="4307">Qiaoyong Zhong</a>, <a class="valid" valid="valid" title="valid: True, node: 4308, level: 8" node_number="4308">Di Xie</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4309, level: 7" node_number="4309"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4310, level: 7" node_number="4310"> Subjects: Computer Vision and Pattern Recognition (cs.CV) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4311, level: 5" node_number="4311">[406] arXiv:2112.04274 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4312, level: 5" node_number="4312"> <div class="valid" valid="valid" title="valid: True, node: 4313, level: 6" node_number="4313"> <div class="valid" valid="valid" title="valid: True, node: 4314, level: 7" node_number="4314"> Title: On the Use of Unrealistic Predictions in Hundreds of Papers Evaluating Graph Representations </div> <div class="valid" valid="valid" title="valid: True, node: 4315, level: 7" node_number="4315"> Authors: Li-Chung Lin, <a class="valid" valid="valid" title="valid: True, node: 4316, level: 8" node_number="4316">Cheng-Hung Liu</a>, <a class="valid" valid="valid" title="valid: True, node: 4317, level: 8" node_number="4317">Chih-Ming Chen</a>, <a class="valid" valid="valid" title="valid: True, node: 4318, level: 8" node_number="4318">Kai-Chin Hsu</a>, <a class="valid" valid="valid" title="valid: True, node: 4319, level: 8" node_number="4319">I-Feng Wu</a>, <a class="valid" valid="valid" title="valid: True, node: 4320, level: 8" node_number="4320">Ming-Feng Tsai</a>, <a class="valid" valid="valid" title="valid: True, node: 4321, level: 8" node_number="4321">Chih-Jen Lin</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4322, level: 7" node_number="4322"> Comments: Accepted by AAAI 2022 </div> <div class="valid" valid="valid" title="valid: True, node: 4323, level: 7" node_number="4323"> Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4324, level: 5" node_number="4324">[407] arXiv:2112.04324 (replaced) [pdf, ps, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4325, level: 5" node_number="4325"> <div class="valid" valid="valid" title="valid: True, node: 4326, level: 6" node_number="4326"> <div class="valid" valid="valid" title="valid: True, node: 4327, level: 7" node_number="4327"> Title: Deep Learning and Mathematical Intuition: A Review of (Davies et al. 2021) </div> <div class="valid" valid="valid" title="valid: True, node: 4328, level: 7" node_number="4328"> Authors: Ernest Davis </div> <div class="valid" valid="valid" title="valid: True, node: 4329, level: 7" node_number="4329"> Subjects: Machine Learning (cs.LG); History and Overview (math.HO) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4330, level: 5" node_number="4330">[408] arXiv:2112.04386 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4331, level: 5" node_number="4331"> <div class="valid" valid="valid" title="valid: True, node: 4332, level: 6" node_number="4332"> <div class="valid" valid="valid" title="valid: True, node: 4333, level: 7" node_number="4333"> Title: Which images to label for few-shot medical landmark detection? </div> <div class="valid" valid="valid" title="valid: True, node: 4334, level: 7" node_number="4334"> Authors: Quan Quan, <a class="valid" valid="valid" title="valid: True, node: 4335, level: 8" node_number="4335">Qingsong Yao</a>, <a class="valid" valid="valid" title="valid: True, node: 4336, level: 8" node_number="4336">Jun Li</a>, <a class="valid" valid="valid" title="valid: True, node: 4337, level: 8" node_number="4337">S. Kevin Zhou</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4338, level: 7" node_number="4338"> Subjects: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) </div> </div> </dd> <dt class="valid" valid="valid" title="valid: True, node: 4339, level: 5" node_number="4339">[409] arXiv:2112.04405 (replaced) [pdf, other]</dt> <dd class="valid" valid="valid" title="valid: True, node: 4340, level: 5" node_number="4340"> <div class="valid" valid="valid" title="valid: True, node: 4341, level: 6" node_number="4341"> <div class="valid" valid="valid" title="valid: True, node: 4342, level: 7" node_number="4342"> Title: Improved Distributed Fractional Coloring Algorithms </div> <div class="valid" valid="valid" title="valid: True, node: 4343, level: 7" node_number="4343"> Authors: Alkida Balliu, <a class="valid" valid="valid" title="valid: True, node: 4344, level: 8" node_number="4344">Fabian Kuhn</a>, <a class="valid" valid="valid" title="valid: True, node: 4345, level: 8" node_number="4345">Dennis Olivetti</a> </div> <div class="valid" valid="valid" title="valid: True, node: 4346, level: 7" node_number="4346"> Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) </div> </div> </dd> </dl> <ul class="valid" valid="valid" title="valid: True, node: 4347, level: 4" node_number="4347"> <li class="valid" valid="valid" title="valid: True, node: 4348, level: 5" node_number="4348">New submissions</li> <li class="valid" valid="valid" title="valid: True, node: 4349, level: 5" node_number="4349"><a class="valid" valid="valid" title="valid: True, node: 4350, level: 6" node_number="4350">Cross-lists</a></li> <li class="valid" valid="valid" title="valid: True, node: 4351, level: 5" node_number="4351"><a class="valid" valid="valid" title="valid: True, node: 4352, level: 6" node_number="4352">Replacements</a></li> </ul> <small class="valid" valid="valid" title="valid: True, node: 4353, level: 4" node_number="4353">[ total of 409 entries: <b class="valid" valid="valid" title="valid: True, node: 4354, level: 5" node_number="4354">1-409</b> ]</small> <small class="valid" valid="valid" title="valid: True, node: 4355, level: 4" node_number="4355">[ showing up to 2000 entries per page: <a class="valid" valid="valid" title="valid: True, node: 4356, level: 5" node_number="4356">fewer</a> | <font class="valid" valid="valid" title="valid: True, node: 4357, level: 5" node_number="4357">more</font> ]</small> </div> <small class="valid" valid="valid" title="valid: True, node: 4358, level: 3" node_number="4358"><a class="valid" valid="valid" title="valid: True, node: 4359, level: 4" node_number="4359">Disable MathJax</a> (<a class="valid" valid="valid" title="valid: True, node: 4360, level: 4" node_number="4360">What is MathJax?</a>)</small> <p class="valid" valid="valid" title="valid: True, node: 4361, level: 3" node_number="4361">Links to: <a class="valid" valid="valid" title="valid: True, node: 4362, level: 4" node_number="4362">arXiv</a>, <a class="valid" valid="valid" title="valid: True, node: 4363, level: 4" node_number="4363">form interface</a>, <a class="valid" valid="valid" title="valid: True, node: 4364, level: 4" node_number="4364">find</a>, <a class="valid" valid="valid" title="valid: True, node: 4365, level: 4" node_number="4365">cs</a>, <a class="valid" valid="valid" title="valid: True, node: 4366, level: 4" node_number="4366">recent</a>, <a class="valid" valid="valid" title="valid: True, node: 4367, level: 4" node_number="4367">2112</a>, <a class="valid" valid="valid" title="valid: True, node: 4368, level: 4" node_number="4368">contact</a>, <a class="valid" valid="valid" title="valid: True, node: 4369, level: 4" node_number="4369">help</a> <small class="valid" valid="valid" title="valid: True, node: 4370, level: 4" node_number="4370">(<a class="valid" valid="valid" title="valid: True, node: 4371, level: 5" node_number="4371">Access key</a> information)</small> </p> </div> </body>
        <style tyle='text/css'>
body{
    position: relative;
    padding-left: 30px;
    top: 60px;
}
* {
    border: 1px solid #eee;
    padding: 5px 12px;
    margin: 3px 0;
    box-sizing: content-box;
    background-color: #fff;
    cursor: no-drop;
}
main:hover > *, section:hover > *, header:hover > *, nav:hover > *, a:hover > *, div:hover > *, p:hover > *, ul:hover > *, h1:hover > *, h2:hover > *, h3:hover > *, li:hover > *, span:hover > *{
    border: 2px solid green;
    background-color: #fffeee;
    padding: 5px 23px !important;
    margin: 1px 0;
    color: green;
}
main:hover, section:hover, header:hover, nav:hover, a:hover, div:hover, p:hover, ul:hover, h1:hover, h2:hover, h3:hover, li:hover, span:hover{
    border: 1px solid #fff;
    background-color: #eee;
}
a, span {
    display: block;
}
.selected {
    border: 2px solid orchid !important;
    opacity: 0.8;
    color: orchid !important;
}
.selected * {
    padding: 2px !important;
    color: orchid !important;
}
.valid {
  cursor: pointer;
}
.btn{
  cursor: pointer;
  font-weight: bolder;
  padding: 8px;
}
</style> 
        <script>function OpenOriginalLink($event){
    $event.stopPropagation();
    console.log(url);
}

function removeItem($event){
    $event.stopPropagation();
    console.log('Remove item: ', url)
    localStorage.removeItem(url)
}

function exportData($event){
    $event.stopPropagation();

    result = []
    for(let i=0; i<localStorage.length; i++) {
        let key = localStorage.key(i);
        result.push(localStorage.getItem(key))
    }
    const _url = URL.createObjectURL(new Blob([result.join("\n")], {type: 'text/plain'}))
    $event.target.href = _url;
    localStorage.clear()
}

var removeItemBtn = document.createElement("BUTTON");   // Create a <button> element
removeItemBtn.innerHTML = "Remove Item";
removeItemBtn.classList.add('btn');
removeItemBtn.style.position = "fixed";
removeItemBtn.style.left = '5px';
removeItemBtn.style.top = 0;
removeItemBtn.style.border = "1px solid";
removeItemBtn.style.boxShadow = "3px 3px #888";
removeItemBtn.onclick = removeItem;
document.body.appendChild(removeItemBtn);

var goToOriginLink = document.createElement("A");   // Create a <button> element
goToOriginLink.innerHTML = "GoToOrigin";
goToOriginLink.classList.add('btn');
goToOriginLink.style.position = "fixed"
goToOriginLink.style.left = '115px'
goToOriginLink.style.top = 0;
goToOriginLink.onclick = OpenOriginalLink;
goToOriginLink.setAttribute('href', decodeURIComponent(url));
goToOriginLink.target = '_blank';
document.body.appendChild(goToOriginLink);

var current = new Date
var exportDataLink = document.createElement("A");   // Create a <button> element
exportDataLink.innerHTML = "Export data";
exportDataLink.classList.add('btn');
exportDataLink.download = current.toISOString() + '.exported.txt';
exportDataLink.style.position = "fixed";
exportDataLink.style.right = '5px';
exportDataLink.style.top = 0;
exportDataLink.style.border = "1px solid #888";
exportDataLink.style.boxShadow = "3px 3px #888";
exportDataLink.onclick = exportData;
document.body.appendChild(exportDataLink);

data = {
    'title': null ,
    'article': null
}

var body = document.getElementsByTagName("body")[0];

body.onclick = function($e){
    var num = $e.target.getAttribute('node_number')
    var valid = $e.target.getAttribute('valid')

    if(!valid){
        console.log("Element is invalid")
        return
    }

    if(data.length > 2){
        data = data.splice(0, 2)
    }

    console.log("node:", $e.target)

    if(!data.title && !data.article){
        data.title = num;
        console.log("data:", data)
        $e.target.classList.add('selected')
    }else if (data.title && !data.article){
        data.article = num;
        console.log("data:", data)
        $e.target.classList.add('selected')
    }else{
        selected = Array.from(document.getElementsByClassName("selected"))
        selected.forEach(function(el){
            el.classList.remove('selected')
        })

        data.title = num;
        data.article = null;
        $e.target.classList.add('selected')

    }

    if(data.title && data.article){
        var obj = {
            url: url,
            text: body_html,
            title: data.title,
            article: data.article,
        }

        var datasetItem = JSON.stringify(obj)
        localStorage.setItem(url, datasetItem)
    }
}
</script> 
      </html>