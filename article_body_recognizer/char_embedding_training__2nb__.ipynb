{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace/upwork/martien_brouver/mylapi/scraping/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "import html\n",
    "import base64\n",
    "import pickle\n",
    "import jsonlines\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import _thread\n",
    "\n",
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Nadam\n",
    "from tensorflow.keras.optimizers.schedules import InverseTimeDecay\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Bidirectional, Dropout, LayerNormalization, GRU, BatchNormalization, Dot\n",
    "from tensorflow.keras.layers import concatenate, Reshape, SpatialDropout1D, Conv1D, Flatten, AveragePooling1D, MaxPool1D, Average, Maximum, Multiply, Add\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow import config as config\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "\n",
    "from article_body_recognizer.ANNs.charemb_comparator import CharembComparatorV1\n",
    "from article_body_recognizer.ANNs.charemb_network import CharEmbeddingV5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tictoc': True, 'emb_trainable': True, 'pretrained_emb_vers': None, 'new_emb_vers': 'v5x10u03', 'pretrained_trainer_vers': 'trainer_v5x10u03_re04_tictoc', 'new_trainer_version': 'trainer_v5x10u03_re04_tictoc', 'lean_dataset': True, 'pretrained_model_vers': None, 'embedding_model_class': <class 'article_body_recognizer.ANNs.designs.CharEmbeddingV5'>, 'comparison_norm_trainable': False, 'max_length': 256, 'min_length': 32, 'num_classes': 154, 'masking_ratio': 0.15, 'close_distance_scale': 1.0, 'neutral_distance_scale': -0.55, 'learning_rate': 0.0001, 'optimizer': <class 'keras.optimizer_v2.rmsprop.RMSprop'>, 'batch_size': 4096, 'epochs': 21, 'buffer_size': 32, 'pribuf_looping': True}\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "  'tictoc': True,\n",
    "  'emb_trainable': True,\n",
    "  'pretrained_emb_vers': None, # str or None\n",
    "  'new_emb_vers': 'v5x10u03',\n",
    "  'pretrained_trainer_vers': 'trainer_v5x10u03_re04_tictoc', # str or None\n",
    "  'new_trainer_version' : 'trainer_v5x10u03_re04_tictoc',\n",
    "  'lean_dataset': True,\n",
    "  'pretrained_model_vers': None,  # if set this will get higher priority than pretrained_trainer_vers\n",
    "  'embedding_model_class': CharEmbeddingV5,\n",
    "  'comparison_norm_trainable': False,\n",
    "  'max_length': char_emb_training_specs['MAX_LENGTH'],\n",
    "  'min_length': char_emb_training_specs['MIN_LENGTH'],\n",
    "  'num_classes': char_emb_training_specs['NUM_CLASSES'],\n",
    "  # 'close_masking_ratio': 0.15,    # Many words are suitable to describe this idea:\n",
    "  # 'neutral_masking_ratio': 0.35,  # It's fundamentally flaw, naive, bad because it reveal obviously to model to easily predict which pair is simimlar and which one disimilar\n",
    "  'masking_ratio': 0.15,\n",
    "  'close_distance_scale': 1.0,\n",
    "  'neutral_distance_scale': -0.55,\n",
    "  'learning_rate': 1e-4,\n",
    "  'optimizer': RMSprop,\n",
    "  'batch_size': 4096,\n",
    "  'epochs': 21,\n",
    "  'buffer_size': 32,\n",
    "  'pribuf_looping': True,  # If is True then buffer_size makes no affect and is set to steps_per_epoch\n",
    "}\n",
    "\n",
    "print(cfg)\n",
    "\n",
    "SLEEP_TIME = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def design_model(cfg):\n",
    "\n",
    "  emb_trainable = cfg['emb_trainable']\n",
    "  comparison_norm_trainable = cfg['comparison_norm_trainable']\n",
    "  num_classes = cfg['num_classes']\n",
    "  max_length = cfg['max_length']\n",
    "  lr = cfg['learning_rate']\n",
    "  embedding_model_class = cfg['embedding_model_class']\n",
    "\n",
    "  if not emb_trainable:\n",
    "    comparison_norm_trainable = True\n",
    "\n",
    "    print('[INFO] Training Comparator')\n",
    "  else:\n",
    "    print('[INFO] Training Char Embedding')\n",
    "\n",
    "  print('[CFG] emb_trainable: ', emb_trainable)\n",
    "  print('[CFG] comparison_norm_trainable: ', comparison_norm_trainable)\n",
    "  print('[CFG] optimizer : ', cfg['optimizer'])\n",
    "  print('[CFG] learning_rate : ', lr)\n",
    "\n",
    "  conv_activation = 'swish'\n",
    "\n",
    "  dense_output_1_lv1_size = 11\n",
    "  dense_output_2_lv1_size = 7\n",
    "  dense_output_3_lv1_size = 7\n",
    "  dense_output_1_lv2_size = 3\n",
    "  dense_output_2_lv2_size = 4\n",
    "  dense_activation = 'swish'\n",
    "\n",
    "  char_embedding_layer = CharEmbeddingV5(cfg, trainable=emb_trainable, name='char_embedding')\n",
    "  assert isinstance(char_embedding_layer, embedding_model_class), f'{char_embedding_layer} is wrong embedding model!'\n",
    "\n",
    "  # Encoder 1\n",
    "  input_1 = Input(shape=(max_length,), dtype='int32', name='input_1')\n",
    "  embedded_1 = char_embedding_layer(input_1)\n",
    "\n",
    "  input_2 = Input(shape=(max_length,), dtype='int32', name='input_2')\n",
    "  embedded_2 = char_embedding_layer(input_2)\n",
    "\n",
    "  convoluted_11 = Conv1D(5, 3, 1, activation=conv_activation, padding='same', name='convoluted_11')(embedded_1)\n",
    "  convoluted_21 = Conv1D(5, 5, 1, activation=conv_activation, padding='same', name='convoluted_21')(embedded_1)\n",
    "  convoluted_31 = Conv1D(5, 7, 1, activation=conv_activation, padding='same', name='convoluted_31')(embedded_1)\n",
    "  convoluted_41 = Conv1D(5, 11, 1, activation=conv_activation, padding='same', name='convoluted_41')(embedded_1)\n",
    "\n",
    "  merged_conv_12 = Maximum(name='merged_conv_12')([convoluted_11, convoluted_21, convoluted_31, convoluted_41])\n",
    "  convoluted_12 = Conv1D(11, 3, 1, activation=conv_activation, padding='same', name='convoluted_12')(merged_conv_12)\n",
    "  pooled_12 = AveragePooling1D(3, 3, padding='same', name='pooled_12')(convoluted_12)\n",
    "  convoluted_22 = Conv1D(11, 3, 1, activation=conv_activation, padding='same', name='convoluted_22')(pooled_12)\n",
    "  pooled_22 = MaxPool1D(11, 1, padding='same', name='pooled_22')(convoluted_22)\n",
    "\n",
    "  merged_conv_13 = Maximum(name='merged_conv_13')([pooled_12, pooled_22])\n",
    "  convoluted_13 = Conv1D(17, 3, 3, activation=conv_activation, padding='same', name='convoluted_13')(merged_conv_13)\n",
    "  pooled_13 = AveragePooling1D(3, 3, padding='same', name='pooled_13')(convoluted_13)\n",
    "\n",
    "  unit_convoluted_1 = Conv1D(1, 1, 1, activation=conv_activation, padding='same', name='unit_convoluted_1')(pooled_13)\n",
    "  squeezed_1 = tf.squeeze(unit_convoluted_1, axis=2, name='squeezed_1')\n",
    "\n",
    "  # Encoder 2\n",
    "\n",
    "  rnn_1 = GRU(10, return_sequences=True, name='rnn_1')(embedded_2)\n",
    "  rnn_2 = GRU(10, return_sequences=True, name='rnn_2')(rnn_1)\n",
    "  rnn_3 = GRU(10, return_sequences=False, name='rnn_3')(rnn_2)\n",
    "\n",
    "  # distance\n",
    "  norm_1 = LayerNormalization(trainable=comparison_norm_trainable, name='norm_1')(squeezed_1)\n",
    "  norm_2 = LayerNormalization(trainable=comparison_norm_trainable, name='norm_2')(rnn_3)\n",
    "\n",
    "  dense_output_11_lv1 = Dense(dense_output_1_lv1_size, name='dense_output_11_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_1)\n",
    "  dense_output_11_lv2 = Dense(dense_output_1_lv2_size, name='dense_output_11_lv2', kernel_regularizer='l2', activation=dense_activation)(dense_output_11_lv1)\n",
    "  dense_output_21_lv1 = Dense(dense_output_2_lv1_size, name='dense_output_21_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_1)\n",
    "  dense_output_21_lv2 = Dense(dense_output_2_lv2_size, name='dense_output_21_lv2', kernel_regularizer='l2', activation=dense_activation)(dense_output_21_lv1)\n",
    "  dense_output_31_lv1 = Dense(dense_output_3_lv1_size, name='dense_output_31_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_1)\n",
    "\n",
    "  dense_output_12_lv1 = Dense(dense_output_1_lv1_size, name='dense_output_12_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_2)\n",
    "  dense_output_12_lv2 = Dense(dense_output_1_lv2_size, name='dense_output_12_lv2', kernel_regularizer='l2', activation=dense_activation)(dense_output_12_lv1)\n",
    "  dense_output_22_lv1 = Dense(dense_output_2_lv1_size, name='dense_output_22_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_2)\n",
    "  dense_output_22_lv2 = Dense(dense_output_2_lv2_size, name='dense_output_22_lv2', kernel_regularizer='l2', activation=dense_activation)(dense_output_22_lv1)\n",
    "  dense_output_32_lv1 = Dense(dense_output_3_lv1_size, name='dense_output_32_lv1', kernel_regularizer='l2', activation=dense_activation)(norm_2)\n",
    "\n",
    "  distance_1 = Dot(axes=1, normalize=True, name='distance_1')([dense_output_11_lv2, dense_output_12_lv2])\n",
    "  distance_2 = Dot(axes=1, normalize=True, name='distance_2')([dense_output_21_lv2, dense_output_22_lv2])\n",
    "  distance_3 = Dot(axes=1, normalize=True, name='distance_3')([dense_output_31_lv1, dense_output_32_lv1])\n",
    "\n",
    "  model = Model(inputs=[input_1, input_2], outputs=[distance_1, distance_2, distance_3])\n",
    "\n",
    "  optimizer = cfg['optimizer'](learning_rate=lr)\n",
    "\n",
    "  model.compile(\n",
    "      loss='mae',\n",
    "      optimizer=optimizer,\n",
    "    )\n",
    "\n",
    "  return model\n",
    "\n",
    "def create_model(cfg):\n",
    "  model = CharembComparatorV1(cfg)\n",
    "  model.summary()\n",
    "\n",
    "  emb_trainable = cfg['emb_trainable']\n",
    "  new_emb_vers = cfg['new_emb_vers']\n",
    "  pretrained_emb_vers = cfg['pretrained_emb_vers']\n",
    "  pretrained_trainer_vers = cfg['pretrained_trainer_vers']\n",
    "  new_trainer_version = cfg['new_trainer_version']\n",
    "\n",
    "  assert new_trainer_version, \"new_trainer_version must be set.\"\n",
    "\n",
    "  if pretrained_trainer_vers == new_trainer_version:\n",
    "    assert pretrained_emb_vers is None, \"Retrain the current trainer, set pretrained_emb_vers to None to mitigate potential of mistake.\"\n",
    "\n",
    "  if emb_trainable:\n",
    "    matched = re.search(r'(v\\d+x\\d\\du\\d\\d)', new_trainer_version)\n",
    "    detected_embedding_vers = matched.group(1)\n",
    "    assert new_emb_vers == detected_embedding_vers, f\"new_emb_vers: {new_emb_vers} does not match with new_trainer_version: {new_trainer_version} -> detected_embedding_vers\"\n",
    "\n",
    "  if not emb_trainable and pretrained_emb_vers:\n",
    "    matched = re.search(r'(v\\d+x\\d\\du\\d\\d)', new_trainer_version)\n",
    "    detected_embedding_vers = matched.group(1)\n",
    "    assert pretrained_emb_vers == detected_embedding_vers, f\"pretrained_emb_vers: {pretrained_emb_vers} does not match with new_trainer_version: {new_trainer_version} -> {detected_embedding_vers}\"\n",
    "\n",
    "  if pretrained_emb_vers:\n",
    "    print(f'[INFO] Load embedding layer weights from {pretrained_emb_vers}')\n",
    "    objectRep = open(f\"parser/pretrained_embedding/{pretrained_emb_vers}.pickle\", \"rb\")\n",
    "    char_embedding_layer_weights = pickle.load(objectRep)\n",
    "    char_embedding_layer = model.get_layer('char_embedding')\n",
    "    char_embedding_layer.set_weights(char_embedding_layer_weights)\n",
    "    objectRep.close()\n",
    "  else:\n",
    "    print(f'[INFO] pretrained_emb_vers is not set, embedding layer weights will be initialized.')\n",
    "\n",
    "  if isinstance(pretrained_trainer_vers, str):\n",
    "    print(f'[INFO] Load trainer weights from {pretrained_trainer_vers}')\n",
    "    model.load_weights(f\"parser/pretrained_embedding/trainers/{pretrained_trainer_vers}.h5\")\n",
    "  else:\n",
    "    print(f'[INFO] pretrained_trainer_vers is not set, trainer weights will be initialized.')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def is_jsonline_file(fname):\n",
    "  is_jlext_p = re.compile('\\.jl$')\n",
    "\n",
    "  return is_jlext_p.search(fname) is not None\n",
    "\n",
    "def load_dataset(source_path, split=None, loop=True):\n",
    "  path_obj = Path(source_path)\n",
    "  dataset = []\n",
    "\n",
    "  for file in path_obj.iterdir():\n",
    "\n",
    "    with open(file.absolute()) as reader:\n",
    "      lines = reader.readlines()\n",
    "      for line in lines:\n",
    "        dataset.append(line)\n",
    "\n",
    "  return dataset\n",
    "\n",
    "emb_trainable = cfg['emb_trainable']\n",
    "validating_dataset_file = 'parser/charembdataset/tmp/validating_dataset.pickle'\n",
    "training1_dataset_file = 'parser/charembdataset/tmp/training1_dataset.pickle'\n",
    "training2_dataset_file = 'parser/charembdataset/tmp/training2_dataset.pickle'\n",
    "\n",
    "# validating_dataset = load_dataset('parser/charembdataset/validating', cfg)\n",
    "# with open(validating_dataset_file, 'wb') as f:\n",
    "#     pickle.dump(validating_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# training1_dataset = load_dataset('parser/charembdataset/training1', cfg)\n",
    "# with open(training1_dataset_file, 'wb') as f:\n",
    "#     pickle.dump(training1_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# training2_dataset = load_dataset('parser/charembdataset/training2', cfg)\n",
    "# with open(training2_dataset_file, 'wb') as f:\n",
    "#     pickle.dump(training2_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(validating_dataset_file, 'rb') as f:\n",
    "  validating_dataset = pickle.load(f)\n",
    "\n",
    "with open(training1_dataset_file, 'rb') as f:\n",
    "  training1_dataset = pickle.load(f)\n",
    "\n",
    "with open(training2_dataset_file, 'rb') as f:\n",
    "  training2_dataset = pickle.load(f)\n",
    "\n",
    "if cfg['emb_trainable']:\n",
    "  training_dataset = training1_dataset\n",
    "else:\n",
    "  training_dataset = training2_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabuary index:  {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '0': 10, '`': 11, '-': 12, '=': 13, 'q': 14, 'w': 15, 'e': 16, 'r': 17, 't': 18, 'y': 19, 'u': 20, 'i': 21, 'o': 22, 'p': 23, '[': 24, ']': 25, '\\\\': 26, 'a': 27, 's': 28, 'd': 29, 'f': 30, 'g': 31, 'h': 32, 'j': 33, 'k': 34, 'l': 35, ';': 36, \"'\": 37, 'z': 38, 'x': 39, 'c': 40, 'v': 41, 'b': 42, 'n': 43, 'm': 44, ',': 45, '.': 46, '/': 47, ' ': 48, '~': 49, '!': 50, '@': 51, '#': 52, '$': 53, '%': 54, '^': 55, '&': 56, '*': 57, '(': 58, ')': 59, '_': 60, '+': 61, 'Q': 62, 'W': 63, 'E': 64, 'R': 65, 'T': 66, 'Y': 67, 'U': 68, 'I': 69, 'O': 70, 'P': 71, '{': 72, '}': 73, '|': 74, 'A': 75, 'S': 76, 'D': 77, 'G': 78, 'H': 79, 'J': 80, 'K': 81, 'L': 82, ':': 83, '\"': 84, 'Z': 85, 'X': 86, 'C': 87, 'V': 88, 'B': 89, 'N': 90, 'M': 91, '<': 92, '>': 93, '?': 94, 'oov': 95, '‘': 96, '”': 97, '“': 98, '’': 99, '—': 100, '–': 101, '€': 102, '❌': 103, '⭐': 104, '✅': 105, '⚡': 106, '✊': 107, '✋': 108, '©': 109, '£': 110, '✨': 111, '∞': 112, '»': 113, '«': 114, '®': 115, '✔': 116, '≈': 117, '★': 118, '□': 119, '♥': 120, '❤': 121, '═': 122, '×': 123, '⬅': 124, '♡': 125, 'ǝ': 126, '♫': 127, 'ä': 128, '™': 129, '➡': 130, 'ë': 131, 'ń': 132, '｡': 133, 'ö': 134, 'м': 135, 'и': 136, 'И': 137, '¢': 138, 'ø': 139, 'ü': 140, 'Ø': 141, 'ō': 142, 'ć': 143, 'å': 144, '♀': 145, 'я': 146, 'ū': 147, 'Ö': 148, '♂': 149, 'Я': 150, 'Å': 151, 'Ü': 152, '•': 153}\n"
     ]
    }
   ],
   "source": [
    "from scraping.char_dict import vocabularies as vocab\n",
    "print('Vocabuary index: ', vocab)\n",
    "\n",
    "\n",
    "def mask_squence(sequence, masking_ratio, fill_value):\n",
    "  lgth = len(sequence)\n",
    "  masking_lgth = math.floor(lgth * masking_ratio)\n",
    "  mask = np.full(lgth, 0)\n",
    "  mask[:masking_lgth] = 1\n",
    "  np.random.shuffle(mask)\n",
    "\n",
    "  masked = ma.masked_array(sequence, mask=mask, fill_value=fill_value)\n",
    "\n",
    "  return masked.filled()\n",
    "\n",
    "\n",
    "def charrnn_encode_sequence(text, vocab, maxlen, masking_ratio=None):\n",
    "    '''\n",
    "    Encodes a text into the corresponding encoding for prediction with\n",
    "    the model.\n",
    "    '''\n",
    "\n",
    "    oov = vocab['oov']\n",
    "    masking_code = 0\n",
    "    encoded = np.array([vocab.get(x, oov) for x in text])\n",
    "    if masking_ratio:\n",
    "      encoded = mask_squence(encoded, masking_ratio, masking_code)\n",
    "    return sequence.pad_sequences([encoded], padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n"
     ]
    }
   ],
   "source": [
    "def is_jsonline_file(fname):\n",
    "  is_jlext_p = re.compile('\\.jl$')\n",
    "\n",
    "  return is_jlext_p.search(fname) is not None\n",
    "\n",
    "\n",
    "def count_dataset_size(data_source, cfg):\n",
    "  max_length = cfg['max_length']\n",
    "  min_length = cfg['min_length']\n",
    "\n",
    "  dataset = load_dataset(data_source, loop=False)\n",
    "\n",
    "  counter = 0\n",
    "  for s in dataset:\n",
    "    lgth = len(s)\n",
    "    if min_length > lgth or lgth > max_length:\n",
    "      continue\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "  return counter\n",
    "\n",
    "\n",
    "def load_dataset(source_path, split=None, loop=True):\n",
    "  path_obj = Path(source_path)\n",
    "\n",
    "  while True:\n",
    "    for file in path_obj.iterdir():\n",
    "\n",
    "      with open(file.absolute()) as reader:\n",
    "        lines = reader.readlines()\n",
    "        for line in lines:\n",
    "          yield line\n",
    "\n",
    "    if not loop:\n",
    "      return None\n",
    "\n",
    "\n",
    "class ThreadBreaker:\n",
    "  _terminated = False\n",
    "  def might_to_exit(self):\n",
    "    if self._terminated:\n",
    "      print('\\n[THREADING] exited!\\n')\n",
    "      _thread.exit()\n",
    "    else:\n",
    "      return True\n",
    "  def exit(self):\n",
    "    self._terminated = True\n",
    "\n",
    "def buffer_data(cfg, dataset, pri_buffer, split_type, breaker, model):\n",
    "  assert isinstance(breaker, ThreadBreaker), \"breaker must be an instance of ThreadBreaker\"\n",
    "  batch_size = cfg['batch_size']\n",
    "  max_length = cfg['max_length']\n",
    "  min_length = cfg['min_length']\n",
    "  masking_ratio = cfg['masking_ratio']\n",
    "  neutral_distance_scale = cfg['neutral_distance_scale']\n",
    "  close_distance_scale = cfg['close_distance_scale']\n",
    "  lean_dataset = cfg['lean_dataset']\n",
    "  pribuf_looping = cfg['pribuf_looping']\n",
    "\n",
    "  if pribuf_looping:\n",
    "    BUFFER_SIZE = pri_buffer.maxlen - 1\n",
    "  else:\n",
    "    BUFFER_SIZE = pri_buffer.maxlen / 2\n",
    "\n",
    "  if lean_dataset:\n",
    "   assert model is not None, \"model must be pre-trained in lean_dataset mode.\"\n",
    "\n",
    "  trial_times = 100\n",
    "  max_prev_text_quantity = 1000\n",
    "  prev_texts_queue = deque(['<p>This implementation of RMSprop uses plain momentum, not Nesterov momentum.</p>']*max_prev_text_quantity, maxlen=max_prev_text_quantity)\n",
    "\n",
    "  def is_training_split():\n",
    "    assert split_type in ['training', 'validating'], \"Invalid split name.\"\n",
    "    return 'training' == split_type\n",
    "\n",
    "  def measure_distance(inputs, labels):\n",
    "    # print('[DEBUG] Generating truth values ...')\n",
    "    preds = model.predict_on_batch(inputs)\n",
    "    distance_1 = np.array(preds[0]).squeeze()\n",
    "    distance_2 = np.array(preds[1]).squeeze()\n",
    "    distance_3 = np.array(preds[2]).squeeze()\n",
    "\n",
    "    mask = np.array(labels) == close_distance_scale\n",
    "    distance_1[mask] = close_distance_scale\n",
    "    distance_2[mask] = close_distance_scale\n",
    "    distance_3[mask] = close_distance_scale\n",
    "\n",
    "    _labels = {\n",
    "      'distance_1': distance_1,\n",
    "      'distance_2': distance_2,\n",
    "      'distance_3': distance_3,\n",
    "    }\n",
    "\n",
    "    # print('[DEBUG] Done.')\n",
    "\n",
    "    return _labels\n",
    "\n",
    "  def will_happen_with_respect_to(probability):\n",
    "    to_happen = random.random() <= probability\n",
    "    return to_happen\n",
    "\n",
    "  def get_prev_text(_text):\n",
    "    _prev = random.choice(prev_texts_queue)\n",
    "\n",
    "    _counter = 1\n",
    "    while _prev == _text and _counter <= trial_times:\n",
    "      _prev = random.choice(prev_texts_queue)\n",
    "      _counter += 1\n",
    "\n",
    "    return _prev\n",
    "\n",
    "  # def _queue_or_count(_X1, _X2, _Y1, _Y2, _count_batch):\n",
    "  def _queue_or_count(_X1, _X2, _Y1, _count_batch):\n",
    "\n",
    "    # Firstly, count batch's volume\n",
    "    _count_batch += 1\n",
    "\n",
    "    if _count_batch % BATCH_SIZE == 0:\n",
    "      _X1 = np.array(_X1)\n",
    "      _X2 = np.array(_X2)\n",
    "      _X = {\n",
    "        'input_1': _X1,\n",
    "        'input_2': _X2,\n",
    "      }\n",
    "\n",
    "      if lean_dataset and is_training_split():\n",
    "        _Y = measure_distance(_X, _Y1)\n",
    "      else:\n",
    "        _Y1 = np.array(_Y1)\n",
    "        _Y = {\n",
    "          'distance_1': _Y1,\n",
    "          'distance_2': _Y1,\n",
    "          'distance_3': _Y1,\n",
    "        }\n",
    "\n",
    "      batch = (_X, _Y)\n",
    "\n",
    "      pri_buffer.appendleft(batch)\n",
    "\n",
    "      # if the primary buffer is full then wait for the number of remaining items less than BUFFER_SIZE\n",
    "      if len(pri_buffer) >= pri_buffer.maxlen:\n",
    "        while len(pri_buffer) > BUFFER_SIZE:\n",
    "          # print('Waiting for data unloaded...')\n",
    "          breaker.might_to_exit()\n",
    "          time.sleep(SLEEP_TIME)\n",
    "\n",
    "      # Reset batch\n",
    "      _X1 = []\n",
    "      _X2 = []\n",
    "      _Y1 = []\n",
    "      # _Y2 = []\n",
    "      _count_batch = 0\n",
    "\n",
    "      return (_X1, _X2, _Y1, _count_batch)\n",
    "\n",
    "    # not thing more than accumulate batch count\n",
    "    return (_X1, _X2, _Y1, _count_batch)\n",
    "\n",
    "\n",
    "  while True:\n",
    "    if len(pri_buffer) < pri_buffer.maxlen:\n",
    "      X1_batch = []\n",
    "      X2_batch = []\n",
    "      Y1_batch = []\n",
    "      # Y2_batch = []\n",
    "      count_batch = 0\n",
    "\n",
    "      for s in dataset:\n",
    "        lgth = len(s)\n",
    "        if min_length > lgth or lgth > max_length:\n",
    "          continue\n",
    "\n",
    "        encoded_1 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "        encoded_2 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "\n",
    "        X1_batch.append(encoded_1)\n",
    "        X2_batch.append(encoded_2)\n",
    "        Y1_batch.append(close_distance_scale)\n",
    "        X1_batch, X2_batch, Y1_batch, count_batch = _queue_or_count(X1_batch, X2_batch, Y1_batch, count_batch)\n",
    "\n",
    "        # Reverse the oder to force distance symmetric\n",
    "        X1_batch.append(encoded_2)\n",
    "        X2_batch.append(encoded_1)\n",
    "        Y1_batch.append(close_distance_scale)\n",
    "        X1_batch, X2_batch, Y1_batch, count_batch = _queue_or_count(X1_batch, X2_batch, Y1_batch, count_batch)\n",
    "\n",
    "        # if not lean_dataset or is_training_split():\n",
    "        if not lean_dataset:\n",
    "          prev = get_prev_text(s)\n",
    "\n",
    "          encoded_1 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "          encoded_2 = charrnn_encode_sequence(prev, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "\n",
    "          X1_batch.append(encoded_1)\n",
    "          X2_batch.append(encoded_2)\n",
    "          Y1_batch.append(neutral_distance_scale)\n",
    "          X1_batch, X2_batch, Y1_batch, count_batch = _queue_or_count(X1_batch, X2_batch, Y1_batch, count_batch)\n",
    "\n",
    "          # Because of the approximation of all far distance is at low accuracy the masking is applied back and forth loosely (differently)\n",
    "          # Reverse the oder to force distance symmetric\n",
    "          encoded_2 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "          encoded_1 = charrnn_encode_sequence(prev, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "\n",
    "          X1_batch.append(encoded_1)\n",
    "          X2_batch.append(encoded_2)\n",
    "          Y1_batch.append(neutral_distance_scale)\n",
    "          X1_batch, X2_batch, Y1_batch, count_batch = _queue_or_count(X1_batch, X2_batch, Y1_batch, count_batch)\n",
    "\n",
    "        else:\n",
    "\n",
    "          # Invalidating prediction just count for the real truth values\n",
    "          # So just include the neutral_distance_scale cases for training\n",
    "          if is_training_split():\n",
    "            prev = get_prev_text(s)\n",
    "\n",
    "            # Try to make two comparators balanced in lean_dataset regime\n",
    "            if  will_happen_with_respect_to(probability=0.5):\n",
    "              encoded_1 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "              encoded_2 = charrnn_encode_sequence(prev, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "            else:\n",
    "              encoded_2 = charrnn_encode_sequence(s, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "              encoded_1 = charrnn_encode_sequence(prev, vocab, max_length, masking_ratio=masking_ratio)[0]\n",
    "\n",
    "            X1_batch.append(encoded_1)\n",
    "            X2_batch.append(encoded_2)\n",
    "            Y1_batch.append(neutral_distance_scale)\n",
    "            X1_batch, X2_batch, Y1_batch, count_batch = _queue_or_count(X1_batch, X2_batch, Y1_batch, count_batch)\n",
    "\n",
    "        # ATTENTION: Big trouble for you if you put this one outside of the loop\n",
    "        # REMEMBER: If you put this one outside of the loop everything is perfect except the performance, THAT'S IT!!!\n",
    "        if will_happen_with_respect_to(probability=0.5):\n",
    "          # print('append to prev_texts_queue, length: ', len(prev_texts_queue))\n",
    "          prev_texts_queue.append(s)\n",
    "\n",
    "\n",
    "def create_generator(buffer_size, pribuf_looping=False, steps_per_epoch=None):\n",
    "  if pribuf_looping:\n",
    "    assert steps_per_epoch is not None, \"steps_per_epoch is required when pribuf_looping is set to True\"\n",
    "    pribuf_size = steps_per_epoch + 1\n",
    "  else:\n",
    "    pribuf_size = buffer_size * 2\n",
    "\n",
    "  subbuf_size = buffer_size\n",
    "  print('[INFO] Primary deque maxlen: ', pribuf_size)\n",
    "  print('[INFO] Secondary deque maxlen: ', subbuf_size)\n",
    "\n",
    "  sub_buffer = deque(maxlen=subbuf_size)\n",
    "  pri_buffer = deque(maxlen=pribuf_size)\n",
    "\n",
    "  def is_primary_buffer_ready():\n",
    "    if pribuf_looping:\n",
    "      return len(pri_buffer) >= pribuf_size\n",
    "    else:\n",
    "      return len(pri_buffer) >= subbuf_size\n",
    "\n",
    "  def is_secondary_buffer_ready():\n",
    "    return len(sub_buffer) > 0\n",
    "\n",
    "  def generator():\n",
    "    while True:\n",
    "      if is_secondary_buffer_ready():\n",
    "        yield sub_buffer.pop()\n",
    "\n",
    "      elif is_primary_buffer_ready():\n",
    "        for i in range(subbuf_size):\n",
    "          batch = pri_buffer.pop()\n",
    "          sub_buffer.appendleft(batch)\n",
    "          if pribuf_looping:\n",
    "            pri_buffer.appendleft(batch)\n",
    "            # print('loop the curren batch, pri_buffer len: ', len(pri_buffer))\n",
    "\n",
    "      else:\n",
    "        # print('Waiting for data...')\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "  return pri_buffer, generator()\n",
    "\n",
    "def start_buffer_data_thread(_cfg, _dataset, _pri_buffer, _split_type, _model):\n",
    "  breaker = ThreadBreaker()\n",
    "  _thread.start_new_thread(buffer_data, (), {'cfg': cfg, 'dataset': _dataset, 'pri_buffer': _pri_buffer, 'split_type': _split_type, 'breaker': breaker, 'model': _model})\n",
    "  return breaker\n",
    "\n",
    "def calculate_training_steps(_cfg, _dataset):\n",
    "  sample_quantity = len(_dataset) * 3 if _cfg['lean_dataset'] else len(_dataset) * 4\n",
    "  steps_per_epoch = math.ceil(sample_quantity/_cfg['batch_size'])\n",
    "\n",
    "  return steps_per_epoch, sample_quantity\n",
    "\n",
    "def calculate_validating_steps(_cfg, _dataset):\n",
    "  sample_quantity = len(_dataset) * 2 if _cfg['lean_dataset'] else len(_dataset) * 4\n",
    "  steps_per_epoch = math.ceil(sample_quantity/_cfg['batch_size'])\n",
    "\n",
    "  return steps_per_epoch, sample_quantity\n",
    "\n",
    "BATCH_SIZE = cfg['batch_size']\n",
    "BUFFER_SIZE = cfg['buffer_size']\n",
    "_pribuf_looping = cfg['pribuf_looping']\n",
    "_lean_dataset = cfg['lean_dataset']\n",
    "\n",
    "steps_per_epoch, training_sample_quantity = calculate_training_steps(_cfg=cfg, _dataset=training_dataset)\n",
    "print('[INFO] training_sample_quantity', training_sample_quantity)\n",
    "print('[INFO] training steps_per_epoch: ', steps_per_epoch)\n",
    "\n",
    "validation_steps, validating_sample_quantity = calculate_validating_steps(_cfg=cfg, _dataset=validating_dataset)\n",
    "print('[INFO] validating_sample_quantity', validating_sample_quantity)\n",
    "print('[INFO] validation_steps: ', validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "max_length = cfg['max_length']\n",
    "\n",
    "class Tester:\n",
    "  def __init__(self, model, dataset):\n",
    "\n",
    "    self.size = 501\n",
    "    self.model = model\n",
    "    self.dataset = dataset\n",
    "    self.arguments = deque(maxlen=self.size)\n",
    "    self.result_cache = {\n",
    "      'preds1': None,\n",
    "      'preds2': None,\n",
    "    }\n",
    "\n",
    "    for i in range(self.size):\n",
    "      self.arguments.appendleft(random.choice(self.dataset))\n",
    "\n",
    "  def will_happen_with_respect_to(self, probability):\n",
    "    to_happen = random.random() <= probability\n",
    "    return to_happen\n",
    "\n",
    "  def prepare_data(self):\n",
    "    _data1 = {\n",
    "      'input_1': [],\n",
    "      'input_2': [],\n",
    "    }\n",
    "\n",
    "    _data2 = {\n",
    "      'input_1': [],\n",
    "      'input_2': [],\n",
    "    }\n",
    "\n",
    "    _argument = '<p>This implementation of RMSprop uses plain momentum, not Nesterov momentum.</p>'\n",
    "    for item in self.dataset:\n",
    "\n",
    "      _data1['input_1'].append(charrnn_encode_sequence(item, vocab, max_length)[0])\n",
    "      _data1['input_2'].append(charrnn_encode_sequence(_argument, vocab, max_length)[0])\n",
    "\n",
    "      # Reverse the order of item and argument\n",
    "      _data2['input_1'].append(charrnn_encode_sequence(_argument, vocab, max_length)[0])\n",
    "      _data2['input_2'].append(charrnn_encode_sequence(item, vocab, max_length)[0])\n",
    "\n",
    "      # in case of argument pool is not full yet, always use previous one as argument and stack item into pool\n",
    "      if self.size != len(self.arguments):\n",
    "        _argument = item\n",
    "        self.arguments.appendleft(item)\n",
    "\n",
    "      # in case of argument pool is ready, pick from and stack item into pool randomly\n",
    "      elif self.will_happen_with_respect_to(probability=0.5):\n",
    "        _argument = random.choice(self.arguments)\n",
    "        self.arguments.appendleft(item)\n",
    "\n",
    "    _data1['input_1'] = np.array(_data1['input_1'])\n",
    "    _data1['input_2'] = np.array(_data1['input_2'])\n",
    "\n",
    "    _data2['input_1'] = np.array(_data2['input_1'])\n",
    "    _data2['input_2'] = np.array(_data2['input_2'])\n",
    "\n",
    "    return _data1, _data2\n",
    "\n",
    "  def get_prediction(self):\n",
    "\n",
    "    if self.result_cache.get('preds1') is None or self.result_cache.get('preds2') is None:\n",
    "      data1, data2 = self.prepare_data()\n",
    "      preds1 = self.model.predict_on_batch(x=data1)\n",
    "      preds2 = self.model.predict_on_batch(x=data2)\n",
    "      # print(preds1[0].tolist())\n",
    "      # print(preds2[0].tolist())\n",
    "\n",
    "      # cache prediction\n",
    "      self.result_cache['preds1'] = preds1\n",
    "      self.result_cache['preds2'] = preds2\n",
    "\n",
    "    return self.result_cache['preds1'], self.result_cache['preds2']\n",
    "\n",
    "  def test_symmetric_distance(self):\n",
    "    preds1, preds2 = self.get_prediction()\n",
    "\n",
    "    losses = []\n",
    "    for pred1, pred2 in zip(preds1, preds2):\n",
    "      loss = np.absolute(np.subtract(pred1, pred2)).mean()\n",
    "      losses.append(loss)\n",
    "\n",
    "    return losses\n",
    "\n",
    "  def test_distance_mean(self):\n",
    "    \"\"\"\n",
    "    Result of this test is the distances against 1 (ideally almost pairs of inputs are different)\n",
    "    and a big number is a signal of both potentially good embedding structure and pattern detectors (comparators)\n",
    "    \"\"\"\n",
    "    preds1, preds2 = self.get_prediction()\n",
    "\n",
    "    pred1_distance_means = []\n",
    "    pred2_distance_means = []\n",
    "    for pred1, pred2 in zip(preds1, preds2):\n",
    "      distance1 = np.subtract(1, pred1).mean()\n",
    "      pred1_distance_means.append(distance1)\n",
    "      distance2 = np.subtract(1, pred2).mean()\n",
    "      pred2_distance_means.append(distance2)\n",
    "\n",
    "    return pred1_distance_means, pred2_distance_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def do_training(_cfg, _steps_per_epoch, _validation_steps, _debug_generator=False):\n",
    "  EPOCHS = _cfg['epochs']\n",
    "  BATCH_SIZE = _cfg['batch_size']\n",
    "  BUFFER_SIZE = _cfg['buffer_size']\n",
    "  pribuf_looping = cfg['pribuf_looping']\n",
    "\n",
    "  pretrained_model = None\n",
    "  if _lean_dataset:\n",
    "    pretrained_trainer_vers = cfg['pretrained_trainer_vers']\n",
    "    pretrained_model_vers = cfg['pretrained_model_vers']\n",
    "\n",
    "    version = pretrained_model_vers if pretrained_model_vers else pretrained_trainer_vers\n",
    "    print(f'[INFO] Model {version} will be used to generate truth labels of dataset.')\n",
    "\n",
    "    pretrained_model = design_model(cfg)\n",
    "    pretrained_model.load_weights(f\"parser/pretrained_embedding/trainers/{version}.h5\")\n",
    "    pretrained_model.trainable = False\n",
    "  else:\n",
    "    print(f'[INFO] Training model by data with hypothetic truth labels.')\n",
    "\n",
    "\n",
    "  # Training generator\n",
    "  split_type = 'training'\n",
    "  training_queue, training_generator = create_generator(buffer_size=BUFFER_SIZE, pribuf_looping=pribuf_looping, steps_per_epoch=_steps_per_epoch)\n",
    "  training_queue_breaker = start_buffer_data_thread(_cfg=_cfg, _dataset=training_dataset, _pri_buffer=training_queue, _split_type=split_type, _model=pretrained_model)\n",
    "\n",
    "  # Validating generator\n",
    "  split_type = 'validating'\n",
    "  validating_queue, validating_generator = create_generator(buffer_size=BUFFER_SIZE, pribuf_looping=pribuf_looping, steps_per_epoch=_validation_steps)\n",
    "  validating_queue_breaker = start_buffer_data_thread(_cfg=_cfg, _dataset=validating_dataset, _pri_buffer=validating_queue, _split_type=split_type, _model=pretrained_model)\n",
    "\n",
    "  if _debug_generator:\n",
    "    return training_generator, validating_generator\n",
    "\n",
    "  model = create_model(_cfg)\n",
    "  model.fit(\n",
    "      training_generator,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      steps_per_epoch=_steps_per_epoch,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validating_generator,\n",
    "      validation_batch_size=BATCH_SIZE,\n",
    "      validation_steps=_validation_steps,\n",
    "      shuffle='batch',\n",
    "    )\n",
    "\n",
    "  training_queue_breaker.exit()\n",
    "  validating_queue_breaker.exit()\n",
    "\n",
    "  return model\n",
    "\n",
    "def do_tictoc_training(_cfg):\n",
    "  EPOCHS = _cfg['epochs']\n",
    "  BATCH_SIZE = _cfg['batch_size']\n",
    "  BUFFER_SIZE = _cfg['buffer_size']\n",
    "  pribuf_looping = cfg['pribuf_looping']\n",
    "\n",
    "  pretrained_trainer_vers = cfg['pretrained_trainer_vers']\n",
    "  pretrained_model_vers = cfg['pretrained_model_vers']\n",
    "  version = pretrained_model_vers if pretrained_model_vers else pretrained_trainer_vers\n",
    "  print(f'[INFO] Model {version} will be used to generate truth labels of dataset.')\n",
    "\n",
    "  pretrained_model = design_model(cfg)\n",
    "  pretrained_model.load_weights(f\"parser/pretrained_embedding/trainers/{version}.h5\")\n",
    "  pretrained_model.trainable = False\n",
    "\n",
    "  _validating_dataset = validating_dataset\n",
    "\n",
    "  tmp_weight_filepath = \"parser/tmp/model_weights.h5\"\n",
    "  pretrained_model.save_weights(tmp_weight_filepath, overwrite=True)\n",
    "\n",
    "  for i in range(EPOCHS):\n",
    "    print('[TRAINING] Grand Epoch: ', i)\n",
    "\n",
    "    if i % 2 == 0:\n",
    "      _training_dataset = training1_dataset\n",
    "      _cfg['emb_trainable'] = True\n",
    "      _epochs = 1\n",
    "    else:\n",
    "      _training_dataset = training2_dataset\n",
    "      _cfg['emb_trainable'] = False\n",
    "      _epochs = 3\n",
    "\n",
    "    _steps_per_epoch, training_sample_quantity = calculate_training_steps(_cfg=_cfg, _dataset=_training_dataset)\n",
    "    print('[INFO] training_sample_quantity', training_sample_quantity)\n",
    "    print('[INFO] training steps_per_epoch: ', _steps_per_epoch)\n",
    "\n",
    "    _validation_steps, validating_sample_quantity = calculate_validating_steps(_cfg=_cfg, _dataset=_validating_dataset)\n",
    "    validation_steps, validating_sample_quantity = calculate_validating_steps(_cfg=cfg, _dataset=validating_dataset)\n",
    "    print('[INFO] validating_sample_quantity', validating_sample_quantity)\n",
    "    print('[INFO] validation_steps: ', _validation_steps)\n",
    "\n",
    "    split_type = 'training'\n",
    "    training_queue, training_generator = create_generator(buffer_size=BUFFER_SIZE, pribuf_looping=pribuf_looping, steps_per_epoch=_steps_per_epoch)\n",
    "    training_queue_breaker = start_buffer_data_thread(_cfg=_cfg, _dataset=_training_dataset, _pri_buffer=training_queue, _split_type=split_type, _model=pretrained_model)\n",
    "\n",
    "    split_type = 'validating'\n",
    "    validating_queue, validating_generator = create_generator(buffer_size=BUFFER_SIZE, pribuf_looping=pribuf_looping, steps_per_epoch=_validation_steps)\n",
    "    validating_queue_breaker = start_buffer_data_thread(_cfg=_cfg, _dataset=_validating_dataset, _pri_buffer=validating_queue, _split_type=split_type, _model=pretrained_model)\n",
    "\n",
    "    model = design_model(_cfg)\n",
    "    model.load_weights(tmp_weight_filepath)\n",
    "\n",
    "    model.fit(\n",
    "        training_generator,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        steps_per_epoch=_steps_per_epoch,\n",
    "        epochs=_epochs,\n",
    "        validation_data=validating_generator,\n",
    "        validation_batch_size=BATCH_SIZE,\n",
    "        validation_steps=_validation_steps,\n",
    "        shuffle='batch',\n",
    "      )\n",
    "\n",
    "    del pretrained_model\n",
    "    pretrained_model = model\n",
    "    pretrained_model.trainable = False\n",
    "    pretrained_model.save_weights(tmp_weight_filepath, overwrite=True)\n",
    "\n",
    "    training_queue_breaker.exit()\n",
    "    validating_queue_breaker.exit()\n",
    "\n",
    "    tester = Tester(dataset=_validating_dataset, model=pretrained_model)\n",
    "    losses = tester.test_symmetric_distance()\n",
    "    print('Divergence of 2 distances of pair of samples: ', losses)\n",
    "    pred1_distance_means, pred2_distance_means = tester.test_distance_mean()\n",
    "    print('(pred1: input_1 vs input_2) Distance of 2 different samples: ', pred1_distance_means)\n",
    "    print('(pred2: input_2 vs input_1) Distance of 2 different samples: ', pred2_distance_means)\n",
    "\n",
    "  return pretrained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model trainer_v5x10u03_re04_tictoc will be used to generate truth labels of dataset.\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 02:27:42.523879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:42.575286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:42.575500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:42.576328: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 02:27:42.576962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:42.577132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:42.577286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:43.169230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:43.169425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:43.169583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 02:27:43.169728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6590 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING] Grand Epoch:  0\n",
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  228\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 02:27:47.704159: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500\n",
      "2022-10-22 02:27:48.442121: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 02:27:48.442384: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 02:27:48.442395: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-10-22 02:27:48.442838: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 02:27:48.442875: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 38s 146ms/step - loss: 0.0465 - distance_1_loss: 0.0050 - distance_2_loss: 0.0049 - distance_3_loss: 0.0037 - val_loss: 0.0412 - val_distance_1_loss: 0.0031 - val_distance_2_loss: 0.0031 - val_distance_3_loss: 0.0021\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.07705416, 0.07445305, 0.052396547]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.97587067, 0.9580259, 0.9635343]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9757111, 0.95818526, 0.9633248]\n",
      "[TRAINING] Grand Epoch:  1\n",
      "[INFO] training_sample_quantity 310500\n",
      "[INFO] training steps_per_epoch:  76\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  77\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Comparator\n",
      "[CFG] emb_trainable:  False\n",
      "[CFG] comparison_norm_trainable:  True\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 16s 146ms/step - loss: 0.0466 - distance_1_loss: 0.0051 - distance_2_loss: 0.0049 - distance_3_loss: 0.0037 - val_loss: 0.0403 - val_distance_1_loss: 0.0029 - val_distance_2_loss: 0.0027 - val_distance_3_loss: 0.0020\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0455 - distance_1_loss: 0.0048 - distance_2_loss: 0.0046 - distance_3_loss: 0.0035 - val_loss: 0.0384 - val_distance_1_loss: 0.0019 - val_distance_2_loss: 0.0023 - val_distance_3_loss: 0.0014\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0454 - distance_1_loss: 0.0048 - distance_2_loss: 0.0045 - distance_3_loss: 0.0035 - val_loss: 0.0380 - val_distance_1_loss: 0.0018 - val_distance_2_loss: 0.0021 - val_distance_3_loss: 0.0014\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.054495446, 0.05374196, 0.036121227]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9746926, 0.9573541, 0.9624309]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9748641, 0.95782423, 0.9623583]\n",
      "[TRAINING] Grand Epoch:  2\n",
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  228\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "227/227 [==============================] - 38s 145ms/step - loss: 0.0442 - distance_1_loss: 0.0042 - distance_2_loss: 0.0042 - distance_3_loss: 0.0033 - val_loss: 0.0377 - val_distance_1_loss: 0.0018 - val_distance_2_loss: 0.0020 - val_distance_3_loss: 0.0014\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.05762825, 0.05552742, 0.04000912]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9776902, 0.9606314, 0.9654281]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9773424, 0.9603125, 0.96521354]\n",
      "[TRAINING] Grand Epoch:  3\n",
      "[INFO] training_sample_quantity 310500\n",
      "[INFO] training steps_per_epoch:  76\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  77\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Comparator\n",
      "[CFG] emb_trainable:  False\n",
      "[CFG] comparison_norm_trainable:  True\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 16s 146ms/step - loss: 0.0447 - distance_1_loss: 0.0045 - distance_2_loss: 0.0043 - distance_3_loss: 0.0035 - val_loss: 0.0366 - val_distance_1_loss: 0.0013 - val_distance_2_loss: 0.0016 - val_distance_3_loss: 0.0013\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 10s 135ms/step - loss: 0.0437 - distance_1_loss: 0.0042 - distance_2_loss: 0.0040 - distance_3_loss: 0.0033 - val_loss: 0.0383 - val_distance_1_loss: 0.0021 - val_distance_2_loss: 0.0023 - val_distance_3_loss: 0.0017\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 10s 135ms/step - loss: 0.0434 - distance_1_loss: 0.0041 - distance_2_loss: 0.0039 - distance_3_loss: 0.0032 - val_loss: 0.0370 - val_distance_1_loss: 0.0016 - val_distance_2_loss: 0.0018 - val_distance_3_loss: 0.0014\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.043440036, 0.042485975, 0.029337635]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9739715, 0.9576529, 0.9631133]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9736114, 0.9572189, 0.96297586]\n",
      "[TRAINING] Grand Epoch:  4\n",
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  228\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "227/227 [==============================] - 37s 145ms/step - loss: 0.0434 - distance_1_loss: 0.0040 - distance_2_loss: 0.0040 - distance_3_loss: 0.0033 - val_loss: 0.0369 - val_distance_1_loss: 0.0016 - val_distance_2_loss: 0.0019 - val_distance_3_loss: 0.0015\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.035890397, 0.034780864, 0.024350228]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.97169894, 0.9559855, 0.96043164]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9715197, 0.9559144, 0.96050817]\n",
      "[TRAINING] Grand Epoch:  5\n",
      "[INFO] training_sample_quantity 310500\n",
      "[INFO] training steps_per_epoch:  76\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  77\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Comparator\n",
      "[CFG] emb_trainable:  False\n",
      "[CFG] comparison_norm_trainable:  True\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 15s 146ms/step - loss: 0.0438 - distance_1_loss: 0.0042 - distance_2_loss: 0.0042 - distance_3_loss: 0.0034 - val_loss: 0.0360 - val_distance_1_loss: 0.0013 - val_distance_2_loss: 0.0015 - val_distance_3_loss: 0.0012\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0426 - distance_1_loss: 0.0039 - distance_2_loss: 0.0038 - distance_3_loss: 0.0031 - val_loss: 0.0372 - val_distance_1_loss: 0.0017 - val_distance_2_loss: 0.0020 - val_distance_3_loss: 0.0017\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0425 - distance_1_loss: 0.0038 - distance_2_loss: 0.0038 - distance_3_loss: 0.0031 - val_loss: 0.0377 - val_distance_1_loss: 0.0019 - val_distance_2_loss: 0.0022 - val_distance_3_loss: 0.0019\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.02694981, 0.027510587, 0.02038423]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9692413, 0.9529779, 0.9581789]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.96907747, 0.9527191, 0.9582165]\n",
      "[TRAINING] Grand Epoch:  6\n",
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  228\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 37s 146ms/step - loss: 0.0433 - distance_1_loss: 0.0041 - distance_2_loss: 0.0041 - distance_3_loss: 0.0034 - val_loss: 0.0371 - val_distance_1_loss: 0.0018 - val_distance_2_loss: 0.0020 - val_distance_3_loss: 0.0018\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.025073996, 0.023641212, 0.02013976]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.97090274, 0.95547116, 0.96069247]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.97078556, 0.9555008, 0.96068186]\n",
      "[TRAINING] Grand Epoch:  7\n",
      "[INFO] training_sample_quantity 310500\n",
      "[INFO] training steps_per_epoch:  76\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  77\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Comparator\n",
      "[CFG] emb_trainable:  False\n",
      "[CFG] comparison_norm_trainable:  True\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 15s 147ms/step - loss: 0.0433 - distance_1_loss: 0.0042 - distance_2_loss: 0.0042 - distance_3_loss: 0.0035 - val_loss: 0.0354 - val_distance_1_loss: 0.0013 - val_distance_2_loss: 0.0014 - val_distance_3_loss: 0.0012\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0425 - distance_1_loss: 0.0040 - distance_2_loss: 0.0039 - distance_3_loss: 0.0032 - val_loss: 0.0367 - val_distance_1_loss: 0.0017 - val_distance_2_loss: 0.0020 - val_distance_3_loss: 0.0017\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 10s 136ms/step - loss: 0.0420 - distance_1_loss: 0.0038 - distance_2_loss: 0.0038 - distance_3_loss: 0.0031 - val_loss: 0.0353 - val_distance_1_loss: 0.0013 - val_distance_2_loss: 0.0014 - val_distance_3_loss: 0.0013\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "\n",
      "[THREADING] exited!\n",
      "\n",
      "Divergence of 2 distances of pair of samples:  [0.03403626, 0.03386817, 0.02463018]\n",
      "(pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9773396, 0.96271235, 0.9661253]\n",
      "(pred2: input_2 vs input_1) Distance of 2 different samples:  [0.97690827, 0.9621815, 0.96587735]\n",
      "[TRAINING] Grand Epoch:  8\n",
      "[INFO] training_sample_quantity 927000\n",
      "[INFO] training steps_per_epoch:  227\n",
      "[INFO] validating_sample_quantity 69948\n",
      "[INFO] validation_steps:  18\n",
      "[INFO] Primary deque maxlen:  228\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Primary deque maxlen:  19\n",
      "[INFO] Secondary deque maxlen:  32\n",
      "[INFO] Training Char Embedding\n",
      "[CFG] emb_trainable:  True\n",
      "[CFG] comparison_norm_trainable:  False\n",
      "[CFG] optimizer :  <class 'keras.optimizer_v2.rmsprop.RMSprop'>\n",
      "[CFG] learning_rate :  0.0001\n",
      " 97/227 [===========>..................] - ETA: 18s - loss: 0.0423 - distance_1_loss: 0.0039 - distance_2_loss: 0.0039 - distance_3_loss: 0.0033"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m   char_model \u001b[38;5;241m=\u001b[39m do_training(\n\u001b[1;32m      3\u001b[0m       _cfg\u001b[38;5;241m=\u001b[39mcfg,\n\u001b[1;32m      4\u001b[0m       _steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[1;32m      5\u001b[0m       _validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m   char_model \u001b[38;5;241m=\u001b[39m \u001b[43mdo_tictoc_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 104\u001b[0m, in \u001b[0;36mdo_tictoc_training\u001b[0;34m(_cfg)\u001b[0m\n\u001b[1;32m    101\u001b[0m model \u001b[38;5;241m=\u001b[39m design_model(_cfg)\n\u001b[1;32m    102\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(tmp_weight_filepath)\n\u001b[0;32m--> 104\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidating_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_validation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pretrained_model\n\u001b[1;32m    116\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not cfg['tictoc']:\n",
    "  char_model = do_training(\n",
    "      _cfg=cfg,\n",
    "      _steps_per_epoch=steps_per_epoch,\n",
    "      _validation_steps=validation_steps,\n",
    "    )\n",
    "else:\n",
    "  char_model = do_tictoc_training(\n",
    "      _cfg=cfg,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "trainable = cfg['emb_trainable']\n",
    "new_emb_vers = cfg['new_emb_vers']\n",
    "if trainable and new_emb_vers:\n",
    "  char_embedding_layer_weights = char_model.get_layer('char_embedding').get_weights()\n",
    "  with open(f'parser/pretrained_embedding/{new_emb_vers}.pickle', 'wb') as f:\n",
    "      pickle.dump(char_embedding_layer_weights, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "new_trainer_version = cfg['new_trainer_version']\n",
    "char_model.save_weights(f\"parser/pretrained_embedding/trainers/{new_trainer_version}.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def inspect_data(batch1, index):\n",
    "  texts = batch1[0]\n",
    "  labels = batch1[1]\n",
    "  texts_1 = texts['input_1'][index]\n",
    "  print('text 1 input shape: ', texts['input_1'].shape)\n",
    "  print('text 1 input: ', texts_1.tolist())\n",
    "  texts_2 = texts['input_2'][index]\n",
    "  print('text 2 input shape: ', texts['input_2'].shape)\n",
    "  print('text 2 input: ', texts_2.tolist())\n",
    "  label_1 = labels['distance_1'][index]\n",
    "  print('label 1 shape: ', labels['distance_1'].shape)\n",
    "  print('label 1: ', label_1)\n",
    "\n",
    "# training_generator, validating_generator = do_training( _cfg=cfg, _steps_per_epoch=steps_per_epoch, _validation_steps=validation_steps, _debug_generator=True)\n",
    "\n",
    "# Test looping\n",
    "# for b in validating_generator:\n",
    "  # time.sleep(1)\n",
    "  # pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# batch1 = next(training_generator)\n",
    "# index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# raise Exception('WIP.')\n",
    "# inspect_data(batch1, index)\n",
    "# index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "max_length = cfg['max_length']\n",
    "raw_data = [\n",
    "    {\n",
    "    'input_1': '<p>The exhibition will follow several high-profile fashion exhibitions for the VA, including <a>Balenciaga: \\\n",
    "                Shaping Fashion</a>, <a>Mary Quant</a> and the record-breaking <a>Christian Dior: Designer of Dreams</a>.</p>',\n",
    "    'input_2': '<p>The exhibition will follow several high-profile fashion exhibitions for the VA, including <a>Balenciaga: \\\n",
    "                Shaping Fashion</a>, <a>Mary Quant</a> and the record-breaking <a>Christian Dior: Designer of Dreams</a>.</p>',\n",
    "    },\n",
    "    {\n",
    "      'input_1': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the \\\n",
    "                perspectives of symmetry and invariance. </p>',\n",
    "      'input_2': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the \\\n",
    "                perspectives of symmetry and invariance. </p>',\n",
    "    },\n",
    "    {\n",
    "    'input_1': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the perspectives \\\n",
    "                of symmetry and invariance. </p>',\n",
    "    'input_2': '<p>The exhibition will follow several high-profile fashion exhibitions for the VA, including <a>Balenciaga: Shaping Fashion</a>, \\\n",
    "                <a>Mary Quant</a> and the record-breaking <a>Christian Dior: Designer of Dreams</a>.</p>',\n",
    "    },\n",
    "    {\n",
    "    'input_1': '<p>The exhibition will follow several high-profile fashion exhibitions for the VA, including <a>Balenciaga: Shaping Fashion</a>, \\\n",
    "                <a>Mary Quant</a> and the record-breaking <a>Christian Dior: Designer of Dreams</a>.</p>',\n",
    "    'input_2': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the perspectives of symmetry and invariance. </p>',\n",
    "    },\n",
    "    {\n",
    "      'input_1': '<div>Advertisement</div>',\n",
    "      'input_2': '<div>Advertisement</div>',\n",
    "    },\n",
    "    {\n",
    "      'input_1': '<div>Advertisement</div>',\n",
    "      'input_2': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the perspectives of symmetry and invariance. <p>',\n",
    "    },\n",
    "    {\n",
    "      'input_1': '<p>Geometric Deep Learning is an attempt for geometric unification of a broad class of ML problems from the perspectives of symmetry \\\n",
    "                and invariance. <p>',\n",
    "      'input_2': '<div>Advertisement</div>',\n",
    "    },\n",
    "]\n",
    "\n",
    "def transform_data(raw):\n",
    "  _data = {\n",
    "    'input_1': [],\n",
    "    'input_2': [],\n",
    "  }\n",
    "\n",
    "  for row in raw:\n",
    "    _data['input_1'].append(charrnn_encode_sequence(row['input_1'], vocab, max_length)[0])\n",
    "    _data['input_2'].append(charrnn_encode_sequence(row['input_2'], vocab, max_length)[0])\n",
    "\n",
    "  _data['input_1'] = np.array(_data['input_1'])\n",
    "  _data['input_2'] = np.array(_data['input_2'])\n",
    "\n",
    "  return _data\n",
    "\n",
    "samples = transform_data(raw_data)\n",
    "preds = char_model.predict_on_batch(x=samples)\n",
    "\n",
    "ind = 0\n",
    "output_1 = preds[0]\n",
    "output_2 = preds[1]\n",
    "output_3 = preds[2]\n",
    "for row in output_1:\n",
    "    print(output_1[ind],\"\\t\", output_2[ind],\"\\t\", output_3[ind])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "tester = Tester(dataset=validating_dataset, model=char_model)\n",
    "\n",
    "losses = tester.test_symmetric_distance()\n",
    "print('Divergence of 2 distances of pair of samples: ', losses)\n",
    "\n",
    "pred1_distance_means, pred2_distance_means = tester.test_distance_mean()\n",
    "print('(pred1: input_1 vs input_2) Distance of 2 different samples: ', pred1_distance_means)\n",
    "print('(pred2: input_2 vs input_1) Distance of 2 different samples: ', pred2_distance_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee2db3",
   "metadata": {},
   "source": [
    "```md\n",
    "### Training result\n",
    "\n",
    "- v01x02u02: (continue of v01x02u01) learning_rate = 1e-3; Nadam; loss = 0.0704\n",
    "- v01x02u03: (continue of v01x02u01) learning_rate = 5e-3; RMSprop; loss = 0.0035\n",
    "- ([CAVEAT!] The perforance seems very bad. This is the obvious example of overfitting, despite the loss is tiny, the model is useless on predicting unseen data)\n",
    "- v01x02u04: (retrain v01x02u00) epoch = 79; learning_rate = 5e-3; RMSprop; loss = 0.0036; Bad performance on test data\n",
    "- v01x02u05: (retrain v01x02u00) epoch = 29; learning_rate = 5e-3; RMSprop; loss = 0.0082; Bad performance on test data\n",
    "- v01x02u06: (retrain v01x02u00) epoch = 7; learning_rate = 5e-3; RMSprop; loss = 0.0812; Performance: [0.00486887] [0.9875436] [0.01160717] [1.0660381] [0.01404977]\n",
    "\n",
    "- v01x03u00: (Shink network size, merge conv layers); epoch = 131; learning_rate = 1e-3; RMSprop; batch_size = 1536; val_loss: 0.5923 - val_tf_op_layer_distance_1_loss: 0.2487 - val_tf_op_layer_distance_2_loss: 0.3240\n",
    "\n",
    "> The best one because it's a result of fixing many mistakes and misundertanding as well as many improvements\n",
    "- Fix bad dataset\n",
    "- Use BatchNormalization instead of LayerNormalization (inappropriate)\n",
    "- Balance information flow between 2 encoders\n",
    "- Preserve sequnce length (in order to balance encoders) by using only stripe of 1 in conv block, using return_sequences in rnn block\n",
    "- In dataset generator, reverse the oder to force distance being symmetric\n",
    "- Using more thang 1 projections to compute distances (dense of size 3 and dense of size 7)\n",
    "- Implement validating dataset\n",
    "\n",
    "- v01x04u00: epoch = 101; parameters = 111,369; learning_rate = 1e-3; RMSprop; loss: 0.1180 - val_loss: 0.0994.\n",
    "> Add third projection for distance measurement. Using Maximum layer so that there is one output.\n",
    "> Embedding layer has input of size 2 and output of size 2\n",
    "\n",
    "- trainer_v01x04u00_re01_freezeemb: epoch = 49; learning_rate = 2e-4, RMSprop; loss ~ 0.09 - val_loss ~ 0.07\n",
    "\n",
    "- v01x04u01 (<- trainer_v01x04u00_re01_freezeemb): epoch = 101; learning_rate = 2e-4 | 1e-4 | 1e-3; No improvement\n",
    "\n",
    "```\n",
    "```md\n",
    "- trainer_v41117x06u00_re00_full -> v41117x06u00 (Use lean dataset): epochs = 7; learning_rate = 1e-3;\n",
    "> loss: 0.4049 - distance_1_loss: 0.1128 - distance_2_loss: 0.1335 - distance_3_loss: 0.1237 - val_loss: 0.4071 - val_distance_1_loss: 0.1106 - val_distance_2_loss: 0.1383 - val_distance_3_loss: 0.1231\n",
    "> epochs = 11; learning_rate = 1e-4; Nadam\n",
    "> loss: 0.3475 - distance_1_loss: 0.0963 - distance_2_loss: 0.1085 - distance_3_loss: 0.1151 - val_loss: 0.3532 - val_distance_1_loss: 0.0959 - val_distance_2_loss: 0.1132 - val_distance_3_loss: 0.1165\n",
    "\n",
    "- trainer_v41117x06u00_re01_freezeemb (<- trainer_v41117x06u00_re00_full): epochs = 51; learning_rate = 1e-4; Nadam;\n",
    "> loss: 0.0697 - distance_1_loss: 0.0202 - distance_2_loss: 0.0189 - distance_3_loss: 0.0098 - val_loss: 0.0463 - val_distance_1_loss: 0.0092 - val_distance_2_loss: 0.0086 - val_distance_3_loss: 0.0079\n",
    "\n",
    "- trainer_v41117x06u01_re02_full (<- trainer_v41117x06u00_re01_freezeemb) <-> v41117x06u01 (Use lean dataset): epochs = 11; learning_rate = 1e-4;\n",
    "> loss: 0.0663 - distance_1_loss: 0.0198 - distance_2_loss: 0.0184 - distance_3_loss: 0.0092 - val_loss: 0.0426 - val_distance_1_loss: 0.0080 - val_distance_2_loss: 0.0081 - val_distance_3_loss: 0.0076\n",
    "\n",
    "- trainer_v41117x06u02_re03_full_newtr (<- v41117x06u01) <-> v41117x06u02: epochs = 21; learning_rate = 1e-3; RMSprop\n",
    "> loss: 0.1086 - distance_1_loss: 0.0269 - distance_2_loss: 0.0388 - distance_3_loss: 0.0182 - val_loss: 0.0891 - val_distance_1_loss: 0.0174 - val_distance_2_loss: 0.0274 - val_distance_3_loss: 0.0200\n",
    "> epochs = 7; learning_rate = 1e-4; Nadam\n",
    "> loss: 0.0721 - distance_1_loss: 0.0216 - distance_2_loss: 0.0200 - distance_3_loss: 0.0133 - val_loss: 0.0553 - val_distance_1_loss: 0.0126 - val_distance_2_loss: 0.0111 - val_distance_3_loss: 0.0145\n",
    "\n",
    "- trainer_v41117x06u02_re04_freezeemb (<- trainer_v41117x06u02_re03_full_newtr): epochs = 51; learning_rate = 1e-4; Nadam;\n",
    "> loss: 0.0533 - distance_1_loss: 0.0174 - distance_2_loss: 0.0168 - distance_3_loss: 0.0087 - val_loss: 0.0347 - val_distance_1_loss: 0.0086 - val_distance_2_loss: 0.0085 - val_distance_3_loss: 0.0072\n",
    "\n",
    "- trainer_v41117x06u03_re05_full (<- trainer_v41117x06u02_re04_freezeemb) <-> v41117x06u03 (Use lean dataset): epochs = 7; learning_rate = 1e-4;\n",
    "> loss: 0.0503 - distance_1_loss: 0.0169 - distance_2_loss: 0.0157 - distance_3_loss: 0.0078 - val_loss: 0.0308 - val_distance_1_loss: 0.0071 - val_distance_2_loss: 0.0071 - val_distance_3_loss: 0.0068\n",
    "```\n",
    "```md\n",
    "- trainer_v4117x07u00_re00_full -> v4117x07u00\n",
    "> Move neutral_distance_scale further to opposite pole; Validating just counts for close_distance_scale cases; Exclude 1 neutral_distance_scale case type from dataset.\n",
    "> Embedding output size of 7; Training process switch regime quicker (fewer epoch number).\n",
    "> epochs = 3; learning_rate = 1e-3; RMSprop\n",
    "> loss: 1.4397 - distance_1_loss: 0.4579 - distance_2_loss: 0.4575 - distance_3_loss: 0.4576 - val_loss: 0.0927 - val_distance_1_loss: 0.0201 - val_distance_2_loss: 0.0111 - val_distance_3_loss: 0.0130\n",
    "\n",
    "- trainer_v4117x07u00_re01_freezeemb (<- trainer_v4117x07u00_re00_full): epochs = 3; learning_rate = 1e-3; RMSprop\n",
    "\n",
    "- trainer_v4117x07u01_re02_full (<- trainer_v4117x07u00_re01_freezeemb) ~ v4117x07u01: epochs = 3; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.0691 - distance_1_loss: 0.0164 - distance_2_loss: 0.0147 - distance_3_loss: 0.0108 - val_loss: 0.0531 - val_distance_1_loss: 0.0092 - val_distance_2_loss: 0.0088 - val_distance_3_loss: 0.0095\n",
    "\n",
    "- trainer_v4117x07u02_re03_full_scratch (<< trainer_v4117x07u01_re02_full) ~ v4117x07u02: epochs = 1; learning_rate = 1e-3; RMSprop\n",
    "> loss: 1.1945 - distance_1_loss: 0.2059 - distance_2_loss: 0.1866 - distance_3_loss: 0.1661 - val_loss: 0.4223 - val_distance_1_loss: 0.0254 - val_distance_2_loss: 0.0313 - val_distance_3_loss: 0.0342\n",
    "\n",
    "- trainer_v4117x07u02_re04_freezeemb (<- trainer_v4117x07u02_re03_full_scratch): epochs = 2; learning_rate = 1e-3; RMSprop\n",
    "> loss: 0.2883 - distance_1_loss: 0.0274 - distance_2_loss: 0.0448 - distance_3_loss: 0.0301 - val_loss: 0.2039 - val_distance_1_loss: 0.0111 - val_distance_2_loss: 0.0141 - val_distance_3_loss: 0.0201\n",
    "\n",
    "- trainer_v4117x07u03_re05_full (<- trainer_v4117x07u02_re04_freezeemb) ~ v4117x07u03: epochs = 1; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.2008 - distance_1_loss: 0.0170 - distance_2_loss: 0.0269 - distance_3_loss: 0.0171 - val_loss: 0.1523 - val_distance_1_loss: 0.0077 - val_distance_2_loss: 0.0097 - val_distance_3_loss: 0.0117\n",
    "> Difference of 2 distances of pair of samples:  [0.034085553, 0.042949438, 0.037845995]\n",
    "\n",
    "*****(terminated)*****\n",
    "- trainer_v4117x07u04_re05_preemb_full_scratch (<< trainer_v4117x07u03_re05_full, <- v4117x07u03) ~ v4117x07u04: epochs = 1; learning_rate = 1e-3; RMSprop\n",
    "> loss: 1.1408 - distance_1_loss: 0.1541 - distance_2_loss: 0.1889 - distance_3_loss: 0.1512 - val_loss: 0.4422 - val_distance_1_loss: 0.0339 - val_distance_2_loss: 0.0338 - val_distance_3_loss: 0.0365\n",
    "> Difference of 2 distances of pair of samples:  [0.06925536, 0.064115696, 0.07904126]\n",
    "\n",
    "- trainer_v4117x07u04_re06_freezeemb (<- trainer_v4117x07u04_re05_preemb_full_scratch): epochs = 2; learning_rate = 1e-3; RMSprop\n",
    "> loss: 0.2639 - distance_1_loss: 0.0247 - distance_2_loss: 0.0314 - distance_3_loss: 0.0250 - val_loss: 0.2090 - val_distance_1_loss: 0.0151 - val_distance_2_loss: 0.0159 - val_distance_3_loss: 0.0211\n",
    "> Difference of 2 distances of pair of samples:  [0.038376033, 0.0489659, 0.059671916]\n",
    "\n",
    "- trainer_v4117x07u05_re07_full (<- trainer_v4117x07u04_re06_freezeemb) ~ v4117x07u05: epochs = 1; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.1843 - distance_1_loss: 0.0159 - distance_2_loss: 0.0178 - distance_3_loss: 0.0133 - val_loss: 0.1620 - val_distance_1_loss: 0.0139 - val_distance_2_loss: 0.0117 - val_distance_3_loss: 0.0164\n",
    "> Difference of 2 distances of pair of samples:  [0.036764663, 0.03671882, 0.04485482]\n",
    "***** * *****\n",
    "\n",
    "- trainer_v4117x07u03_re06_freezeemb (<- trainer_v4117x07u03_re05_full): epochs = 2; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.1585 - distance_1_loss: 0.0147 - distance_2_loss: 0.0249 - distance_3_loss: 0.0142 - val_loss: 0.1219 - val_distance_1_loss: 0.0063 - val_distance_2_loss: 0.0078 - val_distance_3_loss: 0.0085\n",
    "> Difference of 2 distances of pair of samples:  [0.027268814, 0.03409237, 0.03261827]\n",
    "\n",
    "- trainer_v4117x07u04_re07_full (<- trainer_v4117x07u03_re06_freezeemb) ~ v4117x07u04: epochs = 1; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.1349 - distance_1_loss: 0.0132 - distance_2_loss: 0.0201 - distance_3_loss: 0.0129 - val_loss: 0.1004 - val_distance_1_loss: 0.0062 - val_distance_2_loss: 0.0072 - val_distance_3_loss: 0.0074\n",
    "> Difference of 2 distances of pair of samples:  [0.026287805, 0.030200014, 0.030710159]\n",
    "```\n",
    "```md\n",
    "- trainer_v4117x08u00_re00_full_scratch -> v4117x08u00: Reduce comparators size; Reduce decoder dense layers into 7, 5, 3 respectively.\n",
    "> epochs = 1; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.6991 - distance_1_loss: 0.4846 - distance_2_loss: 0.4812 - distance_3_loss: 0.4645 - val_loss: 0.1624 - val_distance_1_loss: 0.0133 - val_distance_2_loss: 0.0159 - val_distance_3_loss: 0.0255\n",
    "> Difference of 2 distances of pair of samples:  [0.049636662, 0.038192183, 0.09868133]\n",
    "\n",
    "- trainer_v4117x08u00_re01_freezeemb (<- trainer_v4117x08u00_re00_full):\n",
    "> epochs = 2; learning_rate = 1e-3; RMSprop\n",
    "> loss: 0.1818 - distance_1_loss: 0.0307 - distance_2_loss: 0.0290 - distance_3_loss: 0.0362 - val_loss: 0.1212 - val_distance_1_loss: 0.0121 - val_distance_2_loss: 0.0082 - val_distance_3_loss: 0.0213\n",
    "> Difference of 2 distances of pair of samples:  [0.061726622, 0.046443712, 0.091107436]\n",
    "\n",
    "- trainer_v4117x08u01_re02_full_scratch (v4117x08u00) -> v4117x08u01:\n",
    "> epochs = 1; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.6805 - distance_1_loss: 0.4756 - distance_2_loss: 0.4731 - distance_3_loss: 0.4614 - val_loss: 0.1552 - val_distance_1_loss: 0.0236 - val_distance_2_loss: 0.0215 - val_distance_3_loss: 0.0138\n",
    "> Difference of 2 distances of pair of samples:  [0.075441495, 0.07104477, 0.054643705]\n",
    "\n",
    "- trainer_v4117x08u01_re03_freezeemb (<- trainer_v4117x08u01_re02_full_scratch):\n",
    "> epochs = 2; learning_rate = 1e-3; RMSprop\n",
    "> loss: 0.1566 - distance_1_loss: 0.0301 - distance_2_loss: 0.0289 - distance_3_loss: 0.0234 - val_loss: 0.1318 - val_distance_1_loss: 0.0197 - val_distance_2_loss: 0.0223 - val_distance_3_loss: 0.0223\n",
    "> Difference of 2 distances of pair of samples:  [0.08107499, 0.0743386, 0.08680491]\n",
    "\n",
    "- trainer_v4117x08u02_re04_full (trainer_v4117x08u01_re03_freezeemb) -> v4117x08u02:\n",
    "> epochs = 1; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.1209 - distance_1_loss: 0.0197 - distance_2_loss: 0.0219 - distance_3_loss: 0.0212 - val_loss: 0.0801 - val_distance_1_loss: 0.0092 - val_distance_2_loss: 0.0095 - val_distance_3_loss: 0.0112\n",
    "> Difference of 2 distances of pair of samples:  [0.050537713, 0.048360188, 0.0647546]\n",
    "\n",
    "- trainer_v4117x08u02_re04_freezeemb (<- trainer_v4117x08u02_re04_full):\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.0832 - distance_1_loss: 0.0150 - distance_2_loss: 0.0152 - distance_3_loss: 0.0128 - val_loss: 0.0628 - val_distance_1_loss: 0.0077 - val_distance_2_loss: 0.0077 - val_distance_3_loss: 0.0088\n",
    "> Difference of 2 distances of pair of samples:  [0.040630516, 0.03862795, 0.052181438]\n",
    "\n",
    "- trainer_v4117x08u03_re05_full (<- trainer_v4117x08u02_re04_freezeemb) -> v4117x08u03:\n",
    "> epochs = 1; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0746 - distance_1_loss: 0.0135 - distance_2_loss: 0.0138 - distance_3_loss: 0.0121 - val_loss: 0.0532 - val_distance_1_loss: 0.0066 - val_distance_2_loss: 0.0069 - val_distance_3_loss: 0.0076\n",
    "> Difference of 2 distances of pair of samples:  [0.031054916, 0.033531073, 0.044989407]\n",
    "\n",
    "- trainer_v4117x08u03_re06_freezeemb (<- trainer_v4117x08u03_re05_full):\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop\n",
    "> loss: 0.0622 - distance_1_loss: 0.0126 - distance_2_loss: 0.0125 - distance_3_loss: 0.0100 - val_loss: 0.0463 - val_distance_1_loss: 0.0064 - val_distance_2_loss: 0.0066 - val_distance_3_loss: 0.0071\n",
    "> Difference of 2 distances of pair of samples:  [0.029187953, 0.030912718, 0.044271752]\n",
    "\n",
    "- trainer_v4117x08u04_re07_full (<- trainer_v4117x08u03_re06_freezeemb) -> v4117x08u04:\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0525 - distance_1_loss: 0.0117 - distance_2_loss: 0.0115 - distance_3_loss: 0.0096 - val_loss: 0.0377 - val_distance_1_loss: 0.0061 - val_distance_2_loss: 0.0064 - val_distance_3_loss: 0.0064\n",
    "> Difference of 2 distances of pair of samples:  [0.025891265, 0.027960178, 0.03889767]\n",
    "\n",
    "- trainer_v4117x08u04_re08_freezeemb_scratch_newtr (<- v4117x08u04):\n",
    "> epochs = 3; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.4653 - distance_1_loss: 0.4443 - distance_2_loss: 0.4436 - distance_3_loss: 0.4386 - val_loss: 0.1518 - val_distance_1_loss: 0.0146 - val_distance_2_loss: 0.0157 - val_distance_3_loss: 0.0148\n",
    "> Difference of 2 distances of pair of samples:  [0.026055524, 0.050250757, 0.040580038]\n",
    "\n",
    "- trainer_v4117x08u05_re09_full (<- trainer_v4117x08u04_re08_freezeemb_scratch_newtr) -> v4117x08u05:\n",
    "> epochs = 1; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.1710 - distance_1_loss: 0.0296 - distance_2_loss: 0.0330 - distance_3_loss: 0.0259 - val_loss: 0.1021 - val_distance_1_loss: 0.0126 - val_distance_2_loss: 0.0113 - val_distance_3_loss: 0.0140\n",
    "> Difference of 2 distances of pair of samples:  [0.024734234, 0.03689484, 0.0431055]\n",
    "\n",
    "- trainer_v4117x08u05_re10_freezeemb (<- trainer_v4117x08u05_re09_full):\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0969 - distance_1_loss: 0.0152 - distance_2_loss: 0.0183 - distance_3_loss: 0.0129 - val_loss: 0.0766 - val_distance_1_loss: 0.0091 - val_distance_2_loss: 0.0088 - val_distance_3_loss: 0.0107\n",
    "> Difference of 2 distances of pair of samples:  [0.0193223, 0.026459107, 0.032876227]\n",
    "\n",
    "- trainer_v4117x08u06_re11_full (<- trainer_v4117x08u05_re10_freezeemb) -> v4117x08u06:\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0629 - distance_1_loss: 0.0125 - distance_2_loss: 0.0128 - distance_3_loss: 0.0096 - val_loss: 0.0457 - val_distance_1_loss: 0.0069 - val_distance_2_loss: 0.0068 - val_distance_3_loss: 0.0063\n",
    "> Difference of 2 distances of pair of samples:  [0.018687766, 0.021196494, 0.024526516]\n",
    "\n",
    "- trainer_v4117x08u06_re12_freezeemb_scratch_newtr (<- v4117x08u06):\n",
    "> epochs = 5; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.3780 - distance_1_loss: 0.4409 - distance_2_loss: 0.4373 - distance_3_loss: 0.4362 - val_loss: 0.0938 - val_distance_1_loss: 0.0123 - val_distance_2_loss: 0.0154 - val_distance_3_loss: 0.0126\n",
    "> Difference of 2 distances of pair of samples:  [0.044141825, 0.061190974, 0.059907958]\n",
    "\n",
    "- trainer_v4117x08u07_re13_full (<- trainer_v4117x08u06_re12_freezeemb_scratch_newtr) -> v4117x08u07:\n",
    "> epochs = 1; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.1272 - distance_1_loss: 0.0301 - distance_2_loss: 0.0279 - distance_3_loss: 0.0230 - val_loss: 0.0753 - val_distance_1_loss: 0.0128 - val_distance_2_loss: 0.0102 - val_distance_3_loss: 0.0124\n",
    "> Difference of 2 distances of pair of samples:  [0.04246903, 0.035525884, 0.0653189]\n",
    "\n",
    "- trainer_v4117x08u07_re14_freezeemb (<- trainer_v4117x08u07_re13_full):\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0759 - distance_1_loss: 0.0168 - distance_2_loss: 0.0135 - distance_3_loss: 0.0130 - val_loss: 0.0528 - val_distance_1_loss: 0.0069 - val_distance_2_loss: 0.0068 - val_distance_3_loss: 0.0078\n",
    "> Difference of 2 distances of pair of samples:  [0.028895056, 0.02595199, 0.04808144]\n",
    "\n",
    "- trainer_v4117x08u08_re15_full (<- trainer_v4117x08u07_re14_freezeemb) -> v4117x08u08:\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0548 - distance_1_loss: 0.0131 - distance_2_loss: 0.0120 - distance_3_loss: 0.0091 - val_loss: 0.0373 - val_distance_1_loss: 0.0058 - val_distance_2_loss: 0.0061 - val_distance_3_loss: 0.0060\n",
    "> Difference of 2 distances of pair of samples:  [0.017690765, 0.016607057, 0.03614808]\n",
    "\n",
    "- trainer_v4117x08u08_re16_freezeemb (<- trainer_v4117x08u08_re15_full):\n",
    "> epochs = 5; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0480 - distance_1_loss: 0.0128 - distance_2_loss: 0.0109 - distance_3_loss: 0.0081 - val_loss: 0.0326 - val_distance_1_loss: 0.0055 - val_distance_2_loss: 0.0060 - val_distance_3_loss: 0.0052\n",
    "> Difference of 2 distances of pair of samples:  [0.014509545, 0.017023578, 0.023978848]\n",
    "\n",
    "- trainer_v4117x08u09_re17_full (<- trainer_v4117x08u08_re16_freezeemb) -> v4117x08u09:\n",
    "> epochs = 3; learning_rate = 1e-4; RMSprop;\n",
    "> val_loss: 0.0288 - val_distance_1_loss: 0.0054 - val_distance_2_loss: 0.0058 - val_distance_3_loss: 0.0049\n",
    "> Difference of 2 distances of pair of samples:  [0.016934907, 0.018039314, 0.018901136]\n",
    "```\n",
    "```md\n",
    "- trainer_v4117x09u00_re00_full_scratch (new structure of convs and rnns) -> v4117x09u00:\n",
    "> epochs = 3; learning_rate = 1e-3; RMSprop;\n",
    "> epochs = 7; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 1.5611 - distance_1_loss: 0.5059 - distance_2_loss: 0.5059 - distance_3_loss: 0.5056 - val_loss: 1.6297 - val_distance_1_loss: 0.5290 - val_distance_2_loss: 0.5294 - val_distance_3_loss: 0.5286\n",
    "> Difference of 2 distances of pair of samples:  [0.021286268, 0.02132288, 0.022075232]\n",
    "\n",
    "- trainer_v4117x09u01_re01_full_scratch (<- trainer_v4117x09u00_re00_full_scratch) -> v4117x09u01:\n",
    "> grand epochs = 31; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0473 - distance_1_loss: 0.0047 - distance_2_loss: 0.0045 - distance_3_loss: 0.0039 - val_loss: 0.0414 - val_distance_1_loss: 0.0029 - val_distance_2_loss: 0.0025 - val_distance_3_loss: 0.0020\n",
    "> Difference of 2 distances of pair of samples:  [0.06160318, 0.047427166, 0.055081192]\n",
    "\n",
    "- trainer_v4117x09u01_re02_freezeemb_scratch_newtr (<- v4117x09u01):\n",
    "> epochs = 3; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.7542 - distance_1_loss: 0.5319 - distance_2_loss: 0.5316 - distance_3_loss: 0.5376 - val_loss: 1.6887 - val_distance_1_loss: 0.5161 - val_distance_2_loss: 0.5131 - val_distance_3_loss: 0.5143\n",
    "> Difference of 2 distances of pair of samples:  [0.067706525, 0.051629826, 0.09510795]\n",
    "\n",
    "- trainer_v4117x09u02_re03_full (<- trainer_v4117x09u01_re02_freezeemb_scratch_newtr) -> v4117x09u02:\n",
    "> epochs = 3; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.2062 - distance_1_loss: 0.0354 - distance_2_loss: 0.0368 - distance_3_loss: 0.0344 - val_loss: 0.1748 - val_distance_1_loss: 0.0267 - val_distance_2_loss: 0.0270 - val_distance_3_loss: 0.0281\n",
    "> Difference of 2 distances of pair of samples:  [0.14084293, 0.1417937, 0.14526837]\n",
    "\n",
    "- trainer_v4117x09u03_re04_tictoc (<- trainer_v4117x09u02_re03_full) -> v4117x09u03:\n",
    "> grand epochs = 11; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0894 - distance_1_loss: 0.0050 - distance_2_loss: 0.0059 - distance_3_loss: 0.0054 - val_loss: 0.0906 - val_distance_1_loss: 0.0056 - val_distance_2_loss: 0.0062 - val_distance_3_loss: 0.0066\n",
    "> Difference of 2 distances of pair of samples:  [0.057340298, 0.060244925, 0.061446954]\n",
    "```\n",
    "```md\n",
    "- trainer_v411x10u00_re00_full_scratch_newtr  -> v411x10u00:\n",
    "> epochs = 23; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.8648 - distance_1_loss: 0.2874 - distance_2_loss: 0.2832 - distance_3_loss: 0.2821 - val_loss: 0.9089 - val_distance_1_loss: 0.2983 - val_distance_2_loss: 0.3018 - val_distance_3_loss: 0.2970\n",
    "> Divergence of 2 distances of pair of samples:  [0.07944203, 0.0715782, 0.06529673]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.96494114, 0.951791, 0.9579267]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.96239793, 0.95012164, 0.9563638]\n",
    "\n",
    "- trainer_v411x10u00_re01_freezeemb_scratch_newtr (<- v411x10u00):\n",
    "> epochs = 31; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.8968 - distance_1_loss: 0.2872 - distance_2_loss: 0.2878 - distance_3_loss: 0.2849 - val_loss: 0.9144 - val_distance_1_loss: 0.2921 - val_distance_2_loss: 0.2947 - val_distance_3_loss: 0.2915\n",
    "> Divergence of 2 distances of pair of samples:  [0.054365903, 0.061435238, 0.05195756]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9682776, 0.9652071, 0.9668705]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.96731555, 0.96434784, 0.9662962]\n",
    "\n",
    "- trainer_v411x10u01_re02_tictoc (<- trainer_v411x10u00_re01_freezeemb_scratch_newtr) -> v411x10u01:\n",
    "> epochs = 11; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0427 - distance_1_loss: 0.0033 - distance_2_loss: 0.0035 - distance_3_loss: 0.0030 - val_loss: 0.0379 - val_distance_1_loss: 0.0013 - val_distance_2_loss: 0.0017 - val_distance_3_loss: 0.0021\n",
    "> Divergence of 2 distances of pair of samples:  [0.021087246, 0.025890617, 0.026460841]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9642659, 0.96205664, 0.95877695]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9642279, 0.9617481, 0.95837444]\n",
    "\n",
    "- trainer_v411x10u01_re03_freezeemb_scratch_newtr (<- v411x10u01):\n",
    "> epochs = 33; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.8948 - distance_1_loss: 0.2887 - distance_2_loss: 0.2863 - distance_3_loss: 0.2845 - val_loss: 0.9063 - val_distance_1_loss: 0.2914 - val_distance_2_loss: 0.2891 - val_distance_3_loss: 0.2913\n",
    "> Divergence of 2 distances of pair of samples:  [0.036684286, 0.03464032, 0.031166082]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.97010344, 0.97128147, 0.9670318]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9697173, 0.971231, 0.96695256]\n",
    "\n",
    "- trainer_v411x10u02_re04_tictoc (<- trainer_v411x10u01_re03_freezeemb_scratch_newtr) -> v411x10u02:\n",
    "> epochs = 7; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0419 - distance_1_loss: 0.0033 - distance_2_loss: 0.0037 - distance_3_loss: 0.0029 - val_loss: 0.0381 - val_distance_1_loss: 0.0018 - val_distance_2_loss: 0.0024 - val_distance_3_loss: 0.0021\n",
    "> Divergence of 2 distances of pair of samples:  [0.027256358, 0.029980812, 0.027633287]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9704229, 0.9704831, 0.9670166]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9707592, 0.97048724, 0.96691155]\n",
    "\n",
    "- trainer_v411x10u02_re05_freezeemb_scratch_newtr (<- v411x10u02):\n",
    "> epochs = 17; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.9521 - distance_1_loss: 0.2890 - distance_2_loss: 0.2897 - distance_3_loss: 0.2878 - val_loss: 0.9869 - val_distance_1_loss: 0.3032 - val_distance_2_loss: 0.3019 - val_distance_3_loss: 0.2996\n",
    "> Divergence of 2 distances of pair of samples:  [0.08110849, 0.07405919, 0.07383506]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.96304977, 0.96587664, 0.9675462]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.96230036, 0.96467155, 0.96672916]\n",
    "\n",
    "- trainer_v411x10u03_re06_tictoc (<- trainer_v411x10u02_re05_freezeemb_scratch_newtr) -> v411x10u03:\n",
    "> epochs = 11; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0831 - distance_1_loss: 0.0038 - distance_2_loss: 0.0039 - distance_3_loss: 0.0040 - val_loss: 0.0814 - val_distance_1_loss: 0.0031 - val_distance_2_loss: 0.0032 - val_distance_3_loss: 0.0042o\n",
    "> Divergence of 2 distances of pair of samples:  [0.038884707, 0.03850267, 0.044099044]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9535243, 0.9563325, 0.9538221]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9537119, 0.9563284, 0.9538446]\n",
    "```\n",
    "```md\n",
    "- trainer_v5x10u00_re00_full_scratch_newtr  -> v5x10u00:\n",
    "> epochs = 13; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.8725 - distance_1_loss: 0.2889 - distance_2_loss: 0.2834 - distance_3_loss: 0.2828 - val_loss: 0.9347 - val_distance_1_loss: 0.3027 - val_distance_2_loss: 0.3127 - val_distance_3_loss: 0.3028\n",
    "> Divergence of 2 distances of pair of samples:  [0.06955675, 0.069537304, 0.065454386]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.95179355, 0.9245245, 0.94187266]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9502538, 0.92379713, 0.9407532]\n",
    "\n",
    "- trainer_v5x10u00_re01_freezeemb_scratch_newtr (<- v5x10u00):\n",
    "> epochs = 17; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.9727 - distance_1_loss: 0.2981 - distance_2_loss: 0.2981 - distance_3_loss: 0.2988 - val_loss: 0.9679 - val_distance_1_loss: 0.2960 - val_distance_2_loss: 0.2978 - val_distance_3_loss: 0.2993\n",
    "> Divergence of 2 distances of pair of samples:  [0.052788354, 0.05439594, 0.05105939]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9587563, 0.9511156, 0.9499051]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9591355, 0.9512607, 0.95055836]\n",
    "\n",
    "- trainer_v5x10u01_re02_tictoc (<- trainer_v5x10u00_re01_freezeemb_scratch_newtr) -> v5x10u01:\n",
    "> epochs = 7; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 0.0823 - distance_1_loss: 0.0042 - distance_2_loss: 0.0044 - distance_3_loss: 0.0056 - val_loss: 0.0772 - val_distance_1_loss: 0.0025 - val_distance_2_loss: 0.0026 - val_distance_3_loss: 0.0045\n",
    "> Divergence of 2 distances of pair of samples:  [0.03146939, 0.03593482, 0.036283962]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9630693, 0.95593, 0.9531112]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9631203, 0.9560219, 0.9525938]\n",
    "\n",
    "- trainer_v5x10u01_re02_freezeemb_scratch_newtr (<- v5x10u01):\n",
    "> epochs = 7; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.2672 - distance_1_loss: 0.3479 - distance_2_loss: 0.3680 - distance_3_loss: 0.3697 - val_loss: 1.1989 - val_distance_1_loss: 0.3297 - val_distance_2_loss: 0.3464 - val_distance_3_loss: 0.3507\n",
    "> Divergence of 2 distances of pair of samples:  [0.1353924, 0.15888196, 0.12628779]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.94780463, 0.9214602, 0.9055155]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9483188, 0.92170423, 0.9056003]\n",
    "\n",
    "- trainer_v5x10u02_re03_full (<- trainer_v5x10u01_re02_freezeemb_scratch_newtr) -> v5x10u02:\n",
    "> epochs = 5; learning_rate = 1e-3; RMSprop;\n",
    "> loss: 1.0051 - distance_1_loss: 0.3025 - distance_2_loss: 0.3022 - distance_3_loss: 0.3019 - val_loss: 0.9648 - val_distance_1_loss: 0.2910 - val_distance_2_loss: 0.2957 - val_distance_3_loss: 0.2905\n",
    "> Divergence of 2 distances of pair of samples: [0.092219986, 0.09734352, 0.083635576]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.9757183, 0.96721876, 0.9754189]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.97595894, 0.9679688, 0.9758508]\n",
    "\n",
    "- trainer_v5x10u03_re04_tictoc (<- trainer_v5x10u02_re03_full) -> v5x10u03:\n",
    "> epochs = 97; learning_rate = 1e-4; RMSprop;\n",
    "> loss: 0.0479 - distance_1_loss: 0.0055 - distance_2_loss: 0.0053 - distance_3_loss: 0.0039 - val_loss: 0.0420 - val_distance_1_loss: 0.0033 - val_distance_2_loss: 0.0033 - val_distance_3_loss: 0.0023\n",
    "> Divergence of 2 distances of pair of samples:  [0.080105916, 0.07581319, 0.05385025]\n",
    "> (pred1: input_1 vs input_2) Distance of 2 different samples:  [0.97792566, 0.96241385, 0.9666872]\n",
    "> (pred2: input_2 vs input_1) Distance of 2 different samples:  [0.9787123, 0.9633786, 0.96718156]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md,ipynb",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
